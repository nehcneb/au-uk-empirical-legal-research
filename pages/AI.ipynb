{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28405948-0a19-4859-8a21-c429619460e3",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import os\n",
    "import io\n",
    "import openpyxl\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "#from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "#PandasAI\n",
    "#from dotenv import load _dotenv\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai import Agent\n",
    "from pandasai.llm import BambooLLM\n",
    "from pandasai.llm.openai import OpenAI\n",
    "import pandasai as pai\n",
    "from pandasai.responses.streamlit_response import StreamlitResponse\n",
    "from pandasai.helpers.openai_info import get_openai_callback\n",
    "\n",
    "#Excel\n",
    "from io import BytesIO\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03334c90-6aba-4b83-9dab-300fdaa10115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Whether users are allowed to use their account\n",
    "from extra_functions import own_account_allowed\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "417a9dd8-c34c-4148-9118-c360cc65f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "284e2004-7b04-4dbf-b135-ab29ebf0d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today and time\n",
    "today_in_nums = str(datetime.now())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8157e0f1-5807-4c93-b9db-13b3cf483b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for saving responses and results\n",
    "def convert_df_to_json(df):\n",
    "    return df.to_json(orient = 'split', compression = 'infer')\n",
    "\n",
    "def convert_df_to_csv(df):\n",
    "   return df.to_csv(index=False).encode('utf-8')\n",
    "\n",
    "#Excel metadata\n",
    "excel_author = 'The Empirical Legal Research Kickstarter'\n",
    "excel_description = 'A 2022 University of Sydney Research Accelerator (SOAR) Prize partially funded the development of the Empirical Legal Research Kickstarter, which generated this spreadsheet.'\n",
    "\n",
    "def convert_df_to_excel(df):\n",
    "    output = BytesIO()\n",
    "    writer = pd.ExcelWriter(output, engine='xlsxwriter', engine_kwargs={'options': {'strings_to_urls': False}})\n",
    "    df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    workbook = writer.book\n",
    "    workbook.set_properties({\"author\": excel_author, \"comments\": excel_description})\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "#    format1 = workbook.add_format({'num_format': '0.00'}) \n",
    "    worksheet.set_column('A:A', None)#, format1)  \n",
    "    writer.save()\n",
    "    processed_data = output.getvalue()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0c9ca-ef4f-4b05-80ab-7b4a88073db7",
   "metadata": {},
   "source": [
    "# AI model and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c49d98-4da0-4d3a-a3a1-f096a07bc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check validity of API key\n",
    "\n",
    "def is_api_key_valid(key_to_check):\n",
    "    openai.api_key = key_to_check\n",
    "    \n",
    "    try:\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[{\"role\": \"user\", \"content\": 'Who is Taylor Swift?'}], \n",
    "            max_tokens = 5\n",
    "        )\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#Module, costs and upperbounds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a55d2072-420d-4cb3-a754-d778d817468e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 09:22:52.212 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "#Initialize API key\n",
    "\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Initialize key validity check\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff680153-f234-4aff-ac74-9894489db347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default choice of AI\n",
    "\n",
    "default_ai = 'GPT'\n",
    "#default_ai = 'BambooLLM'\n",
    "\n",
    "if 'ai_choice' not in st.session_state:\n",
    "    st.session_state['ai_choice'] = default_ai\n",
    "\n",
    "ai_list_raw = ['BambooLLM', 'GPT']\n",
    "\n",
    "ai_list = ['0', '1']\n",
    "\n",
    "for ai in ai_list_raw:\n",
    "    if ai == default_ai:\n",
    "        ai_list[0] = ai\n",
    "    else:\n",
    "        ai_list[1] = ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfdf1922-5388-4b0e-8249-f89070ec88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The choice of model function\n",
    "\n",
    "#API_key = st.session_state.gpt_api_key\n",
    "\n",
    "def ai_model_setting(ai_choice, key, gpt_model_choice):\n",
    "\n",
    "    if gpt_model_choice == 'gpt-4-turbo':\n",
    "        gpt_model_choice = 'gpt-4-0125-preview'\n",
    "    \n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "\n",
    "        llm = OpenAI(api_token=key, model = gpt_model_choice)\n",
    "\n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "\n",
    "        llm = BambooLLM(api_key = st.secrets[\"pandasai\"][\"bamboollm_api_key\"])\n",
    "\n",
    "    return llm\n",
    "        \n",
    "#llm = OpenAI(api_token=st.secrets[\"openai\"][\"gpt_api_key\"], model = 'gpt-3.5-turbo-0125')\n",
    "\n",
    "#llm = BambooLLM(api_key=st.secrets[\"pandasai\"][\"bamboollm_api_key\"])\n",
    "\n",
    "#if 'openai_key' not in st.session_state:\n",
    "#    st.session_state.openai_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "def ai_model_printing(ai_choice, gpt_model_choice):\n",
    "\n",
    "    output = 'BambooLLM'\n",
    "\n",
    "    if ai_choice == 'GPT':\n",
    "        \n",
    "        output = 'GPT model ' + gpt_model_choice\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50dc9d22-f2d0-4732-aed0-cc10a87a58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI model descript\n",
    "#NOT in use\n",
    "\n",
    "def ai_model_description(ai_choice):\n",
    "    \n",
    "    model_description = ''\n",
    "    \n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "    \n",
    "        model_description = \"GPT model gpt-3.5-turbo-0125 is selected by default. This model can explain its reasoning.\"\n",
    "    \n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "    \n",
    "        model_description = 'BambooLLM is selected by default. This model is developed by PandasAI with data analysis in mind (see https://docs.pandas-ai.com/en/stable/).'\n",
    "\n",
    "    return model_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3312aa5-ad83-46cb-ac5d-733a5bcea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent description\n",
    "\n",
    "default_agent_description = 'You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. Each column starting with \"GPT question\" was previously entered by you. You will be given questions or instructions about the spreadsheet.'\n",
    "\n",
    "#visualisation = ' Everytime you are given a question or an instruction, try to provide the code to visualise your answer using Matplotlib.'\n",
    "\n",
    "visualisation = ' If you are asked to visualise your answer, try to provide the code for visualisation using Matplotlib.'\n",
    "\n",
    "agent_description = default_agent_description + visualisation\n",
    "#If want to minimize technicality\n",
    "#agent_description = 'You are a data analyst. Your main goal is to help non-technical users to clean, analyse and visualise data. You will be given a spreadsheet of data. Each column starting with \"GPT question\" was previously entered by you. You will be given questions or instructions about the spreadsheet.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540b2dd-ebae-44b3-b351-00120d549019",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd266ac0-2bde-4537-a686-ef4d8c2bd161",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "724c9ac2-aec5-43bb-ac9f-364acf96a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse hyperlink display\n",
    "\n",
    "def link_heading_picker(df):\n",
    "    y = ''\n",
    "    for x in df.columns:\n",
    "        if 'Hyperlink' in str(x):\n",
    "            y = x\n",
    "    return y\n",
    "\n",
    "def reverse_link(x):\n",
    "    value = str(x).replace('=HYPERLINK(\"', '').replace('\")', '')\n",
    "    return value\n",
    "\n",
    "def convert_links_column(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    link_header = link_heading_picker(df)\n",
    "    new_df[link_header] = df[link_header].apply(reverse_link)\n",
    "\n",
    "    return new_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "295070a7-e023-46ec-b28d-87a503ec1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NSW, function for columns which are lists to strings:\n",
    "\n",
    "list_columns = ['Catchwords', 'Legislation cited', 'Cases cited', 'Texts cited', 'Parties', 'Representation', 'Decision under appeal'] \n",
    "\n",
    "#'Decision under appeal' is a dictionary but the values of some keys are lists\n",
    "\n",
    "def nsw_df_list_columns(df):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    for heading in list_columns:\n",
    "        if heading in df.columns:\n",
    "            df_new[heading] = df[heading].astype(str)\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58690ed3-da87-4880-bbf6-a06b94bb69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache_except_validation():\n",
    "    keys = list(st.session_state.keys())\n",
    "    for key in keys:\n",
    "        if key != 'gpt_api_key_validity': #Remove this line if wants to clear key validation as well\n",
    "            st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a2392-d430-4aec-ae92-ccd440ce76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_most_cache():\n",
    "    keys = list(st.session_state.keys())\n",
    "    #These are the keys to KEEP upon clearing\n",
    "    for key_to_keep in ['gpt_api_key_validity', 'messages', 'df_uploaded_key', 'page_from']: \n",
    "        try:\n",
    "            keys.remove('key_to_keep')\n",
    "        except:\n",
    "            print(f\"No {'key_to_keep'} in session state.\")\n",
    "\n",
    "    for key in keys:\n",
    "        st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73bd94-681c-455f-82dc-a9f7d77dbfd9",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d9a6808-56f8-4e87-a5df-f7be2218bdab",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default maximum number of instructions per thread is 10.\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"instructions_bound\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:398\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:443\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_session_state()[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:91\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:400\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"instructions_bound\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 60\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m#Initialize instructions counter\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction_left\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m---> 60\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstruction_left\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39minstructions_bound\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m#Initialize default show code status\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplain_status\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"instructions_bound\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#Initialize default values\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "#Initalize page_from:\n",
    "if 'page_from' not in st.session_state:\n",
    "    st.session_state['page_from'] = 'Home.py'\n",
    "\n",
    "#Initalize df_individual_output:\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = []\n",
    "\n",
    "#Initalize df_uploaded:\n",
    "if 'df_uploaded' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_uploaded'] = []\n",
    "\n",
    "#Initalize df_uploaded_key\n",
    "if \"df_uploaded_key\" not in st.session_state:\n",
    "    st.session_state[\"df_uploaded_key\"] = 0\n",
    "\n",
    "#Initalize df_produced:\n",
    "if 'df_produced' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_produced'] = []\n",
    "\n",
    "#Initalize df_to_analyse:\n",
    "if 'df_to_analyse' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_to_analyse'] = []\n",
    "\n",
    "#Initalize edited_df:\n",
    "if 'edited_df' not in st.session_state:\n",
    "\n",
    "    st.session_state['edited_df'] = []\n",
    "\n",
    "#Initalize response:\n",
    "if 'response' not in st.session_state:\n",
    "\n",
    "    st.session_state['response'] = ''\n",
    "\n",
    "#Initialize default instructions bound\n",
    "\n",
    "default_instructions_bound = 10\n",
    "\n",
    "print(f\"The default maximum number of instructions per thread is {default_instructions_bound}.\\n\")\n",
    "\n",
    "#Initialize instructions cap\n",
    "\n",
    "if 'instructions_bound' not in st.session_state:\n",
    "    st.session_state['instructions_bound'] = default_instructions_bound\n",
    "\n",
    "#Initialize instructions counter\n",
    "\n",
    "if 'instruction_left' not in st.session_state:\n",
    "\n",
    "    st.session_state[\"instruction_left\"] = default_instructions_bound\n",
    "\n",
    "#Initialize default show code status\n",
    "\n",
    "if 'explain_status' not in st.session_state:\n",
    "    st.session_state[\"explain_status\"] = False\n",
    "\n",
    "#Initialize default own account status\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "#Initilize default gpt model\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "#Initialize default gpt enhacement status\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state[\"gpt_enhancement_entry\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9b477-367e-437b-920a-9fe66e02c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd1560-b1c6-4f36-82b2-60120a02116b",
   "metadata": {},
   "source": [
    "## Form before choosing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a26f9-5092-42cc-a64c-de2415bf5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.button('RETURN to previous page'):\n",
    "\n",
    "    st.switch_page(st.session_state.page_from)\n",
    "\n",
    "st.header(\"You have chosen to :blue[analyse your spreadsheet].\")\n",
    "\n",
    "#Open spreadsheet and personal details\n",
    "if len(st.session_state.df_individual_output) > 0:\n",
    "\n",
    "    #st.session_state['df_to_analyse'] = st.session_state.df_individual_output\n",
    "\n",
    "    st.success('Your spreadsheet has been imported. Please scroll down.')\n",
    "\n",
    "else: #if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.markdown(\"\"\"**:green[Please upload a spreadsheet.]** Supported formats: CSV, XLSX, JSON.\"\"\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"You may upload a spreadsheet generated by the Empirical Legal Research Kickstarter. The CSV format is preferred.\", \n",
    "                                     type=['csv', 'xlsx', 'json'], \n",
    "                                     accept_multiple_files=False, \n",
    "                                     key = st.session_state[\"df_uploaded_key\"])\n",
    "\n",
    "    if uploaded_file:\n",
    "        \n",
    "        #Get uploaded file extension\n",
    "        extension = uploaded_file.name.split('.')[-1].lower()\n",
    "        \n",
    "        if extension == 'csv':\n",
    "            df_uploaded = pd.read_csv(uploaded_file)\n",
    "    \n",
    "        if extension == 'xlsx':\n",
    "            df_uploaded = pd.read_excel(uploaded_file)\n",
    "    \n",
    "        if extension == 'json':\n",
    "            df_uploaded = pd.read_json(uploaded_file, orient= 'split')\n",
    "\n",
    "        st.session_state.df_uploaded = df_uploaded\n",
    "        \n",
    "        #st.session_state[\"df_to_analyse\"]=df_uploaded\n",
    "\n",
    "        st.success('Your spreadsheet has been imported. Please scroll down.')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93d23-fae0-4163-a92f-c69517c7ea33",
   "metadata": {},
   "source": [
    "## Choice of AI and GPT account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ab979-ca91-4c8b-bd0a-467aa5600f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.subheader('Choose an AI')\n",
    "\n",
    "st.markdown(\"\"\"Please choose an AI to help with data cleaning, analysis and visualisation.\n",
    "\"\"\")\n",
    "\n",
    "ai_choice = st.selectbox(label = f'{default_ai} is selected by default.', options = ai_list, index=0)\n",
    "\n",
    "if ai_choice != st.session_state.ai_choice:\n",
    "    pai.clear_cache()\n",
    "    st.session_state['ai_choice'] = ai_choice\n",
    "\n",
    "st.markdown(\"\"\"GPT can explain its reasoning. BambooLLM is developed with data analysis in mind (see https://docs.pandas-ai.com/en/stable/).\"\"\")\n",
    "\n",
    "if st.toggle('See the instruction given to the chosen AI'):\n",
    "    st.write(f\"*{agent_description}*\")\n",
    "\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "\n",
    "    if st.session_state.ai_choice == 'GPT':\n",
    "    \n",
    "        st.subheader(':orange[Enhance program capabilities]')\n",
    "        \n",
    "        st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of instructions to process? You can do so with your own GPT account.\n",
    "        \"\"\")\n",
    "        \n",
    "        own_account_entry = st.toggle('Use my own GPT account')\n",
    "        \n",
    "        if own_account_entry:\n",
    "            #Reset AI first\n",
    "            pai.clear_cache()\n",
    "            \n",
    "            st.session_state[\"own_account\"] = True\n",
    "        \n",
    "            st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage at https://platform.openai.com/signup. You can then find your API key at https://platform.openai.com/api-keys.\n",
    "        \"\"\")\n",
    "                \n",
    "            name_entry = st.text_input(label = \"Your name\", value = st.session_state.name_entry)\n",
    "    \n",
    "            st.session_state['name_entry'] = name_entry\n",
    "            \n",
    "            email_entry = st.text_input(label = \"Your email address\", value = st.session_state.email_entry)\n",
    "            \n",
    "            gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.gpt_api_key_entry)\n",
    "            \n",
    "            valdity_check = st.button('VALIDATE your API key')\n",
    "        \n",
    "            if valdity_check:\n",
    "                \n",
    "                api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                        \n",
    "                if api_key_valid == False:\n",
    "                    st.session_state['gpt_api_key_validity'] = False\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    \n",
    "                else:\n",
    "                    st.session_state['gpt_api_key_validity'] = True\n",
    "                    st.success('Your API key is valid.')\n",
    "        \n",
    "            st.markdown(\"\"\"**:green[You can use the latest version of GPT model (gpt-4-turbo),]** which is :red[20 times more expensive, per character] than the default model (gpt-3.5-turbo) which you can use for free.\"\"\")  \n",
    "            \n",
    "            gpt_enhancement_entry = st.checkbox('Use the latest GPT model', value = False)\n",
    "        \n",
    "            st.caption('For more on pricing for different GPT models, please see https://openai.com/api/pricing.')\n",
    "            \n",
    "            if gpt_enhancement_entry == True:\n",
    "            \n",
    "                st.session_state.gpt_model = \"gpt-4-turbo\"\n",
    "                st.session_state.gpt_enhancement_entry = True\n",
    "    \n",
    "            else:\n",
    "                \n",
    "                st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "                st.session_state.gpt_enhancement_entry = False\n",
    "            \n",
    "            st.write(f'**:green[You can remove the cap on the number of instructions to process.]** The default cap is {default_instructions_bound}.')\n",
    "        \n",
    "            #st.session_state.instructions_bound = round(st.number_input(label = 'Enter the maximum number of instructions', min_value=1, value=default_instructions_bound))\n",
    "        \n",
    "            drop_instructions_bound = st.button('REMOVE the cap on the number of instructions')\n",
    "        \n",
    "            if drop_instructions_bound:\n",
    "        \n",
    "                st.session_state.instructions_bound = 999\n",
    "                st.session_state.instruction_left = 999\n",
    "        \n",
    "            #st.session_state.instruction_left = st.session_state.instructions_bound\n",
    "        \n",
    "        else:\n",
    "            st.session_state[\"own_account\"] = False\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "        \n",
    "            st.session_state.instructions_bound = default_instructions_bound\n",
    "        \n",
    "            st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "            print('User GPT API key not entered. Using own API key instead.')\n",
    "    \n",
    "    else:\n",
    "        st.session_state[\"own_account\"] = False\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "        #st.session_state.ai_choice = default_ai\n",
    "    \n",
    "else:\n",
    "    print('Users are NOT allowed to use their own accounts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d28de1-dabf-4c0f-b1c6-f46df81fd978",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b58031-d08a-4cfd-969a-c57f492dcf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.subheader(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running the Empirical Legal Research Kickstarter, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb7207-52a4-47e7-8eb1-b89cb1cece23",
   "metadata": {},
   "source": [
    "## Spreadsheet analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752865b-8b95-43f9-aa25-7bab0cd342a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine which spreadsheet to analyse\n",
    "\n",
    "if len(st.session_state.df_produced) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_produced\n",
    "    \n",
    "elif len(st.session_state.df_uploaded) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_uploaded\n",
    "    \n",
    "else: #elif len(st.session_state.df_individual_output) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_individual_output\n",
    "\n",
    "if len(st.session_state.df_to_analyse) > 0:\n",
    "\n",
    "    st.subheader('Your spreadsheet')\n",
    "\n",
    "    df_to_analyse = st.session_state.df_to_analyse\n",
    "\n",
    "    #Make any column of hyperlinks clickable\n",
    "\n",
    "    link_heading_config = {} \n",
    "    \n",
    "    try:\n",
    "        link_heading = link_heading_picker(df_to_analyse)       \n",
    "        df_to_analyse = convert_links_column(df_to_analyse)\n",
    "        link_heading_config={link_heading: st.column_config.LinkColumn()}       \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('No column has hyperlinks.')\n",
    "\n",
    "    st.write('You can directly edit this spreadsheet.')\n",
    "    st.caption('To download, search within or maximise this spreadsheet, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "\n",
    "    #Try to avoid conflict between PyArrow and numpy by converting columns with both lists and null values to string\n",
    "\n",
    "    try:\n",
    "        st.session_state[\"edited_df\"] = st.data_editor(df_to_analyse,  column_config=link_heading_config)\n",
    "    \n",
    "    except Exception as e:\n",
    "\n",
    "        error_to_show = ''\n",
    "\n",
    "        if st.session_state.page_from == 'pages/NSW.py':\n",
    "            \n",
    "            df_to_analyse = nsw_df_list_columns(df_to_analyse)\n",
    "\n",
    "            error_to_show = 'The lists in your spreadsheet have been converted to text.'\n",
    "\n",
    "        else:\n",
    "            df_to_analyse = df_to_analyse.astype(str)\n",
    "\n",
    "            error_to_show = 'The non-textual data in your spreadsheet have been converted to text.'\n",
    "                    \n",
    "        st.session_state[\"edited_df\"] = st.data_editor(df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "        st.warning(error_to_show)\n",
    "        \n",
    "        print(f'Error: {e}.')\n",
    "\n",
    "    #New spreadsheet button\n",
    "\n",
    "    if st.button('UPLOAD a new spreadsheet'):\n",
    "        st.session_state.df_uploaded_key += 1\n",
    "        clear_most_cache()\n",
    "        st.rerun()\n",
    "\n",
    "    #Remove button for carried-over spreadsheets only; doesn't work for uploaded spreadsheets\n",
    "\n",
    "    #if 'df_individual_output' in st.session_state:\n",
    "        #if st.button('UPLOAD a spreadsheet instead'):\n",
    "            #clear_cache_except_validation_history_df_produced()\n",
    "            #st.rerun()\n",
    "\n",
    "    #Activate AI\n",
    "    try:\n",
    "        llm = ai_model_setting(st.session_state.ai_choice, st.session_state.gpt_api_key, st.session_state.gpt_model)\n",
    "    except Exception as e:\n",
    "        st.error('Please double-check your API key.')\n",
    "        #st.exception(e)\n",
    "        quit()\n",
    "\n",
    "    agent = Agent(st.session_state.edited_df, config={\"llm\": llm, \"verbose\": True, \"response_parser\": StreamlitResponse, 'enable_cache': True}, memory_size=st.session_state.instructions_bound, description = agent_description)\n",
    "    #agent = SmartDataframe(st.session_state.edited_df, config={\"llm\": llm, \"verbose\": True, \"response_parser\": StreamlitResponse, 'enable_cache': True}, description = agent_description)\n",
    "\n",
    "    st.subheader(f'Enter your instruction(s) for {st.session_state.ai_choice}')\n",
    "\n",
    "    st.write(f':green[Please give your instruction(s) in sequence.] {ai_model_printing(st.session_state.ai_choice, st.session_state.gpt_model)} will respond to at most {st.session_state.instructions_bound} instructions.')\n",
    "            \n",
    "    #prompt = st.text_area(ai_model_description(st.session_state.ai_choice), height= 200, max_chars=1000) \n",
    "    prompt = st.text_area(f'Each instruction must not exceed 1000 characters.', height= 200, max_chars=1000) \n",
    "\n",
    "    st.caption('During the pilot stage, the number of instructions and the number of characters per instruction are capped. Please reach out to Ben at ben.chen@sydney.edu.au should you wish to give more instructions or longer instructions.')\n",
    "\n",
    "    #Generate explain button\n",
    "    if st.session_state.ai_choice == 'GPT':\n",
    "    \n",
    "        #Explain \n",
    "        code_show = st.toggle('Explain reasoning')\n",
    "    \n",
    "        if code_show:\n",
    "            st.session_state.explain_status = True\n",
    "        else:\n",
    "            st.session_state.explain_status = False\n",
    "\n",
    "    else:\n",
    "        st.session_state.explain_status = False\n",
    "\n",
    "    #AI warning\n",
    "    if st.session_state.ai_choice == 'GPT':\n",
    "    \n",
    "        if st.session_state.gpt_model == 'gpt-3.5-turbo-0125':\n",
    "            st.warning('A low-cost version of GPT will respond to your instruction(s). Please note that this version is *not* designed for data analysis.')\n",
    "    \n",
    "        if st.session_state.gpt_model == \"gpt-4-turbo\":\n",
    "            st.warning(f'An expensive version of GPT will respond to your instruction(s).')\n",
    "            \n",
    "    else: #if st.session_state.ai_choice == 'BambooLLM':\n",
    "        st.warning('An experimental AI will respond to your instruction(s). Please be cautious.')\n",
    "\n",
    "    # Generate output\n",
    "\n",
    "    if st.button(\"ASK\"):\n",
    "        if not prompt:\n",
    "            st.warning(\"Please enter some instruction.\")\n",
    "        else:\n",
    "\n",
    "            if int(consent) == 0:\n",
    "                st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "                quit()\n",
    "                \n",
    "            elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "                    \n",
    "                st.warning('You have not validated your API key.')\n",
    "                quit()\n",
    "        \n",
    "            elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "        \n",
    "                st.warning('You have not entered a valid API key.')\n",
    "                quit()  \n",
    "\n",
    "            elif st.session_state.instruction_left == 0:\n",
    "                no_more_instructions = 'You have reached the maximum number of instructions allowed during the pilot stage.'\n",
    "                st.error(no_more_instructions)\n",
    "                \n",
    "                #Keep record of response\n",
    "                st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": no_more_instructions, 'tokens': 0, 'cost (USD)': 0})\n",
    "            \n",
    "            else:\n",
    "                # call pandas_ai.run(), passing dataframe and prompt\n",
    "                with get_openai_callback() as cb, st.spinner(\"Running...\"):\n",
    "\n",
    "                    response = agent.chat(prompt)\n",
    "\n",
    "                    st.session_state.response = response\n",
    "                    \n",
    "                    st.write('If you see an error, please modify your instruction(s) or press :red[RESET] below and try again.') # or :red[RESET] the AI.')\n",
    "\n",
    "                    st.subheader(f'{st.session_state.ai_choice} Response')\n",
    "                    \n",
    "                    st.caption('To download, search within or maximise any spreadsheet produced, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "                    \n",
    "                    st.write(response)\n",
    "\n",
    "                    #Display and keep record of tokens and costs\n",
    "                    cost_tokens = f'(Cost: USD $ {cb.total_cost} Tokens: {cb.total_tokens})'\n",
    "                    st.write(cost_tokens)\n",
    "\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": cb})\n",
    "\n",
    "                    #Keep record of prompt\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "                    #Keep record of response\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "                    #Show any figure generated\n",
    "                    if plt.get_fignums():\n",
    "                        try:\n",
    "\n",
    "                            st.write('**Visualisation**')\n",
    "                            fig_to_plot = plt.gcf()\n",
    "                            st.pyplot(fig = fig_to_plot)\n",
    "\n",
    "                            #Enable downloading\n",
    "                            pdf_to_download = io.BytesIO()\n",
    "                            png_to_download = io.BytesIO()\n",
    "                            \n",
    "                            plt.savefig(pdf_to_download, bbox_inches='tight', format = 'pdf')\n",
    "                            \n",
    "                            pdf_button = ste.download_button(\n",
    "                               label=\"DOWNLOAD the figure as a PDF\",\n",
    "                               data=pdf_to_download,\n",
    "                               file_name='Figure.pdf',\n",
    "                               mime=\"image/pdf\"\n",
    "                            )\n",
    "\n",
    "                            plt.savefig(png_to_download, bbox_inches='tight', format = 'png')\n",
    "                            \n",
    "                            png_button = ste.download_button(\n",
    "                               label=\"DOWNLOAD the figure as a PNG\",\n",
    "                               data=png_to_download,\n",
    "                               file_name='Figure.png',\n",
    "                               mime=\"image/png\"\n",
    "                            )\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            print('An error with visualisation has occured.')\n",
    "                            print(e)\n",
    "\n",
    "                    #Explanations\n",
    "                    if st.session_state.explain_status is True:\n",
    "\n",
    "                        explanation = agent.explain()\n",
    "                        st.write('**Explanation**')\n",
    "                        st.write(explanation)\n",
    "\n",
    "                        #Keep record of explanation\n",
    "                        st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": explanation})\n",
    "\n",
    "                        try:\n",
    "                            code = response.last_code_generated\n",
    "                            st.write(code)\n",
    "                            \n",
    "                            #Keep record of code\n",
    "                            st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": code})\n",
    "                        \n",
    "                        except Exception as e:\n",
    "                            print('No code generated.')\n",
    "                            print(e)\n",
    "\n",
    "                    #Display number of instructionsl left\n",
    "                    st.session_state.instruction_left -= 1\n",
    "                    instructions_left_text = f\"*You have :orange[{st.session_state.instruction_left}] instructions left.*\"\n",
    "                    st.write(instructions_left_text)\n",
    "\n",
    "                    #Keep record of instructions left\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": instructions_left_text})\n",
    "\n",
    "    #Show code and clarification are not working yet\n",
    "    #if len(st.session_state.messages) > 0:\n",
    "        #if st.button('SHOW code'):\n",
    "            #explanation = agent.explain()\n",
    "            #st.write(explanation)\n",
    "            #st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": explanation})\n",
    "\n",
    "        #if st.button('Clarify'):\n",
    "            #instructions = agent.clarification_instructions(prompt)\n",
    "            #for instruction in instructions:\n",
    "                #st.write(instruction)\n",
    "    \n",
    "    #Button for analysis of any df_produced    \n",
    "    if isinstance(st.session_state.response, pd.DataFrame):\n",
    "        #st.write(st.session_state.df_to_analyse.compare(response))\n",
    "        \n",
    "        if st.button('ANALYSE this spreadsheet'):\n",
    "            st.session_state.df_produced = st.session_state.response\n",
    "            st.session_state.df_uploaded_key += 1\n",
    "            #clear_most_cache()\n",
    "            st.rerun()\n",
    "\n",
    "    #Reset button\n",
    "    #if len(str(st.session_state.response)) >0:\n",
    "    if st.button('RESET to get fresh responses', type = 'primary'):#, help = \"Press to engage with the AI afresh.\"):\n",
    "        pai.clear_cache()\n",
    "        st.session_state['response'] = ''\n",
    "        #clear_most_cache()\n",
    "        st.rerun()\n",
    "\n",
    "    #Button for displaying chat history\n",
    "    history_on = st.toggle(label = 'See all instructions and responses')\n",
    "\n",
    "    if history_on:\n",
    "\n",
    "        #Check if history exists\n",
    "        if len(st.session_state.messages) > 0:\n",
    "    \n",
    "            st.subheader('Conversation')\n",
    "\n",
    "            st.write('Instructions and responses are displayed from earliest to latest.')\n",
    "\n",
    "            st.caption('To download, search within or maximise any spreadsheet produced, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "\n",
    "            # Display chat messages from history on app rerun\n",
    "            for message in st.session_state.messages:\n",
    "                st.caption(' ')\n",
    "                st.caption(message[\"time\"][0:19])\n",
    "                with st.chat_message(message[\"role\"]):\n",
    "                    st.write(message[\"content\"])\n",
    "    \n",
    "            #Create and export json file with instructions and responses for downloading\n",
    "            \n",
    "            df_history = pd.DataFrame(st.session_state.messages)\n",
    "        \n",
    "            if \"df_master\" in st.session_state:\n",
    "                history_output_name = st.session_state.df_master.loc[0, 'Your name'] + '_' + str(today_in_nums) + '_chat_history'\n",
    "            else:\n",
    "                history_output_name = str(today_in_nums) + '_chat_history'\n",
    "            \n",
    "            csv = convert_df_to_csv(df_history)\n",
    "        \n",
    "            ste.download_button(\n",
    "                label=\"Download the conversation as a CSV (for use in Excel etc)\", \n",
    "                data = csv,\n",
    "                file_name=history_output_name + '.csv', \n",
    "                mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "            )\n",
    "        \n",
    "            xlsx = convert_df_to_excel(df_history)\n",
    "            \n",
    "            ste.download_button(label='Download the conversation as an Excel spreadsheet (XLSX)',\n",
    "                                data=xlsx,\n",
    "                                file_name=history_output_name + '.xlsx', \n",
    "                                mime='application/vnd.ms-excel',\n",
    "                               )\n",
    "        \n",
    "            json = convert_df_to_json(df_history)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download the conversation as a JSON\", \n",
    "                data = json,\n",
    "                file_name= history_output_name + '.json', \n",
    "                mime= \"application/json\", \n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
