{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38bda467-646f-4d4f-9ee0-74e18b4e0c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#streamlit run Dropbox/Python/GitHub/au-uk-empirical-legal-research/pages/AI.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28405948-0a19-4859-8a21-c429619460e3",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import os\n",
    "import io\n",
    "import openpyxl\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "#from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "#PandasAI\n",
    "#from dotenv import load _dotenv\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai import Agent\n",
    "from pandasai.llm import BambooLLM\n",
    "from pandasai.llm.openai import OpenAI\n",
    "import pandasai as pai\n",
    "\n",
    "#Excel\n",
    "from io import BytesIO\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "417a9dd8-c34c-4148-9118-c360cc65f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34a4a48f-ae9d-4452-8d42-c05e3406cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The maximum number of instructions per thread is 10.\n"
     ]
    }
   ],
   "source": [
    "#Instructions cap\n",
    "instructions_bound = 10\n",
    "\n",
    "print(f\"\\nThe maximum number of instructions per thread is {instructions_bound}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "284e2004-7b04-4dbf-b135-ab29ebf0d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today and time\n",
    "today_in_nums = str(datetime.now())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8157e0f1-5807-4c93-b9db-13b3cf483b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for saving responses and results\n",
    "def convert_df_to_json(df):\n",
    "    return df.to_json(orient = 'split', compression = 'infer')\n",
    "\n",
    "def convert_df_to_csv(df):\n",
    "   return df.to_csv(index=False).encode('utf-8')\n",
    "\n",
    "#Excel metadata\n",
    "excel_author = 'The Empirical Legal Research Kickstarter'\n",
    "excel_description = 'A 2022 University of Sydney Research Accelerator (SOAR) Prize partially funded the development of the Empirical Legal Research Kickstarter, which generated this spreadsheet.'\n",
    "\n",
    "def convert_df_to_excel(df):\n",
    "    output = BytesIO()\n",
    "    writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
    "    df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    workbook = writer.book\n",
    "    workbook.set_properties({\"author\": excel_author, \"comments\": excel_description})\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "#    format1 = workbook.add_format({'num_format': '0.00'}) \n",
    "    worksheet.set_column('A:A', None)#, format1)  \n",
    "    writer.save()\n",
    "    processed_data = output.getvalue()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0c9ca-ef4f-4b05-80ab-7b4a88073db7",
   "metadata": {},
   "source": [
    "# AI model and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff680153-f234-4aff-ac74-9894489db347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default choice of AI\n",
    "\n",
    "default_ai = 'GPT' #'BambooLLM'\n",
    "\n",
    "if 'ai_choice' not in st.session_state:\n",
    "    st.session_state['ai_choice'] = default_ai\n",
    "\n",
    "ai_list_raw = ['BambooLLM', 'GPT']\n",
    "ai_list = ['0', '1']\n",
    "for ai in ai_list_raw:\n",
    "    if ai == default_ai:\n",
    "        ai_list[0] = ai\n",
    "    else:\n",
    "        ai_list[1] = ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bfdf1922-5388-4b0e-8249-f89070ec88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The choice of model function\n",
    "\n",
    "def ai_model_setting(ai_choice):\n",
    "    \n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "\n",
    "        llm = OpenAI(api_token=st.secrets[\"openai\"][\"gpt_api_key\"], model = 'gpt-3.5-turbo-0125')\n",
    "\n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "\n",
    "        llm = BambooLLM(api_key=st.secrets[\"pandasai\"][\"bamboollm_api_key\"])\n",
    "\n",
    "    return llm\n",
    "        \n",
    "#llm = OpenAI(api_token=st.secrets[\"openai\"][\"gpt_api_key\"], model = 'gpt-3.5-turbo-0125')\n",
    "\n",
    "#llm = BambooLLM(api_key=st.secrets[\"pandasai\"][\"bamboollm_api_key\"])\n",
    "\n",
    "#if 'openai_key' not in st.session_state:\n",
    "#    st.session_state.openai_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50dc9d22-f2d0-4732-aed0-cc10a87a58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI model descript\n",
    "\n",
    "def ai_model_description(ai_choice):\n",
    "    \n",
    "    model_description = ''\n",
    "    \n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "    \n",
    "        model_description = \"GPT model gpt-3.5-turbo-0125 will respond to your instructions.\"\n",
    "    \n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "    \n",
    "        model_description = 'BambooLLM will respond to your instruction(s). This model is developed by PandasAI with data analysis in mind (see https://docs.pandas-ai.com/en/latest/LLMs/llms/).'\n",
    "\n",
    "    return model_description\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3312aa5-ad83-46cb-ac5d-733a5bcea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_description = 'You are a data analyst. Your main goal is to help non-technical users to clean and analyze data. You will be given a spreadsheet of data. Each column starting with \"GPT question\" was previously entered by you. You will be given questions or instructions about the spreadsheet.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540b2dd-ebae-44b3-b351-00120d549019",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "724c9ac2-aec5-43bb-ac9f-364acf96a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse hyperlink display\n",
    "\n",
    "def link_heading_picker(df):\n",
    "    y = ''\n",
    "    for x in df.columns:\n",
    "        if 'Hyperlink to' in str(x):\n",
    "            y = x\n",
    "    return y\n",
    "\n",
    "def reverse_link(x):\n",
    "    value = str(x).replace('=HYPERLINK(\"', '').replace('\")', '')\n",
    "    return value\n",
    "\n",
    "def convert_links_column(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    link_header = link_heading_picker(df)\n",
    "    new_df[link_header] = df[link_header].apply(reverse_link)\n",
    "\n",
    "    return new_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "295070a7-e023-46ec-b28d-87a503ec1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NSW, function for columns which are lists to strings:\n",
    "\n",
    "list_columns = ['Catchwords', 'Legislation cited', 'Cases cited', 'Texts cited', 'Parties', 'Representation', 'Decision under appeal'] \n",
    "\n",
    "#'Decision under appeal' is a dictionary but the values of some keys are lists\n",
    "\n",
    "def nsw_df_list_columns(df):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    for heading in list_columns:\n",
    "        if heading in df.columns:\n",
    "            df_new[heading] = df[heading].astype(str)\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "58690ed3-da87-4880-bbf6-a06b94bb69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache():\n",
    "    keys = list(st.session_state.keys())\n",
    "    for key in keys:\n",
    "        st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d9a6808-56f8-4e87-a5df-f7be2218bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display chat messages from history on app rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2c892ba7-bdf3-4244-aaa8-494c8d3813c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize instructions counter\n",
    "if 'instruction_left' not in st.session_state:\n",
    "\n",
    "    st.session_state[\"instruction_left\"] = instructions_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1693bc99-79eb-451c-bd8e-d011d3162e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initalize page_from:\n",
    "if 'page_from' not in st.session_state:\n",
    "    st.session_state['page_from'] = 'Home.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc9a26f9-5092-42cc-a64c-de2415bf5aaf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if st.button('RETURN to previous page'):\n",
    "\n",
    "    st.switch_page(st.session_state.page_from)\n",
    "\n",
    "st.header(\"You have chosen to :blue[analyse your spreadsheet].\")\n",
    "\n",
    "#Open spreadsheet\n",
    "if 'df_individual_output' in st.session_state:\n",
    "\n",
    "    st.session_state['df_to_analyse'] = st.session_state.df_individual_output\n",
    "\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.markdown(\"\"\"**:green[Please upload a spreadsheet.]** Supported formats: CSV, XLSX, JSON.\"\"\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(\"You may upload a spreadsheet generated by the Empirical Legal Research Kickstarter. The CSV format is preferred.\", type=['csv', 'xlsx', 'json'], accept_multiple_files=False)\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        #Extension\n",
    "        extension = uploaded_file.name.split('.')[-1].lower()\n",
    "        \n",
    "        if extension == 'csv':\n",
    "            df_uploaded = pd.read_csv(uploaded_file)\n",
    "    \n",
    "        if extension == 'xlsx':\n",
    "            df_uploaded = pd.read_excel(uploaded_file)\n",
    "    \n",
    "        if extension == 'json':\n",
    "            df_uploaded = pd.read_json(uploaded_file, orient= 'split')\n",
    "\n",
    "        st.session_state[\"df_to_analyse\"]=df_uploaded\n",
    "\n",
    "if 'df_to_analyse' in st.session_state:\n",
    "\n",
    "    df_to_analyse = st.session_state.df_to_analyse\n",
    "\n",
    "    #Make any column of hyperlinks clickable\n",
    "\n",
    "    link_heading_config = {} \n",
    "    \n",
    "    try:\n",
    "        link_heading = link_heading_picker(df_to_analyse)       \n",
    "        df_to_analyse = convert_links_column(df_to_analyse)\n",
    "        link_heading_config={link_heading: st.column_config.LinkColumn()}       \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print('No column has hyperlinks.')\n",
    "\n",
    "    st.write('You can directly edit this spreadsheet.')\n",
    "    st.caption('To download, search or maximise this spreadsheet, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "\n",
    "    #Try to avoid conflict between PyArrow and numpy by converting columns with both lists and null values to string\n",
    "\n",
    "    try:\n",
    "    \n",
    "        st.session_state[\"edited_df\"] = st.data_editor(df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "        error_to_show = ''\n",
    "\n",
    "        if st.session_state.page_from == 'pages/NSW.py':\n",
    "            \n",
    "            df_to_analyse = nsw_df_list_columns(df_to_analyse)\n",
    "\n",
    "            error_to_show = 'The lists in your spreadsheet have been converted to text.'\n",
    "\n",
    "        else:\n",
    "            df_to_analyse = df_to_analyse.astype(str)\n",
    "\n",
    "            error_to_show = 'The non-textual data in your spreadsheet have been converted to text.'\n",
    "            \n",
    "        st.session_state[\"edited_df\"] = st.data_editor(df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "        st.warning(error_to_show)\n",
    "        \n",
    "        print(f'Error: {e}.')\n",
    "    \n",
    "    #Choice of AI\n",
    "#    st.subheader(\"Which AI would you like to use?\")\n",
    "\n",
    "    llm = ai_model_setting(st.session_state.ai_choice)\n",
    "    \n",
    "#    sdf = SmartDataframe(st.session_state.edited_df, config = {'llm': llm})\n",
    "    agent = Agent(st.session_state.edited_df, config={\"llm\": llm}, memory_size=instructions_bound, description = agent_description)\n",
    "    \n",
    "    st.subheader(f'Enter your instruction(s) for {st.session_state.ai_choice}')\n",
    "\n",
    "    st.write(':green[You may give at most 10 instructions in sequence.] Each instruction must not exceed 1000 characters.')\n",
    "    \n",
    "    prompt = st.text_area(ai_model_description(st.session_state.ai_choice), height= 200, max_chars=1000) \n",
    "\n",
    "    st.caption('During the pilot stage, the number of instructions and the number of characters per instruction are capped. Please reach out to Ben at ben.chen@sydney.edu.au should you wish to give more instructions or longer instructions.')\n",
    "\n",
    "    # Generate output\n",
    "\n",
    "    st.warning('A low-cost AI will respond to your instruction(s). Please be cautious.')\n",
    "\n",
    "    if st.button(\"ASK the AI\"):\n",
    "        if prompt:\n",
    "            #Keep record of prompt\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"user\", \"content\": prompt})\n",
    "            \n",
    "            if st.session_state.instruction_left > 0:\n",
    "                # call pandas_ai.run(), passing dataframe and prompt\n",
    "                with st.spinner(\"Running...\"):\n",
    "                    #response = sdf.chat(prompt)\n",
    "\n",
    "                    response = agent.chat(prompt)\n",
    "\n",
    "                    st.write('If you see an error, please modify your instruction or :red[RESET] the AI and try again.') # or :red[RESET] the AI.')\n",
    "\n",
    "                    st.subheader(f'{st.session_state.ai_choice} Response')\n",
    "\n",
    "                    st.caption('To download, search or maximise any spreadsheet produced, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "                    \n",
    "                    st.write(response)\n",
    "\n",
    "                    #st.write('*:red[An experimental AI produced this response. Please be cautious.]*')\n",
    "\n",
    "                    #Display number of instructionsl left\n",
    "                    st.session_state.instruction_left -= 1\n",
    "                    instructions_left_text = f\"You have :orange[{st.session_state.instruction_left}] instructions left.\"\n",
    "                    st.write(instructions_left_text)\n",
    "\n",
    "                    #Keep record of response\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": response})\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"role\": \"assistant\", \"content\": instructions_left_text})\n",
    "\n",
    "            else:\n",
    "                no_more_instructions = 'You have reached the maximum number of instructions allowed during the pilot stage.'\n",
    "                st.write(no_more_instructions)\n",
    "                \n",
    "                #Keep record of response\n",
    "                st.session_state.messages.append({\"role\": \"assistant\", \"content\": no_more_instructions})\n",
    "        else:\n",
    "            st.warning(\"Please enter some instruction.\")\n",
    "\n",
    "    #Show code and clarification are not working yet\n",
    "    #if len(st.session_state.messages) > 0:\n",
    "        #if st.button('SHOW code'):\n",
    "            #explanation = agent.explain()\n",
    "            #st.write(explanation)\n",
    "\n",
    "        #if st.button('Clarify'):\n",
    "            #instructions = agent.clarification_instructions(prompt)\n",
    "            #for instruction in instructions:\n",
    "                #st.write(instruction)\n",
    "\n",
    "    #Reset button, not particularly useful\n",
    "    if st.button('RESET the AI', type = 'primary', help = \"Press to engage with the AI afresh.\"):\n",
    "        pai.clear_cache()\n",
    "        #clear_cache()\n",
    "        #st.rerun()\n",
    "\n",
    "    #Button for displaying chat history\n",
    "    history_on = st.toggle(label = 'SEE all instructions and responses')\n",
    "\n",
    "    if history_on:\n",
    "\n",
    "        #Check if history exists\n",
    "        if len(st.session_state.messages) > 0:\n",
    "    \n",
    "            st.subheader('Conversation')\n",
    "\n",
    "            st.write('Instructions and responses are displayed from earliest to latest.')\n",
    "\n",
    "            st.caption('To download, search or maximise any spreadsheet produced, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "\n",
    "            # Display chat messages from history on app rerun\n",
    "            for message in st.session_state.messages:\n",
    "                st.caption(' ')\n",
    "                st.caption(message[\"time\"][0:19])\n",
    "                with st.chat_message(message[\"role\"]):\n",
    "                    st.write(message[\"content\"])\n",
    "    \n",
    "            #Create and export json file with instructions and responses for downloading\n",
    "            \n",
    "            df_history = pd.DataFrame(st.session_state.messages)\n",
    "        \n",
    "            if \"df_master\" in st.session_state:\n",
    "                history_output_name = st.session_state.df_master.loc[0, 'Your name'] + '_' + str(today_in_nums) + '_chat_history'\n",
    "            else:\n",
    "                history_output_name = str(today_in_nums) + '_chat_history'\n",
    "            \n",
    "            csv = convert_df_to_csv(df_history)\n",
    "        \n",
    "            ste.download_button(\n",
    "                label=\"Download the conversation as a CSV (for use in Excel etc)\", \n",
    "                data = csv,\n",
    "                file_name=history_output_name + '.csv', \n",
    "                mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "            )\n",
    "        \n",
    "            xlsx = convert_df_to_excel(df_history)\n",
    "            \n",
    "            ste.download_button(label='Download the conversation as an Excel spreadsheet (XLSX)',\n",
    "                                data=xlsx,\n",
    "                                file_name=history_output_name + '.xlsx', \n",
    "                                mime='application/vnd.ms-excel',\n",
    "                               )\n",
    "        \n",
    "            json = convert_df_to_json(df_history)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download the conversation as a JSON\", \n",
    "                data = json,\n",
    "                file_name= history_output_name + '.json', \n",
    "                mime= \"application/json\", \n",
    "            )        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
