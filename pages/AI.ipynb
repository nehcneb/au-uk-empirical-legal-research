{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbc6263-3e8d-4ca1-8af6-72518f1f5ebf",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28405948-0a19-4859-8a21-c429619460e3",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import os\n",
    "import io\n",
    "import openpyxl\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "#from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "#PandasAI\n",
    "#from dotenv import load _dotenv\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai import Agent\n",
    "from pandasai.llm import BambooLLM\n",
    "from pandasai.llm.openai import OpenAI\n",
    "import pandasai as pai\n",
    "from pandasai.responses.streamlit_response import StreamlitResponse\n",
    "from pandasai.helpers.openai_info import get_openai_callback as pandasai_get_openai_callback\n",
    "\n",
    "#langchain\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "#from langchain_openai import OpenAI\n",
    "from langchain_community.callbacks import get_openai_callback as langchain_get_openai_callback\n",
    "\n",
    "#Excel\n",
    "from io import BytesIO\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03334c90-6aba-4b83-9dab-300fdaa10115",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'extra_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Whether users are allowed to use their account\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mextra_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m own_account_allowed() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBy default, users are allowed to use their own account\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'extra_functions'"
     ]
    }
   ],
   "source": [
    "#Whether users are allowed to use their account\n",
    "from extra_functions import own_account_allowed\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a9dd8-c34c-4148-9118-c360cc65f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284e2004-7b04-4dbf-b135-ab29ebf0d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today and time\n",
    "today_in_nums = str(datetime.now())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8157e0f1-5807-4c93-b9db-13b3cf483b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function for saving responses and results\n",
    "def convert_df_to_json(df):\n",
    "    return df.to_json(orient = 'split', compression = 'infer')\n",
    "\n",
    "def convert_df_to_csv(df):\n",
    "   return df.to_csv(index=False).encode('utf-8')\n",
    "\n",
    "#Excel metadata\n",
    "excel_author = 'The Empirical Legal Research Kickstarter'\n",
    "excel_description = 'A 2022 University of Sydney Research Accelerator (SOAR) Prize partially funded the development of the Empirical Legal Research Kickstarter, which generated this spreadsheet.'\n",
    "\n",
    "def convert_df_to_excel(df):\n",
    "    output = BytesIO()\n",
    "    writer = pd.ExcelWriter(output, engine='xlsxwriter', engine_kwargs={'options': {'strings_to_urls': False}})\n",
    "    df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    workbook = writer.book\n",
    "    workbook.set_properties({\"author\": excel_author, \"comments\": excel_description})\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "#    format1 = workbook.add_format({'num_format': '0.00'}) \n",
    "    worksheet.set_column('A:A', None)#, format1)  \n",
    "    writer.save()\n",
    "    processed_data = output.getvalue()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0c9ca-ef4f-4b05-80ab-7b4a88073db7",
   "metadata": {},
   "source": [
    "# AI model and context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eeb295-a0e9-47ce-9f04-548336d086e7",
   "metadata": {},
   "source": [
    "## Applicable to all AIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c49d98-4da0-4d3a-a3a1-f096a07bc0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check validity of API key\n",
    "\n",
    "def is_api_key_valid(key_to_check):\n",
    "    openai.api_key = key_to_check\n",
    "    \n",
    "    try:\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[{\"role\": \"user\", \"content\": 'Who is Taylor Swift?'}], \n",
    "            max_tokens = 5\n",
    "        )\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55d2072-420d-4cb3-a754-d778d817468e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Initialize key validity check\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff680153-f234-4aff-ac74-9894489db347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default choice of AI\n",
    "\n",
    "default_ai = 'GPT'\n",
    "#default_ai = 'BambooLLM'\n",
    "#default_ai = 'LangChain'\n",
    "\n",
    "if 'ai_choice' not in st.session_state:\n",
    "    st.session_state['ai_choice'] = default_ai\n",
    "\n",
    "ai_list_raw = ['GPT'] #, 'BambooLLM'] \n",
    "\n",
    "#Add LangChain\n",
    "#ai_list_raw.append('LangChain')\n",
    "\n",
    "#Add BambooLLM\n",
    "#ai_list_raw.append('BambooLLM')\n",
    "\n",
    "default_ai_index = ai_list_raw.index(default_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdf1922-5388-4b0e-8249-f89070ec88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The choice of model function\n",
    "\n",
    "def llm_setting(ai_choice, key, gpt_model_choice):\n",
    "\n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "        if gpt_model_choice == 'gpt-4-turbo':\n",
    "            gpt_model_choice = 'gpt-4-0125-preview'\n",
    "        \n",
    "        llm = OpenAI(api_token=key, model = gpt_model_choice)\n",
    "\n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "\n",
    "        llm = BambooLLM(api_key = st.secrets[\"pandasai\"][\"bamboollm_api_key\"])\n",
    "    \n",
    "    if ai_choice == 'LangChain': #llm.type == 'Bamboollm':\n",
    "\n",
    "        llm = ChatOpenAI(model_name = gpt_model_choice, temperature=0.2, openai_api_key=key, streaming = False)\n",
    "\n",
    "    return llm\n",
    "\n",
    "def ai_model_printing(ai_choice, gpt_model_choice):\n",
    "#NOT in use\n",
    "    \n",
    "    output = ai_choice\n",
    "\n",
    "    if ai_choice == 'GPT':\n",
    "        \n",
    "        output = f'GPT model {gpt_model_choice}'\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e424a9-1734-4f19-9431-2f14755ac51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent description\n",
    "\n",
    "#default_agent_description = \"\"\"You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. \n",
    "#You will be given questions or instructions about the spreadsheet.  \n",
    "#\"\"\"\n",
    "\n",
    "default_agent_description = 'You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. You will be given questions or instructions about the spreadsheet. You think step by step to answer these questions or instructions.'\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c4b39-6af9-46a1-b237-5b1ff3099a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(ai_choice, key, gpt_model_choice, instructions_bound, df):\n",
    "\n",
    "    response = ''\n",
    "    \n",
    "    llm = llm_setting(ai_choice, key, gpt_model_choice)\n",
    "    \n",
    "    if ai_choice in {'GPT', 'BambooLLM'}:            \n",
    "        \n",
    "        agent = Agent(df, \n",
    "                      config={\"llm\": llm, \n",
    "                              \"verbose\": True, \n",
    "                              \"response_parser\": StreamlitResponse, \n",
    "                              'enable_cache': True, \n",
    "                              'use_error_correction_framework': True, \n",
    "                              'max_retries': 10\n",
    "                             }, \n",
    "                      memory_size = instructions_bound, \n",
    "                      description = pandasai_agent_description\n",
    "                     )\n",
    "        #agent = SmartDataframe(st.session_state.edited_df, config={\"llm\": llm, \"verbose\": True, \"response_parser\": StreamlitResponse, 'enable_cache': True}, description = pandasai_agent_description)\n",
    "        \n",
    "    if ai_choice == 'LangChain':\n",
    "\n",
    "        agent_kwargs={\"system_message\": default_agent_description, #+ langchain_pandasai_further_instructions, \n",
    "                    \"handle_parsing_errors\": True,\n",
    "                      'streaming' : False, \n",
    "                     }\n",
    "        \n",
    "        agent =  create_pandas_dataframe_agent(llm, df, verbose=True, agent_type=AgentType.OPENAI_FUNCTIONS, agent_executor_kwargs= agent_kwargs)\n",
    "\n",
    "    return agent\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01063889-e803-450c-a22b-b9a67ecad6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_alt(llm, ai_choice, instructions_bound, df):\n",
    "\n",
    "    response = ''\n",
    "    \n",
    "    #llm = llm_setting(ai_choice, key, gpt_model_choice)\n",
    "    \n",
    "    if ai_choice in {'GPT', 'BambooLLM'}:            \n",
    "        \n",
    "        agent = Agent(df, \n",
    "                      config={\"llm\": llm, \n",
    "                              \"verbose\": True, \n",
    "                              \"response_parser\": StreamlitResponse, \n",
    "                              'enable_cache': True, \n",
    "                              'use_error_correction_framework': True, \n",
    "                              'max_retries': 10\n",
    "                             }, \n",
    "                      memory_size = instructions_bound, \n",
    "                      description = pandasai_agent_description\n",
    "                     )\n",
    "        #agent = SmartDataframe(st.session_state.edited_df, config={\"llm\": llm, \"verbose\": True, \"response_parser\": StreamlitResponse, 'enable_cache': True}, description = pandasai_agent_description)\n",
    "        \n",
    "    if ai_choice == 'LangChain':\n",
    "\n",
    "        agent_kwargs={\"system_message\": default_agent_description, #+ langchain_pandasai_further_instructions, \n",
    "                    \"handle_parsing_errors\": True,\n",
    "                      'streaming' : False, \n",
    "                     }\n",
    "        \n",
    "        agent =  create_pandas_dataframe_agent(llm, df, verbose=True, agent_type=AgentType.OPENAI_FUNCTIONS, agent_executor_kwargs= agent_kwargs)\n",
    "\n",
    "    return agent\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aac73f-93dd-4dea-a14d-fb436f8241c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI model descript\n",
    "#NOT in use\n",
    "\n",
    "def ai_model_description(ai_choice):\n",
    "    \n",
    "    model_description = ''\n",
    "    \n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "    \n",
    "        model_description = \"GPT model gpt-3.5-turbo-0125 is selected by default. This model can explain its reasoning.\"\n",
    "    \n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "    \n",
    "        model_description = 'BambooLLM is selected by default. This model is developed by PandasAI with data analysis in mind (see https://docs.pandas-ai.com/en/stable/).'\n",
    "\n",
    "    return model_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bff5bb-e6f6-41cd-8ffc-7ab344ec45ef",
   "metadata": {},
   "source": [
    "## Pandas AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3312aa5-ad83-46cb-ac5d-733a5bcea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent description\n",
    "\n",
    "#default_agent_description = \"\"\"You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. \n",
    "#You will be given questions or instructions about the spreadsheet.  \n",
    "#\"\"\"\n",
    "\n",
    "pandasai_further_instructions = \"\"\"\n",
    "\n",
    "The columns starting with \"GPT question\" were previously entered by you. These columns likely have the information you need.\n",
    "\n",
    "If you need to use any modules to execute a code, import such modules first. \n",
    "\n",
    "If you are asked to visualise your answer, provide the code for visualisation using Matplotlib. \n",
    "\n",
    "You must not remove the columns entitiled \"Case name\" and \"Medium neutral citation\" from the spreadsheet. \n",
    "\"\"\"\n",
    "\n",
    "#If there are values which are \"nonetype\" objects, you ignore such values first. \n",
    "#If there are values which are \"list\" objects, you convert such values to \"string\" objects first. \n",
    "\n",
    "#visualisation = ' Everytime you are given a question or an instruction, try to provide the code to visualise your answer using Matplotlib.'\n",
    "\n",
    "pandasai_agent_description = default_agent_description + pandasai_further_instructions\n",
    "#If want to minimize technicality\n",
    "#pandasai_agent_description = 'You are a data analyst. Your main goal is to help non-technical users to clean, analyse and visualise data. You will be given a spreadsheet of data. Each column starting with \"GPT question\" was previously entered by you. You will be given questions or instructions about the spreadsheet.'\n",
    "\n",
    "#Common errors:\n",
    "#Value type <class 'list'> must match with type dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b55568-ba8a-4f9b-b932-6cc9cf9a665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pandasai_ask():\n",
    "    with pandasai_get_openai_callback() as cb, st.spinner(\"Running...\"):\n",
    "\n",
    "        #Get response and keep in session state\n",
    "\n",
    "        response = agent.chat(prompt)\n",
    "        st.session_state.response = response\n",
    "    \n",
    "        #Show response\n",
    "        st.subheader(f'{st.session_state.ai_choice} Response')\n",
    "        st.caption('To download, search within or maximise any spreadsheet produced, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "    \n",
    "        #st.write('*If you see an error, please modify your instructions or press :red[RESET] below and try again.*') # or :red[RESET] the AI.')\n",
    "    \n",
    "        if agent.last_error is not None:\n",
    "            st.error(response)\n",
    "        else:\n",
    "            st.write(response)\n",
    "        \n",
    "        #Show any figure generated\n",
    "        if plt.get_fignums():\n",
    "            try:\n",
    "                st.write('**Visualisation**')\n",
    "                fig_to_plot = plt.gcf()\n",
    "                st.pyplot(fig = fig_to_plot)\n",
    "    \n",
    "                #Enable downloading\n",
    "                pdf_to_download = io.BytesIO()\n",
    "                png_to_download = io.BytesIO()\n",
    "                \n",
    "                plt.savefig(pdf_to_download, bbox_inches='tight', format = 'pdf')\n",
    "                \n",
    "                pdf_button = ste.download_button(\n",
    "                   label=\"DOWNLOAD the chart as a PDF\",\n",
    "                   data=pdf_to_download,\n",
    "                   file_name='chart.pdf',\n",
    "                   mime=\"image/pdf\"\n",
    "                )\n",
    "    \n",
    "                plt.savefig(png_to_download, bbox_inches='tight', format = 'png')\n",
    "                \n",
    "                png_button = ste.download_button(\n",
    "                   label=\"DOWNLOAD the chart as a PNG\",\n",
    "                   data=png_to_download,\n",
    "                   file_name='chart.png',\n",
    "                   mime=\"image/png\"\n",
    "                )\n",
    "    \n",
    "            except Exception as e:\n",
    "                print('An error with visualisation has occured.')\n",
    "                print(e)\n",
    "    \n",
    "        #For displaying logs\n",
    "        #st.subheader('Logs')\n",
    "        #df_logs = agent.logs\n",
    "        #st.dataframe(df_logs)\n",
    "                \n",
    "        #Display cost and tokens\n",
    "        response_cost = cb.total_cost\n",
    "        response_tokens = cb.total_tokens\n",
    "        \n",
    "        #Keep record of response, cost and tokens\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": response_cost, \"tokens\": response_tokens,   \"role\": \"assistant\", \"content\": response})\n",
    "    \n",
    "        #Explanations\n",
    "        if st.session_state.explain_status is True:\n",
    "    \n",
    "            explanation = agent.explain()\n",
    "            st.write('**Explanation**')\n",
    "            st.write(explanation)\n",
    "    \n",
    "            #Display cost and tokens\n",
    "            explanation_cost = cb.total_cost - response_cost\n",
    "            explanation_tokens = cb.total_tokens - response_tokens\n",
    "                \n",
    "            #Keep record of explanation\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": explanation_cost, \"tokens\": explanation_tokens,   \"role\": \"assistant\", \"content\": explanation})\n",
    "    \n",
    "            try:\n",
    "                code = agent.generate_code(prompt)\n",
    "                \n",
    "                st.write('**Code**')\n",
    "                st.code(code)\n",
    "    \n",
    "                #Display cost and tokens\n",
    "                code_cost = cb.total_cost - response_cost - explanation_cost\n",
    "                code_tokens = cb.total_tokens - response_tokens  - explanation_tokens\n",
    "    \n",
    "                #Keep record of code\n",
    "                st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": code_cost, \"tokens\": code_tokens,   \"role\": \"assistant\", \"content\": code})\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.warning('No code generated.')\n",
    "                print(e)\n",
    "    \n",
    "        #Display tokens and costs\n",
    "        total_cost_tokens = f'(This response costed USD $ {round(cb.total_cost, 5)} and totalled {cb.total_tokens} tokens.)'\n",
    "        st.write(total_cost_tokens)\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": total_cost_tokens})\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230d201-18f8-4b2e-a5d1-2da4d050a8cc",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a41b4253-a065-4a86-bfec-e64c90db0d22",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Got some ideas from https://dev.to/ngonidzashe/chat-with-your-csv-visualize-your-data-with-langchain-and-streamlit-ej7\n",
    "\n",
    "langchain_further_instructions = \"\"\"\n",
    "\n",
    "If you need to use any modules to execute a code, import such modules first. \n",
    "\n",
    "Your output should be in JSON form with three fields: \"text\", \"dataframe\" and \"code\". These are the only possible fields.\n",
    "\n",
    "If your output includes a table, format the table as a Pandas dataframe, and then place the dataframe in the \"dataframe\" field. Specifcially: {\"dataframe\": the Pandas dataframe from your ouput}.\n",
    "\n",
    "If your output includes a code,  provide the code in the \"code\" field. Specifcially: {\"code\": the code from your output}.\n",
    "\n",
    "Any other part of your output should be placed in the \"text\" field. Specifically: {\"text\": anything that is not a dataframe or a code}.\n",
    "\n",
    "If you do not know how to answer the questions or instructions given, write {\"text\": \"Answer not found.\"}.\n",
    "\n",
    "You must not remove the columns entitiled \"Case name\" and \"Medium neutral citation\" from the spreadsheet. \n",
    "\n",
    "The questions or instructions are as follows: \n",
    "\"\"\"\n",
    "\n",
    "#Return all output as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f603a7-b965-4431-b9e2-733ebb34a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_write(response_json):\n",
    "    #if \"text\" in response_json:\n",
    "\n",
    "    if \"text\" in response_json:\n",
    "    \n",
    "        if response_json[\"text\"]:\n",
    "            \n",
    "            st.write(response_json[\"text\"])\n",
    "    \n",
    "    if \"dataframe\" in response_json:\n",
    "        \n",
    "        if response_json[\"dataframe\"]:\n",
    "        \n",
    "            st.dataframe(response_json[\"dataframe\"])\n",
    "\n",
    "    if \"code\" in response_json:\n",
    "        \n",
    "        if response_json[\"code\"]:\n",
    "\n",
    "            if st.session_state.explain_status == True:\n",
    "            \n",
    "                    st.write(\"**Code**\")\n",
    "                \n",
    "                    st.code(response_json[\"code\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3960e5-6cfb-43c6-8639-26e9cbde0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain ask function\n",
    "\n",
    "def langchain_ask():\n",
    "    with langchain_get_openai_callback() as cb, st.spinner(\"Running...\"):\n",
    "\n",
    "        prompt_to_process = langchain_further_instructions + prompt\n",
    "\n",
    "        if st.session_state.explain_status == True:\n",
    "            \n",
    "            prompt_to_process = prompt_to_process + ' Explain your answer. '\n",
    "\n",
    "        response = agent.invoke(prompt_to_process)\n",
    "\n",
    "        #Keep record of tokens and costs\n",
    "        cost_tokens = f'(Cost: USD $ {round(cb.total_cost, 5)} Tokens: {cb.total_tokens})'\n",
    "\n",
    "        st.subheader(f'{st.session_state.ai_choice} Response')\n",
    "\n",
    "        #st.session_state.response = response.__str__()\n",
    "\n",
    "        try:\n",
    "\n",
    "            response_json = json.loads(response[\"output\"].__str__())\n",
    "\n",
    "            st.session_state.response_json = response_json\n",
    "\n",
    "            langchain_write(response_json)\n",
    "\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": cb.total_tokens,   \"role\": \"assistant\", \"content\": response_json})\n",
    "\n",
    "            #st.success('Converted to JSON successfully.')\n",
    "            \n",
    "        except:\n",
    "            #response_json_manual = '{\"text\": \"placeholder\"}'\n",
    "            #response_json = json.loads(response_json_manual)\n",
    "            #response_json['text'] = response[\"output\"]\n",
    "            #st.success('Manually converted to JSON')\n",
    "            #st.write(response[\"output\"])\n",
    "\n",
    "            st.warning('An error has occured. Please try again.')\n",
    "\n",
    "            #st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": cb.total_tokens,   \"role\": \"assistant\", \"content\": response[\"output\"]})\n",
    "\n",
    "        \n",
    "        #st.write('*If you see an error, please modify your instructions or press :red[RESET] below and try again.*') # or :red[RESET] the AI.')\n",
    "    \n",
    "        #Display tokens and costs\n",
    "        st.write(cost_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540b2dd-ebae-44b3-b351-00120d549019",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd266ac0-2bde-4537-a686-ef4d8c2bd161",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c9ac2-aec5-43bb-ac9f-364acf96a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse hyperlink display\n",
    "\n",
    "def link_heading_picker(df):\n",
    "    y = ''\n",
    "    for x in df.columns:\n",
    "        if 'Hyperlink' in str(x):\n",
    "            y = x\n",
    "    return y\n",
    "\n",
    "def reverse_link(x):\n",
    "    value = str(x).replace('=HYPERLINK(\"', '').replace('\")', '')\n",
    "    return value\n",
    "\n",
    "def convert_links_column(df):\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    link_header = link_heading_picker(df)\n",
    "    new_df[link_header] = df[link_header].apply(reverse_link)\n",
    "\n",
    "    return new_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295070a7-e023-46ec-b28d-87a503ec1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NSW, function for columns which are lists to strings:\n",
    "\n",
    "list_columns = ['Catchwords', 'Legislation cited', 'Cases cited', 'Texts cited', 'Parties', 'Representation', 'Decision under appeal'] \n",
    "\n",
    "#'Decision under appeal' is a dictionary but the values of some keys are lists\n",
    "\n",
    "def nsw_df_list_columns(df):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    for heading in list_columns:\n",
    "        if heading in df.columns:\n",
    "            df_new[heading] = df[heading].astype(str)\n",
    "\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58690ed3-da87-4880-bbf6-a06b94bb69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache_except_validation():\n",
    "    keys = list(st.session_state.keys())\n",
    "    for key in keys:\n",
    "        if key != 'gpt_api_key_validity': #Remove this line if wants to clear key validation as well\n",
    "            st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5a2392-d430-4aec-ae92-ccd440ce76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_most_cache():\n",
    "    keys = list(st.session_state.keys())\n",
    "    #These are the keys to KEEP upon clearing\n",
    "    for key_to_keep in ['gpt_api_key_validity', 'messages', 'df_uploaded_key', 'page_from']: \n",
    "        try:\n",
    "            keys.remove('key_to_keep')\n",
    "        except:\n",
    "            print(f\"No {'key_to_keep'} in session state.\")\n",
    "\n",
    "    for key in keys:\n",
    "        st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73bd94-681c-455f-82dc-a9f7d77dbfd9",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9a6808-56f8-4e87-a5df-f7be2218bdab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "#Initalize page_from:\n",
    "if 'page_from' not in st.session_state:\n",
    "    st.session_state['page_from'] = 'Home.py'\n",
    "\n",
    "#Initalize df_individual_output:\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_master'] = []\n",
    "\n",
    "#Initalize df_individual_output:\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = []\n",
    "\n",
    "#Initalize df_uploaded:\n",
    "if 'df_uploaded' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_uploaded'] = []\n",
    "\n",
    "#Initalize df_uploaded_key\n",
    "if \"df_uploaded_key\" not in st.session_state:\n",
    "    st.session_state[\"df_uploaded_key\"] = 0\n",
    "\n",
    "#Initalize df_produced:\n",
    "if 'df_produced' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_produced'] = []\n",
    "\n",
    "#Initalize df_to_analyse:\n",
    "if 'df_to_analyse' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_to_analyse'] = []\n",
    "\n",
    "#Initalize edited_df:\n",
    "if 'edited_df' not in st.session_state:\n",
    "\n",
    "    st.session_state['edited_df'] = []\n",
    "\n",
    "#Initialize default instructions bound\n",
    "\n",
    "default_instructions_bound = 10\n",
    "\n",
    "print(f\"The default maximum number of instructions per thread is {default_instructions_bound}.\\n\")\n",
    "\n",
    "#Initialize instructions cap\n",
    "\n",
    "if 'instructions_bound' not in st.session_state:\n",
    "    st.session_state['instructions_bound'] = default_instructions_bound\n",
    "\n",
    "#Initialize instructions counter\n",
    "\n",
    "if 'instruction_left' not in st.session_state:\n",
    "\n",
    "    st.session_state[\"instruction_left\"] = default_instructions_bound\n",
    "\n",
    "#Initialize default show code status\n",
    "\n",
    "if 'explain_status' not in st.session_state:\n",
    "    st.session_state[\"explain_status\"] = False\n",
    "\n",
    "#Initialize default own account status\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "#Initilize default gpt model\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "#Initialize default gpt enhacement status\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state[\"gpt_enhancement_entry\"] = False\n",
    "\n",
    "#Initialize responses\n",
    "\n",
    "#For pandas ai\n",
    "if 'response' not in st.session_state:\n",
    "    st.session_state[\"response\"] = {}\n",
    "\n",
    "#For langchain\n",
    "if 'response_json' not in st.session_state:\n",
    "    st.session_state[\"response_json\"] = {}\n",
    "\n",
    "#initialize prompt\n",
    "if 'prompt' not in st.session_state:\n",
    "    st.session_state[\"prompt\"] = ''\n",
    "\n",
    "#Initialize clarifyng questions and answers\n",
    "\n",
    "if 'clarifying_questions' not in st.session_state:\n",
    "    st.session_state[\"clarifying_questions\"] = ['', '', '']\n",
    "\n",
    "if 'clarifying_answers' not in st.session_state:\n",
    "    st.session_state[\"clarifying_answers\"] = ['', '', '']\n",
    "\n",
    "#Initialize enhanced prompt\n",
    "if 'prompt_prefill' not in st.session_state:\n",
    "    st.session_state[\"prompt_prefill\"] = ''\n",
    "\n",
    "#Initialize clarifying questions and answers status\n",
    "if 'q_and_a_provided' not in st.session_state:\n",
    "    st.session_state[\"q_and_a_provided\"] = 0\n",
    "\n",
    "#Initialize clarifying questions and answers toggle\n",
    "if 'q_and_a_toggle' not in st.session_state:\n",
    "    st.session_state[\"q_and_a_toggle\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9b477-367e-437b-920a-9fe66e02c895",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd1560-b1c6-4f36-82b2-60120a02116b",
   "metadata": {},
   "source": [
    "## Form before choosing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a26f9-5092-42cc-a64c-de2415bf5aaf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if st.button('RETURN to previous page'):\n",
    "\n",
    "    st.switch_page(st.session_state.page_from)\n",
    "\n",
    "st.header(\"You have chosen to :blue[analyse your spreadsheet].\")\n",
    "\n",
    "#Open spreadsheet and personal details\n",
    "if len(st.session_state.df_individual_output) > 0:\n",
    "\n",
    "    st.success('Your spreadsheet has been imported. Please scroll down.')\n",
    "\n",
    "else: #if len(st.session_state.df_individual_output) == 0:\n",
    "\n",
    "    st.markdown(\"\"\"**:green[Please upload a spreadsheet.]** Supported formats: CSV, XLSX, JSON.\"\"\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(label = \"You may upload a spreadsheet generated by the Empirical Legal Research Kickstarter. The CSV format is preferred.\", \n",
    "                                     type=['csv', 'xlsx', 'json'], \n",
    "                                     accept_multiple_files=False, \n",
    "                                     key = st.session_state[\"df_uploaded_key\"]\n",
    "                                    )\n",
    "\n",
    "    if uploaded_file:\n",
    "        \n",
    "        #Get uploaded file extension\n",
    "        extension = uploaded_file.name.split('.')[-1].lower()\n",
    "        \n",
    "        if extension == 'csv':\n",
    "            df_uploaded = pd.read_csv(uploaded_file)\n",
    "    \n",
    "        if extension == 'xlsx':\n",
    "            df_uploaded = pd.read_excel(uploaded_file)\n",
    "    \n",
    "        if extension == 'json':\n",
    "            df_uploaded = pd.read_json(uploaded_file, orient= 'split')\n",
    "\n",
    "        st.session_state.df_uploaded = df_uploaded\n",
    "        \n",
    "        st.success('Your spreadsheet has been imported. Please scroll down.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93d23-fae0-4163-a92f-c69517c7ea33",
   "metadata": {},
   "source": [
    "## Choice of AI and GPT account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0ab979-ca91-4c8b-bd0a-467aa5600f2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "if len(ai_list_raw) > 1:\n",
    "\n",
    "    st.subheader('Choose an AI')\n",
    "\n",
    "    st.markdown(\"\"\"Please choose an AI to help with data cleaning, analysis and visualisation.\n",
    "    \"\"\")\n",
    "    \n",
    "    ai_choice = st.selectbox(label = f'{default_ai} is selected by default.', options = ai_list_raw, index=default_ai_index)\n",
    "    \n",
    "    if ai_choice != st.session_state.ai_choice:\n",
    "        #pai.clear_cache()\n",
    "        st.session_state['ai_choice'] = ai_choice\n",
    "        st.rerun()\n",
    "        \n",
    "    st.markdown(\"\"\"\n",
    "    GPT can be interactive. LangChain is more agile but can't produce charts.\n",
    "\"\"\")\n",
    "# BambooLLM is developed for data analysis (see https://docs.pandas-ai.com/en/stable/).\n",
    "    \n",
    "\n",
    "    if st.toggle(f'See the instruction given to {st.session_state.ai_choice}'):\n",
    "        \n",
    "        st.write(f\"*{default_agent_description}*\")\n",
    "\n",
    "else:\n",
    "    st.session_state.ai_choice = 'GPT'\n",
    "\n",
    "#if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "\n",
    "    if st.session_state.ai_choice != 'BambooLLM':\n",
    "    \n",
    "        st.subheader(':orange[Enhance program capabilities]')\n",
    "        \n",
    "        st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of instructions to process? You can do so with your own GPT account.\n",
    "        \"\"\")\n",
    "        \n",
    "        own_account_entry = st.toggle('Use my own GPT account')\n",
    "        \n",
    "        if own_account_entry:\n",
    "            \n",
    "            st.session_state[\"own_account\"] = True\n",
    "        \n",
    "            st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage at https://platform.openai.com/signup. You can then find your API key at https://platform.openai.com/api-keys.\n",
    "\"\"\")\n",
    "                \n",
    "            name_entry = st.text_input(label = \"Your name\", value = st.session_state.name_entry)\n",
    "    \n",
    "            st.session_state['name_entry'] = name_entry\n",
    "            \n",
    "            email_entry = st.text_input(label = \"Your email address\", value = st.session_state.email_entry)\n",
    "            \n",
    "            gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.gpt_api_key_entry)\n",
    "            \n",
    "            valdity_check = st.button('VALIDATE your API key')\n",
    "        \n",
    "            if valdity_check:\n",
    "                \n",
    "                api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                        \n",
    "                if api_key_valid == False:\n",
    "                    st.session_state['gpt_api_key_validity'] = False\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    \n",
    "                else:\n",
    "                    st.session_state['gpt_api_key_validity'] = True\n",
    "                    st.success('Your API key is valid.')\n",
    "        \n",
    "            st.markdown(\"\"\"**:green[You can use the latest version of GPT model (gpt-4-turbo),]** which is :red[20 times more expensive, per character] than the default model (gpt-3.5-turbo) which you can use for free.\"\"\")  \n",
    "            \n",
    "            gpt_enhancement_entry = st.checkbox('Use the latest GPT model', value = False)\n",
    "        \n",
    "            st.caption('For more on pricing for different GPT models, please see https://openai.com/api/pricing.')\n",
    "            \n",
    "            if gpt_enhancement_entry == True:\n",
    "                #Reset AI first\n",
    "                pai.clear_cache()\n",
    "            \n",
    "                st.session_state.gpt_model = \"gpt-4-turbo\"\n",
    "                st.session_state.gpt_enhancement_entry = True\n",
    "    \n",
    "            else:\n",
    "                #Reset AI first\n",
    "                pai.clear_cache()\n",
    "                \n",
    "                st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "                st.session_state.gpt_enhancement_entry = False\n",
    "            \n",
    "            st.write(f'**:green[You can remove the cap on the number of instructions to process.]** The default cap is {default_instructions_bound}.')\n",
    "                \n",
    "            drop_instructions_bound = st.button('REMOVE the cap on the number of instructions')\n",
    "        \n",
    "            if drop_instructions_bound:\n",
    "        \n",
    "                st.session_state.instructions_bound = 999\n",
    "                st.session_state.instruction_left = 999\n",
    "        \n",
    "            #st.session_state.instruction_left = st.session_state.instructions_bound\n",
    "        \n",
    "        else:\n",
    "            st.session_state[\"own_account\"] = False\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "        \n",
    "            st.session_state.instructions_bound = default_instructions_bound\n",
    "        \n",
    "            st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "            \n",
    "            print('User GPT API key not entered. Using own API key instead.')\n",
    "    \n",
    "    else:\n",
    "        st.session_state[\"own_account\"] = False\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "    \n",
    "else:\n",
    "    print('Users are NOT allowed to use their own accounts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d28de1-dabf-4c0f-b1c6-f46df81fd978",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b58031-d08a-4cfd-969a-c57f492dcf2d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.subheader(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb7207-52a4-47e7-8eb1-b89cb1cece23",
   "metadata": {},
   "source": [
    "## Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752865b-8b95-43f9-aa25-7bab0cd342a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine which spreadsheet to analyse\n",
    "\n",
    "if len(st.session_state.df_produced) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_produced\n",
    "    \n",
    "elif len(st.session_state.df_uploaded) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_uploaded\n",
    "    \n",
    "else: #elif len(st.session_state.df_individual_output) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_individual_output\n",
    "\n",
    "#Start analysing spreadsheet\n",
    "if len(st.session_state.df_to_analyse) > 0:\n",
    "\n",
    "    df_to_analyse = st.session_state.df_to_analyse\n",
    "    \n",
    "else:\n",
    "    st.warning('Please upload a spreadsheet.')\n",
    "    quit()\n",
    "\n",
    "#Obtain clolumns with hyperlinks\n",
    "link_heading_config = {} \n",
    "\n",
    "try:\n",
    "    link_heading = link_heading_picker(df_to_analyse)       \n",
    "    df_to_analyse = convert_links_column(df_to_analyse)\n",
    "    link_heading_config={link_heading: st.column_config.LinkColumn()}       \n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('No column has hyperlinks.')\n",
    "\n",
    "\n",
    "#Display spreadsheet\n",
    "st.subheader('Your spreadsheet')\n",
    "\n",
    "st.caption('To download, search within or maximise this spreadsheet, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "\n",
    "st.write('You can directly edit this spreadsheet.')\n",
    "\n",
    "#Make any column of hyperlinks clickable\n",
    "try:\n",
    "    st.session_state[\"edited_df\"] = st.data_editor(df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    error_to_show = ''\n",
    "\n",
    "    if st.session_state.page_from == 'pages/NSW.py':\n",
    "        \n",
    "        df_to_analyse = nsw_df_list_columns(df_to_analyse)\n",
    "\n",
    "        error_to_show = 'The lists in your spreadsheet have been converted to text.'\n",
    "\n",
    "    else:\n",
    "        df_to_analyse = df_to_analyse.astype(str)\n",
    "\n",
    "        error_to_show = 'The non-textual data in your spreadsheet have been converted to text.'\n",
    "                \n",
    "    st.session_state[\"edited_df\"] = st.data_editor(df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "    st.warning(error_to_show)\n",
    "    \n",
    "    print(f'Error: {e}.')\n",
    "\n",
    "#Note importation of AI produced spreadsheet\n",
    "if len(st.session_state.df_produced) > 0:\n",
    "    st.success('The spreadsheet produced has been imported.')\n",
    "\n",
    "#New spreadsheet button\n",
    "\n",
    "if st.button('UPLOAD a new spreadsheet'):\n",
    "    st.session_state.df_uploaded_key += 1\n",
    "    clear_most_cache()\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858dbaca-88d3-4177-83e2-5e2481c035b2",
   "metadata": {},
   "source": [
    "## AI activation and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be33916-6aa6-4124-b132-68e329d98548",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Activate AI\n",
    "\n",
    "#try:\n",
    "    #llm = llm_setting(st.session_state.ai_choice, st.session_state.gpt_api_key, st.session_state.gpt_model)\n",
    "    #agent = agent_alt(llm, st.session_state.ai_choice, st.session_state.instructions_bound, st.session_state.edited_df)\n",
    "\n",
    "#except Exception as e:\n",
    "    #st.error('Please double-check your API key.')\n",
    "    #st.exception(e)\n",
    "    #quit()\n",
    "\n",
    "try:\n",
    "    agent = agent(st.session_state.ai_choice, \n",
    "                  st.session_state.gpt_api_key, \n",
    "                  st.session_state.gpt_model, \n",
    "                  st.session_state.instructions_bound, \n",
    "                  st.session_state.edited_df\n",
    "                 )\n",
    "\n",
    "except Exception as e:\n",
    "    st.error('Please double-check your API key.')\n",
    "    st.exception(e)\n",
    "    quit()\n",
    "\n",
    "#Area for entering instructions\n",
    "st.subheader(f'Enter your instructions for {st.session_state.ai_choice}')\n",
    "\n",
    "st.write(f':green[Please give your instructions in sequence.] {ai_model_printing(st.session_state.ai_choice, st.session_state.gpt_model)} will respond to at most {st.session_state.instructions_bound} instructions.')\n",
    "\n",
    "prompt = st.text_area(f'Each instruction must not exceed 1000 characters.', value = st.session_state.prompt_prefill, height= 200, max_chars=1000) \n",
    "\n",
    "st.session_state.prompt = prompt\n",
    "\n",
    "st.caption('During the pilot stage, the number of instructions and the number of characters per instruction are capped. Please reach out to Ben at ben.chen@sydney.edu.au should you wish to give more instructions or longer instructions.')\n",
    "\n",
    "#Disable toggle for clarifying questions and answers BEFORE asking AI again\n",
    "if st.session_state.q_and_a_provided == 1:\n",
    "    st.success('Your clarifying answers have been added to your instructions. Please press ASK again.')\n",
    "    st.session_state.q_and_a_toggle = False\n",
    "\n",
    "#AI warning\n",
    "if st.session_state.ai_choice == 'GPT':\n",
    "\n",
    "    if st.session_state.gpt_model == 'gpt-3.5-turbo-0125':\n",
    "        st.warning('A low-cost GPT model will process your instructions. This model is *not* designed for data analysis.')\n",
    "\n",
    "    if st.session_state.gpt_model == \"gpt-4-turbo\":\n",
    "        st.warning(f'An expensive GPT model will process your instructions.')\n",
    "        \n",
    "else: #if st.session_state.ai_choice == 'BambooLLM':\n",
    "    st.warning('An experimental AI model will respond to your instructions. Please be cautious.')\n",
    "\n",
    "#Generate explain button\n",
    "if st.session_state.ai_choice != 'BambooLLM':\n",
    "\n",
    "    #Explain \n",
    "    explain_toggle = st.toggle('Explain')\n",
    "\n",
    "    if explain_toggle:\n",
    "        st.session_state.explain_status = True\n",
    "    else:\n",
    "        st.session_state.explain_status = False\n",
    "\n",
    "else:\n",
    "    st.session_state.explain_status = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95312243-9f03-4553-8af2-c8fe9192fd26",
   "metadata": {},
   "source": [
    "## Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be79e726-d8d9-4862-ad31-96f88ad0eafc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 07:01:39.284 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# Generate output\n",
    "\n",
    "if st.button(\"ASK\"):\n",
    "\n",
    "    if int(consent) == 0:\n",
    "        st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "        quit()\n",
    "        \n",
    "    elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "            \n",
    "        st.warning('You have not validated your API key.')\n",
    "        quit()\n",
    "\n",
    "    elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "\n",
    "        st.warning('You have not entered a valid API key.')\n",
    "        quit()\n",
    "\n",
    "    elif st.session_state.instruction_left == 0:\n",
    "        no_more_instructions = 'You have reached the maximum number of instructions allowed during the pilot stage.'\n",
    "        st.error(no_more_instructions)\n",
    "        \n",
    "        #Keep record of response\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": no_more_instructions, 'tokens': 0, 'cost (USD)': 0})\n",
    "\n",
    "    elif len(st.session_state.prompt) == 0:\n",
    "        st.warning(\"Please enter some instruction.\")\n",
    "\n",
    "    else:\n",
    "        \n",
    "        #Keep record of prompt\n",
    "        prompt = st.session_state.prompt\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "        #Change q_and_a_provided status\n",
    "        st.session_state[\"q_and_a_provided\"] = 0\n",
    "\n",
    "        if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "            \n",
    "            pandasai_ask()\n",
    "\n",
    "        else: #if st.session_state.ai_choice == 'LangChain':\n",
    "\n",
    "            langchain_ask()\n",
    "                        \n",
    "        #Display number of instructionsl left\n",
    "        st.session_state.instruction_left -= 1\n",
    "        instructions_left_text = f\"*You have :orange[{st.session_state.instruction_left}] instructions left.*\"\n",
    "        st.write(instructions_left_text)\n",
    "\n",
    "        #Keep record of instructions left\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": instructions_left_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5deb3f-540a-4dc0-a996-f5be8c086ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buttons for importing any df produced    \n",
    "\n",
    "#For Pandasai\n",
    "if isinstance(st.session_state.response, pd.DataFrame):\n",
    "    \n",
    "    if st.button('ANALYSE the spreadsheet produced'):\n",
    "        st.session_state.df_produced = st.session_state.response\n",
    "        st.session_state.df_uploaded_key += 1\n",
    "        st.session_state.response = {}\n",
    "        st.rerun()\n",
    "\n",
    "#For Langchain,\n",
    "if \"dataframe\" in st.session_state.response_json:\n",
    "    if st.session_state.response_json[\"dataframe\"]:\n",
    "\n",
    "        if st.button('ANALYSE this spreadsheet only'):\n",
    "            #data = st.session_state.response_json[\"table\"]\n",
    "            #df_to_add = pd.DataFrame(data[\"data\"], columns=data[\"columns\"])\n",
    "            st.session_state.df_produced = pd.DataFrame(data = st.session_state.response_json[\"dataframe\"])\n",
    "            st.session_state.df_uploaded_key += 1\n",
    "            st.rerun()\n",
    "        \n",
    "        if st.button('MERGE with your spreadsheet'):\n",
    "            #data = st.session_state.response_json[\"table\"]\n",
    "            #df_to_add = pd.DataFrame(data[\"data\"], columns=data[\"columns\"])\n",
    "            current_pd = st.session_state.edited_df\n",
    "            df_to_add = pd.DataFrame(data = st.session_state.response_json[\"dataframe\"])\n",
    "            st.session_state.df_produced = current_pd.merge(df_to_add, on = 'Case name', how = 'left')\n",
    "            st.session_state.df_produced = st.session_state.df_produced.loc[:,~st.session_state.df_produced.columns.duplicated()].copy()\n",
    "            st.session_state.df_uploaded_key += 1\n",
    "            st.session_state.response_json[\"dataframe\"] = {}\n",
    "            st.rerun()\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed82eb5-356a-416b-8b8b-a956370564d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset button\n",
    "\n",
    "if st.button('RESET to get fresh responses', type = 'primary'):#, help = \"Press to engage with the AI afresh.\"):\n",
    "    pai.clear_cache()\n",
    "    st.session_state['response'] = '' #Adding this to hide clarifying questions and answers toggle upon resetting\n",
    "    #clear_most_cache()\n",
    "    st.rerun()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903962cf-cc23-4a66-ab42-4e3ed49b0dc8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Clarifying questions form\n",
    "\n",
    "if ((st.session_state.ai_choice != 'LangChain') \n",
    "    and \n",
    "    (len(st.session_state.response) > 0)\n",
    "    ):\n",
    "    \n",
    "    if st.toggle(label = 'Get clarifying questions', key = 'q_and_a_toggle'):\n",
    "    \n",
    "        with pandasai_get_openai_callback() as cb, st.spinner(\"Running...\"):\n",
    "            prompt = st.session_state.prompt\n",
    "    \n",
    "            clarifying_questions = agent.clarification_questions(prompt)\n",
    "\n",
    "            st.session_state.clarifying_questions = clarifying_questions\n",
    "\n",
    "            #Keep record of clarifying questions\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": {cb.total_tokens},   \"role\": \"assistant\", \"content\": clarifying_questions})\n",
    "                            \n",
    "        with st.form(\"clarifying_questions_form\"):\n",
    "    \n",
    "            st.write('Please answer the following clarifying questions from the AI.')\n",
    "\n",
    "            #Display up to 3 clarifying questions\n",
    "            if len(st.session_state.clarifying_questions) > 0:\n",
    "    \n",
    "                st.warning(f'Question 1: {st.session_state.clarifying_questions[0]}')\n",
    "                st.session_state.clarifying_answers[0] = st.text_input(label = f'Enter your answer to question 1', max_chars = 250)\n",
    "    \n",
    "            if len(st.session_state.clarifying_questions) > 1: \n",
    "    \n",
    "                st.warning(f'Question 2: {st.session_state.clarifying_questions[1]}')\n",
    "                st.session_state.clarifying_answers[1] = st.text_input(label = f'Enter your answer to question 2', max_chars = 250)\n",
    "    \n",
    "            if len(st.session_state.clarifying_questions) > 2: \n",
    "    \n",
    "                st.warning(f'Question 3: {st.session_state.clarifying_questions[2]}')\n",
    "                st.session_state.clarifying_answers[2] = st.text_input(label = f'Enter your answer to question 3', max_chars = 250)\n",
    "    \n",
    "            #Display and keep record of tokens and costs\n",
    "            clarifying_questions_cost_tokens = f'(These clarifying questions costed USD $ {round(cb.total_cost, 5)} to produce and totalled {cb.total_tokens} tokens.)'\n",
    "            st.write(clarifying_questions_cost_tokens)\n",
    "            \n",
    "            add_q_a_button = st.form_submit_button('ADD these answers to your instructions')\n",
    "    \n",
    "            if add_q_a_button:\n",
    "                for question_index in range(0, len(st.session_state.clarifying_answers)):\n",
    "                    st.write(f'Answer to question {question_index + 1}: + st.session_state.clarifying_answers[question_index]')\n",
    "                    \n",
    "                intro_q_and_a = ' Take into account the following clarifying questions and their answers. '             \n",
    "    \n",
    "                q_and_a_pairs = ''\n",
    "                \n",
    "                for question_index in range(0, len(st.session_state.clarifying_answers)):\n",
    "                    if len(st.session_state.clarifying_answers[question_index]) > 0:\n",
    "                        question_answer_pair = f' Question: ' + st.session_state.clarifying_questions[question_index] + f' Answer: ' + st.session_state.clarifying_answers[question_index]\n",
    "                        \n",
    "                        if question_answer_pair[-1] != '.':\n",
    "                            question_answer_pair = question_answer_pair + '. '\n",
    "                        \n",
    "                        q_and_a_pairs = q_and_a_pairs + question_answer_pair            \n",
    "    \n",
    "                if intro_q_and_a in st.session_state.prompt_prefill:\n",
    "                    \n",
    "                    st.session_state.prompt_prefill = st.session_state.prompt + q_and_a_pairs\n",
    "               \n",
    "                else:\n",
    "                    \n",
    "                    st.session_state.prompt_prefill = st.session_state.prompt + intro_q_and_a + q_and_a_pairs\n",
    "\n",
    "                #Add clarifying answers to history\n",
    "                st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": {cb.total_tokens},   \"role\": \"assistant\", \"content\": st.session_state.clarifying_answers})\n",
    "                \n",
    "                #Change clarifying questions and answers status\n",
    "                st.session_state['q_and_a_provided'] = 1\n",
    "\n",
    "                st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ee6c5-9f74-4b3a-8135-0a757b7987f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Button for displaying chat history\n",
    "history_on = st.toggle(label = 'See all instructions and responses')\n",
    "\n",
    "if history_on:\n",
    "\n",
    "    #Check if history exists\n",
    "    if len(st.session_state.messages) > 0:\n",
    "\n",
    "        st.subheader('Conversation')\n",
    "\n",
    "        st.write('Instructions and responses are displayed from earliest to latest.')\n",
    "\n",
    "        st.caption('To download, search within or maximise any spreadsheet produced, hover your mouse/pointer over its top right-hand corner and press the appropriate button.')\n",
    "\n",
    "        # Display chat messages from history on app rerun\n",
    "        for message in st.session_state.messages:\n",
    "            st.caption(' ')\n",
    "            st.caption(message[\"time\"][0:19])\n",
    "            with st.chat_message(message[\"role\"]):\n",
    "                if st.session_state.ai_choice == 'LangChain':\n",
    "                    if isinstance(message[\"content\"], dict):\n",
    "                    #if \"role\" == 'assistant':\n",
    "                        langchain_write(message[\"content\"])\n",
    "                    else: #isinstance(message[\"content\"], str)\n",
    "                        st.write(message[\"content\"])\n",
    "                else: #if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "                    #For pandas ai responses\n",
    "                    st.write(message[\"content\"])\n",
    "\n",
    "        #Create and export json file with instructions and responses for downloading\n",
    "        \n",
    "        df_history = pd.DataFrame(st.session_state.messages)\n",
    "    \n",
    "        if len(st.session_state.df_master)>0:\n",
    "            history_output_name = st.session_state.df_master.loc[0, 'Your name'] + '_' + str(today_in_nums) + '_chat_history'\n",
    "        else:\n",
    "            history_output_name = str(today_in_nums) + '_chat_history'\n",
    "        \n",
    "        csv = convert_df_to_csv(df_history)\n",
    "    \n",
    "        ste.download_button(\n",
    "            label=\"Download the conversation as a CSV (for use in Excel etc)\", \n",
    "            data = csv,\n",
    "            file_name=history_output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "    #            key='download-csv'\n",
    "        )\n",
    "    \n",
    "        xlsx = convert_df_to_excel(df_history)\n",
    "        \n",
    "        ste.download_button(label='Download the conversation as an Excel spreadsheet (XLSX)',\n",
    "                            data=xlsx,\n",
    "                            file_name=history_output_name + '.xlsx', \n",
    "                            mime='application/vnd.ms-excel',\n",
    "                           )\n",
    "    \n",
    "        json = convert_df_to_json(df_history)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download the conversation as a JSON\", \n",
    "            data = json,\n",
    "            file_name= history_output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
