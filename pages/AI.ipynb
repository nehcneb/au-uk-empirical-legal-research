{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcbc6263-3e8d-4ca1-8af6-72518f1f5ebf",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28405948-0a19-4859-8a21-c429619460e3",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import pause\n",
    "import os\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ast\n",
    "#from dotenv import load _dotenv\n",
    "import matplotlib.pyplot as plt\n",
    "#from matplotlib.backends.backend_agg import RendererAgg\n",
    "#import statsmodels.api as sm\n",
    "#import statsmodels.formula.api as smf\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.pipeline import make_pipeline\n",
    "#from sklearn.datasets import load_iris\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.datasets import make_regression\n",
    "#from sklearn.model_selection import cross_validate\n",
    "#from sklearn.ensemble import RandomForestRegressor\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#import seaborn as sns\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#PandasAI\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai import Agent\n",
    "#from pandasai.llm import BambooLLM\n",
    "from pandasai.llm.openai import OpenAI\n",
    "import pandasai as pai\n",
    "from pandasai.responses.streamlit_response import StreamlitResponse\n",
    "from pandasai.helpers.openai_info import get_openai_callback as pandasai_get_openai_callback\n",
    "\n",
    "#langchain\n",
    "#from langchain_community.chat_models import ChatOpenAI\n",
    "#from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "#from langchain.agents.agent_types import AgentType\n",
    "#from langchain_community.callbacks import get_openai_callback as langchain_get_openai_callback\n",
    "\n",
    "#Excel\n",
    "import openpyxl\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03334c90-6aba-4b83-9dab-300fdaa10115",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, clear_cache\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea0c9ca-ef4f-4b05-80ab-7b4a88073db7",
   "metadata": {},
   "source": [
    "# AI model and context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eeb295-a0e9-47ce-9f04-548336d086e7",
   "metadata": {},
   "source": [
    "## Applicable to all AIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c004c6b-20f7-4485-80b2-2470acab3094",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string  \n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a55d2072-420d-4cb3-a754-d778d817468e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 14:42:08.301 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Initialize key validity check\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff680153-f234-4aff-ac74-9894489db347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default choice of AI\n",
    "\n",
    "default_ai = 'GPT'\n",
    "#default_ai = 'BambooLLM'\n",
    "#default_ai = 'LangChain'\n",
    "\n",
    "if 'ai_choice' not in st.session_state:\n",
    "    st.session_state['ai_choice'] = default_ai\n",
    "\n",
    "ai_list_raw = ['GPT'] #, 'BambooLLM'] \n",
    "\n",
    "#Add LangChain\n",
    "#ai_list_raw.append('LangChain')\n",
    "\n",
    "#Add BambooLLM\n",
    "#ai_list_raw.append('BambooLLM')\n",
    "\n",
    "default_ai_index = ai_list_raw.index(default_ai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfdf1922-5388-4b0e-8249-f89070ec88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The choice of model function\n",
    "\n",
    "def llm_setting(ai_choice, key, gpt_model_choice):\n",
    "\n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "        #if gpt_model_choice == 'gpt-4o':\n",
    "            #gpt_model_choice = 'gpt-4o'\n",
    "        \n",
    "        llm = OpenAI(api_token=key, model = gpt_model_choice)\n",
    "\n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "\n",
    "        llm = BambooLLM(api_key = st.secrets[\"pandasai\"][\"bamboollm_api_key\"])\n",
    "    \n",
    "    if ai_choice == 'LangChain': #llm.type == 'Bamboollm':\n",
    "\n",
    "        llm = ChatOpenAI(model_name = gpt_model_choice, temperature=0.2, openai_api_key=key, streaming = False)\n",
    "\n",
    "    return llm\n",
    "\n",
    "def ai_model_printing(ai_choice, gpt_model_choice):\n",
    "#NOT in use\n",
    "    \n",
    "    output = ai_choice\n",
    "\n",
    "    if ai_choice == 'GPT':\n",
    "        \n",
    "        output = f'GPT model {gpt_model_choice}'\n",
    "\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28e424a9-1734-4f19-9431-2f14755ac51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent description\n",
    "\n",
    "#default_agent_description = \"\"\"You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. \n",
    "#You will be given questions or instructions about the spreadsheet.  \n",
    "#\"\"\"\n",
    "\n",
    "default_agent_description = 'You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. You will be given questions or instructions about the spreadsheet. You think step by step to answer these questions or instructions.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "337c4b39-6af9-46a1-b237-5b1ff3099a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(ai_choice, key, gpt_model_choice, instructions_bound, df):\n",
    "\n",
    "    response = ''\n",
    "    \n",
    "    llm = llm_setting(ai_choice, key, gpt_model_choice)\n",
    "    \n",
    "    if ai_choice in {'GPT', 'BambooLLM'}:            \n",
    "\n",
    "        #if gpt_model_choice == 'gpt-4o-mini':\n",
    "            \n",
    "        agent = Agent(df, \n",
    "                      config={\"llm\": llm, \n",
    "                              \"verbose\": True, \n",
    "                              \"response_parser\": StreamlitResponse, \n",
    "                              \"custom_whitelisted_dependencies\": [\"ast\"], \n",
    "                              'enable_cache': True, \n",
    "                              'use_error_correction_framework': True, \n",
    "                              'max_retries': 5\n",
    "                             }, \n",
    "                      memory_size = default_instructions_bound, #change to instructions_bound if want to maximize memory\n",
    "                      description = pandasai_agent_description\n",
    "                     )\n",
    "            #agent = SmartDataframe(st.session_state.edited_df, config={\"llm\": llm, \"verbose\": True, \"response_parser\": StreamlitResponse, 'enable_cache': True}, description = pandasai_agent_description)\n",
    "\n",
    "        #else: #For GPT 4, StreamlitResponse doesn't 'hold' images\n",
    "            #agent = Agent(df, \n",
    "                          #config={\"llm\": llm, \n",
    "                                  #\"verbose\": True, \n",
    "                                  #\"response_parser\": StreamlitResponse, \n",
    "                                  #'enable_cache': True, \n",
    "                                  #'use_error_correction_framework': True, \n",
    "                                  #'max_retries': 5\n",
    "                                 #}, \n",
    "                          #memory_size = default_instructions_bound, \n",
    "                          #description = pandasai_agent_description\n",
    "                         #)\n",
    "            \n",
    "    if ai_choice == 'LangChain':\n",
    "\n",
    "        agent_kwargs={\"system_message\": default_agent_description, #+ langchain_pandasai_further_instructions, \n",
    "                    \"handle_parsing_errors\": True,\n",
    "                      'streaming' : True, \n",
    "                     }\n",
    "        \n",
    "        agent =  create_pandas_dataframe_agent(llm, df, verbose=True, agent_type=AgentType.OPENAI_FUNCTIONS, agent_executor_kwargs= agent_kwargs)\n",
    "\n",
    "    return agent\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63aac73f-93dd-4dea-a14d-fb436f8241c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI model descript\n",
    "#NOT in use\n",
    "\n",
    "def ai_model_description(ai_choice):\n",
    "    \n",
    "    model_description = ''\n",
    "    \n",
    "    if ai_choice == 'GPT': #llm.type == 'GPT':\n",
    "    \n",
    "        model_description = \"GPT model gpt-4o-mini is selected by default. This model can explain its reasoning.\"\n",
    "    \n",
    "    if ai_choice == 'BambooLLM': #llm.type == 'Bamboollm':\n",
    "    \n",
    "        model_description = 'BambooLLM is selected by default. This model is developed by PandasAI with data analysis in mind (see https://docs.pandas-ai.com/en/stable/).'\n",
    "\n",
    "    return model_description\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bff5bb-e6f6-41cd-8ffc-7ab344ec45ef",
   "metadata": {},
   "source": [
    "## Pandas AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3312aa5-ad83-46cb-ac5d-733a5bcea4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agent description\n",
    "\n",
    "#default_agent_description = \"\"\"You are a data analyst. Your main goal is to help clean, analyse and visualise data. You will be given a spreadsheet of data. \n",
    "#You will be given questions or instructions about the spreadsheet.  \n",
    "#\"\"\"\n",
    "\n",
    "pandasai_further_instructions = \"\"\"\n",
    "\n",
    "The columns starting with \"GPT question\" were previously entered by you. These columns likely have the information you need.\n",
    "\n",
    "You must not remove the columns entitiled \"Case name\" and \"Medium neutral citation\" from the spreadsheet. \n",
    "\"\"\"\n",
    "\n",
    "#If you need to use any modules to execute a code, import such modules first. \n",
    "\n",
    "#If you are asked to visualise your answer, provide the code for visualisation using Matplotlib. \n",
    "\n",
    "#If there are values which are \"nonetype\" objects, you ignore such values first. \n",
    "\n",
    "#If there are values which are \"list\" objects, you convert such values to \"string\" objects first. \n",
    "\n",
    "\n",
    "#visualisation = ' Everytime you are given a question or an instruction, try to provide the code to visualise your answer using Matplotlib.'\n",
    "\n",
    "pandasai_agent_description = default_agent_description + pandasai_further_instructions\n",
    "#If want to minimize technicality\n",
    "#pandasai_agent_description = 'You are a data analyst. Your main goal is to help non-technical users to clean, analyse and visualise data. You will be given a spreadsheet of data. Each column starting with \"GPT question\" was previously entered by you. You will be given questions or instructions about the spreadsheet.'\n",
    "\n",
    "#Common errors:\n",
    "#Value type <class 'list'> must match with type dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "338e9b2b-90ce-49e4-b200-1c7207b8da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing purposes\n",
    "\n",
    "def pandasai_ask_test():\n",
    "\n",
    "    with pandasai_get_openai_callback() as cb, st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...}}$\"):\n",
    "\n",
    "        #Get response and keep in session state\n",
    "\n",
    "        #prompt_to_process = prompt + \" Variables 'eval', 'ast' are already declared. \"\n",
    "        response = agent.chat(prompt)\n",
    "        st.session_state.response = response\n",
    "    \n",
    "        #Show response\n",
    "        st.subheader(f'{st.session_state.ai_choice} Response')\n",
    "        st.caption(spreadsheet_caption)\n",
    "    \n",
    "        if agent.last_error is not None:\n",
    "            st.error(response)\n",
    "\n",
    "        else:\n",
    "            st.write(response)\n",
    "\n",
    "        if '.png' in response:\n",
    "            st.image(response)\n",
    "\n",
    "        #Show any figure generated\n",
    "        st.write('**Visualisation**')\n",
    "\n",
    "        st.write('List')\n",
    "        st.write(plt.get_fignums())\n",
    "        \n",
    "        for fig_num in plt.get_fignums():\n",
    "            \n",
    "            fig_to_plot = plt.figure(fig_num)\n",
    "            \n",
    "            st.pyplot(fig = fig_to_plot)\n",
    "\n",
    "        st.write('Labels')\n",
    "        st.write(plt.get_figlabels())\n",
    "\n",
    "        for fig_label in plt.get_figlabels():\n",
    "            \n",
    "            fig_to_plot = plt.figure(fig_label)\n",
    "\n",
    "            st.pyplot(fig = fig_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51b55568-ba8a-4f9b-b932-6cc9cf9a665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandasai_ask():\n",
    "    \n",
    "    with pandasai_get_openai_callback() as cb, st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...}}$\"):\n",
    "\n",
    "        #Proess prompt\n",
    "        \n",
    "        prompt = st.session_state.prompt\n",
    "\n",
    "        #Get response and keep in session state\n",
    "\n",
    "        response = agent.chat(prompt)\n",
    "        st.session_state.response = response\n",
    "\n",
    "        #Keep record of prompt cost and tokens\n",
    "        prompt_tokens = cb.prompt_tokens\n",
    "        prompt_cost = prompt_tokens*gpt_input_cost(st.session_state.gpt_model)\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": prompt_cost, \"tokens\": prompt_tokens,   \"role\": \"user\", \"content\": {\"prompt\": prompt}})\n",
    "        \n",
    "        #Obtain response cost and tokens\n",
    "        response_cost = cb.total_cost - prompt_cost\n",
    "        response_tokens = cb.completion_tokens\n",
    "\n",
    "        #Show response\n",
    "        st.subheader(f'{st.session_state.ai_choice} Response')    \n",
    "        #st.write('*If you see an error, please modify your instructions or click :red[RESET] below and try again.*') # or :red[RESET] the AI.')\n",
    "\n",
    "        if agent.last_error is not None:\n",
    "            st.error(response)\n",
    "\n",
    "        else:\n",
    "            st.write(response)\n",
    "            \n",
    "        #Keep record of response, cost and tokens\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": response_cost, \"tokens\": response_tokens,   \"role\": \"assistant\", \"content\": {'answer': response}})\n",
    "\n",
    "        #Display caption if response is a dataframe\n",
    "        if isinstance(response, pd.DataFrame):\n",
    "            \n",
    "            st.caption(spreadsheet_caption)\n",
    "\n",
    "        #Check if any df produced\n",
    "        #if isinstance(st.session_state.response, pd.DataFrame):\n",
    "    \n",
    "            #col1b, col2b = st.columns(2, gap = 'small')\n",
    "    \n",
    "            #with col1b:\n",
    "                #pandasai_analyse_button = st.button('ANALYSE the spreadsheet produced only')\n",
    "            \n",
    "            #with col2b:\n",
    "                #pandasai_merge_button = st.button('MERGE with your spreadsheet')\n",
    "    \n",
    "            #if pandasai_analyse_button:                \n",
    "                #pandasai_analyse_df_produced()\n",
    "    \n",
    "            #if pandasai_merge_button:\n",
    "                \n",
    "                #pandasai_merge_df_produced()\n",
    "\n",
    "        #For all GPT models, show any figure generated\n",
    "        #st.write(f'The number of figures is {plt.get_fignums()}')\n",
    "\n",
    "        if (('.png' in str(response)[-4:]) or (plt.get_fignums())):\n",
    "            if plt.get_fignums():\n",
    "                try:\n",
    "                    #st.write('**Visualisation**')\n",
    "            \n",
    "                    fig_to_plot = plt.gcf()\n",
    "                    st.pyplot(fig = fig_to_plot)\n",
    "                    \n",
    "                    #Keep record of response, cost and tokens\n",
    "                    st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": {'matplotlib figure': fig_to_plot}})\n",
    "    \n",
    "                    #Enable downloading\n",
    "                    pdf_to_download = io.BytesIO()\n",
    "                    png_to_download = io.BytesIO()\n",
    "    \n",
    "                    col1e, col2e = st.columns(2, gap = 'small')\n",
    "                    \n",
    "                    with col1e:\n",
    "                \n",
    "                        plt.savefig(pdf_to_download, bbox_inches='tight', format = 'pdf')\n",
    "                        \n",
    "                        pdf_button = ste.download_button(\n",
    "                           label=\"DOWNLOAD as a PDF\",\n",
    "                           data=pdf_to_download,\n",
    "                           file_name='chart.pdf',\n",
    "                           mime=\"image/pdf\"\n",
    "                        )\n",
    "                    with col2e:\n",
    "                        plt.savefig(png_to_download, bbox_inches='tight', format = 'png')\n",
    "                        \n",
    "                        png_button = ste.download_button(\n",
    "                           label=\"DOWNLOAD as a PNG\",\n",
    "                           data=png_to_download,\n",
    "                           file_name='chart.png',\n",
    "                           mime=\"image/png\"\n",
    "                        )\n",
    "                    \n",
    "                    #Keep record of response, cost and tokens\n",
    "                    #st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": response_cost, \"tokens\": response_tokens,   \"role\": \"assistant\", \"content\": {'image': response}})\n",
    "        \n",
    "                except Exception as e:\n",
    "                        \n",
    "                    print(e)     \n",
    "\n",
    "\n",
    "            else: #If st.pyplot doesn't work\n",
    "                #st.write('image')\n",
    "                st.warning('Image produced but may not visualise properly.')\n",
    "                \n",
    "                st.image(image = response) #, use_column_width = 'never', output_format='png')                \n",
    "                \n",
    "                st.caption('Right click to save this image.')\n",
    "    \n",
    "        #For displaying logs\n",
    "        #st.subheader('Logs')\n",
    "        #df_logs = agent.logs\n",
    "        #st.dataframe(df_logs)\n",
    "        \n",
    "        #default explanation/cost cost and tokens\n",
    "        explanation_cost = float(0)\n",
    "        explanation_tokens = float(0)\n",
    "        code_cost = float(0)\n",
    "        code_tokens = float(0)\n",
    "        \n",
    "        #Explanations\n",
    "        #if st.session_state.explain_status is True:\n",
    "        if explain_toggle:\n",
    "    \n",
    "            explanation = agent.explain()\n",
    "            st.write('**Explanation**')\n",
    "            st.write(explanation)\n",
    "\n",
    "            #Display cost and tokens\n",
    "            explanation_cost = cb.total_cost - response_cost - prompt_cost\n",
    "            explanation_tokens = cb.total_tokens - response_tokens - prompt_tokens\n",
    "            \n",
    "            #Keep record of explanation\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": explanation_cost, \"tokens\": explanation_tokens,   \"role\": \"assistant\", \"content\": {'answer': explanation}})\n",
    "\n",
    "        #Code\n",
    "        #if st.session_state.code_status is True:\n",
    "        if code_toggle:\n",
    "            try:\n",
    "                code = agent.generate_code(prompt)\n",
    "                \n",
    "                st.write('**Code**')\n",
    "                st.code(code)\n",
    "    \n",
    "                #Display cost and tokens\n",
    "                code_cost = cb.total_cost - explanation_cost - response_cost - prompt_cost\n",
    "                code_tokens = cb.total_tokens -  explanation_tokens  - response_tokens - prompt_tokens\n",
    "    \n",
    "                #Keep record of code\n",
    "                st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": code_cost, \"tokens\": code_tokens,   \"role\": \"assistant\", \"content\": {'code': code}})\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.warning(f'{st.session_state.ai_choice} failed to produce a code.')\n",
    "                print(e)\n",
    "    \n",
    "        #Acivate if want to display tokens and costs only if own account active\n",
    "        #if st.session_state['own_account'] == True:\n",
    "        total_cost_tokens = f'(This exchange costed approximately USD $ {round(cb.total_cost, 5)} and totalled {cb.total_tokens} tokens.)'\n",
    "        st.write(total_cost_tokens)\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": {'answer': total_cost_tokens}})\n",
    "        \n",
    "        #Keep last processed prompt for input disabling purpose\n",
    "        st.session_state['last_prompt'] = prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccc36c90-1538-4d35-a81d-1be571bde4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buttons for importing any df produced    \n",
    "\n",
    "#For Pandasai\n",
    "\n",
    "def pandasai_analyse_df_produced():\n",
    "    st.session_state.df_produced = st.session_state.response\n",
    "    st.session_state.df_uploaded_key += 1\n",
    "    #st.session_state.df_uploaded = pd.DataFrame([])\n",
    "    #st.session_state.df_individual = pd.DataFrame([])\n",
    "    st.session_state.response = {}\n",
    "    #st.session_state[\"analyse_df_produced\"] = False\n",
    "    st.rerun()       \n",
    "\n",
    "def pandasai_merge_df_produced():\n",
    "\n",
    "    current_pd = st.session_state.edited_df\n",
    "    df_to_add = pd.DataFrame(data = st.session_state.response)\n",
    "    st.session_state.df_produced = current_pd.merge(df_to_add, on = 'Case name', how = 'left')\n",
    "    st.session_state.df_produced = st.session_state.df_produced.loc[:,~st.session_state.df_produced.columns.duplicated()].copy()\n",
    "    st.session_state.df_uploaded_key += 1\n",
    "    #st.session_state.df_uploaded = pd.DataFrame([])\n",
    "    #st.session_state.df_individual = pd.DataFrame([])\n",
    "    st.session_state.response = []\n",
    "    #st.session_state[\"merge_df_produced\"] = False\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f230d201-18f8-4b2e-a5d1-2da4d050a8cc",
   "metadata": {},
   "source": [
    "## LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a41b4253-a065-4a86-bfec-e64c90db0d22",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Got some ideas from https://dev.to/ngonidzashe/chat-with-your-csv-visualize-your-data-with-langchain-and-streamlit-ej7\n",
    "\n",
    "langchain_further_instructions = \"\"\"\n",
    "\n",
    "If you need to use any modules to execute a code, import such modules first. \n",
    "\n",
    "Your output should be in JSON form with three fields: \"text\", \"dataframe\" and \"code\". These are the only possible fields.\n",
    "\n",
    "If you are required to produce a table, format the table as a Pandas dataframe, and then place the dataframe in the \"dataframe\" field. Specifcially: {\"dataframe\": the Pandas dataframe from your ouput}.\n",
    "\n",
    "If you are required to produce a code,  provide the code in the \"code\" field. Specifcially: {\"code\": the code from your output}.\n",
    "\n",
    "Any output that is not a dataframe or a code should be placed in the \"text\" field. Specifically: {\"text\": anything that is not a dataframe or a code}.\n",
    "\n",
    "If you do not know how to answer the questions or instructions given, write {\"text\": \"Answer not found.\"}.\n",
    "\n",
    "You must not remove the columns entitiled \"Case name\" and \"Medium neutral citation\" from the spreadsheet. \n",
    "\n",
    "The questions or instructions are as follows: \n",
    "\"\"\"\n",
    "\n",
    "#Return all output as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89f603a7-b965-4431-b9e2-733ebb34a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def langchain_write(response_json):\n",
    "\n",
    "    if \"text\" in response_json:\n",
    "    \n",
    "        if response_json[\"text\"]:\n",
    "            \n",
    "            st.write(response_json[\"text\"])\n",
    "    \n",
    "    if \"dataframe\" in response_json:\n",
    "        \n",
    "        if response_json[\"dataframe\"]:\n",
    "        \n",
    "            st.dataframe(response_json[\"dataframe\"])\n",
    "\n",
    "            col1c, col2c = st.columns(2, gap = 'small')\n",
    "\n",
    "            with col1c:\n",
    "                langchain_analyse_button = st.button('ANALYSE the spreadsheet produced only')\n",
    "            \n",
    "            with col2c:\n",
    "                langchain_merge_button = st.button('MERGE with your spreadsheet')\n",
    "    \n",
    "            if langchain_analyse_button:\n",
    "                langchain_analyse_df_produced()\n",
    "    \n",
    "            if langchain_merge_button:\n",
    "                langchain_merge_df_produced()\n",
    "\n",
    "    if \"code\" in response_json:\n",
    "        \n",
    "        if response_json[\"code\"]:\n",
    "\n",
    "            #if st.session_state.explain_status == True:\n",
    "            \n",
    "            st.write(\"**Code**\")\n",
    "        \n",
    "            st.code(response_json[\"code\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb3960e5-6cfb-43c6-8639-26e9cbde0245",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Langchain ask function\n",
    "\n",
    "def langchain_ask():\n",
    "    with langchain_get_openai_callback() as cb, st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...}}$\"):\n",
    "\n",
    "        #Process prompt\n",
    "\n",
    "        prompt = st.session_state.prompt\n",
    "\n",
    "        prompt_to_process = langchain_further_instructions + prompt\n",
    "\n",
    "        if st.session_state.explain_status == True:\n",
    "            \n",
    "            prompt_to_process += ' Explain your answer in detail. '\n",
    "\n",
    "        if st.session_state.code_status == True:\n",
    "\n",
    "            prompt_to_process += ' Offer a code for obtaining your answer. '\n",
    "\n",
    "        response = agent.invoke(prompt_to_process)\n",
    "\n",
    "        #Keep record of tokens and costs\n",
    "        cost_tokens = f'(Cost: USD $ {round(cb.total_cost, 5)} Tokens: {cb.total_tokens})'\n",
    "\n",
    "        st.subheader(f'{st.session_state.ai_choice} Response')\n",
    "\n",
    "        #st.session_state.response = response.__str__()\n",
    "\n",
    "        #Keep record of prompt\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"user\", \"content\": {\"prompt\": prompt}})\n",
    "\n",
    "        try:\n",
    "\n",
    "            response_json = json.loads(response[\"output\"].__str__())\n",
    "\n",
    "            st.session_state.response_json = response_json\n",
    "\n",
    "            langchain_write(response_json)\n",
    "\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": cb.total_tokens,   \"role\": \"assistant\", \"content\": response_json})\n",
    "\n",
    "            #st.success('Converted to JSON successfully.')\n",
    "            \n",
    "        except:\n",
    "            #response_json_manual = '{\"text\": \"placeholder\"}'\n",
    "            #response_json = json.loads(response_json_manual)\n",
    "            #response_json['text'] = response[\"output\"]\n",
    "            #st.success('Manually converted to JSON')\n",
    "            #st.write(response[\"output\"])\n",
    "\n",
    "            st.warning('An error has occured. Please try again.')\n",
    "\n",
    "            #st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": cb.total_tokens,   \"role\": \"assistant\", \"content\": response[\"output\"]})\n",
    "\n",
    "        \n",
    "        #st.write('*If you see an error, please modify your instructions or click :red[RESET] below and try again.*') # or :red[RESET] the AI.')\n",
    "    \n",
    "        #Display tokens and costs\n",
    "        st.write(cost_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15fea1f1-7b62-4415-9aab-dd7ac30d4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buttons for importing or merging df produced\n",
    "\n",
    "def langchain_analyse_df_produced():\n",
    "    st.session_state.df_produced = pd.DataFrame(data = st.session_state.response_json[\"dataframe\"])\n",
    "    st.session_state.df_uploaded_key += 1\n",
    "    #st.session_state.df_uploaded = pd.DataFrame([])\n",
    "    #st.session_state.df_individual = pd.DataFrame([])\n",
    "    st.session_state.response_json[\"dataframe\"] = pd.DataFrame([])\n",
    "    st.rerun()\n",
    "\n",
    "def langchain_merge_df_produced():\n",
    "    \n",
    "    current_pd = st.session_state.edited_df\n",
    "    df_to_add = pd.DataFrame(data = st.session_state.response_json[\"dataframe\"])\n",
    "    st.session_state.df_produced = current_pd.merge(df_to_add, on = 'Case name', how = 'left')\n",
    "    st.session_state.df_produced = st.session_state.df_produced.loc[:,~st.session_state.df_produced.columns.duplicated()].copy()\n",
    "    st.session_state.df_uploaded_key += 1\n",
    "    #st.session_state.df_uploaded = pd.DataFrame([])\n",
    "    #st.session_state.df_individual = pd.DataFrame([])\n",
    "    st.session_state.response_json[\"dataframe\"] = pd.DataFrame([])\n",
    "    st.rerun()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d540b2dd-ebae-44b3-b351-00120d549019",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd266ac0-2bde-4537-a686-ef4d8c2bd161",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "724c9ac2-aec5-43bb-ac9f-364acf96a07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain columns with hyperlinks\n",
    "\n",
    "def link_headings_picker(df):\n",
    "    link_headings = []\n",
    "    for heading in df.columns:\n",
    "        if 'Hyperlink' in str(heading):\n",
    "            link_headings.append(heading)\n",
    "    return link_headings #A list of headings with hyperlinks\n",
    "\n",
    "#Reverse hyperlink display\n",
    "def reverse_link(x):\n",
    "    value = str(x).replace('=HYPERLINK(\"', '').replace('\")', '')\n",
    "    return value\n",
    "\n",
    "def clean_link_columns(df):\n",
    "        \n",
    "    link_headers_list = link_headings_picker(df)\n",
    "\n",
    "    for link_header in link_headers_list:\n",
    "        df[link_header] = df[link_header].apply(reverse_link)\n",
    "        \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fd30ba2-ebd4-411b-bb6c-cdea04e67561",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Excel to df with hyperlinks\n",
    "\n",
    "def excel_to_df_w_links(uploaded_file):\n",
    "\n",
    "    df = pd.read_excel(uploaded_file)\n",
    "    \n",
    "    wb = openpyxl.load_workbook(uploaded_file)\n",
    "    \n",
    "    sheets = wb.sheetnames\n",
    "    \n",
    "    ws = wb[sheets[0]]\n",
    "\n",
    "    columns_w_links = link_headings_picker(df)\n",
    "\n",
    "    for column in columns_w_links:\n",
    "        \n",
    "        column_index = list(df.columns).index(column) + 1 #Adding 1 because excel column starts with 1 not 0\n",
    "        \n",
    "        row_length = len(df)\n",
    "\n",
    "        for row in range(0, row_length):\n",
    "            \n",
    "            row_index = row + 2 #Adding 1 because excel non-heading row starts with 2 while pandas at 0\n",
    "            \n",
    "            try:\n",
    "\t            new_cell = ws.cell(row=row_index, column=column_index).hyperlink.target\n",
    "            \n",
    "            except:\n",
    "\n",
    "\t            new_cell = (str(ws.cell(row=row_index, column=column_index).value))\n",
    "            \n",
    "            df.loc[row, column] = new_cell\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "295070a7-e023-46ec-b28d-87a503ec1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For NSW, function for columns which are lists to strings:\n",
    "#NOT IN USE\n",
    "\n",
    "nsw_list_columns = ['Catchwords', 'Legislation cited', 'Cases cited', 'Texts cited', 'Parties', 'Representation', 'Decision under appeal'] \n",
    "\n",
    "#'Decision under appeal' is a dictionary but the values of some keys are lists\n",
    "\n",
    "def nsw_df_nsw_list_columns(df):\n",
    "    df_new = df.copy()\n",
    "\n",
    "    for heading in nsw_list_columns:\n",
    "        if heading in df.columns:\n",
    "            df_new[heading] = df[heading].astype(str)\n",
    "\n",
    "    return df_new\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "235dd22c-c674-4779-9c83-5abc099b6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain columns of lists\n",
    "\n",
    "def list_cols_picker(df):\n",
    "\n",
    "    list_columns = [] #Return list of columns which have list types\n",
    "    \n",
    "    columns_to_make_into_string_raw = df.applymap(lambda x: isinstance(x, list)).all()\n",
    "\n",
    "    columns_to_make_into_string = columns_to_make_into_string_raw.index[columns_to_make_into_string_raw].tolist()\n",
    "\n",
    "    for column in columns_to_make_into_string:\n",
    "        list_columns.append(column)\n",
    "    \n",
    "    return list_columns\n",
    "    \n",
    "def list_col_to_str(df):\n",
    "    \n",
    "    for column in list_cols_picker(df):\n",
    "\n",
    "        df[column] = df[column].astype(str)\n",
    "    \n",
    "    return df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6d67610-b8ae-4669-873e-4ca7da0156a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture columns with numerical data only and columns with non-numerical data only\n",
    "\n",
    "def num_non_num_headings_picker(df):\n",
    "    #Returns dictionary of numerical columns and non-numerical columns\n",
    "\n",
    "    num_non_num_cols_dict = {\"Numerical columns\": [], \"Non-numerical columns\": []}\n",
    "\n",
    "    nums_columns_raw = df.applymap(lambda x: isinstance(x, np.float32) or isinstance(x, float) or isinstance(x, int)).all()\n",
    "    \n",
    "    nums_columns = nums_columns_raw.index[nums_columns_raw].tolist()\n",
    "\n",
    "    non_nums_columns_raw = list(df.columns)\n",
    "\n",
    "    #Fill numerical columns with empty integer type\n",
    "    \n",
    "    for col in nums_columns:\n",
    "        \n",
    "        #df[col].fillna(int(), inplace = True) #Activate if wannt to replace nonetype cells in numerical columns with 0\n",
    "        \n",
    "        non_nums_columns_raw.remove(col)\n",
    "\n",
    "        num_non_num_cols_dict[\"Numerical columns\"].append(col)\n",
    "    \n",
    "    for column in non_nums_columns_raw:\n",
    "\n",
    "        num_non_num_cols_dict[\"Non-numerical columns\"].append(column)\n",
    "        \n",
    "    return num_non_num_cols_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "386445c3-37ae-48d9-9742-ca7a2a17140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_num_fill_blank(df):\n",
    "\n",
    "    non_nums_columns = num_non_num_headings_picker(df)[\"Non-numerical columns\"]  \n",
    "    \n",
    "    #Fill non-numerical columns with empty string type\n",
    "\n",
    "    for column in non_nums_columns:\n",
    "        \n",
    "        df[column].fillna('', inplace = True)\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "650c71d1-1f5a-4783-b5fb-81e5210c0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_num_fill_blank(df):\n",
    "\n",
    "    nums_columns = num_non_num_headings_picker(df)[\"Numerical columns\"]\n",
    "\n",
    "    #Fill numerical columns with integer type 0\n",
    "    for col in nums_columns:\n",
    "        \n",
    "        df[col].fillna(int(0), inplace = True) #Activate if wannt to replace nonetype cells in numerical columns with 0\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58690ed3-da87-4880-bbf6-a06b94bb69e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache_except_validation():\n",
    "    keys = list(st.session_state.keys())\n",
    "    for key in keys:\n",
    "        if key != 'gpt_api_key_validity': #Remove this line if wants to clear key validation as well\n",
    "            st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b5a2392-d430-4aec-ae92-ccd440ce76ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_most_cache():\n",
    "    keys = list(st.session_state.keys())\n",
    "    #These are the keys to KEEP upon clearing\n",
    "    for key_to_keep in ['gpt_api_key_validity', 'messages', 'df_uploaded_key', 'page_from']: \n",
    "        try:\n",
    "            keys.remove('key_to_keep')\n",
    "        except:\n",
    "            print(f\"No {'key_to_keep'} in session state.\")\n",
    "\n",
    "    for key in keys:\n",
    "        st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73bd94-681c-455f-82dc-a9f7d77dbfd9",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d9a6808-56f8-4e87-a5df-f7be2218bdab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The default maximum number of instructions per thread is 10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize default values\n",
    "\n",
    "# Initialize chat history\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "if 'df_individual' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "\n",
    "#Initalize df_uploaded:\n",
    "if 'df_uploaded' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_uploaded'] = pd.DataFrame([])\n",
    "\n",
    "#Initalize df_uploaded_key for the purpose of removing uploaded spreadsheets programatically\n",
    "if \"df_uploaded_key\" not in st.session_state:\n",
    "    st.session_state[\"df_uploaded_key\"] = 0\n",
    "\n",
    "#Initalize df_produced:\n",
    "if 'df_produced' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_produced'] = pd.DataFrame([])\n",
    "\n",
    "#Initalize st.session_state.df_to_analyse:\n",
    "if 'st.session_state.df_to_analyse' not in st.session_state:\n",
    "\n",
    "    st.session_state['st.session_state.df_to_analyse'] = pd.DataFrame([])\n",
    "\n",
    "#Initalize edited_df:\n",
    "if 'edited_df' not in st.session_state:\n",
    "\n",
    "    st.session_state['edited_df'] = pd.DataFrame([])\n",
    "\n",
    "#Initialize default instructions bound\n",
    "\n",
    "default_instructions_bound = 10\n",
    "\n",
    "print(f\"The default maximum number of instructions per thread is {default_instructions_bound}.\\n\")\n",
    "\n",
    "#Initialize instructions cap\n",
    "\n",
    "if 'instructions_bound' not in st.session_state:\n",
    "    st.session_state['instructions_bound'] = default_instructions_bound\n",
    "\n",
    "#Initialize instructions counter\n",
    "\n",
    "if 'instruction_left' not in st.session_state:\n",
    "\n",
    "    st.session_state[\"instruction_left\"] = default_instructions_bound\n",
    "\n",
    "#Initialize default explain status\n",
    "\n",
    "#if 'explain_status' not in st.session_state:\n",
    "    #st.session_state[\"explain_status\"] = False\n",
    "\n",
    "#Initialize default show code status\n",
    "\n",
    "#if 'code_status' not in st.session_state:\n",
    "    #st.session_state[\"code_status\"] = False\n",
    "\n",
    "#Initialize default own account status\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "#Initilize default gpt model\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "\n",
    "#Initialize responses\n",
    "\n",
    "#For pandas ai\n",
    "if 'response' not in st.session_state:\n",
    "    st.session_state[\"response\"] = ''\n",
    "\n",
    "#For langchain\n",
    "if 'response_json' not in st.session_state:\n",
    "    st.session_state[\"response_json\"] = {}\n",
    "\n",
    "#initialize prompt\n",
    "if 'prompt' not in st.session_state:\n",
    "    st.session_state[\"prompt\"] = ''\n",
    "\n",
    "#Initialize clarifyng questions and answers\n",
    "\n",
    "if 'clarifying_questions' not in st.session_state:\n",
    "    st.session_state[\"clarifying_questions\"] = ['', '', '']\n",
    "\n",
    "if 'clarifying_answers' not in st.session_state:\n",
    "    st.session_state[\"clarifying_answers\"] = ['', '', '']\n",
    "\n",
    "#Initialize enhanced prompt\n",
    "if 'prompt_prefill' not in st.session_state:\n",
    "    st.session_state[\"prompt_prefill\"] = ''\n",
    "\n",
    "#Initialize clarifying questions and answers status\n",
    "if 'q_and_a_provided' not in st.session_state:\n",
    "    st.session_state['q_and_a_provided'] = False\n",
    "\n",
    "#Initialize clarifying questions and answers toggle\n",
    "if 'q_and_a_toggle' not in st.session_state:\n",
    "    st.session_state[\"q_and_a_toggle\"] = False\n",
    "\n",
    "#initialize spreadsheet produced to analyse or merge\n",
    "\n",
    "#if 'analyse_df_produced' not in st.session_state:\n",
    "    #st.session_state[\"analyse_df_produced\"] = False\n",
    "\n",
    "#if 'merge_df_produced' not in st.session_state:\n",
    "    #st.session_state[\"merge_df_produced\"] = False\n",
    "\n",
    "#Last prompt\n",
    "if 'last_prompt' not in st.session_state:\n",
    "    st.session_state['last_prompt'] = ''\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd1560-b1c6-4f36-82b2-60120a02116b",
   "metadata": {},
   "source": [
    "## Form before choosing AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "055e9c31-a730-4316-8194-6feee644cf90",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "extra_spreadsheet_warning = 'Another spreadsheet has already been imported. Please :red[REMOVE] that one first.'\n",
    "spreadsheet_success = 'Your spreadsheet has been imported. Please scroll down.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc9a26f9-5092-42cc-a64c-de2415bf5aaf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 14:42:24.911 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"df_individual_output\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:398\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:443\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_session_state()[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:91\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:400\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"df_individual_output\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m st\u001b[38;5;241m.\u001b[39mcaption(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPandasAI, [an open-source Python library](https://github.com/Sinaptik-AI/pandas-ai), provides the framework for analysing your spreadsheet with AI.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#Open spreadsheet and personal details\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_individual_output) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_produced) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     15\u001b[0m         st\u001b[38;5;241m.\u001b[39msuccess(spreadsheet_success)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"df_individual_output\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "if st.button('RETURN to previous page'):\n",
    "    \n",
    "    if st.session_state.page_from != 'Home.py':\n",
    "        st.switch_page(st.session_state.page_from)\n",
    "        \n",
    "    else:\n",
    "        st.switch_page('Home.py')\n",
    "\n",
    "st.header(\"You have chosen to :blue[analyse a spreadsheet].\")\n",
    "\n",
    "st.caption(f'[PandasAI](https://github.com/Sinaptik-AI/pandas-ai) provides the framework for analysing your spreadsheet with an AI.')\n",
    "\n",
    "#Open spreadsheet and personal details\n",
    "\n",
    "if len(st.session_state.df_individual) > 0:\n",
    "    \n",
    "    if len(st.session_state.df_produced) == 0:\n",
    "\n",
    "        st.success(spreadsheet_success)\n",
    "\n",
    "    else:\n",
    "\n",
    "        st.warning(extra_spreadsheet_warning)\n",
    "        \n",
    "else: #if len(st.session_state.df_individual) == 0:\n",
    "\n",
    "    st.markdown(\"\"\"**:green[Please upload a spreadsheet.]** Supported formats: CSV, XLSX, JSON.\"\"\")\n",
    "    \n",
    "    uploaded_file = st.file_uploader(label = \"You may upload a spreadsheet generated by LawtoData. The CSV format is preferred.\", \n",
    "                                     type=['csv', 'xlsx', 'json'], \n",
    "                                     accept_multiple_files=False, \n",
    "                                     key = st.session_state[\"df_uploaded_key\"]\n",
    "                                    )\n",
    "\n",
    "    if uploaded_file:\n",
    "        \n",
    "        #Get uploaded file extension\n",
    "        extension = uploaded_file.name.split('.')[-1].lower()\n",
    "        \n",
    "        if extension == 'csv':\n",
    "            df_uploaded = pd.read_csv(uploaded_file)\n",
    "    \n",
    "        if extension == 'xlsx':\n",
    "            \n",
    "            #df_uploaded = pd.read_excel(uploaded_file)\n",
    "            \n",
    "            df_uploaded = excel_to_df_w_links(uploaded_file)\n",
    "    \n",
    "        if extension == 'json':\n",
    "            \n",
    "            df_uploaded = pd.read_json(uploaded_file, orient= 'split')\n",
    "\n",
    "        st.session_state.df_uploaded = df_uploaded\n",
    "\n",
    "        if len(st.session_state.df_produced) == 0:\n",
    "        \n",
    "            st.success(spreadsheet_success)\n",
    "\n",
    "        else:\n",
    "\n",
    "            st.warning(extra_spreadsheet_warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b93d23-fae0-4163-a92f-c69517c7ea33",
   "metadata": {},
   "source": [
    "## Choice of AI and GPT account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a0ab979-ca91-4c8b-bd0a-467aa5600f2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'own_account_allowed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mai_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPT\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m own_account_allowed() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mai_choice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBambooLLM\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     34\u001b[0m         st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:orange[Enhance program capabilities]\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'own_account_allowed' is not defined"
     ]
    }
   ],
   "source": [
    "if len(ai_list_raw) > 1:\n",
    "\n",
    "    st.subheader('Choose an AI')\n",
    "\n",
    "    st.markdown(\"\"\"Please choose an AI to help with data cleaning, analysis and visualisation.\n",
    "    \"\"\")\n",
    "    \n",
    "    ai_choice = st.selectbox(label = f'{default_ai} is selected by default.', options = ai_list_raw, index=default_ai_index)\n",
    "    \n",
    "    if ai_choice != st.session_state.ai_choice:\n",
    "        #pai.clear_cache()\n",
    "        st.session_state['ai_choice'] = ai_choice\n",
    "        st.rerun()\n",
    "        \n",
    "    st.markdown(\"\"\"\n",
    "    GPT can be interactive. LangChain is more agile but can't produce charts.\n",
    "\"\"\")\n",
    "# BambooLLM is developed for data analysis (see https://docs.pandas-ai.com/en/stable/).\n",
    "    \n",
    "\n",
    "    if st.toggle(f'See the instruction given to {st.session_state.ai_choice}'):\n",
    "        \n",
    "        st.write(f\"*{default_agent_description}*\")\n",
    "\n",
    "else:\n",
    "    st.session_state.ai_choice = 'GPT'\n",
    "\n",
    "#if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "\n",
    "    if st.session_state.ai_choice != 'BambooLLM':\n",
    "    \n",
    "        st.subheader(':orange[Enhance app capabilities]')\n",
    "        \n",
    "        st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of instructions to process? You can do so with your own GPT account.\n",
    "        \"\"\")\n",
    "        \n",
    "        own_account_entry = st.toggle('Use my own GPT account')\n",
    "        \n",
    "        if own_account_entry:\n",
    "            \n",
    "            st.session_state['own_account'] = True\n",
    "        \n",
    "            st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "\"\"\")\n",
    "                \n",
    "            name_entry = st.text_input(label = \"Your name\", value = st.session_state.df_master.loc[0, 'Your name'])\n",
    "    \n",
    "            if name_entry:\n",
    "                st.session_state.df_master.loc[0, 'Your name'] = name_entry\n",
    "            #else:\n",
    "                #st.session_state.df_master.loc[0, 'Your name'] = st.session_state.name_entry\n",
    "            \n",
    "            email_entry = st.text_input(label = \"Your email address\", value = st.session_state.df_master.loc[0, 'Your email address'])\n",
    "\n",
    "            if email_entry:\n",
    "                st.session_state.df_master.loc[0, 'Your email address'] = email_entry\n",
    "            #else:\n",
    "                #st.session_state.df_master.loc[0, 'Your email address'] = st.session_state.email_entry\n",
    "\n",
    "            gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.df_master.loc[0, 'Your GPT API key'])\n",
    "\n",
    "            if gpt_api_key_entry:\n",
    "                \n",
    "                st.session_state.df_master.loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "\n",
    "                if ((len(gpt_api_key_entry) < 40) or (gpt_api_key_entry[0:2] != 'sk')):\n",
    "                    \n",
    "                    st.warning('This key is not valid.')\n",
    "\n",
    "            #else:\n",
    "                \n",
    "                #st.session_state.df_master.loc[0, 'Your GPT API key'] = st.session_state.gpt_api_key_entry\n",
    "            \n",
    "            #valdity_check = st.button('VALIDATE your API key')\n",
    "        \n",
    "            #if valdity_check:\n",
    "                \n",
    "                #api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                        \n",
    "                #if api_key_valid == False:\n",
    "                    #st.session_state['gpt_api_key_validity'] = False\n",
    "                    #st.error('Your API key is not valid.')\n",
    "                    \n",
    "                #else:\n",
    "                    #st.session_state['gpt_api_key_validity'] = True\n",
    "                    #st.success('Your API key is valid.')\n",
    "        \n",
    "            st.markdown(\"\"\"**:green[You can use the flagship version of GPT model (gpt-4o),]** which is :red[about 30 times more expensive, per character] than the default model (gpt-4o-mini) which you can use for free.\"\"\")  \n",
    "            \n",
    "            gpt_enhancement_entry = st.checkbox('Use the flagship GPT model', value = False)\n",
    "            st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "            \n",
    "            if gpt_enhancement_entry == True:\n",
    "                #Reset AI first\n",
    "                pai.clear_cache()\n",
    "            \n",
    "                st.session_state.gpt_model = \"gpt-4o\"\n",
    "                st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = True\n",
    "    \n",
    "            else:\n",
    "                #Reset AI first\n",
    "                pai.clear_cache()\n",
    "                \n",
    "                st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "                st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "            \n",
    "            st.write(f'**:green[You can remove the cap on the number of instructions to process.]** The default cap is {default_instructions_bound}.')\n",
    "                \n",
    "            drop_instructions_bound = st.button('REMOVE the cap on the number of instructions')\n",
    "        \n",
    "            if drop_instructions_bound:\n",
    "        \n",
    "                st.session_state.instructions_bound = 999\n",
    "                st.session_state.instruction_left = 999\n",
    "        \n",
    "            #st.session_state.instruction_left = st.session_state.instructions_bound\n",
    "        \n",
    "        else:\n",
    "            st.session_state['own_account'] = False\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "            st.session_state.instructions_bound = default_instructions_bound\n",
    "        \n",
    "            st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "            \n",
    "            print('User GPT API key not entered. Using own API key instead.')\n",
    "    \n",
    "    else:\n",
    "        st.session_state['own_account'] = False\n",
    "        st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "else:\n",
    "    print('Users are NOT allowed to use their own accounts.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d28de1-dabf-4c0f-b1c6-f46df81fd978",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82b58031-d08a-4cfd-969a-c57f492dcf2d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeltaGenerator()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.subheader(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By using this app, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91eb7207-52a4-47e7-8eb1-b89cb1cece23",
   "metadata": {},
   "source": [
    "## Spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9752865b-8b95-43f9-aa25-7bab0cd342a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"df_produced\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:398\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:443\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_session_state()[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:91\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:400\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"df_produced\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Order of spreadsheet to analyse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_produced) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_to_analyse \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_produced\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_individual_output) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"df_produced\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#Order of spreadsheet to analyse\n",
    "if len(st.session_state.df_produced) > 0:\n",
    "    st.session_state.df_to_analyse = st.session_state.df_produced\n",
    "    \n",
    "elif len(st.session_state.df_individual) > 0:\n",
    "    \n",
    "    st.session_state.df_to_analyse = st.session_state.df_individual\n",
    "\n",
    "else: #len(st.session_state.df_uploaded) > 0:\n",
    "    \n",
    "    st.session_state.df_to_analyse = st.session_state.df_uploaded\n",
    "\n",
    "#Check if any spreadsheet is available for analysis\n",
    "if len(st.session_state.df_to_analyse) == 0:\n",
    "\n",
    "    st.warning('Please upload a spreadsheet.')\n",
    "    quit()\n",
    "\n",
    "st.subheader('Your spreadsheet')\n",
    "\n",
    "#AI warning\n",
    "if st.session_state.ai_choice == 'GPT':\n",
    "\n",
    "    if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "        st.warning(\"A low-cost GPT model will process your spreadsheet and instructions. This model is *not* optimised for data analysis. Please email Ben Chen at ben.chen@sydney.edu.au if you'd like to use a better model.\")\n",
    "\n",
    "    if st.session_state.gpt_model == \"gpt-4o\":\n",
    "        st.warning(f'An expensive GPT model will process your spreadsheet and instructions.')\n",
    "    \n",
    "else: #if st.session_state.ai_choice == 'BambooLLM':\n",
    "    st.warning('An experimental AI model will process your spreadsheet and instructions. Please be cautious.')\n",
    "\n",
    "spreadsheet_caption = 'To download, search within or maximise any spreadsheet, hover your mouse/pointer over its top right-hand corner.' # and click the appropriate button.'\n",
    "\n",
    "st.caption(spreadsheet_caption)\n",
    "\n",
    "#Errors to show later\n",
    "\n",
    "conversion_msg_to_show = ''\n",
    "\n",
    "#Last resort error, unlikely displayed\n",
    "everything_error_to_show = 'Failed to make spreadsheet editable. '\n",
    "\n",
    "#Obtain clolumns with hyperlinks\n",
    "\n",
    "link_heading_config = {} \n",
    "\n",
    "link_headings_list = link_headings_picker(st.session_state.df_to_analyse)\n",
    "\n",
    "#try:\n",
    "        \n",
    "for link_heading in link_headings_list:\n",
    "    \n",
    "    link_heading_config[link_heading] = st.column_config.LinkColumn(display_text = 'Click')\n",
    "\n",
    "st.session_state.df_to_analyse = clean_link_columns(st.session_state.df_to_analyse)\n",
    "\n",
    "    #except Exception as e:\n",
    "\n",
    "        #links_error = 'Hyperlinks have not been made clickable. '\n",
    "\n",
    "        #conversion_msg_to_show += links_error\n",
    "        \n",
    "        #print(links_error)\n",
    "        \n",
    "        #print(e)\n",
    "\n",
    "#Convert columns which are list type to string type\n",
    "try:\n",
    "    #Must do this because pandasai won't work with lists\n",
    "\n",
    "    list_cols = list_cols_picker(st.session_state.df_to_analyse)\n",
    "    \n",
    "    st.session_state.df_to_analyse = list_col_to_str(st.session_state.df_to_analyse)\n",
    "\n",
    "    #st.session_state[\"edited_df\"] = st.data_editor(st.session_state.df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "    if len(list_cols) > 0:\n",
    "\n",
    "        list_cols_error_msg = 'Lists have been converted to string (ie plain text). '\n",
    "        \n",
    "        conversion_msg_to_show += list_cols_error_msg\n",
    "        \n",
    "except Exception as e_list:\n",
    "\n",
    "    #print('Cannot display df without converting non-numeric data to string.' )\n",
    "\n",
    "    print('Cannot convert list columns to string.' )\n",
    "\n",
    "    print(e_list)\n",
    "\n",
    "#Try to display df without some conversion to string\n",
    "try:\n",
    "    \n",
    "    st.session_state[\"edited_df\"] = st.data_editor(st.session_state.df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print('Cannot display df without some conversion.' )\n",
    "    \n",
    "    print(e)\n",
    "    \n",
    "    #Try to convert all numerical data to string type\n",
    "    try:\n",
    "\n",
    "        non_num_cols = num_non_num_headings_picker(st.session_state.df_to_analyse)[\"Non-numerical columns\"]\n",
    "\n",
    "        st.session_state.df_to_analyse[non_num_cols] = st.session_state.df_to_analyse[non_num_cols].astype(str)\n",
    "\n",
    "        st.session_state[\"edited_df\"] = st.data_editor(st.session_state.df_to_analyse,  column_config=link_heading_config)\n",
    "\n",
    "        if len(non_num_cols) > 0:\n",
    "        \n",
    "            non_num_error_msg ='Non-numeric data have been converted to plain text. '\n",
    "    \n",
    "            conversion_msg_to_show += non_num_error_msg\n",
    "    \n",
    "        #Activate below if wants to convert non-numerical columns with nonetype cells to empty string type\n",
    "        \n",
    "        #st.session_state.df_to_analyse = non_num_fill_blank(st.session_state.df_to_analyse)\n",
    "        \n",
    "        #if len(num_non_num_headings_picker(st.session_state.df_to_analyse)[\"Non-numerical columns\"]) > 0:\n",
    "    \n",
    "            #non_num_cols_error = 'Nonetype cells in non-numerical columns have been converted to empty strings. '\n",
    "                    \n",
    "            #conversion_msg_to_show += non_num_cols_error\n",
    "\n",
    "    except Exception as e_numeric:\n",
    "        \n",
    "        print('Cannot display df without converting everything to string.' )\n",
    "\n",
    "        print(e_numeric)\n",
    "\n",
    "        try:\n",
    "        \n",
    "            st.session_state.df_to_analyse = st.session_state.df_to_analyse.astype(str)\n",
    "    \n",
    "            st.session_state[\"edited_df\"] = st.data_editor(st.session_state.df_to_analyse,  column_config=link_heading_config)\n",
    "    \n",
    "            non_textual_error_to_show = 'Non-textual data have been converted to plain text. '\n",
    "        \n",
    "            conversion_msg_to_show += non_textual_error_to_show\n",
    "\n",
    "        except Exception as e_non_text:\n",
    "\n",
    "            print('Cannot make df editable at all.' )\n",
    "    \n",
    "            print(e_numeric)\n",
    "\n",
    "            st.session_state[\"edited_df\"] = st.dataframe(st.session_state.df_to_analyse,  column_config=link_heading_config)\n",
    "    \n",
    "            conversion_msg_to_show += everything_error_to_show\n",
    "\n",
    "#Tell users that the spreadsheet is editable if it indeed is\n",
    "\n",
    "if everything_error_to_show not in conversion_msg_to_show:\n",
    "\n",
    "    st.write('You can directly edit this spreadsheet.')\n",
    "\n",
    "#New spreadsheet button\n",
    "\n",
    "#if st.button('UPLOAD a new spreadsheet'):\n",
    "    #st.session_state.df_uploaded_key += 1\n",
    "    #clear_most_cache()\n",
    "    #st.rerun()\n",
    "\n",
    "#Show remove button\n",
    "if st.button('REMOVE this spreadsheet', type = 'primary'):\n",
    "    \n",
    "    st.session_state.df_uploaded_key += 1\n",
    "    \n",
    "    for df_key in {'df_produced', 'df_individual', 'df_uploaded'}:\n",
    "        \n",
    "        if isinstance(st.session_state[df_key], pd.DataFrame):\n",
    "\n",
    "            if st.session_state[df_key].sort_index(inplace=True) == (st.session_state.edited_df.sort_index(inplace=True)):\n",
    "            #(\n",
    "                #st.session_state[df_key].equals(st.session_state.edited_df) or\n",
    "                #(st.session_state[df_key].sort_index(inplace=True) == (st.session_state.edited_df.sort_index(inplace=True)))\n",
    "               #):\n",
    "                st.session_state.pop(df_key)\n",
    "                st.write(f'{df_key} removed.')\n",
    "                #pause.seconds(5)\n",
    "\n",
    "    #Disable unnecessary buttons and pre-filled prompt\n",
    "    conversion_msg_to_show = ''\n",
    "    st.session_state['prompt_prefill'] = ''\n",
    "    st.session_state['q_and_a_provided'] = False\n",
    "    st.session_state.q_and_a_toggle = False\n",
    "\n",
    "    st.rerun()\n",
    "\n",
    "#Display error or success messages\n",
    "if ((len(conversion_msg_to_show) > 0) or (len(st.session_state.df_produced) > 0) or ( st.session_state.q_and_a_provided == True)):\n",
    "    \n",
    "    if st.toggle(label = 'Display messages', value = True):\n",
    "    \n",
    "        if len(conversion_msg_to_show) > 0:\n",
    "            st.warning(conversion_msg_to_show)\n",
    "    \n",
    "        #Note importation of AI produced spreadsheet\n",
    "        if len(st.session_state.df_produced) > 0:\n",
    "            st.success(f'The spreadsheet produced by {st.session_state.ai_choice} has been imported.')\n",
    "    \n",
    "        if st.session_state.q_and_a_provided == True:\n",
    "            st.success('Your clarifying answers have been added to your instructions. Please click ASK again.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858dbaca-88d3-4177-83e2-5e2481c035b2",
   "metadata": {},
   "source": [
    "## AI activation and prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be33916-6aa6-4124-b132-68e329d98548",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Activate AI\n",
    "\n",
    "#try:\n",
    "    #llm = llm_setting(st.session_state.ai_choice, st.session_state.gpt_api_key, st.session_state.gpt_model)\n",
    "    #agent = agent_alt(llm, st.session_state.ai_choice, st.session_state.instructions_bound, st.session_state.edited_df)\n",
    "\n",
    "#except Exception as e:\n",
    "    #st.error('Please double-check your API key.')\n",
    "    #st.exception(e)\n",
    "    #quit()\n",
    "\n",
    "try:\n",
    "    agent = agent(ai_choice = st.session_state.ai_choice, \n",
    "                  key = st.session_state.gpt_api_key, \n",
    "                  gpt_model_choice = st.session_state.gpt_model, \n",
    "                  instructions_bound = st.session_state.instructions_bound, \n",
    "                  df = st.session_state.edited_df,\n",
    "                 )\n",
    "\n",
    "except Exception as e:\n",
    "    st.error('Please double-check your API key.')\n",
    "    st.exception(e)\n",
    "    quit()\n",
    "\n",
    "#Area for entering instructions\n",
    "st.subheader(f'Enter your instructions for {st.session_state.ai_choice}')\n",
    "\n",
    "st.write(f':green[Please give your instructions in sequence.] {ai_model_printing(st.session_state.ai_choice, st.session_state.gpt_model)} will respond to at most {st.session_state.instructions_bound} instructions. It will **only** use  the data and/or information from your spreadsheet.')\n",
    "\n",
    "prompt = st.text_area(f'You may enter at most {question_characters_bound} characters.', value = st.session_state.prompt_prefill, height= 200, max_chars=question_characters_bound) \n",
    "\n",
    "st.session_state.prompt = prompt\n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if prompt:\n",
    "    if prompt != st.session_state.last_prompt:\n",
    "        st.session_state['disable_input'] = False\n",
    "    \n",
    "    else:\n",
    "        st.session_state['disable_input'] = True\n",
    "\n",
    "else:\n",
    "    st.session_state['disable_input'] = True\n",
    "\n",
    "st.caption(\"Please reach out to Ben Chen at ben.chen@sydney.edu.au if you'd like give more or longer instructions.\")\n",
    "\n",
    "#Disable toggle for clarifying questions and answers BEFORE asking AI again\n",
    "if st.session_state.q_and_a_provided == True:\n",
    "    st.session_state.q_and_a_toggle = False\n",
    "    #Remove prefill after importation\n",
    "    #st.session_state['prompt_prefill'] = ''\n",
    "\n",
    "#Generate explain button\n",
    "if st.session_state.ai_choice in {'GPT', 'LangChain'}:\n",
    "\n",
    "    col1, col2, col3, col4 = st.columns(4, gap = 'small')\n",
    "\n",
    "    with col1:\n",
    "        #Explain \n",
    "        explain_toggle = st.toggle('Explain', help = f'Get {st.session_state.ai_choice} to explain its response.', disabled = st.session_state.disable_input)\n",
    "    \n",
    "        #if explain_toggle:\n",
    "            #st.session_state.explain_status = True\n",
    "        #else:\n",
    "            #st.session_state.explain_status = False\n",
    "\n",
    "    with col2:\n",
    "        #Get code \n",
    "        code_toggle = st.toggle('Code', help = f'Get {st.session_state.ai_choice} to produce a code.', disabled = st.session_state.disable_input)\n",
    "    \n",
    "        #if code_toggle:\n",
    "            #st.session_state.code_status = True\n",
    "        #else:\n",
    "            #st.session_state.code_status = False\n",
    "    \n",
    "    #with col3:\n",
    "        #history_on = st.toggle(label = 'Chat history', help = 'Display all instructions and responses.')\n",
    "\n",
    "        #Clarification questions toggle\n",
    "        #if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "            #if len(str(st.session_state.response)) > 0:\n",
    "            #clarification_questions_toggle = st.toggle(label = 'Suggestions', value = 'q_and_a_toggle', help = f'Get clarifying questions to help draft your questions or instructions.')\n",
    "        \n",
    "#else:\n",
    "    #st.session_state.explain_status = False\n",
    "    #st.session_state.code_status = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95312243-9f03-4553-8af2-c8fe9192fd26",
   "metadata": {},
   "source": [
    "## Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7a97ae-8af6-4a07-928a-f2117eebc651",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#col1a, col2a, col3a, col4a = st.columns(4, gap = 'small')\n",
    "\n",
    "#with col1a:\n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "    ask_button = st.button(\"ASK\", disabled = st.session_state.disable_input, help = 'You may need to press :red[RESET] before asking GPT.')\n",
    "\n",
    "#with col2a:\n",
    "reset_button = st.button('RESET', type = 'primary', disabled = bool(len(str(st.session_state.response)) == 0))#, help = f\"Get fresh responses from {st.session_state.ai_choice}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be79e726-d8d9-4862-ad31-96f88ad0eafc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ask_button' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Generate output\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#if st.button('Test'):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#if st.button(\"ASK\"):\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mask_button\u001b[49m:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mint\u001b[39m(consent) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     21\u001b[0m         st\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must click on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes, I agree.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ask_button' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate output\n",
    "\n",
    "#if st.button('Test'):\n",
    "\n",
    "    #pandasai_ask_test()\n",
    "\n",
    "    #st.dataframe(st.session_state.edited_df)\n",
    "\n",
    "    #non_num_cols = num_non_num_headings_picker(st.session_state.df_to_analyse)[\"Non-numerical columns\"]\n",
    "\n",
    "    #st.session_state.edited_df[non_num_cols] = st.session_state.edited_df[non_num_cols].astype(str)\n",
    "\n",
    "    #st.dataframe(st.session_state.edited_df)\n",
    "\n",
    "\n",
    "#if st.button(\"ASK\"):\n",
    "\n",
    "if ask_button:\n",
    "\n",
    "    if int(consent) == 0:\n",
    "        st.warning(\"You must tick '[y]es, I agree[]' to use the app.\")\n",
    "        quit()\n",
    "\n",
    "    elif st.session_state.instruction_left == 0:\n",
    "        no_more_instructions = 'You have reached the maximum number of instructions allowed during the pilot stage.'\n",
    "        st.error(no_more_instructions)\n",
    "        \n",
    "        #Keep record of response\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": {'error': no_more_instructions}})\n",
    "\n",
    "        quit()\n",
    "\n",
    "    elif len(st.session_state.prompt) == 0:\n",
    "        st.warning(\"Please enter some instruction.\")\n",
    "\n",
    "        quit()\n",
    "\n",
    "    else:\n",
    "\n",
    "        #Check GPT API key validity if activated\n",
    "        \n",
    "        if ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "                    \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                \n",
    "                st.session_state['gpt_api_key_validity'] = False\n",
    "                \n",
    "                st.error('Your API key is not valid.')\n",
    "    \n",
    "                quit()\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                st.session_state['gpt_api_key_validity'] = True\n",
    "    \n",
    "        #Change q_and_a_provided status\n",
    "        st.session_state['q_and_a_provided'] = False\n",
    "        #Close clarifying questions form\n",
    "        st.session_state[\"q_and_a_toggle\"] = False\n",
    "        #clarification_questions_toggle = False\n",
    "\n",
    "        if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "            \n",
    "            pandasai_ask()\n",
    "\n",
    "        else: #if st.session_state.ai_choice == 'LangChain':\n",
    "\n",
    "            langchain_ask()\n",
    "                        \n",
    "        #Display number of instructionsl left\n",
    "        st.session_state.instruction_left -= 1\n",
    "        instructions_left_text = f\"*You have :orange[{st.session_state.instruction_left}] instructions left.*\"\n",
    "        st.write(instructions_left_text)\n",
    "\n",
    "        #Keep record of instructions left\n",
    "        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": {'answer': instructions_left_text}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5deb3f-540a-4dc0-a996-f5be8c086ee5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Buttons for importing any df produced    \n",
    "\n",
    "#For Pandasai\n",
    "if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "\n",
    "    if isinstance(st.session_state.response, pd.DataFrame):\n",
    "\n",
    "        col1b, col2b = st.columns(2, gap = 'small')\n",
    "\n",
    "        with col1b:\n",
    "            pandasai_analyse_button = st.button('ANALYSE the spreadsheet produced only')\n",
    "        \n",
    "        with col2b:\n",
    "            pandasai_merge_button = st.button('MERGE with your spreadsheet')\n",
    "\n",
    "        if pandasai_analyse_button:\n",
    "            pandasai_analyse_df_produced()\n",
    "\n",
    "        if pandasai_merge_button:\n",
    "            pandasai_merge_df_produced()\n",
    "\n",
    "#For Langchain,\n",
    "if st.session_state.ai_choice == 'LangChain':\n",
    "\n",
    "    if \"dataframe\" in st.session_state.response_json:\n",
    "        \n",
    "        if st.session_state.response_json[\"dataframe\"]:\n",
    "\n",
    "            col1c, col2c = st.columns(2, gap = 'small')\n",
    "\n",
    "            with col1c:\n",
    "                langchain_analyse_button = st.button('ANALYSE the spreadsheet produced only')\n",
    "            \n",
    "            with col2c:\n",
    "                langchain_merge_button = st.button('MERGE with your spreadsheet')\n",
    "    \n",
    "            if langchain_analyse_button:\n",
    "                langchain_analyse_df_produced()\n",
    "    \n",
    "            if langchain_merge_button:\n",
    "                langchain_merge_df_produced()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed82eb5-356a-416b-8b8b-a956370564d6",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Reset button\n",
    "\n",
    "#if st.button('RESET to get fresh responses', type = 'primary'):#, help = \"click to engage with the AI afresh.\"):\n",
    "if reset_button:\n",
    "    pai.clear_cache()\n",
    "    st.session_state['response'] = '' #Adding this to hide clarifying questions and answers toggle upon resetting\n",
    "    st.session_state['last_prompt'] = '' #Adding this to allow asking the same question again\n",
    "    #clear_most_cache()\n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903962cf-cc23-4a66-ab42-4e3ed49b0dc8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Clarifying questions form\n",
    "\n",
    "if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "    if ((len(str(st.session_state.response)) > 0) and \n",
    "        (st.session_state.q_and_a_provided == False)\n",
    "       ):\n",
    "        if st.toggle(label = 'Suggestions', key = 'q_and_a_toggle', help = f'Get clarifying questions from {st.session_state.ai_choice} to help draft your instructions.'):\n",
    "        #if clarification_questions_toggle:\n",
    "        \n",
    "            with pandasai_get_openai_callback() as cb, st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...}}$\"):\n",
    "                \n",
    "                prompt = st.session_state.prompt\n",
    "    \n",
    "                #if len(prompt) > 0:\n",
    "            \n",
    "                clarifying_questions = agent.clarification_questions(prompt)\n",
    "    \n",
    "                st.session_state.clarifying_questions = clarifying_questions\n",
    "    \n",
    "                #Keep record of clarifying questions\n",
    "                st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": cb.total_cost, \"tokens\": cb.total_tokens,   \"role\": \"assistant\", \"content\": {'answer': clarifying_questions}})\n",
    "                            \n",
    "            if len(clarifying_questions) == 0:\n",
    "                st.error(f'{st.session_state.ai_choice} did not have any clarifying questions. Please amend your instructions and try again.')\n",
    "            \n",
    "            else: #if len(clarifying_questions) > 0:\n",
    "                with st.form(\"clarifying_questions_form\"):\n",
    "            \n",
    "                    st.write(f'Please consider the following clarifying questions from {st.session_state.ai_choice}. You may answer them here, or redraft your questions or instructions in light of them.')\n",
    "        \n",
    "                    #Display up to 3 clarifying questions\n",
    "                    if len(st.session_state.clarifying_questions) > 0:\n",
    "            \n",
    "                        st.warning(f'Question 1: {st.session_state.clarifying_questions[0]}')\n",
    "                        st.session_state.clarifying_answers[0] = st.text_input(label = f'Enter your answer to question 1', max_chars = 250)\n",
    "            \n",
    "                    if len(st.session_state.clarifying_questions) > 1: \n",
    "            \n",
    "                        st.warning(f'Question 2: {st.session_state.clarifying_questions[1]}')\n",
    "                        st.session_state.clarifying_answers[1] = st.text_input(label = f'Enter your answer to question 2', max_chars = 250)\n",
    "            \n",
    "                    if len(st.session_state.clarifying_questions) > 2: \n",
    "            \n",
    "                        st.warning(f'Question 3: {st.session_state.clarifying_questions[2]}')\n",
    "                        st.session_state.clarifying_answers[2] = st.text_input(label = f'Enter your answer to question 3', max_chars = 250)\n",
    "            \n",
    "                    #Acivate if want to display tokens and costs only if own account active\n",
    "                    #if st.session_state['own_account'] == True:\n",
    "                            \n",
    "                    add_q_a_button = st.form_submit_button('ADD these answers to your instructions')\n",
    "            \n",
    "                    if add_q_a_button:\n",
    "                        for question_index in range(0, len(st.session_state.clarifying_answers)):\n",
    "                            \n",
    "                            st.write(f'Answer to question {question_index + 1}: + st.session_state.clarifying_answers[question_index]')\n",
    "                            \n",
    "                        intro_q_and_a = ' Take into account the following clarifying questions and their answers. '             \n",
    "            \n",
    "                        q_and_a_pairs = ''\n",
    "                        \n",
    "                        for question_index in range(0, len(st.session_state.clarifying_answers)):\n",
    "                            if len(st.session_state.clarifying_answers[question_index]) > 0:\n",
    "                                question_answer_pair = f' Question: ' + st.session_state.clarifying_questions[question_index] + f' Answer: ' + st.session_state.clarifying_answers[question_index]\n",
    "                                \n",
    "                                if question_answer_pair[-1] != '.':\n",
    "                                    question_answer_pair = question_answer_pair + '. '\n",
    "                                \n",
    "                                q_and_a_pairs = q_and_a_pairs + question_answer_pair            \n",
    "            \n",
    "                        if intro_q_and_a in st.session_state.prompt_prefill:\n",
    "                            \n",
    "                            st.session_state.prompt_prefill = st.session_state.prompt + q_and_a_pairs\n",
    "                       \n",
    "                        else:\n",
    "                            \n",
    "                            st.session_state.prompt_prefill = st.session_state.prompt + intro_q_and_a + q_and_a_pairs\n",
    "        \n",
    "                        #Add clarifying answers to history\n",
    "                        st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"user\", \"content\": {\"prompt\": st.session_state.clarifying_answers}})\n",
    "                        \n",
    "                        #Change clarifying questions and answers status\n",
    "                        st.session_state['q_and_a_provided'] = True\n",
    "\n",
    "                        #Change disable input status\n",
    "                        st.session_state['disable_input'] = False\n",
    "        \n",
    "                        st.rerun()\n",
    "            \n",
    "            clarifying_questions_cost_tokens = f'(These clarifying questions costed USD $ {round(cb.total_cost, 5)} to produce and totalled {cb.total_tokens} tokens.)'\n",
    "            \n",
    "            st.write(clarifying_questions_cost_tokens)\n",
    "\n",
    "            st.session_state.messages.append({\"time\": str(datetime.now()), \"cost (usd)\": float(0), \"tokens\": float(0),   \"role\": \"assistant\", \"content\": {'answer': clarifying_questions_cost_tokens}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0ee6c5-9f74-4b3a-8135-0a757b7987f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying chat history\n",
    "#history_on = st.toggle(label = 'Display all instructions and responses')\n",
    "\n",
    "if len(str(st.session_state.response)) > 0:\n",
    "    history_on = st.toggle(label = 'Chat history', help = 'Display all instructions and responses.')\n",
    "    \n",
    "    if history_on:\n",
    "    #if st.toggle(label = 'Display all instructions and responses'):\n",
    "    \n",
    "        #Check if history exists\n",
    "        if len(st.session_state.messages) == 0:\n",
    "            st.warning(\"You haven't given any instructions or questions yet.\")\n",
    "            \n",
    "        #Check if history exists\n",
    "        else: #if len(st.session_state.messages) > 0:\n",
    "    \n",
    "            st.subheader('Conversation')\n",
    "    \n",
    "            st.write('Instructions and responses are displayed from earliest to flagship.')\n",
    "    \n",
    "            st.caption(spreadsheet_caption)\n",
    "    \n",
    "            # Display chat messages from history on app rerun\n",
    "            for message in st.session_state.messages:\n",
    "                st.caption(' ')\n",
    "                st.caption(message[\"time\"][0:19])\n",
    "                with st.chat_message(message[\"role\"]):\n",
    "    \n",
    "                    #For pandas ai responses\n",
    "                    if st.session_state.ai_choice in {'GPT', 'BambooLLM'}:\n",
    "                        \n",
    "                        if isinstance(message[\"content\"], dict):\n",
    "    \n",
    "                            if 'prompt' in message[\"content\"]:\n",
    "                                st.write(message[\"content\"]['prompt'])\n",
    "                            \n",
    "                            if 'answer' in message[\"content\"]:                           \n",
    "                                st.write(message[\"content\"]['answer'])\n",
    "    \n",
    "                                #Display caption if response is a dataframe\n",
    "                                if isinstance(message[\"content\"]['answer'], pd.DataFrame):\n",
    "                                    \n",
    "                                    st.caption(spreadsheet_caption)\n",
    "    \n",
    "                            if 'error' in message[\"content\"]:                           \n",
    "                                st.error(message[\"content\"]['error'])\n",
    "    \n",
    "                            if 'image' in message[\"content\"]:                           \n",
    "                                st.image(message[\"content\"]['image'], use_column_width = \"never\")\n",
    "                                st.caption('Right click to save this image.')\n",
    "    \n",
    "                            if 'matplotlib figure' in message[\"content\"]:\n",
    "                                st.pyplot(fig = message[\"content\"]['matplotlib figure'])\n",
    "                                st.caption('Right click to save this image.')\n",
    "                                \n",
    "                            if 'code' in message[\"content\"]:\n",
    "                                st.code(message[\"content\"]['code'])\n",
    "    \n",
    "                            #else:                           \n",
    "                                #st.write(message[\"content\"])\n",
    "                        else:\n",
    "                            st.write(message[\"content\"])\n",
    "                    \n",
    "                    else: #if st.session_state.ai_choice == 'LangChain':\n",
    "                        if isinstance(message[\"content\"], dict):\n",
    "                            langchain_write(message[\"content\"])\n",
    "                        else: #not isinstance(message[\"content\"], str)\n",
    "                            st.write(message[\"content\"])\n",
    "    \n",
    "            #Create and export json file with instructions and responses for downloading\n",
    "            \n",
    "            df_history = pd.DataFrame(st.session_state.messages)\n",
    "        \n",
    "            history_output_name = str(today_in_nums) + '_chat_history'\n",
    "            \n",
    "            csv = convert_df_to_csv(df_history)\n",
    "        \n",
    "            ste.download_button(\n",
    "                label=\"Download the conversation as a CSV (for use in Excel etc)\", \n",
    "                data = csv,\n",
    "                file_name=history_output_name + '.csv', \n",
    "                mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "            )\n",
    "        \n",
    "            xlsx = convert_df_to_excel(df_history)\n",
    "            \n",
    "            ste.download_button(label='Download the conversation as an Excel spreadsheet (XLSX)',\n",
    "                                data=xlsx,\n",
    "                                file_name=history_output_name + '.xlsx', \n",
    "                                mime='application/vnd.ms-excel',\n",
    "                               )\n",
    "        \n",
    "            json = convert_df_to_json(df_history)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download the conversation as a JSON\", \n",
    "                data = json,\n",
    "                file_name= history_output_name + '.json', \n",
    "                mime= \"application/json\", \n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
