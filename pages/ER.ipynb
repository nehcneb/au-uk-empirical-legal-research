{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import urllib.request\n",
    "import PyPDF2\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "import math\n",
    "from math import ceil\n",
    "\n",
    "#Google\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from io import BytesIO\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b77045-bdcc-4ee1-a9a4-b7dd03b6bfd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default, users are allowed to use their own account\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n",
    "#Import variables\n",
    "from common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c94f73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# English Reports search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151727b0-e03c-4ab1-be18-4fd113d064af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f841231-e0ad-4647-b5c2-244594a4cc51",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    \n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "\n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "    \n",
    "    #Judgment counter bound\n",
    "    judgments_counter_bound = st.session_state.judgments_counter_bound\n",
    "\n",
    "    #GPT enhancement\n",
    "    gpt_enhancement = st.session_state.gpt_enhancement_entry\n",
    "\n",
    "    #GPT choice and entry\n",
    "    gpt_activation_status = gpt_activation_entry\n",
    "    \n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: question_characters_bound]\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "            'Enter search query': query_entry,\n",
    "           'Find (method)': method_entry,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your questions for GPT': gpt_questions, \n",
    "            'Use GPT': gpt_activation_status,\n",
    "              'Use own account': own_account,\n",
    "            'Use latest version of GPT' : gpt_enhancement\n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "        \n",
    "    return df_master_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f2f670-342c-44ab-a87b-58aa2b023b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of search methods\n",
    "\n",
    "methods_list = ['using autosearch', 'this Boolean query', 'any of these words', 'all of these words', 'this phrase', 'this case name']\n",
    "method_types = ['auto', 'boolean', 'any', 'all', 'phrase', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url\n",
    "\n",
    "def er_search(query= '', \n",
    "              method = ''\n",
    "             ):\n",
    "    base_url = \"http://www.commonlii.org/cgi-bin/sinosrch.cgi?\" #+ method\n",
    "\n",
    "    method_index = methods_list.index(method)\n",
    "    method_type = method_types[method_index]\n",
    "\n",
    "    query_text = query\n",
    "\n",
    "    params = {'meta' : '/commonlii', \n",
    "              'mask_path' : '+uk/cases/EngR+', \n",
    "              'method' : method_type,\n",
    "              'query' : query_text\n",
    "             }\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    \n",
    "    return response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6321d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function turning search results url to case_link_pairs to judgments\n",
    "def search_results_to_case_link_pairs(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    hrefs = soup.find_all('a', href=True)\n",
    "    case_link_pairs = []\n",
    "\n",
    "    #number of search results\n",
    "    docs_found_string = str(soup.find_all('span', {'class' : 'ndocs'})).split('Documents found:')[1].split('<')[0].replace(' ', '')\n",
    "    docs_found = int(docs_found_string)\n",
    "    \n",
    "    #Start counter\n",
    "    counter = 1\n",
    "    \n",
    "    for link in hrefs:\n",
    "        if ((counter <= judgment_counter_bound) and (' ER ' in str(link)) and ('cases' in str(link))):\n",
    "#        if ((counter <= judgment_counter_bound) and ('commonlii' in str(link)) and ('cases/EngR' in str(link)) and ('LawCite' not in str(link))):\n",
    "            case = link.get_text()\n",
    "            link_direct = link.get('href')\n",
    "            sub_link = link_direct.replace('.html', '.pdf').split('cases')[1].split('.pdf')[0]\n",
    "            pdf_link = 'http://www.commonlii.org/uk/cases' + sub_link + '.pdf'\n",
    "            dict_object = { 'case':case, 'link_direct': pdf_link}\n",
    "            case_link_pairs.append(dict_object)\n",
    "            counter = counter + 1\n",
    "        \n",
    "    for ending in range(20, docs_found, 20):\n",
    "        if counter <= min(judgment_counter_bound, docs_found):\n",
    "            url_next_page = url_search_results + ';offset=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            \n",
    "            hrefs_next_page = soup_judgment_next_page.find_all('a', href=True)\n",
    "            for extra_link in hrefs_next_page:\n",
    "                if ((counter <= judgment_counter_bound) and (' ER ' in str(extra_link)) and ('cases' in str(extra_link))):\n",
    "#                if ((counter <= judgment_counter_bound) and ('commonlii' in str(extra_link)) and ('cases/EngR' in str(extra_link)) and ('LawCite' not in str(extra_link))):\n",
    "                    case = extra_link.get_text()\n",
    "                    extra_link_direct = extra_link.get('href')\n",
    "                    sub_extra_link = extra_link_direct.replace('.html', '.pdf').split('cases')[1].split('.pdf')[0]\n",
    "                    pdf_extra_link = 'http://www.commonlii.org/uk/cases' + sub_extra_link + '.pdf'\n",
    "                    dict_object = { 'case':case, 'link_direct': pdf_extra_link}\n",
    "                    case_link_pairs.append(dict_object)\n",
    "                    counter = counter + 1\n",
    "\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return case_link_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a72562c-8dce-4d9e-a2f4-c7a14a5877a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert case-link pairs to judgment text\n",
    "\n",
    "def judgment_text(case_link_pair):\n",
    "    url = case_link_pair['link_direct']\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    remote_file_bytes = io.BytesIO(r.content)\n",
    "    pdfdoc_remote = PyPDF2.PdfReader(remote_file_bytes)\n",
    "    \n",
    "    text_list = []\n",
    "    \n",
    "    for page in pdfdoc_remote.pages:\n",
    "        text_list.append(page.extract_text())\n",
    "    \n",
    "    return str(text_list)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a85223-64ca-4d1b-998c-1c2769c5a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "\n",
    "def meta_judgment_dict(case_link_pair):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                     'Medium neutral citation' : '', \n",
    "                     'English Reports': '', \n",
    "                     'Nominate Reports': '', \n",
    "                     'Hyperlink to CommonLII': '', \n",
    "                     'Year' : '', \n",
    "                     'judgment': ''\n",
    "                    }\n",
    "\n",
    "    case_name = case_link_pair['case']\n",
    "    year = case_link_pair['link_direct'].split('EngR/')[-1][0:4]\n",
    "    case_num = case_link_pair['link_direct'].split('/')[-1].replace('.pdf', '')\n",
    "    mnc = '[' + year + ']' + ' EngR ' + case_num\n",
    "\n",
    "    er_cite = ''\n",
    "    nr_cite = ''\n",
    "        \n",
    "    try:\n",
    "        case_name = case_link_pair['case'].split('[')[0][:-1]\n",
    "        nr_cite = case_link_pair['case'].split(';')[1][1:]\n",
    "        er_cite = case_link_pair['case'].split(';')[2][1:]\n",
    "    except:\n",
    "        pass\n",
    "                \n",
    "    judgment_dict['Case name'] = case_name\n",
    "    judgment_dict['Medium neutral citation'] = mnc\n",
    "    judgment_dict['English Reports'] = er_cite\n",
    "    judgment_dict['Nominate Reports'] = nr_cite\n",
    "    judgment_dict['Year'] = year\n",
    "    judgment_dict['Hyperlink to CommonLII'] = link(case_link_pair['link_direct'])\n",
    "    judgment_dict['judgment'] = judgment_text(case_link_pair)\n",
    "\n",
    "#    pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #try:\n",
    "     #   judgment_text = str(soup.find_all('content'))\n",
    "    #except:\n",
    "      #  judgment_text= soup.get_text(strip=True)\n",
    "        \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24172f8-acaf-4be0-ac0c-dd0dfc6737a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string, judgment_prompt_json, GPT_json_tokens, engage_GPT_json_tokens  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, default_judgment_counter_bound, role_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25483b-ed35-41f6-882d-6b84c6045b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f082f6b-c141-4a8a-822b-8cbf00b1c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "role_content_er = ' The string or images given to you may contain judgments for multiple cases. Please provide answers only for the specific case identified in the \"Case name\" section of the metadata.'\n",
    "intro_for_GPT_er = [{\"role\": \"system\", \"content\": role_content + role_content_er}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a03e8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 11:36:13.781 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions for GPT are capped at 1000 characters.\n",
      "\n",
      "The default number of judgments to scrape per request is capped at 10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-3.5-turbo-0125\"\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Upperbound on number of judgments to scrape\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "def run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "\n",
    "    url_search_results = er_search(query= df_master.loc[0, 'Enter search query'], \n",
    "                                   method = df_master.loc[0, 'Find (method)']\n",
    "                                  )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_link_pairs = search_results_to_case_link_pairs(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for case_link_pair in case_link_pairs:\n",
    "\n",
    "        judgment_dict = meta_judgment_dict(case_link_pair)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "\n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use latest version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json_tokens(questions_json, df_individual, GPT_activation, gpt_model)\n",
    "\n",
    "    df_updated.pop('judgment')\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dacc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_url(df_master):\n",
    "\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url = er_search(query= df_master.loc[0, 'Enter search query'],\n",
    "                    method= df_master.loc[0, 'Find (method)']\n",
    "                   )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb4142-30d3-4dfa-a2b1-0317592f5704",
   "metadata": {},
   "source": [
    "# For gpt-4o vision, ER only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bbaaf-a520-4113-a22b-c6206ff44680",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from gpt_functions import get_image_dims, calculate_image_token_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9ed9ee2-0dea-4f6a-840b-bb5ed83eca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert case-link pairs to judgment text\n",
    "\n",
    "def judgment_tokens_b64(case_link_pair):\n",
    "\n",
    "    output_b64 = {'judgment':[], 'tokens_raw': 0}\n",
    "    \n",
    "    url = case_link_pair['link_direct']\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    bytes_data = io.BytesIO(r.content)\n",
    "    \n",
    "    images = pdf2image.convert_from_bytes(bytes_data.read(), timeout=30, fmt=\"jpeg\")\n",
    "    \n",
    "    for image in images[ : len(images)]:\n",
    "\n",
    "        output = BytesIO()\n",
    "        image.save(output, format='JPEG')\n",
    "        im_data = output.getvalue()\n",
    "        \n",
    "        image_data = base64.b64encode(im_data)\n",
    "        if not isinstance(image_data, str):\n",
    "            # Python 3, decode from bytes to string\n",
    "            image_data = image_data.decode()\n",
    "        data_url = 'data:image/jpg;base64,' + image_data\n",
    "\n",
    "        #b64 = base64.b64encode(image_raw).decode('utf-8')\n",
    "\n",
    "        b64_to_attach = data_url\n",
    "        #b64_to_attach = f\"data:image/png;base64,{b64}\"\n",
    "\n",
    "        output_b64['judgment'].append(b64_to_attach)\n",
    "    \n",
    "    for image_b64 in output_b64['judgment']:\n",
    "\n",
    "        output_b64['tokens_raw'] = output_b64['tokens_raw'] + calculate_image_token_cost(image_b64, detail=\"auto\")\n",
    "    \n",
    "    return output_b64\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a95d7b4-0db7-4e5f-84e4-a6e937420034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "\n",
    "def meta_judgment_dict_b64(case_link_pair):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                     'Medium neutral citation' : '', \n",
    "                     'English Reports': '', \n",
    "                     'Nominate Reports': '', \n",
    "                     'Hyperlink to CommonLII': '', \n",
    "                     'Year' : '', \n",
    "                     'judgment': '', \n",
    "                     'tokens_raw': 0\n",
    "                    }\n",
    "\n",
    "    case_name = case_link_pair['case']\n",
    "    year = case_link_pair['link_direct'].split('EngR/')[-1][0:4]\n",
    "    case_num = case_link_pair['link_direct'].split('/')[-1].replace('.pdf', '')\n",
    "    mnc = '[' + year + ']' + ' EngR ' + case_num\n",
    "\n",
    "    er_cite = ''\n",
    "    nr_cite = ''\n",
    "        \n",
    "    try:\n",
    "        case_name = case_link_pair['case'].split('[')[0][:-1]\n",
    "        nr_cite = case_link_pair['case'].split(';')[1][1:]\n",
    "        er_cite = case_link_pair['case'].split(';')[2][1:]\n",
    "    except:\n",
    "        pass\n",
    "                \n",
    "    judgment_dict['Case name'] = case_name\n",
    "    judgment_dict['Medium neutral citation'] = mnc\n",
    "    judgment_dict['English Reports'] = er_cite\n",
    "    judgment_dict['Nominate Reports'] = nr_cite\n",
    "    judgment_dict['Year'] = year\n",
    "    judgment_dict['Hyperlink to CommonLII'] = link(case_link_pair['link_direct'])\n",
    "    judgment_dict['judgment'] = judgment_tokens_b64(case_link_pair)['judgment']\n",
    "    judgment_dict['tokens_raw'] = judgment_tokens_b64(case_link_pair)['tokens_raw']\n",
    "\n",
    "#    pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #try:\n",
    "     #   judgment_text = str(soup.find_all('content'))\n",
    "    #except:\n",
    "      #  judgment_text= soup.get_text(strip=True)\n",
    "        \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2332d698-126d-4069-8ee3-286af5ab7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT answer function for answers in json form, YES TOKENS\n",
    "#For gpt-4o vision\n",
    "\n",
    "def GPT_b64_er_json_tokens(questions_json, judgment_json, gpt_model):\n",
    "    #'question_json' variable is a json of questions to GPT\n",
    "\n",
    "    #file_for_GPT = [{\"role\": \"user\", \"content\": file_prompt(file_triple, gpt_model) + 'you will be given questions to answer in JSON form.'}]\n",
    "\n",
    "    #Add images to messages to GPT\n",
    "    image_content_value = [{\"type\": \"text\", \"text\": 'Based on the following images:'}]\n",
    "\n",
    "    for image_b64 in judgment_json['judgment']:\n",
    "        image_message_to_attach = {\"type\": \"image_url\", \"image_url\": {\"url\": image_b64,}}\n",
    "        image_content_value.append(image_message_to_attach)\n",
    "\n",
    "    image_content = [{\"role\": \"user\", \n",
    "                      \"content\": image_content_value\n",
    "                     }\n",
    "                  ]\n",
    "\n",
    "    #Create metadata content\n",
    "\n",
    "    metadata_content = [{\"role\": \"user\", \"content\": ''}]\n",
    "\n",
    "    metadata_json_raw = judgment_json\n",
    "\n",
    "    for key in ['Hyperlink to CommonLII', 'judgment', 'tokens_raw']:\n",
    "        try:\n",
    "            metadata_json_raw.pop(key)\n",
    "        except:\n",
    "            print(f'Unable to remove {key} from metadata_json_raw')\n",
    "\n",
    "    metadata_json = metadata_json_raw\n",
    "\n",
    "    if 'judgment' not in metadata_json.keys():\n",
    "        metadata_content = [{\"role\": \"user\", \"content\": 'Based on the following metadata:' + str(metadata_json)}]\n",
    "\n",
    "    #Create json direction content\n",
    "\n",
    "    json_direction = [{\"role\": \"user\", \"content\": 'You will be given questions to answer in JSON form.'}]\n",
    "\n",
    "    file_for_GPT = image_content + metadata_content + json_direction\n",
    "    \n",
    "    #Create answer format\n",
    "    \n",
    "    q_keys = [*questions_json]\n",
    "    \n",
    "    answers_json = {}\n",
    "    \n",
    "    for q_index in q_keys:\n",
    "        answers_json.update({q_index: 'Your answer to the question with index ' + q_index + '. State specific page numbers or sections of the file.'})\n",
    "    \n",
    "    #Create questions, which include the answer format\n",
    "    \n",
    "    question_for_GPT = [{\"role\": \"user\", \"content\": str(questions_json).replace(\"\\'\", '\"') + ' Give responses in the following JSON form: ' + str(answers_json).replace(\"\\'\", '\"')}]\n",
    "    \n",
    "    #Create messages in one prompt for GPT\n",
    "    intro_for_GPT_er = [{\"role\": \"system\", \"content\": role_content + role_content_er}]\n",
    "\n",
    "    messages_for_GPT = intro_for_GPT_er + file_for_GPT + question_for_GPT\n",
    "    \n",
    "#   return messages_for_GPT\n",
    "\n",
    "    #os.environ[\"OPENAI_API_KEY\"] = API_key\n",
    "\n",
    "    #openai.api_key = API_key\n",
    "    \n",
    "    #client = OpenAI()\n",
    "    \n",
    "    try:\n",
    "        #completion = client.chat.completions.create(\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=gpt_model,\n",
    "            messages=messages_for_GPT, \n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "#        return completion.choices[0].message.content #This gives answers as a string containing a dictionary\n",
    "        \n",
    "        #To obtain a json directly, use below\n",
    "        answers_dict = json.loads(completion.choices[0].message.content)\n",
    "        \n",
    "        #Obtain tokens\n",
    "        output_tokens = completion.usage.completion_tokens\n",
    "        \n",
    "        prompt_tokens = completion.usage.prompt_tokens\n",
    "        \n",
    "        return [answers_dict, output_tokens, prompt_tokens]\n",
    "\n",
    "    except Exception as error:\n",
    "        \n",
    "        for q_index in q_keys:\n",
    "            answers_json[q_index] = error\n",
    "        \n",
    "        return [answers_json, 0, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d494f30b-28e6-40fd-bfcb-47e184e2d38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT function for each respondent's dataframe, index by judgment then question, with input and output tokens given by GPT itself\n",
    "#For gpt-4o vision\n",
    "\n",
    "#The following function DOES NOT check for existence of questions for GPT\n",
    "    # To so check, active line marked as #*\n",
    "def engage_GPT_b64_er_json_tokens(questions_json, df_individual, GPT_activation, gpt_model):\n",
    "    # Variable questions_json refers to the json of questions\n",
    "    # Variable df_individual refers to each respondent's df\n",
    "    # Variable activation refers to status of GPT activation (real or test)\n",
    "    # The output is a new JSON for the relevant respondent with new columns re:\n",
    "        # f\"Length of first 10 pages in tokens (up to {tokens_cap(gpt_model)} given to GPT)\"\n",
    "        # 'GPT cost estimate (USD excl GST)'\n",
    "        # 'GPT time estimate (seconds)'\n",
    "        # GPT questions/answers\n",
    "\n",
    "    #os.environ[\"OPENAI_API_KEY\"] = API_key\n",
    "\n",
    "    #openai.api_key = API_key\n",
    "    \n",
    "    #client = OpenAI()\n",
    "    \n",
    "    question_keys = [*questions_json]\n",
    "\n",
    "    for judgment_index in df_individual.index:\n",
    "        \n",
    "        judgment_json = df_individual.to_dict('index')[judgment_index]\n",
    "        \n",
    "        #Calculate and append number of tokens of judgment, regardless of whether given to GPT\n",
    "        #judgment_json['tokens_raw'] = num_tokens_from_string(str(judgment_json), \"cl100k_base\")\n",
    "\n",
    "        df_individual.loc[judgment_index, f\"Tokens (up to {tokens_cap(gpt_model)} given to GPT)\"] = judgment_json['tokens_raw']       \n",
    "\n",
    "        #Indicate whether judgment truncated\n",
    "        \n",
    "        df_individual.loc[judgment_index, \"judgment truncated (if given to GPT)?\"] = ''       \n",
    "        \n",
    "        if judgment_json['tokens_raw'] <= tokens_cap(gpt_model):\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"judgment truncated (if given to GPT)?\"] = 'No'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"judgment truncated (if given to GPT)?\"] = 'Yes'\n",
    "\n",
    "        #Create columns for respondent's GPT cost, time\n",
    "        df_individual.loc[judgment_index, 'GPT cost estimate (USD excl GST)'] = ''\n",
    "        df_individual.loc[judgment_index, 'GPT time estimate (seconds)'] = ''\n",
    "                \n",
    "        #Calculate GPT start time\n",
    "\n",
    "        GPT_start_time = datetime.now()\n",
    "\n",
    "        #Depending on activation status, apply GPT_json function to each judgment, gives answers as a string containing a dictionary\n",
    "\n",
    "        if int(GPT_activation) > 0:\n",
    "            GPT_judgment_json = GPT_b64_er_json_tokens(questions_json, judgment_json, gpt_model) #Gives [answers as a JSON, output tokens, input tokens]\n",
    "            answers_dict = GPT_judgment_json[0]\n",
    "\n",
    "            #Calculate and append GPT finish time and time difference to individual df\n",
    "            GPT_finish_time = datetime.now()\n",
    "            \n",
    "            GPT_time_difference = GPT_finish_time - GPT_start_time\n",
    "    \n",
    "            df_individual.loc[judgment_index, 'GPT time estimate (seconds)'] = GPT_time_difference.total_seconds()\n",
    "        \n",
    "        else:\n",
    "            answers_dict = {}    \n",
    "            for q_index in question_keys:\n",
    "                #Increases judgment index by 2 to ensure consistency with Excel spreadsheet\n",
    "                answer = 'Placeholder answer for ' + ' judgment ' + str(int(judgment_index) + 2) + ' ' + str(q_index)\n",
    "                answers_dict.update({q_index: answer})\n",
    "            \n",
    "            #Own calculation of GPT costs for Placeholder answer fors\n",
    "\n",
    "            #Calculate capped judgment tokens\n",
    "\n",
    "            judgment_capped_tokens = min(judgment_json['tokens_raw'], tokens_cap(gpt_model))\n",
    "\n",
    "            #Calculate questions tokens and cost\n",
    "\n",
    "            questions_tokens = num_tokens_from_string(str(questions_json), \"cl100k_base\")\n",
    "\n",
    "            #Calculate metadata tokens\n",
    "\n",
    "            metadata_tokens = 0\n",
    "            \n",
    "            metadata_json_for_counting = judgment_json\n",
    "\n",
    "            for key in ['Hyperlink to CommonLII', 'judgment', 'tokens_raw']:\n",
    "                try:\n",
    "                    metadata_json_for_counting.pop(key)\n",
    "                except:\n",
    "                    print(f'Unable to remove {key} from metadata_json_for_counting')        \n",
    "\n",
    "            if 'judgment' not in metadata_json_for_counting.keys():\n",
    "                metadata_tokens = metadata_tokens + num_tokens_from_string(str(metadata_json_for_counting), \"cl100k_base\")\n",
    "\n",
    "            #Calculate other instructions' tokens\n",
    "\n",
    "            other_instructions = role_content + 'you will be given questions to answer in JSON form.' + ' Give responses in the following JSON form: '\n",
    "\n",
    "            other_tokens = num_tokens_from_string(other_instructions, \"cl100k_base\") + len(question_keys)*num_tokens_from_string(\"GPT question x:  Your answer to the question with index GPT question x. State specific page numbers or sections of the judgment.\", \"cl100k_base\")\n",
    "\n",
    "            #Calculate number of tokens of answers\n",
    "            answers_tokens = num_tokens_from_string(str(answers_dict), \"cl100k_base\")\n",
    "\n",
    "            input_tokens = judgment_capped_tokens + questions_tokens + metadata_tokens + other_tokens\n",
    "            \n",
    "            GPT_judgment_json = [answers_dict, answers_tokens, input_tokens]\n",
    "\n",
    "        #Create GPT question headings and append answers to individual spreadsheets\n",
    "\n",
    "        for question_index in question_keys:\n",
    "            question_heading = question_index + ': ' + questions_json[question_index]\n",
    "            df_individual.loc[judgment_index, question_heading] = answers_dict[question_index]\n",
    "\n",
    "        #Calculate GPT costs\n",
    "\n",
    "        GPT_cost = GPT_judgment_json[1]*gpt_output_cost(gpt_model) + GPT_judgment_json[2]*gpt_input_cost(gpt_model)\n",
    "\n",
    "        #Calculate and append GPT cost to individual df\n",
    "        df_individual.loc[judgment_index, 'GPT cost estimate (USD excl GST)'] = GPT_cost\n",
    "    \n",
    "    return df_individual\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3046c1e-5d6f-463a-92e4-84897573bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For gpt-4o vision\n",
    "\n",
    "def run_b64_er(df_master):\n",
    "\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "\n",
    "    url_search_results = er_search(query= df_master.loc[0, 'Enter search query'], \n",
    "                                   method = df_master.loc[0, 'Find (method)']\n",
    "                                  )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_link_pairs = search_results_to_case_link_pairs(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for case_link_pair in case_link_pairs:\n",
    "\n",
    "        judgment_dict = meta_judgment_dict_b64(case_link_pair)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "\n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use latest version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    df_updated = engage_GPT_b64_er_json_tokens(questions_json, df_individual, GPT_activation, gpt_model)\n",
    "\n",
    "    #Remove redundant columns\n",
    "\n",
    "    for column in ['tokens_raw', 'judgment']:\n",
    "        try:\n",
    "            df_updated.pop(column)\n",
    "        except:\n",
    "            print(f\"No {column} column.\")\n",
    "\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5dcd6",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39542ce-8064-49ad-89da-907107f6bfe3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85681973-6bb0-44b9-a537-ae6a2ac75709",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ca910eae-4fa4-4113-8805-3c054f17ffae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = pd.DataFrame([])\n",
    "\n",
    "#Initialize enhanced prompt\n",
    "if 'prompt_prefill' not in st.session_state:\n",
    "    st.session_state[\"prompt_prefill\"] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c34e962e-e030-4e2e-ae21-a087229a9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945ecc8-f9bc-4fd4-8d43-01dbae99b91a",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c683d9af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-10 11:36:13.893 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Create form\n",
    "\n",
    "return_button = st.button('RETURN to first page')\n",
    "\n",
    "st.header(f\"You have selected to study :blue[the English Reports].\")\n",
    "\n",
    "#Search terms\n",
    "\n",
    "#    st.header(\"Judgment Search Criteria\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[Please enter your search terms.]** This program will collect (ie scrape) the first 10 judgments returned by your search terms.\n",
    "\n",
    "For search tips, please visit CommonLII at http://www.commonlii.org/form/search1.html?mask=uk/cases/EngR. This section mimics their search function.\n",
    "\"\"\")\n",
    "st.caption('During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben at ben.chen@sydney.edu.au should you wish to cover more judgments.')\n",
    "\n",
    "st.subheader(\"Your search terms\")\n",
    "\n",
    "method_entry = st.selectbox('Find', methods_list, index=1)\n",
    "\n",
    "query_entry = st.text_input('Enter search query')\n",
    "    \n",
    "st.markdown(\"\"\"You can preview the judgments returned by your search terms on CommonLII after you have entered some search terms.\n",
    "\n",
    "You may have to unblock a popped up window, refresh this page, and re-enter your search terms.\n",
    "\"\"\")\n",
    "\n",
    "preview_button = st.button('PREVIEW on CommonLII (in a popped up window)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778721bb-0c19-4fdf-97a7-6f3c93486722",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "50794dc5-ef8b-40a0-86df-a79182328a93",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "#    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "st.markdown(\"**:green[Would you like GPT to answer questions about the judgments returned by your search terms?]**\")\n",
    "\n",
    "st.markdown(\"\"\"Please consider trying this program without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract the judgment metadata without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox('Use GPT', value = False)\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default, Ben's own experience suggests that it costs approximately USD \\$0.003-\\$0.008 (excl GST) per judgment. The exact cost for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced (as elaborated at https://openai.com/pricing for model gpt-3.5-turbo-0125). You will be given ex-post cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your questions for each judgment\")\n",
    "\n",
    "st.markdown(\"\"\"Please enter one question **per line or per paragraph**. GPT will answer your questions for **each** judgment based only on information from **that** judgment. \"\"\")\n",
    "\n",
    "gpt_questions_entry = st.text_area(f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound) \n",
    "\n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-3.5-turbo-0125. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-3.5-turbo-0125')*3/4)} words from each judgment.\")\n",
    "\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "if st.toggle('See the instruction given to GPT'):\n",
    "    st.write(f\"*{intro_for_GPT_er[0]['content']}*\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "    \n",
    "if own_account_allowed() > 0:\n",
    "\n",
    "    st.subheader(':orange[Enhance program capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of judgments to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle('Use my own GPT account')\n",
    "    \n",
    "    if own_account_entry:\n",
    "    \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage at https://platform.openai.com/signup. You can then find your API key at https://platform.openai.com/api-keys.\n",
    "    \"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state.name_entry)\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value = st.session_state.email_entry)\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.gpt_api_key_entry)\n",
    "        \n",
    "        valdity_check = st.button('VALIDATE your API key')\n",
    "    \n",
    "        if valdity_check:\n",
    "            \n",
    "            api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                    \n",
    "            if api_key_valid == False:\n",
    "                st.session_state['gpt_api_key_validity'] = False\n",
    "                st.error('Your API key is not valid.')\n",
    "                \n",
    "            else:\n",
    "                st.session_state['gpt_api_key_validity'] = True\n",
    "                st.success('Your API key is valid.')\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[You can use the latest version of GPT model (gpt-4o),]** which is :red[10 times more expensive, per character] than the default model (gpt-3.5-turbo) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the latest GPT model', value = False)\n",
    "        st.caption('For more on pricing for different GPT models, please see https://openai.com/api/pricing.')\n",
    "        \n",
    "        if gpt_enhancement_entry == True:\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o\"\n",
    "            st.session_state.gpt_enhancement_entry = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "            st.session_state.gpt_enhancement_entry = False\n",
    "        \n",
    "        st.write(f'**:green[You can increase the maximum number of judgments to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        #judgments_counter_bound_entry = round(st.number_input(label = 'Enter a whole number between 1 and 100', min_value=1, max_value=100, value=default_judgment_counter_bound))\n",
    "\n",
    "        #st.session_state.judgments_counter_bound = judgments_counter_bound_entry\n",
    "\n",
    "        judgments_counter_bound_entry = st.text_input(label = 'Enter a whole number between 1 and 100', value=str(default_judgment_counter_bound))\n",
    "\n",
    "        if judgments_counter_bound_entry:\n",
    "            wrong_number_warning = f'You have not entered a whole number between 1 and 100. The program will process up to {default_judgment_counter_bound} judgments instead.'\n",
    "            try:\n",
    "                st.session_state.judgments_counter_bound = int(judgments_counter_bound_entry)\n",
    "            except:\n",
    "                st.warning(wrong_number_warning)\n",
    "                st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "\n",
    "            if ((st.session_state.judgments_counter_bound <= 0) or (st.session_state.judgments_counter_bound > 100)):\n",
    "                st.warning(wrong_number_warning)\n",
    "                st.session_state.judgments_counter_bound = default_judgment_counter_bound   \n",
    "\n",
    "        st.write(f'*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state.judgments_counter_bound} judgments.*')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "\n",
    "        st.session_state.judgments_counter_bound = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb57c9d-ee02-43d8-9e64-68aa5ecc233f",
   "metadata": {},
   "source": [
    "## Consent and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4607e180-0acf-4d16-8f9f-32368070ba86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"gpt_model\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:398\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 398\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:443\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:119\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:90\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     89\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m get_session_state()[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:91\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state[key]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:400\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"gpt_model\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 30\u001b[0m\n\u001b[1;32m     26\u001b[0m keep_button \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mbutton(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOWNLOAD your entries\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     28\u001b[0m reset_button \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mbutton(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRESET to start afresh\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprimary\u001b[39m\u001b[38;5;124m'\u001b[39m,  help \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPress to process new search terms or questions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mgpt_model \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4-turbo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     32\u001b[0m     st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mThe English Reports are available as PDFs. By default, this program will use an Optical Character Recognition (OCR) engine to extract text from the relevant PDFs, and then send such text to GPT.\u001b[39m\n\u001b[1;32m     33\u001b[0m \n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mAlternatively, you can send the relevant PDFs to GPT as images. This alternative approach may produce better responses for \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muntidy\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m PDFs, but tends to be slower and costlier than the default approach.\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m#st.write('Not getting the best responses for your images? You can try a more costly')\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m#b64_help_text = 'GPT will process images directly, instead of text first extracted from images by an Optical Character Recognition engine. This only works for PNG, JPEG, JPG, GIF images.'\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:121\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"gpt_model\". Did you forget to initialize it? More info: https://docs.streamlit.io/library/advanced-features/session-state#initialization"
     ]
    }
   ],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")\n",
    "\n",
    "st.header(\"Next steps\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[You can now run the Empirical Legal Research Kickstarter.]** A spreadsheet which hopefully has the data you seek will be available for download.\n",
    "\n",
    "You can also download a record of your entries.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Warning\n",
    "if st.session_state.gpt_model == 'gpt-3.5-turbo-0125':\n",
    "    st.warning(\"A low-cost GPT model will answer your questions. This model is *not* designed for processing the file format (PDF) to which the English Reports are encoded. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you'd like to use a better model.\")\n",
    "\n",
    "#if st.session_state.gpt_model == \"gpt-4o\":\n",
    "    #st.warning('An expensive GPT model will answer your questions. Please be cautious.')\n",
    "\n",
    "run_button = st.button('RUN the program')\n",
    "\n",
    "keep_button = st.button('DOWNLOAD your entries')\n",
    "\n",
    "reset_button = st.button(label='RESET to start afresh', type = 'primary',  help = \"Press to process new search terms or questions.\")\n",
    "\n",
    "if st.session_state.gpt_model == \"gpt-4o\":\n",
    "\n",
    "    st.markdown(\"\"\"The English Reports are available as PDFs. By default, this program will use an Optical Character Recognition (OCR) engine to extract text from the relevant PDFs, and then send such text to GPT.\n",
    "\n",
    "Alternatively, you can send the relevant PDFs to GPT as images. This alternative approach may produce better responses for \"untidy\" PDFs, but tends to be slower and costlier than the default approach.\n",
    "\"\"\")\n",
    "    \n",
    "    #st.write('Not getting the best responses for your images? You can try a more costly')\n",
    "    #b64_help_text = 'GPT will process images directly, instead of text first extracted from images by an Optical Character Recognition engine. This only works for PNG, JPEG, JPG, GIF images.'\n",
    "    run_button_b64 = st.button(label = 'SEND PDFs to GPT as images')\n",
    "\n",
    "#test_button = st.button('Test')\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if st.session_state.need_resetting == 1:\n",
    "    if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output) > 0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de3c0b25-ba6f-4224-897b-e11890cd011e",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48005178-1f0f-43a7-985b-839b7ce39aac",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Create placeholder download buttons if previous entries and results in st.session_state:\n",
    "\n",
    "if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "    \n",
    "    #Load previous entries and results\n",
    "    \n",
    "    df_master = st.session_state.df_master\n",
    "    df_individual_output = st.session_state.df_individual_output\n",
    "\n",
    "    #Buttons for downloading entries\n",
    "    st.subheader('Looking for your previous entries and results?')\n",
    "\n",
    "    st.write('Previous entries')\n",
    "\n",
    "    entries_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_entries'\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    ste.download_button(\n",
    "        label=\"Download your previous entries as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=entries_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download your previous entries as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=entries_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "\n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous entries as a JSON\", \n",
    "        data = json,\n",
    "        file_name= entries_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.write('Previous results')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "    \n",
    "    ste.download_button(label='Download your previous results as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your previous spreadsheet with an AI\", icon = 'ðŸ¤”')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f71a3",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d89e4a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if preview_button:\n",
    "    \n",
    "    df_master = create_df()\n",
    "\n",
    "    judgments_url = search_url(df_master)\n",
    "\n",
    "    open_page(judgments_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "\n",
    "    all_search_terms = str(query_entry)\n",
    "        \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "\n",
    "    elif int(consent) == 0:\n",
    "        st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "\n",
    "    elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "            \n",
    "        st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "            \n",
    "        st.warning('You have not validated your API key.')\n",
    "        quit()\n",
    "\n",
    "    elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "\n",
    "        st.warning('You have not entered a valid API key.')\n",
    "        quit()  \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.markdown(\"\"\"Your results will be available for download soon. The estimated waiting time is about 2-3 minutes per 10 judgments.\"\"\")\n",
    "        #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        with st.spinner('Running...'):\n",
    "\n",
    "            try:\n",
    "\n",
    "                #Create spreadsheet of responses\n",
    "                df_master = create_df()\n",
    "    \n",
    "                #Activate user's own key or mine\n",
    "                if st.session_state.own_account == True:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "                openai.api_key = API_key\n",
    "                \n",
    "                #Produce results\n",
    "\n",
    "                df_individual_output = run(df_master)\n",
    "\n",
    "                #Keep results in session state\n",
    "                st.session_state[\"df_individual_output\"] = df_individual_output#.astype(str)\n",
    "        \n",
    "                st.session_state[\"df_master\"] = df_master\n",
    "\n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                \n",
    "                st.session_state[\"page_from\"] = 'pages/ER.py'\n",
    "        \n",
    "                #Write results\n",
    "        \n",
    "                st.success(\"Your results are now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                \n",
    "                #Button for downloading results\n",
    "                output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "        \n",
    "                csv_output = convert_df_to_csv(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a CSV (for use in Excel etc)\", \n",
    "                    data = csv_output,\n",
    "                    file_name= output_name + '.csv', \n",
    "                    mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "                )\n",
    "        \n",
    "                excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "                \n",
    "                ste.download_button(label='Download your results as an Excel spreadsheet (XLSX)',\n",
    "                                    data=excel_xlsx,\n",
    "                                    file_name= output_name + '.xlsx', \n",
    "                                    mime='application/vnd.ms-excel',\n",
    "                                   )\n",
    "        \n",
    "                json_output = convert_df_to_json(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a JSON\", \n",
    "                    data = json_output,\n",
    "                    file_name= output_name + '.json', \n",
    "                    mime= \"application/json\", \n",
    "                )\n",
    "        \n",
    "                st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = 'ðŸ¤”')\n",
    "\n",
    "                    \n",
    "                #Keep record on Google sheet\n",
    "                #Obtain google spreadsheet       \n",
    "                #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                #df_google = conn.read()\n",
    "                #df_google = df_google.fillna('')\n",
    "                #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                #df_master[\"Processed\"] = datetime.now()\n",
    "                #df_master.pop(\"Your GPT API key\")\n",
    "                #df_to_update = pd.concat([df_google, df_master])\n",
    "                #conn.update(worksheet=\"ER\", data=df_to_update, )\n",
    "        \n",
    "            except Exception as e:\n",
    "                st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "                st.exception(e)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77c411-3c9e-44d0-9702-8e28fac65045",
   "metadata": {},
   "outputs": [],
   "source": [
    "if st.session_state.gpt_model == \"gpt-4o\":\n",
    "\n",
    "    if run_button_b64:\n",
    "    \n",
    "        all_search_terms = str(query_entry)\n",
    "            \n",
    "        if all_search_terms.replace('None', '') == \"\":\n",
    "    \n",
    "            st.warning('You must enter some search terms.')\n",
    "    \n",
    "        elif int(consent) == 0:\n",
    "            st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "    \n",
    "        elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "            st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "                    \n",
    "            st.session_state['need_resetting'] = 1\n",
    "    \n",
    "        elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "                \n",
    "            st.warning('You have not validated your API key.')\n",
    "            quit()\n",
    "    \n",
    "        elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "    \n",
    "            st.warning('You have not entered a valid API key.')\n",
    "            quit()  \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            st.markdown(\"\"\"Your results will be available for download soon. The estimated waiting time is about 1-2 minutes per judgment.\"\"\")\n",
    "            #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "    \n",
    "            with st.spinner('Running...'):\n",
    "    \n",
    "                try:\n",
    "\n",
    "                    #Create spreadsheet of responses\n",
    "                    df_master = create_df()\n",
    "        \n",
    "                    #Activate user's own key or mine\n",
    "                    if st.session_state.own_account == True:\n",
    "                        \n",
    "                        API_key = df_master.loc[0, 'Your GPT API key']\n",
    "        \n",
    "                    else:\n",
    "                        API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "                    openai.api_key = API_key\n",
    "                    \n",
    "                    #Produce results\n",
    "    \n",
    "                    df_individual_output = run_b64_er(df_master)\n",
    "    \n",
    "                    #Keep results in session state\n",
    "                    st.session_state[\"df_individual_output\"] = df_individual_output#.astype(str)\n",
    "            \n",
    "                    st.session_state[\"df_master\"] = df_master\n",
    "\n",
    "                    #Change session states\n",
    "                    st.session_state['need_resetting'] = 1\n",
    "                \n",
    "                    st.session_state[\"page_from\"] = 'pages/ER.py'\n",
    "            \n",
    "                    #Write results\n",
    "            \n",
    "                    st.success(\"Your results are now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                    \n",
    "                    #Button for downloading results\n",
    "                    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "            \n",
    "                    csv_output = convert_df_to_csv(df_individual_output)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your results as a CSV (for use in Excel etc)\", \n",
    "                        data = csv_output,\n",
    "                        file_name= output_name + '.csv', \n",
    "                        mime= \"text/csv\", \n",
    "            #            key='download-csv'\n",
    "                    )\n",
    "            \n",
    "                    excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "                    \n",
    "                    ste.download_button(label='Download your results as an Excel spreadsheet (XLSX)',\n",
    "                                        data=excel_xlsx,\n",
    "                                        file_name= output_name + '.xlsx', \n",
    "                                        mime='application/vnd.ms-excel',\n",
    "                                       )\n",
    "            \n",
    "                    json_output = convert_df_to_json(df_individual_output)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your results as a JSON\", \n",
    "                        data = json_output,\n",
    "                        file_name= output_name + '.json', \n",
    "                        mime= \"application/json\", \n",
    "                    )\n",
    "            \n",
    "                    st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = 'ðŸ¤”')\n",
    "    \n",
    "                        \n",
    "                    #Keep record on Google sheet\n",
    "                    #Obtain google spreadsheet       \n",
    "                    #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                    #df_google = conn.read()\n",
    "                    #df_google = df_google.fillna('')\n",
    "                    #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                    #df_master[\"Processed\"] = datetime.now()\n",
    "                    #df_master.pop(\"Your GPT API key\")\n",
    "                    #df_to_update = pd.concat([df_google, df_master])\n",
    "                    #conn.update(worksheet=\"ER\", data=df_to_update, )\n",
    "            \n",
    "                except Exception as e:\n",
    "                    st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "                    st.exception(e)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873fffb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    \n",
    "    all_search_terms = str(query_entry)\n",
    "        \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "\n",
    "    elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "\n",
    "        if 'need_resetting' not in st.session_state:\n",
    "            \n",
    "            st.session_state['need_resetting'] = 1\n",
    "\n",
    "    else:\n",
    "                            \n",
    "        df_master = create_df()\n",
    "    \n",
    "        df_master.pop(\"Your GPT API key\")\n",
    "    \n",
    "        df_master.pop(\"Processed\")\n",
    "    \n",
    "        responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "    \n",
    "        #Produce a file to download\n",
    "    \n",
    "        csv = convert_df_to_csv(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a CSV (for use in Excel etc)\", \n",
    "            data = csv,\n",
    "            file_name=responses_output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "    #            key='download-csv'\n",
    "        )\n",
    "\n",
    "        xlsx = convert_df_to_excel(df_master)\n",
    "        \n",
    "        ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                            data=xlsx,\n",
    "                            file_name=responses_output_name + '.xlsx', \n",
    "                            mime='application/vnd.ms-excel',\n",
    "                           )\n",
    "        \n",
    "        json = convert_df_to_json(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a JSON\", \n",
    "            data = json,\n",
    "            file_name= responses_output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995962d0-2a30-4327-9a0e-55b2f3e27b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab063d-6b65-41a1-b8b1-1ba2f18f6fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_button:\n",
    "    clear_cache_except_validation_df_master()\n",
    "    st.rerun()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
