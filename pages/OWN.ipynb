{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import timedelta\n",
    "import sys\n",
    "import pause\n",
    "import os\n",
    "import io\n",
    "import math\n",
    "from math import ceil\n",
    "import traceback\n",
    "\n",
    "#Conversion to text\n",
    "#import fitz\n",
    "from io import StringIO\n",
    "from io import BytesIO\n",
    "import pdf2image\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "import mammoth\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#aws\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52fe89-71ce-4728-9bc5-e660fb601f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"LawtoData: An Empirical Legal Research Automator\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "651ed485-489f-4c0c-9412-06d15e64dfe0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default, users are allowed to use their own account\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, batch_mode_allowed, immediate_b64, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, str_to_int, str_to_int_page, save_input, download_buttons, uploaded_file_to_df, send_notification_email, report_error\n",
    "\n",
    "#Import variables\n",
    "from functions.common_functions import judgment_batch_cutoff, judgment_batch_max, today_in_nums, errors_list, scraper_pause_mean, default_judgment_counter_bound, default_page_bound, own_gpt_headings, check_questions_answers, gpt_cost_msg, search_error_display, search_error_display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# Functions for Own Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e69f7f-1c1d-4fec-ae31-3024cd9f7ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.own_functions import doc_types, image_types, languages_dict, languages_list, doc_to_text, image_to_text, role_content_own, run_own, own_batch_request_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56fe91c-5bfb-4ee0-a36e-1369cf3b180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "#@st.cache_data\n",
    "def own_create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "\n",
    "    #Own account status\n",
    "    try:\n",
    "        own_account = own_account_entry\n",
    "    except:\n",
    "        own_account = False\n",
    "        print('Own account not selected')\n",
    "    \n",
    "    #file counter bound\n",
    "    #file_counter_bound = st.session_state['df_master'].loc[0, 'Maximum number of files']\n",
    "    try:\n",
    "        file_counter_bound = file_counter_bound_entry\n",
    "    except:\n",
    "        print('File counter bound not entered')\n",
    "        file_counter_bound = default_judgment_counter_bound\n",
    "\n",
    "    #Page counter bound\n",
    "    #page_bound = st.session_state['df_master'].loc[0,'Maximum number of pages per file']\n",
    "    try:\n",
    "        page_bound = page_bound_entry\n",
    "    except:\n",
    "        print('Page bound not entered')\n",
    "        page_bound = default_page_bound\n",
    "    \n",
    "    #GPT enhancement\n",
    "    try:\n",
    "        gpt_enhancement = gpt_enhancement_entry\n",
    "    except:\n",
    "        print('GPT enhancement not entered')\n",
    "        gpt_enhancement = False\n",
    "\n",
    "    if gpt_enhancement:\n",
    "        st.session_state.gpt_model = flagship_model\n",
    "    else:\n",
    "        st.session_state.gpt_model = basic_model\n",
    "        \n",
    "    #GPT choice and entry\n",
    "    try:\n",
    "        gpt_activation_status = gpt_activation_entry\n",
    "    except:\n",
    "        gpt_activation_status = False\n",
    "\n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "\n",
    "    #Get uploaded file names\n",
    "\n",
    "    file_names_list = []\n",
    "\n",
    "    for uploaded_doc in uploaded_docs:\n",
    "        file_names_list.append(uploaded_doc.name)\n",
    "\n",
    "    for uploaded_image in uploaded_images:\n",
    "        file_names_list.append(uploaded_image.name)\n",
    "\n",
    "    #Language choice\n",
    "\n",
    "    language = language_entry\n",
    "\n",
    "\n",
    "    #System instruction\n",
    "    try:\n",
    "        system_instruction = st.session_state['df_master'].loc[0, 'System instruction']\n",
    "    except:\n",
    "        system_instruction = role_content_own\n",
    "    \n",
    "    #Example\n",
    "    try:\n",
    "        df_example = st.session_state['df_master'].loc[0, 'Example']\n",
    "    except:\n",
    "        df_example = ''\n",
    "\n",
    "    #Consent\n",
    "    try:\n",
    "        consent = consent_entry\n",
    "    except:\n",
    "        print('Consent not entered')\n",
    "        consent = True\n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "            'Your uploaded files' : str(file_names_list), \n",
    "           'Language choice': language, \n",
    "           'Maximum number of files': file_counter_bound, \n",
    "          'Maximum number of pages per file': page_bound, \n",
    "            'Use GPT': gpt_activation_status, \n",
    "           'Enter your questions for GPT': gpt_questions, \n",
    "            'Use own account': own_account,\n",
    "            'Use flagship version of GPT': gpt_enhancement,\n",
    "            'System instruction': system_instruction,\n",
    "            'Example': df_example, \n",
    "            'Consent': consent\n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "    \n",
    "    return df_master_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bfae1df-142c-4583-ab1f-fd94500499b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string  \n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, system_characters_bound, basic_model, flagship_model, gpt_system_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = basic_model\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7af6e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Define system role content for GPT\n",
    "#system_instruction = role_content_own\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb2c4cf-70cf-48cb-856b-1df1b044be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions for vision, own file only\n",
    "from functions.gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "from functions.own_functions import image_to_b64_own, run_b64_own#, #GPT_b64_json_own, engage_GPT_b64_json_own"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5dcd6",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7b67cc-8e62-4287-b082-7c7d2d3e4a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from functions.common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faedfcb1-cb5a-4b37-8187-55068736fb1b",
   "metadata": {},
   "source": [
    "## Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400fc691-0352-4d0f-b1d1-8446507bab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.dialog(\"Producing data\")\n",
    "def own_run_function():\n",
    "    \n",
    "    if ((len(uploaded_docs) == 0) and (len(uploaded_images) == 0)):\n",
    "\n",
    "        st.warning('You must upload some file(s).')\n",
    "\n",
    "    elif ((st.session_state['df_master'].loc[0, 'Use GPT'] == False) or (len(gpt_questions_entry) < 5)):\n",
    "\n",
    "        st.warning(\"You must tick 'Use GPT' and enter some questions.\")\n",
    "        \n",
    "    elif int(consent_entry) == 0:\n",
    "        \n",
    "        st.warning(\"You must tick 'Yes, I agree.' to use the app.\")\n",
    "    \n",
    "    elif len(st.session_state.df_individual)>0:\n",
    "        \n",
    "        st.warning('You must :red[REMOVE] the last produced data before producing new data.')\n",
    "\n",
    "    else:\n",
    "\n",
    "        if ((own_account_entry) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                st.error('Your API key is not valid.')\n",
    "                st.stop()\n",
    "\n",
    "        spinner_text = \"In progress...\"\n",
    "        \n",
    "        with st.spinner(spinner_text):\n",
    "\n",
    "            try:\n",
    "                #Warning\n",
    "                if gpt_activation_entry:\n",
    "                    if st.session_state.gpt_model == basic_model:\n",
    "                        st.warning('A low-cost GPT model is in use. Please be cautious.')\n",
    "                        st.caption(f'Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more files or use a better model.')\n",
    "                    \n",
    "                    #if st.session_state.gpt_model == flagship_model:\n",
    "                        #st.warning('An expensive GPT model will process your files. Please be cautious.')\n",
    "                      \n",
    "                #Create spreadsheet of responses\n",
    "                df_master = own_create_df()\n",
    "\n",
    "                #Reduce maximum run number to batch limit if needed\n",
    "                if df_master.loc[0, 'Maximum number of files'] > st.session_state[\"judgment_batch_cutoff\"]:\n",
    "\n",
    "                    df_master.loc[0, 'Maximum number of files'] = st.session_state[\"judgment_batch_cutoff\"]\n",
    "                \n",
    "                #Activate user's own key or mine\n",
    "                if own_account_entry:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    \n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "    \n",
    "                openai.api_key = API_key\n",
    "                \n",
    "                df_individual = run_own(df_master, uploaded_docs, uploaded_images)\n",
    "        \n",
    "                #Keep entries in session state\n",
    "                st.session_state[\"df_master\"] = df_master\n",
    "    \n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                st.session_state[\"page_from\"] = 'pages/OWN.py'\n",
    "                \n",
    "                #Keep data in session state\n",
    "                st.session_state[\"df_individual\"] = df_individual\n",
    "\n",
    "                #Download data\n",
    "                #download_buttons(df_master, df_individual)\n",
    "\n",
    "                #Clear any error\n",
    "                st.session_state[\"batch_error\"] = False\n",
    "                st.session_state['error_msg'] = ''\n",
    "                \n",
    "                st.rerun()\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                #Clear output\n",
    "                st.session_state[\"df_individual\"] = pd.DataFrame([])\n",
    "                \n",
    "                st.error(search_error_display)\n",
    "                                \n",
    "                print(traceback.format_exc())\n",
    "\n",
    "                st.session_state['error_msg'] = traceback.format_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f831b63-bd1f-495c-9b64-72c31d7d5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@st.dialog(\"Producing data\")\n",
    "def run_b64_function():         \n",
    "\n",
    "    if len(uploaded_images) == 0:\n",
    "\n",
    "        st.warning('You must upload some image(s).')\n",
    "\n",
    "    elif ((st.session_state['df_master'].loc[0, 'Use GPT'] == False) or (len(gpt_questions_entry) < 5)):\n",
    "\n",
    "        st.warning(\"You must tick 'Use GPT' and enter some questions.\")\n",
    "\n",
    "    elif int(consent_entry) == 0:\n",
    "        st.warning(\"You must tick 'Yes, I agree.' to use the app.\")\n",
    "    \n",
    "    elif len(st.session_state.df_individual)>0:\n",
    "        st.warning('You must :red[REMOVE] the data already produced before producing new data.')\n",
    "\n",
    "    else:\n",
    "\n",
    "        if ((own_account_entry) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                st.error('Your API key is not valid.')\n",
    "                st.stop()\n",
    "                \n",
    "        #st.write('Your results should be available for download soon. The estimated waiting time is 3-5 minutes per 10 judgments.')\n",
    "        #st.write('If this app produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        spinner_text = \"In progress...\"\n",
    "\n",
    "        with st.spinner(spinner_text):\n",
    "\n",
    "            try:                    \n",
    "                #Create spreadsheet of responses\n",
    "                df_master = own_create_df()\n",
    "\n",
    "                #Reduce maximum run number to batch limit if needed\n",
    "                if df_master.loc[0, 'Maximum number of files'] > st.session_state[\"judgment_batch_cutoff\"]:\n",
    "\n",
    "                    df_master.loc[0, 'Maximum number of files'] = st.session_state[\"judgment_batch_cutoff\"]\n",
    "                \n",
    "                #Check for non-supported file types\n",
    "                if '.bmp' in str(df_master['Your uploaded files']).lower():\n",
    "                    st.error('Sorry, this app does not support BMP images.')\n",
    "                    st.stop()\n",
    "                    \n",
    "                if '.tiff' in str(df_master['Your uploaded files']).lower():\n",
    "                    st.error('Sorry, this app does not support TIFF images.')\n",
    "                    st.stop()\n",
    "                \n",
    "                #Activate user's own key or mine\n",
    "                if own_account_entry:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    \n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "    \n",
    "                openai.api_key = API_key\n",
    "                \n",
    "                df_individual = run_b64_own(df_master, uploaded_images)\n",
    "\n",
    "                #Keep entries in session state    \n",
    "                st.session_state[\"df_master\"] = df_master\n",
    "            \n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                st.session_state[\"page_from\"] = 'pages/OWN.py'\n",
    "                \n",
    "                #Keep data in session state\n",
    "                st.session_state[\"df_individual\"] = df_individual\n",
    "\n",
    "                #Download data\n",
    "                #download_buttons(df_master, df_individual)\n",
    "                \n",
    "                #if df_master.loc[0, 'Language choice'] != 'English':\n",
    "        \n",
    "                    #st.warning(\"If your spreadsheet reader does not display non-English text properly, please change the encoding to UTF-8 Unicode.\")\n",
    "\n",
    "                #Clear any error\n",
    "                st.session_state[\"batch_error\"] = False\n",
    "                st.session_state['error_msg'] = ''\n",
    "                \n",
    "                st.rerun()\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                #Clear output\n",
    "                st.session_state[\"df_individual\"] = pd.DataFrame([])\n",
    "                \n",
    "                st.error(search_error_display)\n",
    "                                \n",
    "                print(traceback.format_exc())\n",
    "\n",
    "                st.session_state['error_msg'] = traceback.format_exc()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f4f1ab-dc99-40a2-98cb-21bd59af47fc",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd44ad7-935b-4e9b-896f-19894c9d3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "#if 'jurisdiction_page' not in st.session_state:\n",
    "st.session_state['jurisdiction_page'] = 'pages/OWN.py'\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "#if 'own_account' not in st.session_state:\n",
    "    #st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    df_master_dict = {'Your name': '',\n",
    "    'Your email address': '',\n",
    "    'Your GPT API key': '',\n",
    "    'Maximum number of files': default_judgment_counter_bound,\n",
    "    'Maximum number of pages per file': default_page_bound,\n",
    "    'Language choice': 'English',\n",
    "    'Enter your questions for GPT': '',\n",
    "    'Use GPT': False,\n",
    "    'Use own account': False,\n",
    "    'Use flagship version of GPT': False,\n",
    "    'System instruction': role_content_own,\n",
    "    'Example': '', \n",
    "    'b64_enabled': False\n",
    "    }\n",
    "    \n",
    "    st.session_state['df_master'] = pd.DataFrame([df_master_dict])\n",
    "\n",
    "if 'System instruction' not in st.session_state.df_master.columns:\n",
    "        \n",
    "    st.session_state['df_master'].loc[0, 'System instruction'] = role_content_own\n",
    "\n",
    "if 'Example' not in st.session_state.df_master.columns:\n",
    "        \n",
    "    st.session_state['df_master'].loc[0, 'Example'] = ''\n",
    "\n",
    "if 'Consent' not in st.session_state.df_master.columns:\n",
    "    st.session_state['df_master'].loc[0, 'Consent'] = False\n",
    "\n",
    "if 'df_individual' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True\n",
    "\n",
    "#default_judgment_counter_bound < judgment_batch_cutoff < judgment_batch_max\n",
    "\n",
    "#Instant mode max/batch mode threshold\n",
    "if own_account_allowed() > 0:\n",
    "    st.session_state[\"judgment_batch_cutoff\"] = judgment_batch_cutoff\n",
    "else:\n",
    "    st.session_state[\"judgment_batch_cutoff\"] = default_judgment_counter_bound\n",
    "\n",
    "#Maximum number of judgments to process under any mode\n",
    "if \"judgment_counter_max\" not in st.session_state:\n",
    "\n",
    "    st.session_state[\"judgment_counter_max\"] = judgment_batch_cutoff\n",
    "\n",
    "if batch_mode_allowed() > 0:\n",
    "\n",
    "    if own_account_allowed() > 0:\n",
    "\n",
    "        st.session_state[\"judgment_counter_max\"] = judgment_batch_max\n",
    "\n",
    "    else:\n",
    "\n",
    "        st.session_state[\"judgment_counter_max\"] = judgment_batch_cutoff\n",
    "\n",
    "#Initalize for the purpuse of disabling multiple submissions of batch requests\n",
    "if \"batch_submitted\" not in st.session_state:\n",
    "    st.session_state[\"batch_submitted\"] = False\n",
    "\n",
    "if \"batch_error\" not in st.session_state:\n",
    "    st.session_state[\"batch_error\"] = False\n",
    "\n",
    "if \"batch_ready_for_submission\" not in st.session_state:\n",
    "    st.session_state[\"batch_ready_for_submission\"] = False\n",
    "\n",
    "#For example df\n",
    "if 'df_example_to_show' not in st.session_state:\n",
    "    st.session_state[\"df_example_to_show\"] = pd.DataFrame([])\n",
    "\n",
    "#Initalize df_example_key for the purpose of removing uploaded spreadsheets programatically\n",
    "if \"df_example_key\" not in st.session_state:\n",
    "    st.session_state[\"df_example_key\"] = 0\n",
    "\n",
    "#Initialise waiting time\n",
    "if 'estimated_waiting_secs' not in st.session_state:\n",
    "    \n",
    "    st.session_state['estimated_waiting_secs'] = int(float(st.session_state[\"judgment_batch_cutoff\"]))*30\n",
    "\n",
    "#Initialise jurisdiction_page\n",
    "if 'jurisdiction_page' not in st.session_state:\n",
    "    st.session_state['jurisdiction_page'] = 'pages/OWN.py'\n",
    "\n",
    "#Initialise error reporting status\n",
    "if 'error_msg' not in st.session_state:\n",
    "    st.session_state['error_msg'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffea44a-35e1-41a0-b8fa-1b8ba802e3b9",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683d9af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Create form\n",
    "\n",
    "return_button = st.button('RETURN to first page')\n",
    "\n",
    "st.header(f\"Research :blue[your own files]\")\n",
    "    \n",
    "st.success(f'Please upload your documents or images.')\n",
    "\n",
    "st.caption(f'By default, this app will extract text from up to {default_judgment_counter_bound} files, and process up to approximately {round(tokens_cap(basic_model)*3/4)} words from the first {default_page_bound} pages of each file. Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more files or more pages per file.')\n",
    "\n",
    "st.warning('This app works only if the text from your file(s) is displayed horizontally and neatly.')\n",
    "\n",
    "st.subheader('Upload documents')\n",
    "\n",
    "st.markdown(\"\"\"Supported document formats: **searchable PDF**, **DOCX**, **TXT**, **JSON**, CS,  EPUB, MOBI, XML, HTML, XPS.\n",
    "\"\"\")\n",
    "\n",
    "uploaded_docs = st.file_uploader(\"Please choose your document(s).\", type = doc_types, accept_multiple_files=True)\n",
    "\n",
    "st.caption('DOC is not yet supported. Microsoft Word or a similar software can convert a DOC file to a DOCX file.')\n",
    "\n",
    "st.subheader('Upload images')\n",
    "\n",
    "st.markdown(\"\"\"Supported image formats: **non-searchable PDF**, **JPG**, **JPEG**, **PNG**, BMP, GIF, TIFF.\n",
    "\"\"\")\n",
    "\n",
    "uploaded_images = st.file_uploader(\"Please choose your image(s).\", type = image_types, accept_multiple_files=True)\n",
    "\n",
    "st.caption(\"By default, [Python-tesseract](https://pypi.org/project/pytesseract/) will extract text from images. This tool is based on [Googleâ€™s Tesseract-OCR Engine](https://github.com/tesseract-ocr/tesseract).\")\n",
    "\n",
    "st.subheader('Language of uploaded files')\n",
    "\n",
    "st.markdown(\"\"\"In what language is the text from your uploaded file(s) written?\"\"\")\n",
    "    \n",
    "language_entry = st.selectbox(\"Please choose a language.\", languages_list, index=0)\n",
    "\n",
    "st.caption('Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to choose a language which is not available under this menu.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eacfac-cb27-4abb-b5fc-94ce69696a56",
   "metadata": {},
   "source": [
    "## Form for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d8a8b7-9d6d-4b79-a89f-bb3623714f72",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\":blue[Would you like GPT to get data or information from your files?]\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox(label = 'Use GPT (free for users by default)', value = st.session_state['df_master'].loc[0, 'Use GPT'])\n",
    "\n",
    "#if gpt_activation_entry:\n",
    "    \n",
    "st.session_state['df_master'].loc[0, 'Use GPT'] = gpt_activation_entry\n",
    "    \n",
    "st.caption(f\"{gpt_cost_msg}\")\n",
    "\n",
    "st.subheader(\"Tell GPT what to get from each file\")\n",
    "\n",
    "st.success(\"\"\"In question form, please tell GPT what to get from each file. **Enter one question per paragraph**. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"For each file, GPT will respond based only on information from the file itself. This is to minimise the risk of giving incorrect information (ie hallucination).\n",
    "GPT will also provide references for its responses.\n",
    "\"\"\")\n",
    "\n",
    "gpt_questions_entry = st.text_area(label = f\"Your questions (up to {question_characters_bound} characters)\", height= 250, max_chars=question_characters_bound, value = st.session_state['df_master'].loc[0, 'Enter your questions for GPT']) \n",
    "\n",
    "st.caption(f\"By default, this app will use model {basic_model}. This model will read up to approximately {round(tokens_cap(basic_model)*3/4)} words from each file.\")\n",
    "\n",
    "#if st.toggle('See tips for using GPT'):\n",
    "with st.expander(\"See tips for using GPT\"):\n",
    "    tips()\n",
    "\n",
    "#if st.toggle('See/edit the system instruction for GPT (advanced users only)'):\n",
    "with st.expander(\"See/edit the system instruction for GPT (advanced users only)\"):\n",
    "\n",
    "    st.warning(gpt_system_msg)\n",
    "\n",
    "    if st.button(label = 'RESET the system instruction', type=\"primary\"):\n",
    "\n",
    "        if 'System instruction' in st.session_state.df_master.columns:\n",
    "    \n",
    "            st.session_state.df_master.pop('System instruction')\n",
    "    \n",
    "        st.rerun()\n",
    "    \n",
    "    gpt_system_entry = st.text_area(label = f\"System instruction (up to {system_characters_bound} characters)\", height= 250, max_chars=system_characters_bound, value = st.session_state['df_master'].loc[0, 'System instruction']) \n",
    "\n",
    "    st.session_state['df_master'].loc[0, 'System instruction'] = gpt_system_entry\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    \n",
    "    st.warning(\"Please do not try to obtain personally identifiable information. Your questions/instructions and GPT's answers will be checked for potential privacy violation.\")\n",
    "\n",
    "#if gpt_questions_entry:\n",
    "    \n",
    "st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = gpt_questions_entry\n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        st.session_state['disable_input'] = True\n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "    \n",
    "#Upload example\n",
    "st.subheader(\"Share an exemplar (optional)\")\n",
    "\n",
    "st.markdown(\"\"\"This app will produce a spreadsheet with rows of files and columns of answers to your questions. If you have a preferred layout, please feel free to upload an example for GPT to follow.\"\"\")\n",
    "\n",
    "uploaded_file = st.file_uploader(label = \"Upload an example\", \n",
    "                                 type=['csv', 'xlsx', 'json'], \n",
    "                                 accept_multiple_files=False, \n",
    "                                  key = st.session_state[\"df_example_key\"]\n",
    "                                )\n",
    "\n",
    "if uploaded_file:\n",
    "\n",
    "    try:\n",
    "    \n",
    "        df_example_to_show = uploaded_file_to_df(uploaded_file)\n",
    "        \n",
    "        indice = df_example_to_show.index.tolist()\n",
    "    \n",
    "        if len(indice) > 0:\n",
    "    \n",
    "            for index in indice [1: ]:\n",
    "    \n",
    "                df_example_to_show.drop(index, axis=0, inplace = True)\n",
    "\n",
    "        #Create copy to show before dropping GPT stats headings\n",
    "        st.session_state.df_example_to_show = df_example_to_show.copy(deep = True)\n",
    "\n",
    "        #Drop any GPT stats headings and add example to df_master as a string of a json\n",
    "        columns = df_example_to_show.columns.tolist()\n",
    "\n",
    "        for col in columns:\n",
    "            \n",
    "            for gpt_col in own_gpt_headings:\n",
    "                \n",
    "                if ((gpt_col.lower() in col.lower()) and (col in df_example_to_show.columns)):\n",
    "                    \n",
    "                    df_example_to_show.drop(col, axis=1, inplace = True)\n",
    "                            \n",
    "        st.session_state.df_master.loc[0, 'Example'] = json.dumps(df_example_to_show.loc[0].to_json(default_handler=str))\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        st.error(f'Sorry, this app is unable to follow the selected example.')\n",
    "\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "        st.session_state['error_msg'] = traceback.format_exc()\n",
    "\n",
    "if len(st.session_state.df_example_to_show) > 0:\n",
    "        \n",
    "    st.success('For each file, GPT will *try* to produce something like the following:')\n",
    "\n",
    "    st.dataframe(st.session_state.df_example_to_show)\n",
    "\n",
    "    #Button for removing example\n",
    "    if st.button(label = 'REMOVE the uploaded example', type = 'primary'):\n",
    "    \n",
    "        st.session_state.df_example_key += 1\n",
    "    \n",
    "        st.session_state.df_example_to_show = pd.DataFrame([])\n",
    "    \n",
    "        st.session_state.df_master.loc[0, 'Example'] = ''\n",
    "    \n",
    "        st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa52a4f-f0d8-46bb-b9c0-7328e861425d",
   "metadata": {},
   "source": [
    "## Own account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c1dc36-7348-4a92-8867-c22175ee020e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if own_account_allowed() == 0:\n",
    "    \n",
    "    own_account_entry = False\n",
    "\n",
    "else:\n",
    "    \n",
    "#if own_account_allowed() > 0:\n",
    "    \n",
    "    st.header(':orange[Enhance app capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum number of files to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle(label = 'Use my own GPT account',  disabled = st.session_state.disable_input, value = st.session_state['df_master'].loc[0, 'Use own account'])\n",
    "    \n",
    "    if own_account_entry:\n",
    "    \n",
    "        #st.session_state['df_master'].loc[0, 'Use own account'] = own_account_entry\n",
    "        \n",
    "        #st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "    \"\"\")\n",
    "        \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state['df_master'].loc[0, 'Your name'])\n",
    "\n",
    "        #if name_entry:\n",
    "            \n",
    "        #st.session_state['df_master'].loc[0, 'Your name'] = name_entry\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value =  st.session_state['df_master'].loc[0, 'Your email address'])\n",
    "\n",
    "        #if email_entry:\n",
    "            \n",
    "        #st.session_state['df_master'].loc[0, 'Your email address'] = email_entry\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state['df_master'].loc[0, 'Your GPT API key'])\n",
    "        \n",
    "        if gpt_api_key_entry:\n",
    "            \n",
    "            #st.session_state['df_master'].loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "\n",
    "            if ((len(gpt_api_key_entry) < 40) or (gpt_api_key_entry[0:2] != 'sk')):\n",
    "                \n",
    "                st.warning('This key is not valid.')\n",
    "                \n",
    "        st.markdown(f\"\"\"**:green[You can use the flagship GPT model ({flagship_model}),]** which is :red[significantly more expensive] than the default model ({basic_model}).\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the flagship GPT model', value = st.session_state['df_master'].loc[0, 'Use flagship version of GPT'])\n",
    "        \n",
    "        st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "\n",
    "        #if gpt_enhancement_entry == True:\n",
    "        \n",
    "            #st.session_state.gpt_model = flagship_model\n",
    "            #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = True\n",
    "\n",
    "        #else:\n",
    "            \n",
    "            #st.session_state.gpt_model = basic_model\n",
    "            #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "        \n",
    "        st.write(f'**:green[You can change the maximum number of files to process.]**')\n",
    "\n",
    "        file_counter_bound_entry = st.slider(label = f'Up to {st.session_state[\"judgment_counter_max\"]} files', min_value = 1, max_value = st.session_state[\"judgment_counter_max\"], step = 1, value = str_to_int(st.session_state['df_master'].loc[0, 'Maximum number of files']))\n",
    "\n",
    "        #if file_counter_bound_entry:\n",
    "            \n",
    "        #st.session_state['df_master'].loc[0, 'Maximum number of files'] = file_counter_bound_entry\n",
    "        \n",
    "        if file_counter_bound_entry > st.session_state[\"judgment_batch_cutoff\"]:\n",
    "    \n",
    "            st.warning(f\"Given more than {st.session_state['judgment_batch_cutoff']} files may need to be processes, this app will send your requested data to your nominated email address in about **2 business days**.\")\n",
    "\n",
    "        st.write(f'**:orange[You can change the maximum number of pages per file to process.]**')\n",
    "        \n",
    "        page_bound_entry = st.slider(label = f'Up to {default_page_bound} pages', min_value = 1, max_value = default_page_bound, step = 1, value = str_to_int_page(st.session_state['df_master'].loc[0, 'Maximum number of pages per file']))\n",
    "\n",
    "        #if page_bound_entry:\n",
    "            \n",
    "        #st.session_state['df_master'].loc[0, 'Maximum number of pages per file'] = page_bound_entry\n",
    "        \n",
    "        #st.write(f\"*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {int(round(tokens_cap(st.session_state.gpt_model)*3/4))} words from the first  {int(st.session_state['df_master'].loc[0,'Maximum number of pages per file'])} page(s) of each file, for up to {int(st.session_state['df_master'].loc[0, 'Maximum number of files'])} file(s).*\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        #st.session_state[\"own_account\"] = False\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    \n",
    "        st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "        #st.session_state.gpt_model = basic_model\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Maximum number of files'] = default_judgment_counter_bound #st.session_state[\"judgment_batch_cutoff\"]\n",
    "\n",
    "        st.session_state['df_master'].loc[0,'Maximum number of pages per file'] = default_page_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd61bdce-8fc2-4835-b4d7-1bd4f07eb320",
   "metadata": {},
   "source": [
    "## Save entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34fe3779-93b5-4899-91aa-2a894dd4cdd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gpt_keep_button \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241m.\u001b[39mbutton(label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDOWNLOAD entries\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpt_keep_button:\n\u001b[1;32m      4\u001b[0m     st\u001b[38;5;241m.\u001b[39msuccess(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScroll down to download your entries.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "keep_button = st.button(label = 'DOWNLOAD entries')\n",
    "\n",
    "if keep_button:\n",
    "    \n",
    "    st.success('Scroll down to download your entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3644b48-7cf1-4f9a-81d0-dafd8ba910a4",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550daa8-1f1c-4845-a0f6-2a519d66cb9e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By using this app, you agree that the data and/or information you and/or this app provide will be temporarily stored on one or more remote servers. Any such data and/or information may also be given to an artificial intelligence provider. Any such data and/or information [will not be used to train any artificial intelligence model.](https://platform.openai.com/docs/models/how-we-use-your-data#how-we-use-your-data) \n",
    "\"\"\")\n",
    "\n",
    "consent_entry =  st.checkbox('Yes, I agree.', value = bool(st.session_state['df_master'].loc[0, 'Consent']), disabled = st.session_state.disable_input)\n",
    "\n",
    "st.session_state['df_master'].loc[0, 'Consent'] = consent_entry\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this app. \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b38b59d-7b8a-4c23-afbb-2acfb0ad1d20",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd86776-9d3c-4111-8133-401241a1f6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Next steps\")\n",
    "\n",
    "#Calculate estimating waiting time\n",
    "\n",
    "#Instructions\n",
    "st.markdown(f\"\"\"You can now press :green[PRODUCE data] to obtain a spreadsheet which hopefully has the data you seek. This app will immediately process up to {int(min(st.session_state[\"judgment_batch_cutoff\"], st.session_state['df_master'].loc[0, 'Maximum number of files']))} cases. The estimated waiting time is **{min(st.session_state[\"judgment_batch_cutoff\"], st.session_state['df_master'].loc[0, 'Maximum number of files'])*30/60} minute(s)**.\n",
    "\"\"\")\n",
    "\n",
    "if batch_mode_allowed() > 0:\n",
    "    st.markdown(f\"\"\"Alternatively, you can press :orange[REQUEST data] to process up to {st.session_state[\"judgment_counter_max\"]} files. Your requested data will be sent to your nominated email address in about **2 business days**. \n",
    "\"\"\")\n",
    "\n",
    "reset_button = st.button(label='REMOVE data', type = 'primary', disabled = not bool(st.session_state.need_resetting))\n",
    "\n",
    "if batch_mode_allowed() > 0:\n",
    "    with stylable_container(\n",
    "        \"orange\",\n",
    "        css_styles=\"\"\"\n",
    "        button {\n",
    "            background-color: #F9F500;\n",
    "            color: black;\n",
    "        }\"\"\",\n",
    "    ):\n",
    "        batch_button = st.button(label = f\"REQUEST data (up to {st.session_state['judgment_counter_max']} files)\", \n",
    "                                  help = 'You can only :orange[REQUEST] data once per session.', \n",
    "                                 disabled = bool((st.session_state.batch_submitted) or (st.session_state.disable_input))\n",
    "                                )\n",
    "        \n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "\n",
    "    run_button = st.button(label = f\"PRODUCE data now (up to {int(min(st.session_state['judgment_batch_cutoff'], st.session_state['df_master'].loc[0, 'Maximum number of files']))} files)\", \n",
    "                          help = 'You must :red[REMOVE] any data previously produced before producing new data.', \n",
    "                           disabled = bool((st.session_state.need_resetting) or (st.session_state.disable_input) or (bool(st.session_state['df_master'].loc[0, 'Maximum number of files'] > st.session_state[\"judgment_batch_cutoff\"])))\n",
    "                          )\n",
    "\n",
    "if ((own_account_entry == True) and (uploaded_images)):\n",
    "\n",
    "    if immediate_b64() > 0:\n",
    "    \n",
    "        st.markdown(\"\"\"By default, this app will use an Optical Character Recognition (OCR) engine to extract text from images, and then send such text to GPT.\n",
    "        \n",
    "Alternatively, you can send images directly to GPT. This alternative approach may produce better responses for \"untidy\" images, but tends to be slower and costlier than the default approach.\n",
    "\"\"\")\n",
    "    \n",
    "        run_button_b64 = st.button(label = f\"SEND images to GPT directly now (up to {min(st.session_state['judgment_batch_cutoff'], st.session_state['df_master'].loc[0, 'Maximum number of files'])} files)\", \n",
    "                                  help = 'You must :red[REMOVE] any data previously produced before producing new data.', \n",
    "                                   disabled = bool((st.session_state.need_resetting) or (st.session_state.disable_input) or (bool(st.session_state['df_master'].loc[0, 'Maximum number of files'] > st.session_state[\"judgment_batch_cutoff\"])))\n",
    "                                  )\n",
    "    \n",
    "    else:\n",
    "\n",
    "        st.markdown(\"\"\"By default, this app will use an Optical Character Recognition (OCR) engine to extract text from images, and then send such text to GPT.\n",
    "        \n",
    "Alternatively, you can request to send images directly to GPT. This alternative approach may produce better responses for \"untidy\" images, but tends to be slower and costlier than the default approach. Your request data will be sent to your nominated email address in about **2 business days**.\n",
    "\"\"\")\n",
    "        \n",
    "        batch_button_b64 = st.button(label = f\"REQUEST to send images to GPT directly (up to {st.session_state['judgment_counter_max']} files)\", \n",
    "                                       help = 'You can only :orange[REQUEST] data once per session.', \n",
    "                                 disabled = bool((st.session_state.batch_submitted) or (st.session_state.disable_input))\n",
    "                                    )\n",
    "\n",
    "#test_button = st.button('Test')\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "#if st.session_state.need_resetting == 1:\n",
    "    #if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual) > 0)):\n",
    "        #st.warning('You must :red[REMOVE] the data previously produced before producing new data.')\n",
    "        #st.warning('You must :red[RESET] the app before producing new data. Please press the :red[RESET] button above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c72a80-7164-4525-b07a-0a79019ce5b6",
   "metadata": {},
   "source": [
    "## Download entries and and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71f054d-f177-4766-805b-2a50fd122662",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Create placeholder download buttons if previous entries and output in st.session_state:\n",
    "\n",
    "if len(st.session_state.df_individual) > 0:\n",
    "\n",
    "    #Current output\n",
    "    if st.session_state[\"page_from\"] == 'pages/OWN.py':\n",
    "\n",
    "        download_buttons(df_master = st.session_state.df_master, df_individual = st.session_state.df_individual)\n",
    "\n",
    "    #Previous entries and output\n",
    "    else:\n",
    "\n",
    "        download_buttons(df_master = st.session_state.df_master, df_individual = st.session_state.df_individual, saving = False, previous = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9dd7be-bfc0-41c3-965a-b457c2fd114f",
   "metadata": {},
   "source": [
    "# Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86074cc-a57e-47a8-b1af-4d5f77ce1acf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#b64 batch\n",
    "if (batch_mode_allowed() > 0) and ((own_account_entry) and (uploaded_images)):\n",
    "\n",
    "    if batch_button_b64:\n",
    "    \n",
    "        if len(uploaded_images) == 0:\n",
    "    \n",
    "            st.warning('You must upload some image(s).')\n",
    "    \n",
    "        elif ((st.session_state['df_master'].loc[0, 'Use GPT'] == False) or (len(gpt_questions_entry) < 5)):\n",
    "    \n",
    "            st.warning(\"You must tick 'Use GPT' and enter some questions.\")\n",
    "            \n",
    "        elif int(consent_entry) == 0:\n",
    "            \n",
    "            st.warning(\"You must tick 'Yes, I agree.' to use the app.\")\n",
    "        \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            \n",
    "            st.warning('You must :red[REMOVE] the last produced data before producing new data.')\n",
    "\n",
    "        else:\n",
    "\n",
    "            #Create spreadsheet of responses\n",
    "            df_master = own_create_df()\n",
    "\n",
    "            #Check for non-supported file types\n",
    "            if '.bmp' in str(df_master['Your uploaded files']).lower():\n",
    "                st.error('Sorry, this app does not support BMP images.')\n",
    "                st.stop()\n",
    "                \n",
    "            if '.tiff' in str(df_master['Your uploaded files']).lower():\n",
    "                st.error('Sorry, this app does not support TIFF images.')\n",
    "                st.stop()\n",
    "\n",
    "            #Ensure b64 is turned on\n",
    "            df_master.loc[0, 'b64_enabled'] = True\n",
    "            \n",
    "            #Keep entries in session state    \n",
    "            st.session_state[\"df_master\"] = df_master\n",
    "            \n",
    "            own_batch_request_function(df_master, uploaded_docs, uploaded_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53d3b8-f2d3-452a-8f34-1cf8fe65d665",
   "metadata": {},
   "source": [
    "## Save and run etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3bbb09-b5e6-420f-a4cc-d64375f9f9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "            \n",
    "    own_run_function()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d036f750-9693-4b10-8cbe-6df501f5fecc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#NOT IN USE\n",
    "\n",
    "if immediate_b64() > 0:\n",
    "    \n",
    "    if ((own_account_entry) and (uploaded_images)):\n",
    "        \n",
    "        if run_button_b64:\n",
    "\n",
    "            run_b64_function()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873fffb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    if ((len(uploaded_docs) == 0) and (len(uploaded_images) == 0)):\n",
    "\n",
    "        st.warning('You must upload some file(s).')\n",
    "\n",
    "    elif len(gpt_questions_entry) < 5:\n",
    "\n",
    "        st.warning('You must enter some questions for GPT.')\n",
    "            \n",
    "    else:\n",
    "\n",
    "        df_master = own_create_df()\n",
    "    \n",
    "        st.session_state[\"df_master\"] = df_master\n",
    "\n",
    "        download_buttons(df_master = st.session_state.df_master, df_individual = [], saving = True, previous = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995962d0-2a30-4327-9a0e-55b2f3e27b78",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    try:\n",
    "\n",
    "        df_master = own_create_df()\n",
    "    \n",
    "        save_input(df_master)\n",
    "        \n",
    "    except:\n",
    "        print('df_master not created.')\n",
    "\n",
    "    st.session_state[\"page_from\"] = 'pages/OWN.py'\n",
    "\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c823ead-52f0-430c-9e6a-9f471d5e703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_button:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "    \n",
    "    st.session_state['need_resetting'] = 0\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    \n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76b189-fcad-4279-aa55-81d5ea7eb767",
   "metadata": {},
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449ec332-d321-4a82-8f8f-436462a10ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regular batch\n",
    "if batch_mode_allowed() > 0:\n",
    "    \n",
    "    if batch_button:\n",
    "\n",
    "        if ((len(uploaded_docs) == 0) and (len(uploaded_images) == 0)):\n",
    "    \n",
    "            st.warning('You must upload some file(s).')\n",
    "    \n",
    "        elif ((st.session_state['df_master'].loc[0, 'Use GPT'] == False) or (len(gpt_questions_entry) < 5)):\n",
    "    \n",
    "            st.warning(\"You must tick 'Use GPT' and enter some questions.\")\n",
    "            \n",
    "        elif int(consent_entry) == 0:\n",
    "            \n",
    "            st.warning(\"You must tick 'Yes, I agree.' to use the app.\")\n",
    "        \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            \n",
    "            st.warning('You must :red[REMOVE] the last produced data before producing new data.')\n",
    "\n",
    "        else:\n",
    "\n",
    "            #Create spreadsheet of responses\n",
    "            df_master = own_create_df()\n",
    "\n",
    "            #Ensure b64 is turned off\n",
    "            df_master.loc[0, 'b64_enabled'] = False\n",
    "            \n",
    "            #Keep entries in session state    \n",
    "            st.session_state[\"df_master\"] = df_master\n",
    "            \n",
    "            own_batch_request_function(df_master, uploaded_docs, uploaded_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227263b9-2ace-45bd-b529-c4576e7b819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch submission status\n",
    "if batch_mode_allowed() > 0:\n",
    "    \n",
    "    if st.session_state.batch_submitted and (st.session_state.batch_error == False):\n",
    "        \n",
    "        st.success('Your data request has been submitted. This app will send your requested data to your nominated email address in about **2 business days**. Feel free to close this app.')\n",
    "\n",
    "        #Warning\n",
    "        if gpt_activation_entry:\n",
    "            if st.session_state.gpt_model == basic_model:\n",
    "                st.warning('A low-cost GPT model is in use. Please be cautious.')\n",
    "                st.caption(f'Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more cases or use a better model.')\n",
    "            \n",
    "            #if st.session_state.gpt_model == flagship_model:\n",
    "                #st.warning('An expensive GPT model will process the cases found. Please be cautious.')\n",
    "\n",
    "    if (st.session_state.batch_error) and (len(st.session_state.error_msg) > 0):\n",
    "\n",
    "        st.error(search_error_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fac532-6836-41cc-b609-a69856661342",
   "metadata": {},
   "source": [
    "## Report error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87433267-5b07-4954-b639-c99d07ac40cb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if len(st.session_state.error_msg) > 0:\n",
    "\n",
    "    report_error_button = st.button(label = 'REPORT the error', type = 'primary', help = 'Send your entries and a report of the error to the developer.')\n",
    "\n",
    "    if report_error_button:\n",
    "\n",
    "        st.session_state.error_msg = report_error(error_msg = st.session_state.error_msg, jurisdiction_page = st.session_state.jurisdiction_page, df_master = st.session_state.df_master)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
