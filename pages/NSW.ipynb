{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51218f00-183e-4f7a-9fe5-2393c3de15b0",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07019cf3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import PyPDF2\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#NSWCaseLaw\n",
    "from nswcaselaw.search import Search\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5120eafa-8759-48bb-9e56-cee8e8cd2ac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n",
    "#Import variables\n",
    "from common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ffaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e432b7",
   "metadata": {},
   "source": [
    "# CaseLaw NSW functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b999856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary lists\n",
    "search_criteria = ['Free text', 'Case name', 'Before', 'Catchwords', 'Party names', 'Medium neutral citation', 'Decision date from', 'Decision date to', 'File number', 'Legislation cited', 'Cases cited']\n",
    "meta_labels_droppable = [\"Catchwords\", \"Before\", \"Decision date(s)\", \"Hearing date(s)\", \"Date(s) of order\",  \"Jurisdiction\", \"Decision\", \"Legislation cited\", \"Cases cited\", \"Texts cited\", \"Category\", \"Parties\", \"File number\", \"Representation\", \"Decision under appeal\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28525de2-5be8-495a-af01-b3b172106e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of nsw courts\n",
    "\n",
    "#For showing as menu\n",
    "nsw_courts =[\"Court of Appeal\", \n",
    "             \"Court of Criminal Appeal\", \n",
    "             \"Supreme Court\", \n",
    "             'Land and Environment Court (Judges)', \n",
    "             'Land and Environment Court (Commissioners)', \n",
    "             'District Court', \n",
    "             'Local Court',\n",
    "             \"Children's Court\", \n",
    "             'Compensation Court', \n",
    "             'Drug Court', \n",
    "             'Industrial Court',\n",
    "             'Industrial Relations Commission (Judges)', \n",
    "             'Industrial Relations Commission (Commissioners)'\n",
    "            ] #, \"All of the above Courts\"]\n",
    "\n",
    "#For positioning\n",
    "nsw_courts_positioning = [\"Placeholder\", \"Children's Court\",\n",
    " 'Compensation Court',\n",
    " 'Court of Appeal',\n",
    " 'Court of Criminal Appeal',\n",
    " 'District Court',\n",
    " 'Drug Court',\n",
    " 'Industrial Court',\n",
    " 'Industrial Relations Commission (Commissioners)',\n",
    " 'Industrial Relations Commission (Judges)',\n",
    " 'Land and Environment Court (Commissioners)',\n",
    " 'Land and Environment Court (Judges)',\n",
    " 'Local Court',\n",
    " 'Supreme Court']\n",
    "\n",
    "#Default courts\n",
    "nsw_default_courts = [\"Court of Appeal\", \"Court of Criminal Appeal\", \"Supreme Court\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7183b01d-ed57-4d21-836c-0ac3a49bb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of NSW tribunals\n",
    "\n",
    "nsw_tribunals = ['Administrative Decisions Tribunal (Appeal Panel)',\n",
    " 'Administrative Decisions Tribunal (Divisions)',\n",
    " 'Civil and Administrative Tribunal (Administrative and Equal Opportunity Division)',\n",
    " 'Civil and Administrative Tribunal (Appeal Panel)',\n",
    " 'Civil and Administrative Tribunal (Consumer and Commercial Division)',\n",
    " 'Civil and Administrative Tribunal (Enforcement)',\n",
    " 'Civil and Administrative Tribunal (Guardianship Division)',\n",
    " 'Civil and Administrative Tribunal (Occupational Division)',\n",
    " 'Dust Diseases Tribunal',\n",
    " 'Equal Opportunity Tribunal',\n",
    " 'Fair Trading Tribunal',\n",
    " 'Legal Services Tribunal',\n",
    " 'Medical Tribunal',\n",
    " 'Transport Appeal Boards']\n",
    "\n",
    "nsw_tribunals_positioning = ['Placeholder',\n",
    " 'Administrative Decisions Tribunal (Appeal Panel)',\n",
    " 'Administrative Decisions Tribunal (Divisions)',\n",
    " 'Civil and Administrative Tribunal (Administrative and Equal Opportunity Division)',\n",
    " 'Civil and Administrative Tribunal (Appeal Panel)',\n",
    " 'Civil and Administrative Tribunal (Consumer and Commercial Division)',\n",
    " 'Civil and Administrative Tribunal (Enforcement)',\n",
    " 'Civil and Administrative Tribunal (Guardianship Division)',\n",
    " 'Civil and Administrative Tribunal (Occupational Division)',\n",
    " 'Dust Diseases Tribunal',\n",
    " 'Equal Opportunity Tribunal',\n",
    " 'Fair Trading Tribunal',\n",
    " 'Legal Services Tribunal',\n",
    " 'Medical Tribunal',\n",
    " 'Transport Appeal Boards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e79f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "\n",
    "def create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "        #This is the user's entered API key whether valid or invalid, not necessarily the one used to produce outputs\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "\n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "    \n",
    "    #Judgment counter bound\n",
    "    judgments_counter_bound = st.session_state.judgments_counter_bound\n",
    "\n",
    "    #GPT enhancement\n",
    "    gpt_enhancement = st.session_state.gpt_enhancement_entry\n",
    "    \n",
    "    #NSW court choices\n",
    "\n",
    "    courts_list = courts_entry\n",
    "\n",
    "    courts = ', '.join(courts_list)\n",
    "    \n",
    "    #NSW tribunals choices\n",
    "    \n",
    "    tribunals_list = tribunals_entry\n",
    "\n",
    "    tribunals = ', '.join(tribunals_list)\n",
    "\n",
    "    #Search terms\n",
    "    \n",
    "    body = body_entry\n",
    "    title = title_entry\n",
    "    before = before_entry\n",
    "    catchwords = catchwords_entry\n",
    "    party = party_entry\n",
    "    mnc = mnc_entry\n",
    "\n",
    "    startDate = ''\n",
    "\n",
    "    if startDate_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            startDate = startDate_entry.strftime('%d/%m/%Y')\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    endDate = ''\n",
    "\n",
    "    if endDate_entry != 'None':\n",
    "        \n",
    "        try:\n",
    "            endDate = endDate_entry.strftime('%d/%m/%Y')\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    fileNumber = fileNumber_entry\n",
    "    legislationCited = legislationCited_entry\n",
    "    casesCited = casesCited_entry\n",
    "\n",
    "    #metadata choice\n",
    "\n",
    "    meta_data_choice = meta_data_entry\n",
    "    \n",
    "    #GPT choice and entry\n",
    "    gpt_activation_status = gpt_activation_entry\n",
    "\n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: 1000]\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "\n",
    "    #Create row\n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "           'Courts': courts,\n",
    "           'Tribunals': tribunals, \n",
    "           'Free text': body, \n",
    "           'Case name': title, \n",
    "           'Before' : before, \n",
    "           'Catchwords' : catchwords, \n",
    "           'Party names' : party, \n",
    "           'Medium neutral citation': mnc, \n",
    "           'Decision date from': startDate, \n",
    "           'Decision date to': endDate, \n",
    "           'File number': fileNumber, \n",
    "           'Legislation cited': legislationCited,\n",
    "           'Cases cited': casesCited, \n",
    "#           'Information to Collect from Judgment Headnotes': headnotes,\n",
    "            'Metadata inclusion' : meta_data_choice,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your questions for GPT': gpt_questions, \n",
    "            'Use GPT': gpt_activation_status, \n",
    "            'Use own account': own_account,\n",
    "            'Use latest version of GPT' : gpt_enhancement\n",
    "          }\n",
    "    \n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "        \n",
    "    return df_master_new\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ef07dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to convert the string of chosen courts to a list; 13 = NSWSC, 3 = NSWCA, 4 = NSWCCA\n",
    "#For more, see https://github.com/Sydney-Informatics-Hub/nswcaselaw/blob/main/src/nswcaselaw/constants.py\n",
    "\n",
    "def court_choice(x):\n",
    "    individual_choice = []\n",
    "\n",
    "    if len(x) < 5:\n",
    "        pass #If want to select no court absent any choice\n",
    "        #individual_choice = [3, 4, 13] #If want to select NSWSC, CA and CCA absent any choice\n",
    "        #for j in range(1, len(nsw_courts_positioning)):\n",
    "            #individual_choice.append(j) #If want to select all courts absent any choice\n",
    "    else:\n",
    "        y = x.split(', ')\n",
    "        for i in y:\n",
    "            individual_choice.append(nsw_courts_positioning.index(i))            \n",
    "    \n",
    "    return individual_choice\n",
    "\n",
    "def tribunal_choice(x):\n",
    "    individual_choice = []\n",
    "\n",
    "    if len(x) < 5:\n",
    "        pass #If want to select no tribunal absent any choice\n",
    "        #for j in range(1, len(nsw_tribunals_positioning)):\n",
    "            #individual_choice.append(j) #If want to select all tribunals absent any choice\n",
    "    else:\n",
    "        y = x.split(', ')\n",
    "        for i in y:\n",
    "            individual_choice.append(nsw_tribunals_positioning.index(i))            \n",
    "    \n",
    "    return individual_choice\n",
    "\n",
    "#Functions for tidying up\n",
    "\n",
    "#Tidy up dates\n",
    "def date(x):\n",
    "    if len(str(x)) >0:\n",
    "        return str(x).split()[0]\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "# Headnotes fields\n",
    "headnotes_fields = [\"Free text\", \"Case name\", \"Before\", \"Decision date(s)\", \"Catchwords\", \"Hearing date(s)\", \"Date(s) of order\",  \"Jurisdiction\", \"Decision\", \"Legislation cited\", \"Cases cited\", \"Texts cited\", \"Category\", \"Parties\", \"Medium neutral citation\", \"Decision date from\", \"Decision date to\", \"File number\", \"Representation\", \"Decision under appeal\"]\n",
    "headnotes_keys = [\"body\", \"title\", \"before\", \"decisionDate\", \"catchwords\", \"hearingDates\", \"dateOfOrders\", \"jurisdiction\", \"decision\", \"legislationCited\", \"casesCited\", \"textsCited\", \"category\", \"parties\", \"mnc\", \"startDate\", \"endDate\", \"fileNumber\", \"representation\", \"decisionUnderAppeal\"]\n",
    "\n",
    "#Functions for tidying up headings of columns\n",
    "\n",
    "#Tidy up hyperlink\n",
    "def nsw_link(x):\n",
    "    link='https://www.caselaw.nsw.gov.au'+ str(x)\n",
    "    value = '=HYPERLINK(\"' + link + '\")'\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12bc2af9-d2ed-4d64-95a0-7e0a84dda2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for short judgments, which checks if judgment is in PDF\n",
    "#returns a list of judgment type and judgment text\n",
    "\n",
    "def short_judgment(html_link):\n",
    "    page_html = requests.get(html_link)\n",
    "    soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "\n",
    "    judgment_type = ''\n",
    "\n",
    "    #Check if judgment contains PDF link\n",
    "    PDF_raw_link = soup_html.find('a', text='See Attachment (PDF)')\n",
    "    \n",
    "    if str(PDF_raw_link).lower() != 'none':\n",
    "        PDF_link = 'https://www.caselaw.nsw.gov.au' + PDF_raw_link.get('href')    \n",
    "        headers = {'User-Agent': 'whatever'}\n",
    "        r = requests.get(PDF_link, headers=headers)\n",
    "        remote_file_bytes = io.BytesIO(r.content)\n",
    "        pdfdoc_remote = PyPDF2.PdfReader(remote_file_bytes)\n",
    "        text_list = []\n",
    "        \n",
    "        for page in pdfdoc_remote.pages:\n",
    "            text_list.append(page.extract_text())\n",
    "\n",
    "        judgment_type = 'pdf'\n",
    "        \n",
    "        return [judgment_type, str(text_list)]\n",
    "\n",
    "    #Return html text if no PDF\n",
    "    else:\n",
    "        judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "        judgment_type = 'html'\n",
    "\n",
    "        return [judgment_type, judgment_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ec03917-e834-4104-9a39-90feb884114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Courts'] = df_master['Courts'].apply(court_choice)\n",
    "    df_master['Tribunals'] = df_master['Tribunals'].apply(tribunal_choice)\n",
    "\n",
    "    #df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    #df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    search_dict = {'body': df_master.loc[0, 'Free text']}\n",
    "    search_dict.update({'title': df_master.loc[0, 'Case name']})\n",
    "    search_dict.update({'before': df_master.loc[0, 'Before']})\n",
    "    search_dict.update({'catchwords': df_master.loc[0, 'Catchwords']})\n",
    "    search_dict.update({'party': df_master.loc[0, 'Party names']})\n",
    "    search_dict.update({'mnc': df_master.loc[0, 'Medium neutral citation']})\n",
    "    search_dict.update({'startDate': df_master.loc[0, 'Decision date from']})\n",
    "    search_dict.update({'endDate': df_master.loc[0, 'Decision date to']})\n",
    "    search_dict.update({'fileNumber': df_master.loc[0, 'File number']})\n",
    "    search_dict.update({'legislationCited': df_master.loc[0, 'Legislation cited']})\n",
    "    search_dict.update({'casesCited': df_master.loc[0, 'Cases cited']})\n",
    "    df_master.loc[0, 'SearchCriteria']=[search_dict]\n",
    "\n",
    "    #Conduct search\n",
    "    \n",
    "    query = Search(courts=df_master.loc[0, 'Courts'], \n",
    "                   tribunals=df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, \"SearchCriteria\"]['body'], \n",
    "                   title = df_master.loc[0, \"SearchCriteria\"]['title'], \n",
    "                   before = df_master.loc[0, \"SearchCriteria\"]['before'], \n",
    "                   catchwords = df_master.loc[0, \"SearchCriteria\"]['catchwords'], \n",
    "                   party = df_master.loc[0, \"SearchCriteria\"]['party'], \n",
    "                   mnc = df_master.loc[0, \"SearchCriteria\"]['mnc'], \n",
    "                   startDate = date(df_master.loc[0, \"SearchCriteria\"]['startDate']), \n",
    "                   endDate = date(df_master.loc[0, \"SearchCriteria\"]['endDate']),\n",
    "                   fileNumber = df_master.loc[0, \"SearchCriteria\"]['fileNumber'], \n",
    "                   legislationCited  = df_master.loc[0, \"SearchCriteria\"]['legislationCited'], \n",
    "                   casesCited = df_master.loc[0, \"SearchCriteria\"]['legislationCited'],\n",
    "                   pause = 0\n",
    "                  )\n",
    "    return query.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984b836",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264f776f-9383-4727-bc0f-fdee31463433",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string, judgment_prompt_json, GPT_json_tokens, engage_GPT_json_tokens  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound, role_content\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, default_judgment_counter_bound, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b3481-b897-4ee6-af9c-ca38d2412631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8b81-719b-4672-a141-7d9331cde96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "system_instruction = role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76efd97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module, costs and upperbounds\n",
    "\n",
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35635339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "def run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "#    df_master['Information to Collect from Judgment Headnotes'] = df_master['Information to Collect from Judgment Headnotes'].apply(headnotes_choice)\n",
    "    df_master['Courts'] = df_master['Courts'].apply(court_choice)\n",
    "    df_master['Tribunals'] = df_master['Tribunals'].apply(tribunal_choice)\n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Do search\n",
    "\n",
    "    search_dict = {'body': df_master.loc[0, 'Free text']}\n",
    "    search_dict.update({'title': df_master.loc[0, 'Case name']})\n",
    "    search_dict.update({'before': df_master.loc[0, 'Before']})\n",
    "    search_dict.update({'catchwords': df_master.loc[0, 'Catchwords']})\n",
    "    search_dict.update({'party': df_master.loc[0, 'Party names']})\n",
    "    search_dict.update({'mnc': df_master.loc[0, 'Medium neutral citation']})\n",
    "    search_dict.update({'startDate': df_master.loc[0, 'Decision date from']})\n",
    "    search_dict.update({'endDate': df_master.loc[0, 'Decision date to']})\n",
    "    search_dict.update({'fileNumber': df_master.loc[0, 'File number']})\n",
    "    search_dict.update({'legislationCited': df_master.loc[0, 'Legislation cited']})\n",
    "    search_dict.update({'casesCited': df_master.loc[0, 'Cases cited']})\n",
    "    df_master.loc[0, 'SearchCriteria']=[search_dict]\n",
    "\n",
    "    #Conduct search\n",
    "    \n",
    "    query = Search(courts=df_master.loc[0, 'Courts'], \n",
    "                   tribunals=df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, \"SearchCriteria\"]['body'], \n",
    "                   title = df_master.loc[0, \"SearchCriteria\"]['title'], \n",
    "                   before = df_master.loc[0, \"SearchCriteria\"]['before'], \n",
    "                   catchwords = df_master.loc[0, \"SearchCriteria\"]['catchwords'], \n",
    "                   party = df_master.loc[0, \"SearchCriteria\"]['party'], \n",
    "                   mnc = df_master.loc[0, \"SearchCriteria\"]['mnc'], \n",
    "                   startDate = date(df_master.loc[0, \"SearchCriteria\"]['startDate']), \n",
    "                   endDate = date(df_master.loc[0, \"SearchCriteria\"]['endDate']),\n",
    "                   fileNumber = df_master.loc[0, \"SearchCriteria\"]['fileNumber'], \n",
    "                   legislationCited  = df_master.loc[0, \"SearchCriteria\"]['legislationCited'], \n",
    "                   casesCited = df_master.loc[0, \"SearchCriteria\"]['legislationCited'],\n",
    "                   pause = 0\n",
    "                  )\n",
    "\n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Counter to limit search results to append\n",
    "    counter = 0\n",
    "\n",
    "    #Go through search results\n",
    "    \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "    \n",
    "    for decision in query.results():\n",
    "        if counter < judgments_counter_bound:\n",
    "    \n",
    "            decision.fetch()\n",
    "            decision_v=decision.values\n",
    "                                    \n",
    "            #add search results to json\n",
    "            judgments_file.append(decision_v)\n",
    "            counter +=1\n",
    "    \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Check length of judgment text, replace with raw html if smaller than lower boound\n",
    "\n",
    "    for judgment_index in df_individual.index:\n",
    "\n",
    "        #Checking if judgment text has been scrapped\n",
    "        try:\n",
    "            judgment_raw_text = str(df_individual.loc[judgment_index, \"judgment\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"judgment\"] = ['Error. Judgment text not scrapped.']\n",
    "            judgment_raw_text = str(df_individual.loc[judgment_index, \"judgment\"])\n",
    "            print(f'{df_individual.loc[judgment_index, \"title\"]}: judgment text scraping error.')\n",
    "            print(e)\n",
    "            \n",
    "        if num_tokens_from_string(judgment_raw_text, \"cl100k_base\") < judgment_text_lower_bound:\n",
    "            html_link = 'https://www.caselaw.nsw.gov.au'+ df_individual.loc[judgment_index, \"uri\"]\n",
    "\n",
    "#            page_html = requests.get(html_link)\n",
    "#            soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "#            judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            judgment_type_text = short_judgment(html_link)\n",
    "\n",
    "            #attach judgment text\n",
    "            df_individual.loc[judgment_index, \"judgment\"] = judgment_type_text[1]\n",
    "\n",
    "            #identify pdf judgment\n",
    "\n",
    "            if judgment_type_text[0] == 'pdf':\n",
    "                try:\n",
    "                    mnc_raw = df_individual.loc[judgment_index, \"mnc\"]\n",
    "                    df_individual.loc[judgment_index, \"title\"] =  mnc_raw.split(' [')[0]\n",
    "                    df_individual.loc[judgment_index, \"mnc\"] = '[' + mnc_raw.split(' [')[1]\n",
    "                    df_individual.loc[judgment_index, \"catchwords\"] = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.'\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Rename column titles\n",
    "    \n",
    "    try:\n",
    "        df_individual['Hyperlink to NSW Caselaw'] = df_individual['uri'].apply(nsw_link)\n",
    "        df_individual.pop('uri')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for col_name in headnotes_keys:\n",
    "        if col_name in df_individual.columns:\n",
    "            col_index = headnotes_keys.index(col_name)\n",
    "            new_col_name = headnotes_fields[col_index]\n",
    "            df_individual[new_col_name] = df_individual[col_name]\n",
    "            df_individual.pop(col_name)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use latest version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58df2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tidy up output\n",
    "\n",
    "def tidying_up(df_master, df_individual):\n",
    "\n",
    "    #Reorganise columns\n",
    "\n",
    "    old_columns = list(df_individual.columns)\n",
    "    \n",
    "    for i in ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw']:\n",
    "        if i in old_columns:\n",
    "            old_columns.remove(i)\n",
    "    \n",
    "    new_columns = ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw'] + old_columns\n",
    "    \n",
    "    df_individual = df_individual.reindex(columns=new_columns)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "    \n",
    "    if int(df_master.loc[0, 'Metadata inclusion']) == 0:\n",
    "        for meta_label in meta_labels_droppable:\n",
    "            try:\n",
    "                df_individual.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    #Remove judgment and uri columns\n",
    "    try:\n",
    "        df_individual.pop(\"judgment\")\n",
    "        df_individual.pop(\"uri\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    #Check case name, medium neutral citation \n",
    "\n",
    "    for k in df_individual.index:\n",
    "        if ' [' in df_individual.loc[k, \"Case name\"]:\n",
    "            case_name_proper = df_individual.loc[k, \"Case name\"].split(' [')[0]\n",
    "            mnc_proper = '[' + df_individual.loc[k, \"Case name\"].split(' [')[-1]\n",
    "            df_individual.loc[k, \"Case name\"] = case_name_proper\n",
    "            df_individual.loc[k, \"Medium neutral citation\"] = mnc_proper\n",
    "        elif ' [' in df_individual.loc[k, \"Medium neutral citation\"]:\n",
    "            case_name_proper = df_individual.loc[k, \"Medium neutral citation\"].split(' [')[0]\n",
    "            mnc_proper = '[' + df_individual.loc[k, \"Medium neutral citation\"].split(' [')[-1]\n",
    "            df_individual.loc[k, \"Case name\"] = case_name_proper\n",
    "            df_individual.loc[k, \"Medium neutral citation\"] = mnc_proper\n",
    "    \n",
    "    return df_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e594d8b9",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03b3e3-defd-4c0b-8c62-96a8f1ed1753",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada3ec0a-7448-4d6f-9a27-3a59ec3a9f48",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec27fb-b8f3-4a31-8efc-383aed27fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'default_courts' not in st.session_state:\n",
    "    st.session_state['default_courts'] = []\n",
    "\n",
    "if 'default_tribunals' not in st.session_state:\n",
    "    st.session_state['default_tribunals'] = []\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4613b2a1-9731-4265-a10e-f18dd3d8931d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0604ab96-8eb6-457a-a1de-aec0999862cd",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439b657a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Create form\n",
    "\n",
    "return_button = st.button('RETURN to first page')\n",
    "\n",
    "st.header(\"You have selected to study :blue[judgments of the New South Wales courts and tribunals].\")\n",
    "\n",
    "#Search terms\n",
    "\n",
    "st.write(f'**:green[Please enter your search terms.]** This program will collect (ie scrape) the first {default_judgment_counter_bound} judgments returned by your search terms.')\n",
    "\n",
    "st.caption(f\"[An open-source Python module](https://github.com/Sydney-Informatics-Hub/nswcaselaw) will scrape NSW judgments. During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you'd like to cover more judgments.\")\n",
    "\n",
    "st.subheader(\"NSW courts and tribunals to cover\")\n",
    "\n",
    "default_on_courts = st.checkbox('Prefill the Court of Appeal, the Court of Criminal Appeal, and the Supreme Court')\n",
    "\n",
    "if default_on_courts:\n",
    "\n",
    "    st.session_state.default_courts = nsw_default_courts\n",
    "\n",
    "else:\n",
    "    st.session_state.default_courts = []\n",
    "\n",
    "courts_entry = st.multiselect(label = 'Select or type in the courts to cover', options = nsw_courts, default = st.session_state.default_courts)\n",
    "\n",
    "tribunals_entry = st.multiselect(label = 'Select or type in the tribunals to cover', options = nsw_tribunals, default = st.session_state.default_tribunals)\n",
    "\n",
    "#st.caption(f\"All courts and tribunals listed in these menus will be covered if left blank.\")\n",
    "\n",
    "st.subheader(\"Your search terms\")\n",
    "\n",
    "st.markdown(\"\"\"For search tips, please visit NSW Caselaw at https://www.caselaw.nsw.gov.au/search/advanced. This section mimics their Advanced Search function.\"\"\")\n",
    "\n",
    "catchwords_entry = st.text_input(\"Catchwords\")\n",
    "\n",
    "body_entry = st.text_input(\"Free text (searches the entire judgment)\") \n",
    "\n",
    "title_entry = st.text_input(\"Case name\")\n",
    "\n",
    "before_entry = st.text_input(\"Before\")\n",
    "\n",
    "st.caption(\"Name of judge, commissioner, magistrate, member, registrar or assessor\")\n",
    "\n",
    "party_entry = st.text_input(\"Party names\")\n",
    "\n",
    "mnc_entry = st.text_input(\"Medium neutral citation\")\n",
    "\n",
    "st.caption(\"Must include square brackets eg [2022] NSWSC 922\")\n",
    "\n",
    "startDate_entry = st.date_input(\"Decision date from (01/01/1999 the earliest)\", value = None, format=\"DD/MM/YYYY\")\n",
    "\n",
    "st.caption(\"Pre-1999 decisions are usually not available at NSW Caselaw and will unlikely to be collected (see https://www.caselaw.nsw.gov.au/about).\")\n",
    "\n",
    "endDate_entry = st.date_input(\"Decision date to\", value = None,  format=\"DD/MM/YYYY\")\n",
    "\n",
    "fileNumber_entry = st.text_input(\"File number\")\n",
    "\n",
    "legislationCited_entry = st.text_input(\"Legislation cited\")\n",
    "\n",
    "casesCited_entry = st.text_input(\"Cases cited\")\n",
    "\n",
    "st.markdown(\"\"\"You can preview the judgments returned by your search terms on NSW Caselaw after you have entered some search terms.\n",
    "\n",
    "You may have to unblock a popped up window, refresh this page, and re-enter your search terms.\n",
    "\"\"\")\n",
    "\n",
    "preview_button = st.button('PREVIEW on NSW Caselaw (in a popped up window)')\n",
    "\n",
    "#    headnotes_entry = st.multiselect(\"Please select\", headnotes_choices)\n",
    "\n",
    "st.subheader(\"Judgment metadata collection\")\n",
    "\n",
    "st.markdown(\"\"\"Would you like to obtain judgment metadata? Such data include the name of the judge, the decision date and so on. \n",
    "\n",
    "Case name and medium neutral citation are always included with your results.\n",
    "\"\"\")\n",
    "\n",
    "meta_data_entry = st.checkbox('Include metadata', value = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2e8bc7-0ce3-4022-b7ef-3a5727ab9078",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20918f9-15d3-4298-b633-7afe74b274ef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "#    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "st.markdown(\"**:green[Would you like GPT to answer questions about the judgments returned by your search terms?]**\")\n",
    "\n",
    "st.markdown(\"\"\"Please consider trying this program without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract the judgment metadata without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox('Use GPT', value = False)\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default, Ben's own experience suggests that it costs approximately USD \\$0.003-\\$0.008 (excl GST) per judgment. The exact cost for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced (as elaborated at https://openai.com/pricing for model gpt-3.5-turbo-0125). You will be given ex-post cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your questions for each judgment\")\n",
    "\n",
    "st.markdown(\"\"\"Please enter one question **per line or per paragraph**. GPT will answer your questions for **each** judgment based only on information from **that** judgment. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "if st.toggle('See the instruction given to GPT'):\n",
    "    st.write(f\"{intro_for_GPT[0]['content']}\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "gpt_questions_entry = st.text_area(f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound) \n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        st.session_state['disable_input'] = True\n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "    \n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-3.5-turbo-0125. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-3.5-turbo-0125')*3/4)} words from each judgment.\")\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    \n",
    "    st.subheader(':orange[Enhance program capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of judgments to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle('Use my own GPT account',  disabled = st.session_state.disable_input)\n",
    "    \n",
    "    if own_account_entry:\n",
    "    \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage at https://platform.openai.com/signup. You can then find your API key at https://platform.openai.com/api-keys.\n",
    "    \"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state.name_entry)\n",
    "    \n",
    "        email_entry = st.text_input(label = \"Your email address\", value = st.session_state.email_entry)\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.gpt_api_key_entry)\n",
    "        \n",
    "        valdity_check = st.button('VALIDATE your API key')\n",
    "    \n",
    "        if valdity_check:\n",
    "            \n",
    "            api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                    \n",
    "            if api_key_valid == False:\n",
    "                st.session_state['gpt_api_key_validity'] = False\n",
    "                st.error('Your API key is not valid.')\n",
    "                \n",
    "            else:\n",
    "                st.session_state['gpt_api_key_validity'] = True\n",
    "                st.success('Your API key is valid.')\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[You can use the latest version of GPT model (gpt-4o),]** which is :red[10 times more expensive, per character] than the default model (gpt-3.5-turbo) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the latest GPT model', value = False)\n",
    "        st.caption('For more on pricing for different GPT models, please see https://openai.com/api/pricing.')\n",
    "        \n",
    "        if gpt_enhancement_entry == True:\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o\"\n",
    "            st.session_state.gpt_enhancement_entry = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "            st.session_state.gpt_enhancement_entry = False\n",
    "        \n",
    "        st.write(f'**:green[You can increase the maximum number of judgments to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        #judgments_counter_bound_entry = round(st.number_input(label = 'Enter a whole number between 1 and 100', min_value=1, max_value=100, value=default_judgment_counter_bound))\n",
    "\n",
    "        #st.session_state.judgments_counter_bound = judgments_counter_bound_entry\n",
    "\n",
    "        judgments_counter_bound_entry = st.text_input(label = 'Enter a whole number between 1 and 100', value=str(default_judgment_counter_bound))\n",
    "\n",
    "        if judgments_counter_bound_entry:\n",
    "            wrong_number_warning = f'You have not entered a whole number between 1 and 100. The program will process up to {default_judgment_counter_bound} judgments instead.'\n",
    "            try:\n",
    "                st.session_state.judgments_counter_bound = int(judgments_counter_bound_entry)\n",
    "            except:\n",
    "                st.warning(wrong_number_warning)\n",
    "                st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "\n",
    "            if ((st.session_state.judgments_counter_bound <= 0) or (st.session_state.judgments_counter_bound > 100)):\n",
    "                st.warning(wrong_number_warning)\n",
    "                st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "    \n",
    "        st.write(f'*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state.judgments_counter_bound} judgments.*')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "    \n",
    "        st.session_state.judgments_counter_bound = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1126255f-2f41-4db8-b93e-3c02fa3c11ae",
   "metadata": {},
   "source": [
    "## Consent and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48729100-7df7-4e98-8739-c738742d9172",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False, disabled = st.session_state.disable_input)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")\n",
    "\n",
    "st.header(\"Next steps\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[You can now run the Empirical Legal Research Kickstarter.]** A spreadsheet which hopefully has the data you seek will be available for download.\n",
    "\n",
    "You can also download a record of your entries.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Warning\n",
    "if st.session_state.gpt_model == 'gpt-3.5-turbo-0125':\n",
    "    st.warning('A low-cost GPT model will answer your questions. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you would like to use the latest model instead.')\n",
    "\n",
    "if st.session_state.gpt_model == \"gpt-4o\":\n",
    "    st.warning('An expensive GPT model will answer your questions. Please be cautious.')\n",
    "\n",
    "run_button = st.button('RUN the program')\n",
    "\n",
    "keep_button = st.button('DOWNLOAD your entries')\n",
    "\n",
    "reset_button = st.button(label='RESET to start afresh', type = 'primary',  help = \"Press to process new search terms or questions.\")\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if st.session_state.need_resetting == 1:\n",
    "    if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output) > 0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c5330-ee37-4d4c-8679-69c288959f9f",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a9495-d8a8-45e0-84e4-5b56d755e6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create placeholder download buttons if previous entries and results in st.session_state:\n",
    "\n",
    "if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output) > 0)):\n",
    "    \n",
    "    #Load previous entries and results\n",
    "    \n",
    "    df_master = st.session_state.df_master\n",
    "    df_individual_output = st.session_state.df_individual_output\n",
    "\n",
    "    #Buttons for downloading entries\n",
    "    st.subheader('Looking for your previous entries and results?')\n",
    "\n",
    "    st.write('Previous entries')\n",
    "\n",
    "    entries_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_entries'\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    ste.download_button(\n",
    "        label=\"Download your previous entries as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=entries_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download your previous entries as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=entries_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "\n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous entries as a JSON\", \n",
    "        data = json,\n",
    "        file_name= entries_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.write('Previous results')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "    \n",
    "    ste.download_button(label='Download your previous results as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your previous spreadsheet with an AI\", icon = 'ðŸ¤”')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a1cf1",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95712963",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if preview_button:\n",
    "    \n",
    "    df_master = create_df()\n",
    "\n",
    "    judgments_url = search_url(df_master)\n",
    "\n",
    "    open_page(judgments_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ff3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    all_search_terms = str(catchwords_entry) + str(body_entry) + str(title_entry) + str(before_entry) + str(party_entry) + str(mnc_entry) + str(startDate_entry) + str(endDate_entry) + str(fileNumber_entry) + str(legislationCited_entry) + str(casesCited_entry)\n",
    "    \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "    \n",
    "    elif (len(courts_entry) == 0) and (len(tribunals_entry) == 0):\n",
    "        st.write('Please select at least one court or tribunal to cover.')\n",
    "\n",
    "    elif int(consent) == 0:\n",
    "        st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "    \n",
    "    elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "            \n",
    "        st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "            \n",
    "        st.warning('You have not validated your API key.')\n",
    "        quit()\n",
    "\n",
    "    elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "\n",
    "        st.warning('You have not entered a valid API key.')\n",
    "        quit()  \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.markdown(\"\"\"Your results will be available for download soon. The estimated waiting time is about 2-3 minutes per 10 judgments.\"\"\")\n",
    "        #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        with st.spinner(\"Running... Please :red[don't change] your entries (yet).\"):\n",
    "\n",
    "            #Create spreadsheet of responses\n",
    "            df_master = create_df()\n",
    "            \n",
    "            #Activate user's own key or mine\n",
    "            if st.session_state.own_account == True:\n",
    "                \n",
    "                API_key = df_master.loc[0, 'Your GPT API key']\n",
    "\n",
    "            else:\n",
    "                API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "            openai.api_key = API_key\n",
    "            \n",
    "            #Produce results\n",
    "            df_individual = run(df_master)\n",
    "\n",
    "            #Check if judgments found\n",
    "            if len(df_individual) > 0:\n",
    "        \n",
    "                df_individual_output = tidying_up(df_master, df_individual)\n",
    "\n",
    "                #Keep results in session state\n",
    "                st.session_state[\"df_individual_output\"] = df_individual_output#.astype(str)\n",
    "        \n",
    "                st.session_state[\"df_master\"] = df_master\n",
    "\n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                \n",
    "                st.session_state[\"page_from\"] = 'pages/NSW.py'\n",
    "        \n",
    "                st.success(\"Your results are now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                \n",
    "                #Button for downloading results\n",
    "                output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "        \n",
    "                csv_output = convert_df_to_csv(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a CSV (for use in Excel etc)\", \n",
    "                    data = csv_output,\n",
    "                    file_name= output_name + '.csv', \n",
    "                    mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "                )\n",
    "        \n",
    "                excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "                \n",
    "                ste.download_button(label='Download your results as an Excel spreadsheet (XLSX)',\n",
    "                                    data=excel_xlsx,\n",
    "                                    file_name= output_name + '.xlsx', \n",
    "                                    mime='application/vnd.ms-excel',\n",
    "                                   )\n",
    "                \n",
    "                json_output = convert_df_to_json(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a JSON\", \n",
    "                    data = json_output,\n",
    "                    file_name= output_name + '.json', \n",
    "                    mime= \"application/json\", \n",
    "                )\n",
    "        \n",
    "                st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = 'ðŸ¤”')\n",
    "\n",
    "            \n",
    "                #Keep record on Google sheet\n",
    "                #Obtain google spreadsheet       \n",
    "                #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                #df_google = conn.read()\n",
    "                #df_google = df_google.fillna('')\n",
    "                #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                #df_master[\"Processed\"] = datetime.now()\n",
    "                #df_master.pop(\"Your GPT API key\")\n",
    "                #df_to_update = pd.concat([df_google, df_master])\n",
    "                #conn.update(worksheet=\"NSW\", data=df_to_update, )\n",
    "\n",
    "    \n",
    "            else:\n",
    "                st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5959b0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    all_search_terms = str(catchwords_entry) + str(body_entry) + str(title_entry) + str(before_entry) + str(party_entry) + str(mnc_entry) + str(startDate_entry) + str(endDate_entry) + str(fileNumber_entry) + str(legislationCited_entry) + str(casesCited_entry)\n",
    "    \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "\n",
    "    elif (len(courts_entry) == 0) and (len(tribunals_entry) == 0):\n",
    "        st.write('Please select at least one court or tribunal to cover.')\n",
    "\n",
    "    elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "\n",
    "        if 'need_resetting' not in st.session_state:\n",
    "            \n",
    "            st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        df_master = create_df()\n",
    "\n",
    "        #Pop unnecessary columns\n",
    "    \n",
    "        df_master.pop(\"Your GPT API key\")\n",
    "    \n",
    "        df_master.pop(\"Processed\")\n",
    "\n",
    "        #Create outputs\n",
    "    \n",
    "        responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "    \n",
    "        #Buttons for downloading responses\n",
    "    \n",
    "        csv = convert_df_to_csv(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a CSV (for use in Excel etc)\", \n",
    "            data = csv,\n",
    "            file_name=responses_output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "    #            key='download-csv'\n",
    "        )\n",
    "\n",
    "        xlsx = convert_df_to_excel(df_master)\n",
    "        \n",
    "        ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                            data=xlsx,\n",
    "                            file_name=responses_output_name + '.xlsx', \n",
    "                            mime='application/vnd.ms-excel',\n",
    "                           )\n",
    "    \n",
    "        json = convert_df_to_json(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a JSON\", \n",
    "            data = json,\n",
    "            file_name= responses_output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b67f0f-e5e5-463a-addc-7fffd8165825",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fadbfc-5700-4732-8995-68822b2dcf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_button:\n",
    "    clear_cache_except_validation_df_master()\n",
    "    st.rerun()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
