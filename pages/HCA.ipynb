{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "#from dateutil import parser\n",
    "from dateutil.parser import parse\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import PyPDF2\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default, users are allowed to use their own account\n",
      "The pause between judgment scraping is 5 second.\n",
      "\n",
      "The lower bound on lenth of judgment text to process is 1000 tokens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n",
    "#Import variables\n",
    "from common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d9bad00-82f7-478a-93bc-9d4b623e74df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# High Court of Australia search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3329d8-1716-4570-8dd0-4b5aa22aaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca5f1d2-b354-45be-b365-0f01233c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collections available\n",
    "\n",
    "hca_collections = ['Judgments 2000-present', 'Judgments 1948-1999', '1 CLR - 100 CLR (judgments 1903-1958)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00f0e228-8b90-4951-83fb-7668f7010106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "    \n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "    \n",
    "    #Judgment counter bound\n",
    "    judgments_counter_bound = st.session_state.judgments_counter_bound\n",
    "\n",
    "    #GPT enhancement\n",
    "    gpt_enhancement = st.session_state.gpt_enhancement_entry    \n",
    "\n",
    "    #Other entries\n",
    "    collection = collection_entry\n",
    "    quick_search = quick_search_entry\n",
    "    citation =  citation_entry\n",
    "\n",
    "    full_text = ''\n",
    "    try:\n",
    "        full_text = full_text_entry\n",
    "\n",
    "    except:\n",
    "        print('Full text not entered.')\n",
    "\n",
    "    #Can't figure out how to add the following based on the HCA's filtered search function\n",
    "    #parties_include = parties_include_entry\n",
    "    #parties_not_include = parties_not_include_entry\n",
    "    #year_is = year_is_entry\n",
    "    #year_is_not = year_is_not_entry\n",
    "    #case_number = case_number_entry\n",
    "    #judges_include = judges_include_entry\n",
    "    #judges_not_include = judges_not_include_entry\n",
    "\n",
    "    #The following are based on my own filter\n",
    "\n",
    "    own_parties_include = ''\n",
    "\n",
    "    try:\n",
    "        own_parties_include = own_parties_include_entry\n",
    "    \n",
    "    except:\n",
    "        \n",
    "        print('Parties to include not entered.')\n",
    "\n",
    "    own_parties_exclude = ''\n",
    "\n",
    "    try:\n",
    "        own_parties_exclude = own_parties_exclude_entry\n",
    "\n",
    "    except:\n",
    "        print('Parties to exclude not entered.')\n",
    "\n",
    "    own_min_year = ''\n",
    "\n",
    "    try:\n",
    "        own_min_year = own_min_year_entry\n",
    "\n",
    "    except:\n",
    "        print('Minimum year not entered.')\n",
    "\n",
    "    own_max_year = ''\n",
    "\n",
    "    try:\n",
    "        own_max_year = own_max_year_entry\n",
    "    \n",
    "    except:\n",
    "        print('Maximum year not entered.')\n",
    "\n",
    "    #own_case_numbers_include = ['']\n",
    "\n",
    "    #try:\n",
    "        #own_case_numbers_include_list = own_case_numbers_include_entry.replace(';', ',').split(',')\n",
    "\n",
    "        #for case_number in own_case_numbers_include_list:\n",
    "            \n",
    "            #own_case_numbers_include.append(case_number)\n",
    "        \n",
    "    #except:\n",
    "        #print('Case numbers to include not entered.')\n",
    "\n",
    "    #own_case_numbers_exclude = ['']\n",
    "\n",
    "    #try:\n",
    "        #own_case_numbers_exclude_list = own_case_numbers_exclude_entry.replace(';', ',').split(',')\n",
    "\n",
    "        #for case_number in own_case_numbers_exclude_list:\n",
    "            \n",
    "            #own_case_numbers_exclude.append(case_number)\n",
    "        \n",
    "    #except:\n",
    "        \n",
    "        #print('Case numbers to exclude not entered.')\n",
    "        \n",
    "    own_judges_include = ''\n",
    "\n",
    "    try:\n",
    "        own_judges_include = own_judges_include_entry\n",
    "    \n",
    "    except:\n",
    "        print('judges to include not entered.')\n",
    "\n",
    "    own_judges_exclude = ''\n",
    "\n",
    "    try:\n",
    "        own_judges_exclude = own_judges_exclude_entry\n",
    "\n",
    "    except:\n",
    "        print('judges to exclude not entered.')\n",
    "    \n",
    "    #GPT choice and entry\n",
    "    gpt_activation_status = False\n",
    "   \n",
    "    try:\n",
    "        gpt_activation_status = gpt_activation_entry\n",
    "\n",
    "    except:\n",
    "        print('GPT activation status not entered.')\n",
    "    \n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: 1000]\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "\n",
    "    #metadata choice\n",
    "\n",
    "    meta_data_choice = True\n",
    "\n",
    "    try:\n",
    "\n",
    "        meta_data_choice = meta_data_entry\n",
    "    \n",
    "    except:\n",
    "        print('Metadata choice not entered.')        \n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "            'Collection' : collection, \n",
    "            'Quick search': quick_search, \n",
    "            'Search for medium neutral citation': citation, \n",
    "             'Full text search': full_text, \n",
    "            #Can't figure out how to add the following based on the HCA's filtered search function\n",
    "           #'Parties include': parties_include, \n",
    "            #'Parties do not include': parties_not_include, \n",
    "            #'Year is': year_is, \n",
    "            #'Year is not': year_is_not, \n",
    "            #'Case number': case_number, \n",
    "            #'Judges include': judges_include, \n",
    "            #'Judges do not include': judges_not_include, \n",
    "               #The following are based on my own filter\n",
    "           'Parties include': own_parties_include, \n",
    "            'Parties do not include': own_parties_exclude, \n",
    "            'Before this year': own_min_year, \n",
    "            'After this year': own_max_year, \n",
    "           #'Case numbers include': own_case_numbers_include, \n",
    "            #'Case numbers do not include': own_case_numbers_exclude, \n",
    "            'Judges include': own_judges_include, \n",
    "            'Judges do not include': own_judges_exclude, \n",
    "           #The following are common to all pages\n",
    "            'Metadata inclusion' : meta_data_choice,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your questions for GPT': gpt_questions, \n",
    "            'Use GPT': gpt_activation_status,\n",
    "           'Use own account': own_account,\n",
    "            'Use latest version of GPT' : gpt_enhancement\n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "            \n",
    "    return df_master_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url AND number of search results\n",
    "def hca_search(collection = '', \n",
    "               quick_search = '', \n",
    "               #citation = '', \n",
    "                full_text = ''):\n",
    "    #Default base url is for judgments 2000-current\n",
    "    #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "    base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "    \n",
    "    if collection == 'Judgments 2000-present':\n",
    "    \n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=1&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=1'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=2&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=2'\n",
    "    \n",
    "    params = {'qsrch-term': quick_search, \n",
    "              #'Citation_ST': citation, \n",
    "              'srch-term': full_text\n",
    "             }\n",
    "\n",
    "    #Get response page\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    # Process the response (e.g., extract relevant information)\n",
    "    # Your code here...\n",
    "\n",
    "    #Get url_search_results\n",
    "    url_search_results = response.url\n",
    "\n",
    "    #Get number of search results\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    number_of_results = soup.find(\"span\", id=\"itemTotal\").text\n",
    "        \n",
    "    return {'url': url_search_results, 'results_num': number_of_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e95d9963-c3b6-46f0-a1ea-c30c63e5aba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function turning search results url to links to judgments\n",
    "def search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    \n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    #Get number of pages\n",
    "    #There are up to 20 pages per page\n",
    "    number_of_pages = soup.find(\"span\", id=\"lastItem\").text\n",
    "    \n",
    "    #Start links list\n",
    "    links = []\n",
    "    \n",
    "    #Get first page of results\n",
    "    raw_links = soup.find_all(class_='case')\n",
    "    \n",
    "    if len(raw_links) > 0:\n",
    "    \n",
    "        for raw_link in raw_links:\n",
    "            if counter <= judgment_counter_bound:\n",
    "                link = 'https://eresources.hcourt.gov.au' + raw_link['href']\n",
    "                links.append(link)\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #Go to next page if still below judgment_counter_bound\n",
    "    if counter <= judgment_counter_bound:\n",
    "        if int(number_of_pages) > 1:\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            for page_raw in range(1, int(number_of_pages)):\n",
    "                page = page_raw + 1\n",
    "                url_search_results_new_page = url_search_results + f'&page={page}'\n",
    "                page_new_page = requests.get(url_search_results_new_page)\n",
    "                soup_new_page = BeautifulSoup(page_new_page.content, \"lxml\")\n",
    "                raw_links_new_page = soup_new_page.find_all(class_='case')\n",
    "            \n",
    "                if len(raw_links_new_page) > 0:\n",
    "                \n",
    "                    for raw_link in raw_links_new_page:\n",
    "                        if counter <= judgment_counter_bound:\n",
    "                            link = 'https://eresources.hcourt.gov.au' + raw_link['href']\n",
    "                            links.append(link)\n",
    "                            counter += 1\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "    return links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90302a99-07e1-4516-bd21-4b6f9c33e2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for judgment link containing PDF\n",
    "def pdf_judgment(url):\n",
    "    pdf_url = url.replace('showCase', 'downloadPdf')\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(pdf_url, headers=headers)\n",
    "    remote_file_bytes = io.BytesIO(r.content)\n",
    "    pdfdoc_remote = PyPDF2.PdfReader(remote_file_bytes)\n",
    "    text_list = []\n",
    "\n",
    "    for page in pdfdoc_remote.pages:\n",
    "        text_list.append(page.extract_text())\n",
    "    \n",
    "    return str(text_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8b71004-5c2d-412a-8762-7afcc22673bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if string is date\n",
    "\n",
    "#From https://stackoverflow.com/questions/25341945/check-if-string-has-date-any-format\n",
    "\n",
    "def is_date(string, fuzzy=False):\n",
    "    \"\"\"\n",
    "    Return whether the string can be interpreted as a date.\n",
    "\n",
    "    :param string: str, string to check for date\n",
    "    :param fuzzy: bool, ignore unknown tokens in string if True\n",
    "    \"\"\"\n",
    "    try: \n",
    "        parse(string, fuzzy=fuzzy)\n",
    "        return True\n",
    "\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d93cfb-26fb-436a-bddf-eb20e1095d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "meta_labels_droppable = ['Reported', 'Date', 'Case number', 'Before', 'Catchwords', 'Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "632eaa5c-4f2b-47af-8c7f-c0a575d895f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If judgment link contains 'showCase'\n",
    "\n",
    "def meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                 'Catchwords' : '',  \n",
    "                'Order': '', \n",
    "                'judgment' : ''\n",
    "                }\n",
    "    \n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Case name\n",
    "    judgment_dict['Case name'] = soup.find('title').text\n",
    "\n",
    "    #Medium neutral citation\n",
    "    year = judgment_url.split('showCase/')[1][0:4]\n",
    "    num = judgment_url.split('HCA/')[1]\n",
    "    \n",
    "    judgment_dict['Medium neutral citation'] = f'[{year}] HCA {num}'\n",
    "\n",
    "    #Reported, decision date, before\n",
    "\n",
    "    h2_tags = soup.find_all('h2')\n",
    "\n",
    "    if len(h2_tags) > 0:\n",
    "        \n",
    "        for h2 in soup.find_all('h2'):\n",
    "            if 'clr' in h2.text.lower():\n",
    "                \n",
    "                judgment_dict['Reported'] = h2.text\n",
    "    \n",
    "            elif is_date(h2.text, fuzzy=False):\n",
    "    \n",
    "                judgment_dict['Date'] = h2.text\n",
    "    \n",
    "            elif 'before' in h2.text.lower():\n",
    "                judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "    \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    #Case number\n",
    "\n",
    "    case_number_list = soup.find_all(string=re.compile('Case Number'))\n",
    "\n",
    "    if len(case_number_list) > 0:\n",
    "        \n",
    "        judgment_dict['Case number'] = case_number_list[0].split('Case Number')[1].replace(': ', '')\n",
    "\n",
    "    #Catchwords\n",
    "\n",
    "    catchwords_list = soup.find_all('div', class_='well')\n",
    "\n",
    "    if len(catchwords_list) > 0:\n",
    "        \n",
    "        judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "\n",
    "    #Judgment text\n",
    "    try:\n",
    "\n",
    "        judgment_dict['judgment'] = pdf_judgment(judgment_url)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        judgment_dict['judgment'] = 'Error. Judgment not available or not downloaded.'\n",
    "        judgment_dict['Case name'] = judgment_dict['Case name'] + '. Error. Judgment not available or not downloaded.'\n",
    "\n",
    "    return judgment_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf3f7be-addd-4f87-82f7-b286f2b1fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If judgment link contains 'showbyHandle'\n",
    "\n",
    "def meta_judgment_dict_alt(judgment_url):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                 'Catchwords' : '',\n",
    "                'Order': '',\n",
    "                'judgment' : ''\n",
    "                }\n",
    "    \n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Case name\n",
    "    judgment_dict['Case name'] = soup.find('title').text\n",
    "\n",
    "    #Judgment text\n",
    "\n",
    "    judgment_list = soup.find_all(\"div\", {\"class\": \"opinion\"})\n",
    "    \n",
    "    judgment_pdfs_list = soup.find_all('a', {'class': 'btn btn-success'})\n",
    "    \n",
    "    if len(judgment_list) > 0:\n",
    "\n",
    "        judgment_dict['judgment'] = judgment_list[0].text\n",
    "\n",
    "    elif len(judgment_pdfs_list) > 0:\n",
    "        raw_link = judgment_pdfs_list[0]['href']\n",
    "        pdf_link = 'https://eresources.hcourt.gov.au' + raw_link\n",
    "        judgment_dict['judgment'] = pdf_judgment(pdf_link)\n",
    "\n",
    "    else:\n",
    "        judgment_dict['judgment'] = 'Error. Judgment not available or not downloaded.'\n",
    "        \n",
    "        judgment_dict['Case name'] = judgment_dict['Case name'] + '. Error. Judgment not available or not downloaded.'\n",
    "\n",
    "    #Catchwords\n",
    "\n",
    "    catchwords_list = soup.find_all(\"div\", {\"class\": \"Catchphrases\"})\n",
    "\n",
    "    if len(catchwords_list) > 0:\n",
    "        judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "    \n",
    "    #Medium neutral citation meta tag\n",
    "    mnc_list = soup.find_all(\"div\", {\"class\": \"MNC\"})\n",
    "\n",
    "    if len(mnc_list):\n",
    "\n",
    "        judgment_dict['Medium neutral citation'] = mnc_list[0].text\n",
    "\n",
    "    elif len(judgment_pdfs_list) > 0:\n",
    "\n",
    "        mnc_raw = judgment_pdfs_list[0]['href'].replace('/downloadPdf/', '').replace('/', '')\n",
    "\n",
    "        year = mnc_raw.lower().split('hca')[0]\n",
    "\n",
    "        num = mnc_raw.lower().split('hca')[1]\n",
    "\n",
    "        judgment_dict['Medium neutral citation'] = f\"[{year}] HCA {num}\"\n",
    "\n",
    "    #Before\n",
    "    judges_list = soup.find_all(\"div\", {\"class\": \"judges-title\"})\n",
    "\n",
    "    if len(judges_list) > 0:\n",
    "\n",
    "        judgment_dict['Before'] = judges_list[0].text\n",
    "\n",
    "\n",
    "    #Order\n",
    "    order_list = soup.find_all(\"div\", {\"class\": \"order-text\"})\n",
    "\n",
    "    if len(order_list) > 0:\n",
    "\n",
    "        order = order_list[0].text#.replace('\\n            ', '')\n",
    "\n",
    "        judgment_dict['Order'] = order\n",
    "\n",
    "    #Reported, decision date, before\n",
    "\n",
    "    h2_tags = soup.find_all('h2')\n",
    "\n",
    "    if len(h2_tags) > 0:\n",
    "        \n",
    "        for h2 in soup.find_all('h2'):\n",
    "            if 'clr' in h2.text.lower():\n",
    "                \n",
    "                judgment_dict['Reported'] = h2.text\n",
    "    \n",
    "            elif is_date(h2.text, fuzzy=False):\n",
    "    \n",
    "                judgment_dict['Date'] = h2.text\n",
    "    \n",
    "            elif 'before' in h2.text.lower():\n",
    "                judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "    \n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d2e602-2dc9-4d8b-abc3-856d2cca791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slow way of finding a case from mnc\n",
    "\n",
    "def mnc_to_link_browse(collection, year, num):\n",
    "\n",
    "    #Default judgment without the prefix https://eresources.hcourt.gov.au\n",
    "    judgment_url_raw = ''\n",
    "\n",
    "    if collection == 'Judgments 2000-present':\n",
    "                    \n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=0&facets=dateDecided'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=1&facets=dateDecided'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        \n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=2&facets=dateDecided'\n",
    "    \n",
    "    params = {'srch-term': year}\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "    pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Get list of pages\n",
    "\n",
    "    pages_list = []\n",
    "    \n",
    "    options = soup.find_all('option')\n",
    "        \n",
    "    for option in options:\n",
    "        if len(option.text) < 4:\n",
    "            pages_list.append(option.text)\n",
    "    \n",
    "    for page in pages_list:\n",
    "        \n",
    "        page_start = (int(page) - 1)*20\n",
    "\n",
    "        params_page = {'srch-term': year, 'page': page_start}\n",
    "\n",
    "        response_page = requests.get(base_url, params=params_page)\n",
    "        \n",
    "        response_page.raise_for_status()\n",
    "        \n",
    "        soup_page = BeautifulSoup(response_page.content, \"lxml\")\n",
    "\n",
    "        cases_list = soup_page.find_all(class_='case')\n",
    "\n",
    "        for case in cases_list:\n",
    "\n",
    "            if f'HCA {num}' in str(case):\n",
    "                judgment_url_raw = case['href']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if (('showbyHandle' in judgment_url_raw) or ('showCase' in judgment_url_raw)):\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            continue\n",
    "\n",
    "    return 'https://eresources.hcourt.gov.au' + judgment_url_raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ed7fc5ce-d593-4ecd-a4f4-8cfd3a324fbe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Load hca_data\n",
    "\n",
    "hca_data_url = 'https://raw.githubusercontent.com/nehcneb/au-uk-empirical-legal-research/main/hca_data.csv'\n",
    "\n",
    "response = requests.get(hca_data_url)\n",
    "\n",
    "hca_df = pd.read_csv(StringIO(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92253933-ae02-4584-b643-a8a2622d0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation = '175 CLR 1'\n",
    "\n",
    "try:\n",
    "    index = np.where(hca_df['reported'].str.contains(citation, case=False))[0][0]\n",
    "except:\n",
    "    try:\n",
    "        index = np.where(hca_df['date'].str.contains(citation, case=False))[0][0]\n",
    "    except Exception as e:\n",
    "        print('Citation entered but not found.')\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b7311b19-4d21-4ea9-bb3e-c0f8ca8593dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = hca_df.index[hca_df['reported'].str.contains(citation, case=False, na=False)].tolist()\n",
    "index = index_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cb9ee624-ec1c-4752-97cf-9b1faa6b521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning citation to judgment_url\n",
    "def citation_to_link(collection, citation):\n",
    "\n",
    "    #Placeholder error url\n",
    "    judgment_url = f'https://eresources.hcourt.gov.au/showCase/1900/HCA/1'\n",
    "    \n",
    "    #Use mnc if entered\n",
    "    if 'hca' in citation.lower():\n",
    "       \n",
    "        try:\n",
    "            citation_formatted = citation.replace(' ', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            year = citation_formatted.lower().split('hca')[0]\n",
    "            \n",
    "            num = citation_formatted.lower().split('hca')[1]\n",
    "            \n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "            \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "\n",
    "        except Exception as e:\n",
    "            print('MNC entered but error.')\n",
    "            print(e)\n",
    "\n",
    "    else: #Get mnc from hca_df if not entered\n",
    "        try:\n",
    "            index_list = hca_df.index[hca_df['reported'].str.contains(citation, case=False, na=False)].tolist()\n",
    "            index = index_list[0]            \n",
    "        except:\n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['name'].str.contains(citation, case=False, na=False)].tolist()\n",
    "                index = index_list[0]\n",
    "            except:\n",
    "                try:\n",
    "                    index_list = hca_df.index[hca_df['date'].str.contains(citation, case=False, na=False)].tolist()\n",
    "                    index = index_list[0]\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print('Citation entered but not found.')\n",
    "                    print(e)\n",
    "                \n",
    "        try:\n",
    "            mnc = hca_df.loc[index, 'mnc']\n",
    "    \n",
    "            citation_formatted = mnc.replace(' ', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "            year = citation_formatted.lower().split('hca')[0]\n",
    "            \n",
    "            num = citation_formatted.lower().split('hca')[1]\n",
    "    \n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "    \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "            \n",
    "            return judgment_url\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Citation entered but error.')\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    #Check if judgment_url works\n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "        return judgment_url\n",
    "\n",
    "    else:\n",
    "        #Check if direct link to PDF works\n",
    "        try:\n",
    "            pdf_url = judgment_url.replace('showCase', 'downloadPdf')\n",
    "            \n",
    "            page = requests.get(pdf_url)\n",
    "        \n",
    "            soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "            if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "    \n",
    "                return pdf_url\n",
    "    \n",
    "            else:\n",
    "                #Try to use HCA's browse function to get link to case\n",
    "                judgment_url = mnc_to_link_browse(collection, year, num)\n",
    "    \n",
    "                return judgment_url\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(\"Can't get case url for citation\")\n",
    "            print(e)\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21a2914b-388f-469d-9dba-2a66152f03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning mnc to judgment_url\n",
    "def mnc_to_link(collection, mnc):\n",
    "#NOT in use\n",
    "    \n",
    "    mnc_formatted = mnc.replace(' ', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "    if 'HCA' in mnc_formatted:\n",
    "\n",
    "        year = mnc_formatted.split('HCA')[0]\n",
    "        \n",
    "        num = mnc_formatted.split('HCA')[1]\n",
    "       \n",
    "        try:\n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "            \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "\n",
    "            page = requests.get(judgment_url)\n",
    "            \n",
    "            soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "            if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "                return judgment_url\n",
    "\n",
    "            else:\n",
    "                \n",
    "                judgment_url = f'https://eresources.hcourt.gov.au/downloadPdf/{year_int}/HCA/{num_int}'\n",
    "\n",
    "                page = requests.get(judgment_url)\n",
    "            \n",
    "                soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "                if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "                    return judgment_url\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    judgment_url = mnc_to_link_browse(collection, year, num)\n",
    "\n",
    "                    return judgment_url\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return ''\n",
    "            \n",
    "    else:\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fac32bb1-b57f-4c14-b1b9-d96b49b2e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for minimum and maximum year\n",
    "\n",
    "def min_max_year(collection):\n",
    "#NOT IN USE\n",
    "    \n",
    "    if collection == 'Judgments 2000-present':\n",
    "\n",
    "        min_year = int(2000)\n",
    "\n",
    "        max_year = datetime.now().year\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "        \n",
    "        min_year = int(1948)\n",
    "\n",
    "        max_year = int(1999)\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "\n",
    "        min_year = int(1903)\n",
    "\n",
    "        max_year = int(1958)\n",
    "\n",
    "    return {'min_year': min_year, 'max_year': max_year}\n",
    "\n",
    "def year_check(year_entry):\n",
    "\n",
    "    #Default validity\n",
    "    validity = False\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if (len(str(int(year_entry))) == 4):     \n",
    "            \n",
    "            validity = True\n",
    "\n",
    "    except:\n",
    "        print('Year entry invalid.')\n",
    "        \n",
    "    return validity\n",
    "\n",
    "def min_year_validity(collection, min_year_entry):\n",
    "    #NOT IN USE\n",
    "\n",
    "    if year_check(min_year_entry) == False:\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    elif int(min_year_entry) <= min_max_year(collection)['min_year']:\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return True\n",
    "\n",
    "def max_year_validity(collection, max_year_entry):\n",
    "    #NOT IN USE\n",
    "\n",
    "    if year_check(max_year_entry) == False:\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    elif int(max_year_entry) >= min_max_year(collection)['max_year']:\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    else:\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54f8abaa-bab8-4a19-be59-1cec553bc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to excluding unwanted jugdments\n",
    "\n",
    "def judgment_to_exclude(case_info = {}, \n",
    "                        own_parties_include = '', \n",
    "                        own_parties_exclude = '', \n",
    "                        own_min_year = '', \n",
    "                        own_max_year = '', \n",
    "                        #own_case_numbers_include = [], \n",
    "                        #own_case_numbers_exclude = [], \n",
    "                        own_judges_include = '', \n",
    "                        own_judges_exclude = ''\n",
    "                       ):\n",
    "\n",
    "    #Default status is not to exclude\n",
    "    exclude_status = False\n",
    "\n",
    "    #Exclude parties\n",
    "\n",
    "    for party in own_parties_include.replace(';', ',').split(','):\n",
    "        \n",
    "        if ((len(party) > 0) and (party.lower() not in case_info['name'].lower())):\n",
    "        \n",
    "            exclude_status = True\n",
    "        \n",
    "            break\n",
    "\n",
    "    for party in own_parties_exclude.replace(';', ',').split(','):\n",
    "        \n",
    "        if ((len(party) > 0) and (party.lower() in case_info['name'].lower())):\n",
    "        \n",
    "            exclude_status = True\n",
    "        \n",
    "            break\n",
    "\n",
    "    #Exclude year\n",
    "\n",
    "    potential_year_list = []\n",
    "\n",
    "    potential_year_raw_list = case_info['name'].split('[')\n",
    "\n",
    "    for potential_year in potential_year_raw_list:\n",
    "\n",
    "        try:\n",
    "            year_decided_raw = int(potential_year[0:4])\n",
    "            \n",
    "            potential_year_list.append(year_decided_raw)\n",
    "\n",
    "        except:\n",
    "            \n",
    "            print('Potential year value is not integer')\n",
    "\n",
    "    if len(potential_year_list) > 0:\n",
    "    #Defining year_decided here to avoid the possibility of year not being picked up\n",
    "        year_decided = potential_year_list[-1]\n",
    "\n",
    "        if len(own_min_year) >= 4:\n",
    "    \n",
    "            try:       \n",
    "    \n",
    "                if year_decided < int(own_min_year):\n",
    "        \n",
    "                    exclude_status = True\n",
    "            \n",
    "            except:\n",
    "                print('Case not excluded for earlier than min year')\n",
    "    \n",
    "        if len(own_max_year) >= 4:\n",
    "    \n",
    "            try:        \n",
    "    \n",
    "                if year_decided > int(own_max_year):\n",
    "        \n",
    "                    exclude_status = True\n",
    "    \n",
    "            except:\n",
    "                print('Case not excluded for later than max year')\n",
    "\n",
    "    #Exclude judges\n",
    "\n",
    "    if len(case_info['before']) > 2:\n",
    "\n",
    "        for judge in own_judges_include.replace(';', ',').split(','):\n",
    "            \n",
    "            if ((len(judge) > 0) and (judge.lower() not in case_info['before'].lower())):\n",
    "            \n",
    "                exclude_status = True\n",
    "            \n",
    "                break\n",
    "    \n",
    "        for judge in own_judges_exclude.replace(';', ',').split(','):\n",
    "            \n",
    "            if ((len(judge) > 0) and (judge.lower() in case_info['before'].lower())):\n",
    "            \n",
    "                exclude_status = True\n",
    "            \n",
    "                break\n",
    "    \n",
    "    return exclude_status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3034ac9-b1aa-400d-81b3-13e16c6a9f7a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Function to get judgment links with filters\n",
    "\n",
    "def search_results_to_judgment_links_filtered(url_search_results, \n",
    "                                     judgment_counter_bound,\n",
    "                                      collection, \n",
    "                                    own_parties_include, \n",
    "                                    own_parties_exclude, \n",
    "                                    own_min_year, \n",
    "                                    own_max_year, \n",
    "                                    #own_case_numbers_include, \n",
    "                                    #own_case_numbers_exclude, \n",
    "                                    own_judges_include, \n",
    "                                    own_judges_exclude):\n",
    "    \n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "        \n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    #Get number of pages\n",
    "    #There are up to 20 pages per page\n",
    "    number_of_pages = soup.find(\"span\", id=\"lastItem\").text\n",
    "\n",
    "    #Start links list\n",
    "    links = []\n",
    "            \n",
    "    for page_raw in range(0, int(number_of_pages)):\n",
    "        \n",
    "        if counter <= judgment_counter_bound:\n",
    "                        \n",
    "            page = page_raw + 1\n",
    "            \n",
    "            url_search_results_page = url_search_results + f'&page={page}'\n",
    "    \n",
    "            page_page = requests.get(url_search_results_page)\n",
    "    \n",
    "            soup_page = BeautifulSoup(page_page.content, \"lxml\")\n",
    "    \n",
    "            #Get citation, judge pairs with some extra unnecessaries\n",
    "            \n",
    "            citation_judge_pairs_raw = soup_page.find_all('h5')\n",
    "    \n",
    "            #Get raw links and names of cases\n",
    "            \n",
    "            raw_links = soup_page.find_all(class_='case')\n",
    "    \n",
    "            #Start empty citation-judge pairs and case_info list\n",
    "            \n",
    "            citation_judge_pairs = []\n",
    "            \n",
    "            case_infos = []\n",
    "    \n",
    "            #Get all cases with info, judge names, links and citations from this pager\n",
    "                    \n",
    "            if ((len(citation_judge_pairs_raw) > 0) and (len(raw_links)>0)):\n",
    "\n",
    "                if collection != '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "\n",
    "                    for h5 in citation_judge_pairs_raw:\n",
    "                        h5_index = citation_judge_pairs_raw.index(h5)\n",
    "                        if len(h5.text)> 0: \n",
    "                            if h5.text[-1] == 'J':\n",
    "                                citation_value = citation_judge_pairs_raw[h5_index-1].text\n",
    "                                \n",
    "                                citation_judge_pair = {'citation': citation_value, 'before': h5.text}\n",
    "                                \n",
    "                                citation_judge_pairs.append(citation_judge_pair)\n",
    "                    \n",
    "                    for raw_link in raw_links:\n",
    "                        index = raw_links.index(raw_link)\n",
    "                        case_info = {'name': raw_link.text, \n",
    "                                     'url': 'https://eresources.hcourt.gov.au' + raw_link['href'], \n",
    "                                     'citation': citation_judge_pairs[index]['citation'], \n",
    "                                     'before': citation_judge_pairs[index]['before']\n",
    "                                    }\n",
    "                        case_infos.append(case_info)\n",
    "\n",
    "                else: #if collection = '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "\n",
    "                    for h5 in citation_judge_pairs_raw:\n",
    "                        if 'clr' in h5.text.lower():\n",
    "                            \n",
    "                            citation_value = h5.text\n",
    "                            \n",
    "                            citation_judge_pair = {'citation': citation_value, 'before': ''}\n",
    "                                \n",
    "                            citation_judge_pairs.append(citation_judge_pair)\n",
    "\n",
    "                    for raw_link in raw_links:\n",
    "                        \n",
    "                        index = raw_links.index(raw_link)\n",
    "                        \n",
    "                        case_info = {'name': raw_link.text, \n",
    "                                     'url': 'https://eresources.hcourt.gov.au' + raw_link['href'], \n",
    "                                     'citation': citation_judge_pairs[index]['citation'], \n",
    "                                     'before': citation_judge_pairs[index]['before']\n",
    "                                    }\n",
    "                        \n",
    "                        case_infos.append(case_info)\n",
    "    \n",
    "            #Add cases from case_infos unless filtered out or counter reached\n",
    "            \n",
    "            for case_info in case_infos:\n",
    "                if counter <= judgment_counter_bound:\n",
    "                    if judgment_to_exclude(case_info, \n",
    "                            own_parties_include, \n",
    "                            own_parties_exclude, \n",
    "                            own_min_year, \n",
    "                            own_max_year, \n",
    "                            #own_case_numbers_include = [], \n",
    "                            #own_case_numbers_exclude = [], \n",
    "                            own_judges_include, \n",
    "                            own_judges_exclude\n",
    "                           ) == False:\n",
    "                        \n",
    "                        links.append(case_info['url'])\n",
    "                        \n",
    "                        counter += 1\n",
    "                        \n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "        else:\n",
    "            break    \n",
    "\n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions for GPT are capped at 1000 characters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, default_judgment_counter_bound#, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acfae300-2b55-45a0-842c-83f12e8a555a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions for GPT are capped at 1000 characters.\n",
      "\n",
      "The default number of judgments to scrape per request is capped at 10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "hca_role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from specific paragraphs, pages or sections, provide the paragraph or page numbers or section names as part of your answer. If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". '\n",
    "\n",
    "system_instruction = hca_role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a03e8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 20:26:59.229 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-3.5-turbo-0125\"\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Upperbound on number of judgments to scrape\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "def run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search']\n",
    "                        )['url']\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    #Use the following if don't want to filter results\n",
    "    #judgments_links = search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    #Use the following if want to filter results. Will be slow.\n",
    "    judgments_links = search_results_to_judgment_links_filtered(url_search_results, \n",
    "                                     judgments_counter_bound,\n",
    "                                    df_master.loc[0, 'Collection'], \n",
    "                                    df_master.loc[0, 'Parties include'], \n",
    "                                    df_master.loc[0, 'Parties do not include'], \n",
    "                                    df_master.loc[0, 'Before this year'], \n",
    "                                    df_master.loc[0, 'After this year'], \n",
    "                                    #df_master.loc[0, 'Case numbers include'], \n",
    "                                    #df_master.loc[0, 'Case numbers do not include'], \n",
    "                                    df_master.loc[0, 'Judges include'], \n",
    "                                    df_master.loc[0, 'Judges do not include'])\n",
    "\n",
    "    for link in judgments_links:\n",
    "\n",
    "        if 'showbyHandle' in link:\n",
    "            \n",
    "            judgment_dict = meta_judgment_dict_alt(link)\n",
    "\n",
    "        else: #If 'showCase' in link:\n",
    "\n",
    "            judgment_dict = meta_judgment_dict(link)\n",
    "    \n",
    "        judgments_file.append(judgment_dict)\n",
    "        \n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Add judgment if mnc entered\n",
    "\n",
    "    if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "        #direct_link = mnc_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "        direct_link = citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "\n",
    "        if len(direct_link) > 0:\n",
    "            \n",
    "            judgment_dict_direct = meta_judgment_dict(direct_link)\n",
    "            \n",
    "            judgments_file.append(judgment_dict_direct)\n",
    "        \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use latest version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "\n",
    "    df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(df_master.loc[0, 'Metadata inclusion']) == 0:\n",
    "        for meta_label in meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dacc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get link to search results and number of results\n",
    "def search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_num_dict = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search']\n",
    "                        )\n",
    "    url = url_num_dict['url']\n",
    "    results_num = url_num_dict['results_num']\n",
    "    \n",
    "    #If mnc entered\n",
    "\n",
    "    if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "        #direct_link = mnc_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "        direct_link = citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "\n",
    "        if len(direct_link) > 0:\n",
    "            \n",
    "            url = direct_link\n",
    "\n",
    "            results_num = '1'\n",
    "    \n",
    "    return {'url': url, 'results_num': results_num}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5dcd6",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01e54f7a-0689-49e5-a6c9-39ea7ce6b7b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765f659-bf18-4e59-a76c-af2c58f910a9",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "523f9d21-666d-4b2e-8749-e89692939761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bddaeece-b45b-4d88-a6b6-c4d8278b07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2246bdb4-83b6-4289-9172-6dda19e45793",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Number of search results to display\n",
    "if 'number_of_results' not in st.session_state:\n",
    "\n",
    "    st.session_state['number_of_results'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d818b-8edf-4510-adb8-a81a60a55bb6",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c683d9af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-27 20:26:59.357 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Create form\n",
    "\n",
    "return_button = st.button('RETURN to first page')\n",
    "\n",
    "st.header(f\"You have selected to study :blue[judgments of the High Court of Australia].\")\n",
    "\n",
    "#    st.header(\"Judgment Search Criteria\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[Please enter your search terms.]** This program will collect (ie scrape) the first 10 judgments returned by your search terms.\n",
    "\"\"\")\n",
    "\n",
    "st.caption('During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more judgments, courts, or tribunals.')\n",
    "\n",
    "st.subheader(\"Jugdments to cover\")\n",
    "\n",
    "collection_entry = st.selectbox(label = 'Select or type in the collection of judgments to cover', options = hca_collections)\n",
    "\n",
    "st.subheader(\"Your search terms\")\n",
    "\n",
    "st.markdown(\"\"\"For search tips, please visit the [High Court Judgments Database](https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term=). This section largely mimics their judgments search function except the filter function.\n",
    "\"\"\")\n",
    "\n",
    "quick_search_entry = st.text_input('Quick search (search party names and catchwords)')\n",
    "\n",
    "citation_entry = st.text_input('Search for medium neutral citation (eg [2014] HCA 1)')\n",
    "st.caption('CLR or other citations may work only up to 2014.')\n",
    "\n",
    "#if citation_entry:\n",
    "    #if 'hca' not in citation_entry.lower():\n",
    "        \n",
    "        #st.error('Sorry, this pilot program only searches for medium neutral citation (eg [2014] HCA 1).')\n",
    "\n",
    "if collection_entry != '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "\n",
    "    full_text_entry = st.text_input('Full text search')\n",
    "\n",
    "else:\n",
    "    full_text_entry = ''\n",
    "\n",
    "st.markdown(\"\"\"You can preview the judgments returned by your search terms on the High Court Judgments Database after you have entered some search terms.\n",
    "\n",
    "You may have to unblock a popped up window, refresh this page, and re-enter your search terms.\n",
    "\"\"\")\n",
    "\n",
    "preview_button = st.button('PREVIEW on the High Court Judgments Database (in a pop-up window)')\n",
    "\n",
    "#if st.session_state.number_of_results != '0':\n",
    "\n",
    "    #hca_results_num_button = st.button('DISPLAY the number of results')\n",
    "    \n",
    "    #if hca_results_num_button:\n",
    "\n",
    "results_num_button = st.button(label = 'SHOW the number of judgments found')\n",
    "\n",
    "if results_num_button:\n",
    "\n",
    "    if len(st.session_state.df_master) > 0:\n",
    "\n",
    "        if int(st.session_state.number_of_results) == 0:\n",
    "\n",
    "            st.error(f'There are {st.session_state.number_of_results} results. Please change your search terms.')\n",
    "\n",
    "        elif int(st.session_state.number_of_results) == 1:\n",
    "    \n",
    "            st.success(f'There is {st.session_state.number_of_results} result.')\n",
    "    \n",
    "        else:\n",
    "        \n",
    "            st.success(f'There are {st.session_state.number_of_results} results.')\n",
    "\n",
    "    else:\n",
    "\n",
    "        st.warning('Please enter some search terms and press the PREVIEW button first.')\n",
    "        \n",
    "    #hca_results_num()\n",
    "\n",
    "#The following filters are not based on HCA's filter at https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term=\n",
    "\n",
    "filter_toggle = st.toggle(\"Filter your search results\")\n",
    "\n",
    "if filter_toggle:\n",
    "\n",
    "    #st.subheader(\"Filter your search results\")\n",
    "    \n",
    "    st.warning(\"The following is *not* based on the filtered search function of the [High Court Judgments Database](https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term=). The PREVIEW and SHOW buttons will *not* reflect your search filters.\")\n",
    "    \n",
    "    own_parties_include_entry = st.text_input('Parties include (separate parties by comma or semi-colon)')\n",
    "    st.caption('If entered, then this program will only process cases that include at least one of the parties entered.')\n",
    "    \n",
    "    own_parties_exclude_entry = st.text_input('Parties do not include (separate parties by comma or semi-colon)')\n",
    "    st.caption('If entered, then this program will only process cases that do not include any of the parties entered.')\n",
    "    \n",
    "    own_min_year_entry = st.text_input('After this year')\n",
    "    \n",
    "    if own_min_year_entry:\n",
    "\n",
    "        own_min_year_validity = year_check(own_min_year_entry)\n",
    "    \n",
    "        if not own_min_year_validity:\n",
    "                \n",
    "            st.error('You have not entered a year.')\n",
    "        \n",
    "    own_max_year_entry = st.text_input('Before this year')\n",
    "    \n",
    "    if own_max_year_entry:\n",
    "\n",
    "        own_max_year_validity = year_check(own_max_year_entry)\n",
    "\n",
    "        if not own_max_year_validity:\n",
    "    \n",
    "            st.error('You have not entered a year.')\n",
    "    \n",
    "    if collection_entry != '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "    \n",
    "        #own_case_numbers_include_entry = st.text_input('Case numbers include (separate case numbers by comma or semi-colon)') \n",
    "        #st.caption('If entered, then this program will only process cases with at least one of the case numbers entered.')\n",
    "    \n",
    "        #own_case_numbers_exclude_entry = st.text_input('Case numbers do not include (separate case numbers by comma or semi-colon)') \n",
    "        #st.caption('If entered, then this program will only process cases without any of the case numbers entered.')\n",
    "    \n",
    "        own_judges_include_entry = st.text_input('Judges include (separate judges by comma or semi-colon)')\n",
    "        st.caption('If entered, then this program will only process cases heared by at least one of the judges entered.')\n",
    "        \n",
    "        own_judges_exclude_entry = st.text_input('Judges do not include (separate judges by comma or semi-colon)')\n",
    "        st.caption('If entered, then this program will only process cases not heared by any of the judges entered.')\n",
    "    \n",
    "    else:\n",
    "        #own_case_numbers_include_entry = ''\n",
    "        #own_case_numbers_exclude_entry = ''\n",
    "        own_judges_include_entry = ''\n",
    "        own_judges_exclude_entry = ''\n",
    "    \n",
    "st.subheader(\"Judgment metadata collection\")\n",
    "\n",
    "st.markdown(\"\"\"Would you like to obtain judgment metadata? Such data include the name of the judge, the decision date and so on. \n",
    "\n",
    "Case name and medium neutral citation are always included with your results.\n",
    "\"\"\")\n",
    "\n",
    "meta_data_entry = st.checkbox('Include metadata', value = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd466b-8924-44a8-97ff-aec1b36da9c7",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "18c42ba5-19a1-4e50-a69b-daf68c403ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "#    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "st.markdown(\"**:green[Would you like GPT to answer questions about the judgments returned by your search terms?]**\")\n",
    "\n",
    "st.markdown(\"\"\"Please consider trying this program without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract the judgment metadata without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox('Use GPT', value = False)\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default (gpt-3.5-turbo-0125), Ben's own experience suggests that it costs approximately USD \\$0.003-\\$0.008 (excl GST) per judgment. The [exact cost](https://openai.com/pricing) for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced. You will be given ex-post cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your questions for each judgment\")\n",
    "\n",
    "st.markdown(\"\"\"Please enter one question **per line or per paragraph**. GPT will answer your questions for **each** judgment based only on information from **that** judgment. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "if st.toggle('See the instruction given to GPT'):\n",
    "    st.write(f\"{intro_for_GPT[0]['content']}\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "gpt_questions_entry = st.text_area(f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound) \n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        st.session_state['disable_input'] = True\n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "    \n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-3.5-turbo-0125. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-3.5-turbo-0125')*3/4)} words from each judgment.\")\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    \n",
    "    st.subheader(':orange[Enhance program capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of judgments to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle('Use my own GPT account',  disabled = st.session_state.disable_input)\n",
    "    \n",
    "    if own_account_entry:\n",
    "    \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "    \"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state.name_entry)\n",
    "    \n",
    "        email_entry = st.text_input(label = \"Your email address\", value = st.session_state.email_entry)\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.gpt_api_key_entry)\n",
    "        \n",
    "        valdity_check = st.button('VALIDATE your API key')\n",
    "    \n",
    "        if valdity_check:\n",
    "            \n",
    "            api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                    \n",
    "            if api_key_valid == False:\n",
    "                st.session_state['gpt_api_key_validity'] = False\n",
    "                st.error('Your API key is not valid.')\n",
    "                \n",
    "            else:\n",
    "                st.session_state['gpt_api_key_validity'] = True\n",
    "                st.success('Your API key is valid.')\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[You can use the latest version of GPT model (gpt-4o),]** which is :red[10 times more expensive, per character] than the default model (gpt-3.5-turbo) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the latest GPT model', value = False)\n",
    "        st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "        \n",
    "        if gpt_enhancement_entry == True:\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o\"\n",
    "            st.session_state.gpt_enhancement_entry = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "            st.session_state.gpt_enhancement_entry = False\n",
    "        \n",
    "        st.write(f'**:green[You can increase the maximum number of judgments to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        #judgments_counter_bound_entry = round(st.number_input(label = 'Enter a whole number between 1 and 100', min_value=1, max_value=100, value=default_judgment_counter_bound))\n",
    "\n",
    "        #st.session_state.judgments_counter_bound = judgments_counter_bound_entry\n",
    "\n",
    "        judgments_counter_bound_entry = st.text_input(label = 'Enter a whole number between 1 and 100', value=str(default_judgment_counter_bound))\n",
    "\n",
    "        if judgments_counter_bound_entry:\n",
    "            wrong_number_warning = f'You have not entered a whole number between 1 and 100. The program will process up to {default_judgment_counter_bound} judgments instead.'\n",
    "            try:\n",
    "                st.session_state.judgments_counter_bound = int(judgments_counter_bound_entry)\n",
    "            except:\n",
    "                st.warning(wrong_number_warning)\n",
    "                st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "\n",
    "            if ((st.session_state.judgments_counter_bound <= 0) or (st.session_state.judgments_counter_bound > 100)):\n",
    "                st.warning(wrong_number_warning)\n",
    "                st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "    \n",
    "        st.write(f'*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state.judgments_counter_bound} judgments.*')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "    \n",
    "        st.session_state.judgments_counter_bound = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d157be-355a-49d3-ac0f-b7b735191be9",
   "metadata": {},
   "source": [
    "## Consent and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc1842da-69dd-436b-ab06-c51c84f2b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False, disabled = st.session_state.disable_input)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")\n",
    "\n",
    "st.header(\"Next steps\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[You can now run the Empirical Legal Research Kickstarter.]** A spreadsheet which hopefully has the data you seek will be available for download.\n",
    "\n",
    "You can also download a record of your entries.\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "#Warning\n",
    "if st.session_state.gpt_model == 'gpt-3.5-turbo-0125':\n",
    "    st.warning('A low-cost GPT model will answer your questions. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you would like to use the latest model instead.')\n",
    "\n",
    "if st.session_state.gpt_model == \"gpt-4o\":\n",
    "    st.warning('An expensive GPT model will answer your questions. Please be cautious.')\n",
    "\n",
    "run_button = st.button('RUN the program')\n",
    "\n",
    "keep_button = st.button('DOWNLOAD your entries')\n",
    "\n",
    "reset_button = st.button(label='RESET to start afresh', type = 'primary',  help = \"Press to process new search terms or questions.\")\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if st.session_state.need_resetting == 1:\n",
    "    if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output) > 0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5868728-8697-4c05-8532-bc4c77589a5a",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a528871-82e9-48d1-9af2-56053b82fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create placeholder download buttons if previous entries and results in st.session_state:\n",
    "\n",
    "if ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "    \n",
    "    #Load previous entries and results\n",
    "    \n",
    "    df_master = st.session_state.df_master\n",
    "    df_individual_output = st.session_state.df_individual_output\n",
    "\n",
    "    #Buttons for downloading entries\n",
    "    st.subheader('Looking for your previous entries and results?')\n",
    "\n",
    "    st.write('Previous entries')\n",
    "\n",
    "    entries_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_entries'\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    ste.download_button(\n",
    "        label=\"Download your previous entries as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=entries_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download your previous entries as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=entries_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "\n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous entries as a JSON\", \n",
    "        data = json,\n",
    "        file_name= entries_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.write('Previous results')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "    \n",
    "    ste.download_button(label='Download your previous results as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your previous spreadsheet with an AI\", icon = 'ðŸ¤”')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f71a3",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b45fb18-cc54-4b47-99d9-855395417af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preview_button:\n",
    "\n",
    "    df_master = create_df()\n",
    "\n",
    "    st.session_state['df_master'] = df_master\n",
    "\n",
    "    judgments_url_num = search_url(df_master)\n",
    "    \n",
    "    judgments_url = judgments_url_num['url']\n",
    "\n",
    "    judgments_num = judgments_url_num['results_num']\n",
    "\n",
    "    st.session_state['number_of_results'] = judgments_num\n",
    "\n",
    "    open_page(judgments_url)\n",
    "    \n",
    "    #st.rerun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98a8fa86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if run_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    all_search_terms = str(collection_entry) + str(quick_search_entry) + str(citation_entry) + str(full_text_entry)\n",
    "    \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "    \n",
    "    elif int(consent) == 0:\n",
    "        st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "\n",
    "    elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "\n",
    "        st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "            \n",
    "        st.warning('You have not validated your API key.')\n",
    "        quit()\n",
    "\n",
    "    elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "\n",
    "        st.warning('You have not entered a valid API key.')\n",
    "        quit()  \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.write('Your results will be available for download soon. The estimated waiting time is about 2-3 minutes per 10 judgments.')\n",
    "        #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        with st.spinner(\"Running... Please :red[don't change] your entries (yet).\"):\n",
    "\n",
    "            try:\n",
    "\n",
    "                #Create spreadsheet of responses\n",
    "                df_master = create_df()\n",
    "\n",
    "                #Activate user's own key or mine\n",
    "                if st.session_state.own_account == True:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                \n",
    "                openai.api_key = API_key\n",
    "\n",
    "                #Produce results\n",
    "                df_individual_output = run(df_master)\n",
    "        \n",
    "                #Keep results in session state\n",
    "                st.session_state[\"df_individual_output\"] = df_individual_output\n",
    "        \n",
    "                st.session_state[\"df_master\"] = df_master\n",
    "\n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                \n",
    "                st.session_state[\"page_from\"] = 'pages/HCA.py'\n",
    "        \n",
    "                #Write results\n",
    "        \n",
    "                st.success(\"Your results are now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                \n",
    "                #Button for downloading results\n",
    "                output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "        \n",
    "                csv_output = convert_df_to_csv(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a CSV (for use in Excel etc)\", \n",
    "                    data = csv_output,\n",
    "                    file_name= output_name + '.csv', \n",
    "                    mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "                )\n",
    "        \n",
    "                excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "                \n",
    "                ste.download_button(label='Download your results as an Excel spreadsheet (XLSX)',\n",
    "                                    data=excel_xlsx,\n",
    "                                    file_name= output_name + '.xlsx', \n",
    "                                    mime='application/vnd.ms-excel',\n",
    "                                   )\n",
    "        \n",
    "                json_output = convert_df_to_json(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a JSON\", \n",
    "                    data = json_output,\n",
    "                    file_name= output_name + '.json', \n",
    "                    mime= \"application/json\", \n",
    "                )\n",
    "        \n",
    "                st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = 'ðŸ¤”')\n",
    "\n",
    "                    \n",
    "                #Keep record on Google sheet\n",
    "                #Obtain google spreadsheet       \n",
    "                #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                #df_google = conn.read()\n",
    "                #df_google = df_google.fillna('')\n",
    "                #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                #df_master[\"Processed\"] = datetime.now()\n",
    "                #df_master.pop(\"Your GPT API key\")\n",
    "                #df_to_update = pd.concat([df_google, df_master])\n",
    "                #conn.update(worksheet=\"CTH\", data=df_to_update, )\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "                st.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4873fffb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    all_search_terms = str(collection_entry) + str(quick_search_entry) + str(citation_entry) + str(full_text_entry)\n",
    "    \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "    \n",
    "    elif ((len(st.session_state.df_master) > 0) and (len(st.session_state.df_individual_output)>0)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "        \n",
    "        if 'need_resetting' not in st.session_state:\n",
    "            \n",
    "            st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        df_master = create_df()\n",
    "    \n",
    "        df_master.pop(\"Your GPT API key\")\n",
    "    \n",
    "        df_master.pop(\"Processed\")\n",
    "    \n",
    "        responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "    \n",
    "        #Produce a file to download\n",
    "    \n",
    "        csv = convert_df_to_csv(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a CSV (for use in Excel etc)\", \n",
    "            data = csv,\n",
    "            file_name=responses_output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "    #            key='download-csv'\n",
    "        )\n",
    "\n",
    "\n",
    "        xlsx = convert_df_to_excel(df_master)\n",
    "        \n",
    "        ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                            data=xlsx,\n",
    "                            file_name=responses_output_name + '.xlsx', \n",
    "                            mime='application/vnd.ms-excel',\n",
    "                           )\n",
    "        \n",
    "        json = convert_df_to_json(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a JSON\", \n",
    "            data = json,\n",
    "            file_name= responses_output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_button:\n",
    "    clear_cache_except_validation_df_master()\n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470438d-e485-44e4-8e10-798973642140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
