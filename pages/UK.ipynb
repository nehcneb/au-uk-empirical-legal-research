{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "from io import BytesIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2790eb5a-6de3-4548-89c7-902015d5ec10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, list_range_check, au_date\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, list_range_check, au_date\n",
    "#Import variables\n",
    "from common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# UK Courts search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f841231-e0ad-4647-b5c2-244594a4cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def uk_create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    \n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "        \n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "    \n",
    "    #Judgment counter bound\n",
    "    judgments_counter_bound = st.session_state.judgments_counter_bound\n",
    "\n",
    "    #GPT enhancement\n",
    "    gpt_enhancement = st.session_state.gpt_enhancement_entry\n",
    "    \n",
    "    #Free text\n",
    "\n",
    "    query = query_entry\n",
    "    \n",
    "    #dates        \n",
    "    \n",
    "    from_day= '',\n",
    "    from_month='', \n",
    "    from_year='', \n",
    "\n",
    "    if from_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "            from_day = str(from_date_entry.strftime('%d'))\n",
    "            from_month = str(from_date_entry.strftime('%m'))\n",
    "            from_year = str(from_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    to_day= '',\n",
    "    to_month='', \n",
    "    to_year='', \n",
    "\n",
    "    if to_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "            to_day = str(to_date_entry.strftime('%d'))\n",
    "            to_month = str(to_date_entry.strftime('%m'))\n",
    "            to_year = str(to_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #Courts\n",
    "    courts_list = courts_entry\n",
    "    court_string = ', '.join(courts_list)\n",
    "    court = court_string\n",
    "    \n",
    "    #Other entries\n",
    "    party = party_entry\n",
    "    judge =  judge_entry\n",
    "\n",
    "    #GPT choice and entry\n",
    "    try:\n",
    "        gpt_activation_status = gpt_activation_entry\n",
    "    except:\n",
    "        gpt_activation_status = False\n",
    "    \n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: question_characters_bound]\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "        \n",
    "    #metadata choice\n",
    "\n",
    "    meta_data_choice = meta_data_entry\n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "            'Free text': query,\n",
    "           'From day': from_day, \n",
    "            'From month': from_month,\n",
    "            'From year': from_year,\n",
    "            'To day': to_day,\n",
    "            'To month': to_month,\n",
    "            'To year' : to_year,\n",
    "            'Courts' : court, \n",
    "            'Party' : party,\n",
    "            'Judge' : judge, \n",
    "            'Metadata inclusion' : meta_data_choice,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your questions for GPT': gpt_questions, \n",
    "            'Use GPT': gpt_activation_status, \n",
    "          'Use own account': own_account,\n",
    "            'Use flagship version of GPT' : gpt_enhancement\n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "    \n",
    "#    df_master_new.to_json(current_dir + '/df_master.json', orient = 'split', compression = 'infer')\n",
    "#    df_master_new.to_excel(current_dir + '/df_master.xlsx', index=False)\n",
    "\n",
    "#    if len(df_master_new) > 0:\n",
    "        \n",
    "    return df_master_new\n",
    "\n",
    "#    else:\n",
    "#        return 'Error: spreadsheet of reponses NOT generated.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c62702-7127-48dd-bac4-875f92cd7369",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Initialize default courts\n",
    "\n",
    "uk_courts_default_list = ['United Kingdom Supreme Court',\n",
    " 'Privy Council',\n",
    " 'Court of Appeal Civil Division',\n",
    " 'Court of Appeal Criminal Division',\n",
    " 'High Court (England & Wales) Administrative Court',\n",
    " 'High Court (England & Wales) Admiralty Court',\n",
    " 'High Court (England & Wales) Chancery Division',\n",
    " 'High Court (England & Wales) Commercial Court',\n",
    " 'High Court (England & Wales) Family Division',\n",
    " 'High Court (England & Wales) Intellectual Property Enterprise Court',\n",
    " \"High Court (England & Wales) King's/Queen's Bench Division\",\n",
    " 'High Court (England & Wales) Mercantile Court',\n",
    " 'High Court (England & Wales) Patents Court',\n",
    " 'High Court (England & Wales) Senior Courts Costs Office',\n",
    " 'High Court (England & Wales) Technology and Construction Court'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035a5c8b-f936-4100-9ddf-b7547e4c5d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define format functions for courts choice, and GPT questions\n",
    "\n",
    "#auxiliary lists and variables\n",
    "uk_courts ={'United Kingdom Supreme Court': 'uksc',\n",
    "'Privy Council': 'ukpc',  \n",
    "'Court of Appeal Civil Division': 'ewca%2Fciv', \n",
    " 'Court of Appeal Criminal Division':  'ewca%2Fcrim',  \n",
    "'High Court (England & Wales) Administrative Court': 'ewhc%2Fadmin',\n",
    "'High Court (England & Wales) Admiralty Court': 'ewhc%2Fadmlty',  \n",
    "'High Court (England & Wales) Chancery Division': 'ewhc%2Fch',  \n",
    "'High Court (England & Wales) Commercial Court': 'ewhc%2Fcomm',  \n",
    "'High Court (England & Wales) Family Division': 'ewhc%2Ffam',  \n",
    "'High Court (England & Wales) Intellectual Property Enterprise Court': 'ewhc%2Fipec',  \n",
    "\"High Court (England & Wales) King's/Queen's Bench Division\" : 'ewhc%2Fkb',\n",
    "'High Court (England & Wales) Mercantile Court': 'ewhc%2Fmercantile',  \n",
    "'High Court (England & Wales) Patents Court': 'ewhc%2Fpat',  \n",
    "'High Court (England & Wales) Senior Courts Costs Office': 'ewhc%2Fscco',  \n",
    "'High Court (England & Wales) Technology and Construction Court': 'ewhc%2Ftcc',  \n",
    "'Court of Protection': 'ewcop',  \n",
    "'Family Court': 'ewfc',  \n",
    "'Employment Appeal Tribunal': 'eat',  \n",
    "'Administrative Appeals Chamber': 'ukut%2Faac',  \n",
    "'Immigration and Asylum Chamber': 'ukut%2Fiac',\n",
    "'Lands Chamber': 'ukut%2Flc',  \n",
    "'Tax and Chancery Chamber': 'ukut%2Ftcc',  \n",
    "'General Regulatory Chamber': 'ukftt%2Fgrc',  \n",
    "'Tax Chamber' : 'ukftt%2Ftc'\n",
    "}\n",
    "\n",
    "uk_courts_list = list(uk_courts.keys())\n",
    "\n",
    "def uk_court_choice(x):\n",
    "    individual_choice = []\n",
    "    if len(x) < 5:\n",
    "        pass #If want no court to be covered absent choice\n",
    "        #for i in uk_courts.keys():\n",
    "            #individual_choice.append(uk_courts[i])\n",
    "    else:\n",
    "        y = x.split(', ')\n",
    "        for j in y:\n",
    "            individual_choice.append(uk_courts[j])\n",
    "    \n",
    "    return individual_choice\n",
    "\n",
    "\n",
    "#Tidy up hyperlink\n",
    "def uk_link(x):\n",
    "    y =str(x).replace('.uk/id', '.uk')\n",
    "    value = '=HYPERLINK(\"' + y + '\")'\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url\n",
    "def uk_search(query= '', \n",
    "              from_day= '',\n",
    "              from_month='', \n",
    "              from_year='', \n",
    "              to_day='', \n",
    "              to_month='', \n",
    "              to_year='', \n",
    "              court = [], \n",
    "              party = '', \n",
    "              judge = ''\n",
    "             ):\n",
    "    base_url = \"https://caselaw.nationalarchives.gov.uk/judgments/search?per_page=50&order=relevance\"\n",
    "    params = {'query' : query, \n",
    "              'from_date_0' : from_day,\n",
    "              'from_date_1' : from_month, \n",
    "              'from_date_2' : from_year, \n",
    "              'to_date_0' : to_day, \n",
    "              'to_date_1' : to_month, \n",
    "              'to_date_2' : to_year, \n",
    "              'court' : court, \n",
    "              'party' : party, \n",
    "              'judge' : judge}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    proper_url = str(response.url).replace('%25', '%')\n",
    "    \n",
    "    return proper_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd2a117c-a027-474a-93e7-31aabf01150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_search_results = 'https://caselaw.nationalarchives.gov.uk/judgments/search?per_page=50&order=relevance&query=constitution&from_day=&from_month=&from_year=&to_day=&to_month=&to_year=&court=uksc&court=ukpc&court=ewca%2Fciv&court=ewca%2Fcrim&court=ewhc%2Fadmin&court=ewhc%2Fadmlty&court=ewhc%2Fch&court=ewhc%2Fcomm&court=ewhc%2Ffam&court=ewhc%2Fipec&court=ewhc%2Fkb&court=ewhc%2Fmercantile&court=ewhc%2Fpat&court=ewhc%2Fscco&court=ewhc%2Ftcc&party=&judge='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6321d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function turning search results url to links to judgments\n",
    "def uk_search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    hrefs = soup.find_all('a', href=True)\n",
    "    links = []\n",
    "\n",
    "    #Get total number of pages\n",
    "    page_nums_raw = soup.find_all('li', attrs={'class': 'pagination__list-item'})\n",
    "    page_nums = []\n",
    "    \n",
    "    for page_num in page_nums_raw:\n",
    "        try:\n",
    "            if ('Previous' not in page_num.get_text()) and ('Next' not in page_num.get_text()):\n",
    "                \n",
    "                page_nums.append(page_num)\n",
    "    \n",
    "        except:\n",
    "            print('No new page')\n",
    "    \n",
    "    if len(page_nums) > 1:\n",
    "        \n",
    "        page_total = int(page_nums[-1].get_text().split('Page')[1].split('\\n')[0])\n",
    "    \n",
    "    else:\n",
    "        page_total = 1\n",
    "    \n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    for link in hrefs:\n",
    "        if ((counter <= judgment_counter_bound) and ('a href=\"/' in str(link)) and '\">' in str(link) and '?' in str(link)):\n",
    "            link_direct = 'https://caselaw.nationalarchives.gov.uk' + str(link).split('?')[0][9:] + '/data.xml'\n",
    "            links.append(link_direct.replace('.uk/id', '.uk'))\n",
    "            counter = counter + 1\n",
    "\n",
    "    if page_total > 1:  \n",
    "    \n",
    "        for page_ending in range(page_total):\n",
    "            \n",
    "            if counter <=judgment_counter_bound:\n",
    "                \n",
    "                url_next_page = url_search_results + f\"&page={page_ending + 1}\"\n",
    "                \n",
    "                page_judgment_next_page = requests.get(url_next_page)\n",
    "                soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "        \n",
    "                #Check if stll more results\n",
    "                if 'No results have been found' not in str(soup_judgment_next_page):\n",
    "                    hrefs_next_page = soup_judgment_next_page.find_all('a', href=True)\n",
    "                    for extra_link in hrefs_next_page:\n",
    "                        if ((counter <= judgment_counter_bound) and ('a href=\"/' in str(extra_link)) and '\">' in str(extra_link) and '?' in str(extra_link)):\n",
    "                            extra_link_direct = 'https://caselaw.nationalarchives.gov.uk' + str(extra_link).split('?')[0][9:] + '/data.xml'\n",
    "                            links.append(extra_link_direct.replace('.uk/id', '.uk'))\n",
    "                            counter = counter + 1\n",
    "    \n",
    "                else:\n",
    "                    break\n",
    "                \n",
    "                pause.seconds(np.random.randint(10, 20))\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86a85223-64ca-4d1b-998c-1c2769c5a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "\n",
    "uk_meta_labels_droppable = ['Date', \n",
    "                         'Court', \n",
    "                         'Case number', \n",
    "                         'Judge(s) (non-exhaustiveive)', \n",
    "                         'Parties', \n",
    "                         'Header'\n",
    "                        ]\n",
    "\n",
    "    \n",
    "def uk_meta_judgment_dict(judgment_url_xml):\n",
    "    page = requests.get(judgment_url_xml)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to The National Archives' : '', \n",
    "                'Date' : '',\n",
    "                'Court' : '', \n",
    "                'Case number': '',\n",
    "                'Judge(s) (non-exhaustiveive)' : [], \n",
    "                'Parties' : [],\n",
    "                'Header' : '',\n",
    "                'judgment': ''\n",
    "                }\n",
    "    try:\n",
    "        judgment_dict['Case name'] = soup.find(\"frbrname\")['value']\n",
    "        judgment_dict['Medium neutral citation'] = soup.find(\"uk:cite\").getText()\n",
    "        judgment_dict['Hyperlink to The National Archives'] = uk_link(soup.find(\"frbruri\")['value'])\n",
    "        judgment_dict['Date'] = soup.find(\"frbrdate\")['date']\n",
    "        judgment_dict['Court'] = soup.find(\"uk:court\").getText()\n",
    "        judgment_dict['Header'] = soup.find('header').getText()\n",
    "        if judgment_dict['Header'][0:1] == '\\n':\n",
    "            judgment_dict['Header'] = judgment_dict['Header'][1: ]\n",
    "        judgment_dict['Case number'] = soup.find(\"docketnumber\").getText()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for person in soup.find_all(\"tlcperson\"):\n",
    "        if 'judge' in str(person):\n",
    "            judgment_dict['Judge(s) (non-exhaustiveive)'].append(person[\"showas\"])\n",
    "        else:\n",
    "            judgment_dict['Parties'].append(person[\"showas\"])\n",
    "    \n",
    "    #Get judgment content as a list of headings and paras, but not enumeration/paragraph number\n",
    "    #for text in soup.find_all('content'):\n",
    "    #    judgment_dict['judgment'].append(text.getText())\n",
    "\n",
    "    #Get judgment\n",
    "\n",
    "    pause.seconds(np.random.randint(5, 10))\n",
    "\n",
    "    html_link = judgment_url_xml.replace('/data.xml', '')\n",
    "    page_html = requests.get(html_link)\n",
    "    soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "    \n",
    "    judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    try:\n",
    "        before_end_of_doc = judgment_text.split('End of document')[0]\n",
    "        after_skip_to_end = before_end_of_doc.split('Skip to end')[1]\n",
    "        judgment_text = after_skip_to_end\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    judgment_dict['judgment'] = judgment_text\n",
    "    \n",
    "    #try:\n",
    "     #   judgment_text = str(soup.find_all('content'))\n",
    "    #except:\n",
    "      #  judgment_text= soup.get_text(strip=True)\n",
    "        \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c19fca0c-c315-45ce-b07a-f3cfc9950737",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound, role_content\u001b[38;5;66;03m#, intro_for_GPT\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, default_judgment_counter_bound, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d395ed00-ca84-4f86-b761-69e08c6619d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfedd057-c5e3-4cb4-ad49-54144c16ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "system_instruction = role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Upperbound on number of judgments to scrape\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "def uk_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    df_master['Courts'] = df_master['Courts'].apply(uk_court_choice)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = uk_search(query= df_master.loc[0, 'Free text'], \n",
    "                                   from_day= df_master.loc[0, 'From day'],\n",
    "                                   from_month=df_master.loc[0, 'From month'], \n",
    "                                   from_year=df_master.loc[0, 'From year'], \n",
    "                                   to_day=df_master.loc[0, 'To day'], \n",
    "                                   to_month=df_master.loc[0, 'To month'], \n",
    "                                   to_year=df_master.loc[0, 'To year'], \n",
    "                                   court= df_master.loc[0, 'Courts'], \n",
    "                                   party = df_master.loc[0, 'Party'], \n",
    "                                   judge = df_master.loc[0, 'Judge']\n",
    "                                  )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    judgments_links = uk_search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for link in judgments_links:\n",
    "\n",
    "        judgment_dict = uk_meta_judgment_dict(link)\n",
    "\n",
    "#        meta_data = meta_dict(link)  \n",
    "#        doc_link = link_to_doc(link)\n",
    "#        judgment_dict = doc_link_to_dict(doc_link)\n",
    "#        judgment_dict = link_to_dict(link)\n",
    "#        judgments_all_info = { **meta_data, **judgment_dict}\n",
    "#        judgments_file.append(judgments_all_info)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(10, 20))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #For UK, convert date to string so as to avoid Excel producing random numbers for dates\n",
    "    df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "\n",
    "    df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(df_master.loc[0, 'Metadata inclusion']) == 0:\n",
    "        for meta_label in uk_meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uk_search_url(df_master):\n",
    "\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    df_master['Courts'] = df_master['Courts'].apply(uk_court_choice)\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url = uk_search(query= df_master.loc[0, 'Free text'], \n",
    "                                   from_day= df_master.loc[0, 'From day'],\n",
    "                                   from_month=df_master.loc[0, 'From month'], \n",
    "                                   from_year=df_master.loc[0, 'From year'], \n",
    "                                   to_day=df_master.loc[0, 'To day'], \n",
    "                                   to_month=df_master.loc[0, 'To month'], \n",
    "                                   to_year=df_master.loc[0, 'To year'], \n",
    "                                   court= df_master.loc[0, 'Courts'], \n",
    "                                   party = df_master.loc[0, 'Party'], \n",
    "                                   judge = df_master.loc[0, 'Judge']\n",
    "                                  )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5dcd6",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2c1c8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b36918-83c1-44dc-b3d2-520630758e05",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a202d49-5317-4d84-9e40-f42a6bcfbaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default_courts\n",
    "\n",
    "if 'default_courts' not in st.session_state:\n",
    "    st.session_state['default_courts'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b6160-1b8d-45c4-9749-cd8f414f5884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = True\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "    #Jurisdiction specific\n",
    "    st.session_state.df_master.loc[0, 'Free text'] = None \n",
    "    st.session_state.df_master.loc[0, 'From day'] = None\n",
    "    st.session_state.df_master.loc[0, 'From month'] = None \n",
    "    st.session_state.df_master.loc[0, 'From year'] = None \n",
    "    st.session_state.df_master.loc[0, 'To day'] = None \n",
    "    st.session_state.df_master.loc[0, 'To month'] = None \n",
    "    st.session_state.df_master.loc[0, 'To year'] = None \n",
    "    st.session_state.df_master.loc[0, 'Courts'] = '' \n",
    "    st.session_state.df_master.loc[0, 'Party'] = None \n",
    "    st.session_state.df_master.loc[0, 'Judge'] = None\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = st.session_state['df_master'].replace({np.nan: None})\n",
    "\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = pd.DataFrame([])\n",
    "    \n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879ee8cb-46f3-49ae-8617-ed9eada52394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0fd02-45fc-448b-8595-df6b28b0cbd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If landing page is not home\n",
    "if 'page_from' not in st.session_state:\n",
    "    st.session_state['page_from'] = 'Home.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d821de9f-8f64-4b49-998d-c67d2de32f42",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683d9af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if st.session_state.page_from != \"pages/UK.py\": #Need to add in order to avoid GPT page from showing form of previous page\n",
    "\n",
    "    #Create form for court selection\n",
    "    \n",
    "    return_button = st.button('RETURN to first page')\n",
    "    \n",
    "    st.header(f\"You have selected to study :blue[judgments of select United Kingdom courts and tribunals].\")\n",
    "    \n",
    "    #st.header(\"Judgment Search Criteria\")\n",
    "    \n",
    "    st.markdown(\"\"\"**:green[Please enter your search terms.]** This program will collect (ie scrape) the first 10 judgments returned by your search terms.\n",
    "\"\"\")\n",
    "    \n",
    "    st.caption('During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more judgments.')\n",
    "    \n",
    "    st.subheader(\"Courts and tribunals to cover\")\n",
    "    \n",
    "    default_on = st.checkbox('Prefill the Supreme Court, the Privy Council, the Court of Appeal, the High Court of England & Wales')\n",
    "    \n",
    "    if default_on:\n",
    "    \n",
    "        st.session_state.default_courts = uk_courts_default_list\n",
    "    \n",
    "    else:\n",
    "        st.session_state.default_courts = list_range_check(uk_courts, st.session_state['df_master'].loc[0, 'Courts'])\n",
    "    \n",
    "    courts_entry = st.multiselect(label = 'Select or type in the courts and tribunals to cover', options = uk_courts_list, default = st.session_state.default_courts)\n",
    "        \n",
    "    #st.caption(\"All courts and tribunals listed in this menu will be covered if left blank.\")\n",
    "    \n",
    "    #Search terms\n",
    "    \n",
    "    st.subheader(\"Your search terms\")\n",
    "    \n",
    "    st.markdown(\"\"\"For search tips, please visit [The National Archives](https://caselaw.nationalarchives.gov.uk/structured_search). This section mimics their search function.\n",
    "\"\"\")\n",
    "    \n",
    "    query_entry = st.text_input(label = 'Free text', value = st.session_state.df_master.loc[0, 'Free text'])\n",
    "    \n",
    "    from_date_entry = st.date_input('From day', value = au_date(f\"{st.session_state.df_master.loc[0, 'From day']}/{st.session_state.df_master.loc[0, 'From month']}/{st.session_state.df_master.loc[0, 'From year']}\"), format=\"DD/MM/YYYY\", min_value = date(1900, 1, 1), max_value = datetime.now())\n",
    "    \n",
    "    to_date_entry = st.date_input('To day', value = au_date(f\"{st.session_state.df_master.loc[0, 'To day']}/{st.session_state.df_master.loc[0, 'To month']}/{st.session_state.df_master.loc[0, 'To year']}\"), format=\"DD/MM/YYYY\", min_value = date(1900, 1, 1), max_value = datetime.now())\n",
    "    \n",
    "    st.caption('[Relatively earlier](https://caselaw.nationalarchives.gov.uk/structured_search) judgments are not available.')\n",
    "    \n",
    "    judge_entry = st.text_input(label = 'Judge name', value = st.session_state.df_master.loc[0, 'Judge'])\n",
    "    \n",
    "    party_entry = st.text_input(label = 'Party name', value = st.session_state.df_master.loc[0, 'Party'])\n",
    "    \n",
    "    st.markdown(\"\"\"You can preview the judgments returned by your search terms on The National Archives after you have entered some search terms.\n",
    "    \n",
    "You may have to unblock a popped up window, refresh this page, and re-enter your search terms.\n",
    "\"\"\")\n",
    "    \n",
    "    preview_button = st.button(label = 'PREVIEW on The National Archives (in a popped up window)', type = 'primary')\n",
    "    \n",
    "    st.subheader(\"Judgment metadata collection\")\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to obtain judgment metadata? Such data include the name of the judge, the names of the parties and so on. \n",
    "    \n",
    "Case name and medium neutral citation are always included with your results.\n",
    "\"\"\")\n",
    "\n",
    "    meta_data_entry = st.checkbox('Include metadata', value = st.session_state['df_master'].loc[0, 'Metadata inclusion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c58a4b-c7b2-45b0-973d-f5e113384a1e",
   "metadata": {},
   "source": [
    "## Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5428b07e-fe2e-4854-88a1-d216fd143912",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Buttons\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m col1, col2, col3, col4 \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns(\u001b[38;5;241m4\u001b[39m, gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m col1:\n\u001b[1;32m      6\u001b[0m     keep_button \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mbutton(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAVE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "    #Buttons\n",
    "    \n",
    "    #col1, col2, col3, col4 = st.columns(4, gap = 'small')\n",
    "    \n",
    "    #with col1:\n",
    "    \n",
    "        #reset_button = st.button(label='RESET', type = 'primary')\n",
    "    \n",
    "    #with col4:\n",
    "    with stylable_container(\n",
    "        \"green\",\n",
    "        css_styles=\"\"\"\n",
    "        button {\n",
    "            background-color: #00FF00;\n",
    "            color: black;\n",
    "        }\"\"\",\n",
    "    ):\n",
    "        next_button = st.button(label='NEXT')\n",
    "    \n",
    "    keep_button = st.button('SAVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f71a3",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d89e4a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    if preview_button:\n",
    "    \n",
    "        df_master = uk_create_df()\n",
    "    \n",
    "        judgments_url = uk_search_url(df_master)\n",
    "    \n",
    "        open_page(judgments_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873fffb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    if keep_button:\n",
    "    \n",
    "        all_search_terms = str(query_entry) + str(from_date_entry) + str(to_date_entry) + str(judge_entry) + str(party_entry)\n",
    "            \n",
    "        if all_search_terms.replace('None', '') == \"\":\n",
    "    \n",
    "            st.warning('You must enter some search terms.')\n",
    "    \n",
    "        elif len(courts_entry) == 0:\n",
    "            st.write('Please select at least one court to cover.')\n",
    "                \n",
    "        else:\n",
    "                                \n",
    "            df_master = uk_create_df()\n",
    "\n",
    "            st.session_state['df_master'] = df_master\n",
    "        \n",
    "            df_master.pop(\"Your GPT API key\")\n",
    "        \n",
    "            df_master.pop(\"Processed\")\n",
    "        \n",
    "            responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "        \n",
    "            #Produce a file to download\n",
    "        \n",
    "            csv = convert_df_to_csv(df_master)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download as a CSV (for use in Excel etc)\", \n",
    "                data = csv,\n",
    "                file_name=responses_output_name + '.csv', \n",
    "                mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "            )\n",
    "    \n",
    "            xlsx = convert_df_to_excel(df_master)\n",
    "            \n",
    "            ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                                data=xlsx,\n",
    "                                file_name=responses_output_name + '.xlsx', \n",
    "                                mime='application/vnd.ms-excel',\n",
    "                               )\n",
    "        \n",
    "            json = convert_df_to_json(df_master)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download as a JSON\", \n",
    "                data = json,\n",
    "                file_name= responses_output_name + '.json', \n",
    "                mime= \"application/json\", \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85760097-ba4b-4769-9a61-69a52c52182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if return_button:\n",
    "    \n",
    "        st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08899688-9534-4de3-9dbf-1d6cc21ad94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #if reset_button:\n",
    "        #clear_cache_except_validation_df_master()\n",
    "        #st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c03aaf-eb74-4561-b298-6b97c342ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if next_button:\n",
    "    \n",
    "        all_search_terms = str(query_entry) + str(from_date_entry) + str(to_date_entry) + str(judge_entry) + str(party_entry)\n",
    "            \n",
    "        if all_search_terms.replace('None', '') == \"\":\n",
    "    \n",
    "            st.warning('You must enter some search terms.')\n",
    "    \n",
    "        elif len(courts_entry) == 0:\n",
    "            st.write('Please select at least one court to cover.')\n",
    "        \n",
    "        else:\n",
    "    \n",
    "            df_master = uk_create_df()\n",
    "            \n",
    "            st.session_state['df_master'] = df_master\n",
    "            \n",
    "            st.session_state[\"page_from\"] = 'pages/UK.py'\n",
    "            \n",
    "            st.switch_page('pages/GPT.py')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
