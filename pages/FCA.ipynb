{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import PyPDF2\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_range_check, au_date, save_input, pdf_judgment\n",
    "#Import variables\n",
    "from common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf29b97-5256-4214-b4f6-ac6a95a702f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"LawtoData: An Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# Federal Courts search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3329d8-1716-4570-8dd0-4b5aa22aaed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m link\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "from common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f0e228-8b90-4951-83fb-7668f7010106",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def fca_create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "    \n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "\n",
    "    #Judgment counter bound\n",
    "    try:\n",
    "        judgments_counter_bound = judgments_counter_bound_entry\n",
    "    except:\n",
    "        print('judgments_counter_bound not entered')\n",
    "        judgments_counter_bound = default_judgment_counter_bound\n",
    "        \n",
    "    #GPT enhancement\n",
    "    try:\n",
    "        gpt_enhancement = gpt_enhancement_entry\n",
    "    except:\n",
    "        print('GPT enhancement not entered')\n",
    "        gpt_enhancement = False\n",
    "        \n",
    "    #Courts\n",
    "    #courts_list = courts_entry\n",
    "    #court_string = ', '.join(courts_list)\n",
    "    #court = court_string\n",
    "\n",
    "    court = courts_entry\n",
    "    \n",
    "    #dates\n",
    "    \n",
    "    on_this_date = ''\n",
    "\n",
    "    if on_this_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            #on_this_date = on_this_date_entry.strftime('%d/%m/%Y') + on_this_date_entry.strftime('%d') + on_this_date_entry.strftime('%B').lower()[:3] + on_this_date_entry.strftime('Y')\n",
    "\n",
    "            on_this_date = str(on_this_date_entry.strftime('%d')) + str(on_this_date_entry.strftime('%B')).lower()[:3] + str(on_this_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    before_date = ''\n",
    "\n",
    "    if before_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            before_date = str(before_date_entry.strftime('%d')) + str(before_date_entry.strftime('%B')).lower()[:3] + str(before_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    after_date = ''\n",
    "\n",
    "    if after_date_entry != 'None':\n",
    "        \n",
    "        try:\n",
    "            after_date = str(after_date_entry.strftime('%d')) + str(after_date_entry.strftime('%B')).lower()[:3] + str(after_date_entry.strftime('%Y'))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    #Other entries\n",
    "    case_name_mnc = case_name_mnc_entry\n",
    "    judge =  judge_entry\n",
    "    reported_citation = reported_citation_entry\n",
    "    file_number = file_number_entry\n",
    "    npa = npa_entry\n",
    "    with_all_the_words = with_all_the_words_entry\n",
    "    with_at_least_one_of_the_words = with_at_least_one_of_the_words_entry\n",
    "    without_the_words = without_the_words_entry\n",
    "    phrase = phrase_entry\n",
    "    proximity = proximity_entry\n",
    "    legislation = legislation_entry\n",
    "    cases_cited = cases_cited_entry\n",
    "    catchwords = catchwords_entry \n",
    "    \n",
    "    #GPT choice and entry\n",
    "    try:\n",
    "        gpt_activation_status = gpt_activation_entry\n",
    "    except:\n",
    "        gpt_activation_status = False\n",
    "    \n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: 1000]\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "\n",
    "    #metadata choice\n",
    "\n",
    "    meta_data_choice = meta_data_entry\n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "           'Courts' : court, \n",
    "           'Case name or medium neutral citation': case_name_mnc, \n",
    "           'Judge' : judge, \n",
    "            'Reported citation' : reported_citation, \n",
    "            'File number': file_number,\n",
    "            'National practice area': npa,\n",
    "            'With all the words': with_all_the_words,\n",
    "            'With at least one of the words': with_at_least_one_of_the_words,\n",
    "            'Without the words': without_the_words,\n",
    "            'Phrase': phrase,\n",
    "            'Proximity': proximity,\n",
    "            'On this date': on_this_date,\n",
    "            'Decision date is after': after_date,\n",
    "            'Decision date is before': before_date,\n",
    "            'Legislation': legislation,\n",
    "            'Cases cited': cases_cited,\n",
    "            'Catchwords' : catchwords, \n",
    "            'Metadata inclusion' : meta_data_choice,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your questions for GPT': gpt_questions, \n",
    "            'Use GPT': gpt_activation_status,\n",
    "           'Use own account': own_account,\n",
    "            'Use flagship version of GPT' : gpt_enhancement\n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "            \n",
    "    return df_master_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb5735b-cbd1-454a-937d-bdefcdcbcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define format functions for courts choice, and GPT questions\n",
    "\n",
    "#auxiliary lists and variables\n",
    "\n",
    "fca_courts = {'Federal Court': 'fca', \n",
    "              'Industrial Relations Court of Australia': 'irc', \n",
    "              'Australian Competition Tribunal': 'tribunals%2Facompt', \n",
    "              'Copyright Tribunal': 'tribunals%2Facopyt', \n",
    "              'Defence Force Discipline Appeal Tribunal': 'tribunals%2Fadfdat', \n",
    "              'Federal Police Discipline Tribunal': 'tribunals%2Ffpdt', \n",
    "              'Trade Practices Tribunal': 'tribunals%2Fatpt', \n",
    "              'Supreme Court of Norfolk Island': 'nfsc',\n",
    "             'All': ''}\n",
    "\n",
    "fca_courts_list = list(fca_courts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url\n",
    "def fca_search(court = '', \n",
    "               case_name_mnc= '', \n",
    "               judge ='', \n",
    "               reported_citation ='', \n",
    "               file_number ='', \n",
    "               npa = '', \n",
    "               with_all_the_words = '', \n",
    "               with_at_least_one_of_the_words = '', \n",
    "               without_the_words = '', \n",
    "               phrase = '', \n",
    "               proximity = '', \n",
    "               on_this_date = '', \n",
    "               after_date = '', \n",
    "               before_date = '', \n",
    "               legislation = '', \n",
    "               cases_cited = '', \n",
    "               catchwords = ''):\n",
    "\n",
    "    #If only searching FCA\n",
    "    #base_url = \"https://search2.fedcourt.gov.au/s/search.html?collection=judgments&sort=date&meta_v_phrase_orsand=judgments%2FJudgments%2Ffca\"\n",
    "\n",
    "    #If allowing users to search which court\n",
    "    base_url = \"https://search2.fedcourt.gov.au/s/search.html?collection=judgments&sort=date&meta_v_phrase_orsand=judgments%2FJudgments%2F\" + fca_courts[court]\n",
    "    \n",
    "    params = {'meta_2' : case_name_mnc, \n",
    "              'meta_A' : judge, \n",
    "              'meta_z' : reported_citation, \n",
    "              'meta_3' : file_number, \n",
    "              'meta_n_phrase_orsand' : npa, \n",
    "              'query_sand' : with_all_the_words, \n",
    "              'query_or' : with_at_least_one_of_the_words, \n",
    "              'query_not' : without_the_words, \n",
    "              'query_phrase' : phrase, \n",
    "              'query_prox' : proximity, \n",
    "              'meta_d' : on_this_date, \n",
    "              'meta_d1' : after_date, \n",
    "              'meta_d2' : before_date, \n",
    "              'meta_7' : legislation, \n",
    "              'meta_4' : cases_cited, \n",
    "              'meta_B' : catchwords}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    # Process the response (e.g., extract relevant information)\n",
    "    # Your code here...\n",
    "    return response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6321d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:01:41.159 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function turning search results url to links to judgments\n",
    "\n",
    "@st.cache_data\n",
    "def fca_search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "\n",
    "    counter = 1\n",
    "    \n",
    "    # Get links of first 20 results\n",
    "    #links_raw = soup.find_all(\"a\", href=re.compile(\"fca\")) #If want to search FCA only\n",
    "    \n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "    links = []\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            remove_title = str(i).split('\" title=')[0]\n",
    "            remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "            if 'a class=' not in remove_leading_words:\n",
    "                links.append(remove_leading_words)\n",
    "                counter = counter + 1\n",
    "\n",
    "    #Go beyond first 20 results\n",
    "\n",
    "    #Auxiliary list for getting more pages of search results\n",
    "    further_page_ending_list = []\n",
    "    for i in range(100):\n",
    "        further_page_ending = 20 + i\n",
    "        if ((str(further_page_ending)[-1] =='1') & (str(further_page_ending)[0] not in ['3', '5', '7', '9', '11'])):\n",
    "            further_page_ending_list.append(str(further_page_ending))\n",
    "    \n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            #links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\"))  #If want to search FCA only\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "\n",
    "            #Check if stll more results\n",
    "            if len(links_next_page_raw) > 0:\n",
    "                for i in links_next_page_raw:\n",
    "                    if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "                        remove_title = str(i).split('\" title=')[0]\n",
    "                        remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "                        if 'a class=' not in remove_leading_words:\n",
    "                            links.append(remove_leading_words)\n",
    "                            counter = counter + 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15def0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#judgment url to word document\n",
    "#NOT in use\n",
    "def fca_link_to_doc(url_judgment):\n",
    "    page_judgment = requests.get(url_judgment)\n",
    "    soup_judgment = BeautifulSoup(page_judgment.content, \"lxml\")\n",
    "    link_word_raw = soup_judgment.find_all('a', string=re.compile('Word'))\n",
    "    if len(link_word_raw)> 0:\n",
    "        link_to_word = str(link_word_raw).split('>')[0].replace('[<a href=\"', '')\n",
    "        return link_to_word\n",
    "    else:\n",
    "        return url_judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962fad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:01:50.649 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "fca_metalabels = ['MNC', 'Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published', 'Appeal_to']\n",
    "fca_metalabels_droppable = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published', 'Appeal_to', 'Order']\n",
    "\n",
    "@st.cache_data\n",
    "def fca_meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to Federal Court Digital Law Library' : '', \n",
    "                'MNC' : '',  \n",
    "                 'Year' : '',  \n",
    "                 'Appeal' : '',  \n",
    "                 'File_Number' : '',  \n",
    "                 'Judge' : '',  \n",
    "                 'Judgment_Dated' : '',  \n",
    "                 'Catchwords' : '',  \n",
    "                 'Subject' : '',  \n",
    "                 'Words_Phrases' : '',  \n",
    "                 'Legislation' : '',  \n",
    "                 'Cases_Cited' : '',  \n",
    "                 'Division' : '',  \n",
    "                 'NPA' : '',  \n",
    "                'Sub_NPA' : '', \n",
    "                 'Pages' : '',  \n",
    "                 'All_Parties' : '',  \n",
    "                 'Jurisdiction' : '',  \n",
    "                 'Reported' : '',  \n",
    "                 'Summary' : '',  \n",
    "                 'Corrigenda' : '',  \n",
    "                 'Parties' : '',  'FileName' : '',  \n",
    "                 'Asset_ID' : '',  \n",
    "                 'Date.published' : '', \n",
    "                'Appeal_to' : '', \n",
    "                'Order': '',\n",
    "                'judgment' : ''\n",
    "                }\n",
    "\n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink to Federal Court Digital Law Library'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    meta_tags = soup.find_all(\"meta\")\n",
    "\n",
    "    #Attach meta tags\n",
    "    if len(meta_tags)>0:\n",
    "        for tag_index in range(len(meta_tags)):\n",
    "            meta_name = meta_tags[tag_index].get(\"name\")\n",
    "            if meta_name in fca_metalabels:\n",
    "                meta_content = meta_tags[tag_index].get(\"content\")\n",
    "                judgment_dict[meta_name] = meta_content\n",
    "\n",
    "    #Check if not gets taken to a PDF\n",
    "\n",
    "    if '.pdf' not in judgment_url.lower():\n",
    "    \n",
    "        try:\n",
    "            judgment_dict['Case name'] = judgment_dict['MNC'].split('[')[0]\n",
    "            judgment_dict['Medium neutral citation'] = '[' + judgment_dict['MNC'].split('[')[1]\n",
    "            del judgment_dict['MNC']\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Attach order_text and judgment\n",
    "    \n",
    "        judgment_text = ''\n",
    "        order_text = ''\n",
    "    \n",
    "        try:\n",
    "            judgment_raw = ''\n",
    "            judgment_raw = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "            above_reasons_for_judgment = str(re.split(\"REASONS FOR JUDGMENT\", judgment_raw, flags=re.IGNORECASE)[0])\n",
    "    \n",
    "            below_reasons_for_judgment = str(re.split(\"REASONS FOR JUDGMENT\", judgment_raw, flags=re.IGNORECASE)[1:])\n",
    "    \n",
    "            order_text = \"BETWEEEN:\" + str(re.split(\"BETWEEN:\", above_reasons_for_judgment, flags=re.IGNORECASE)[1:])[2:][:-2]\n",
    "    \n",
    "            judgment_text = below_reasons_for_judgment\n",
    "    \n",
    "        except:\n",
    "            try:\n",
    "                judgment_text = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "            except:\n",
    "                judgment_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "        \n",
    "        judgment_dict['judgment'] = judgment_text\n",
    "        judgment_dict['Order'] = order_text\n",
    "\n",
    "    #Check if gets taken to a PDF\n",
    "\n",
    "    else:\n",
    "        #Attach case name\n",
    "        judgment_dict['Case name'] = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.'\n",
    "\n",
    "        #Attach judgment pdf text\n",
    "        try:\n",
    "            judgment_pdf_raw = pdf_judgment(judgment_url)\n",
    "            judgment_dict['judgment'] = judgment_pdf_raw\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        #Attach medium neutral citation\n",
    "        try:\n",
    "            mnc_raw = judgment_url.split('/')[-1].replace('.pdf', '')\n",
    "\n",
    "            #for court_i in ['fca', 'fcafc']: #If want to search FCA only\n",
    "            for court_i in ['fca', 'fcafc', 'irc', 'acompt', 'acopyt', 'adfdat', 'fpdt', 'atpt', 'nfsc']:\n",
    "                if court_i in mnc_raw.lower():\n",
    "                    mnc_list = mnc_raw.lower().split(court_i)\n",
    "                    judgment_dict['Medium neutral citation'] = '[' + mnc_list[0] + '] ' + court_i.upper()  + ' ' +  mnc_list[1]\n",
    "                    judgment_dict['Medium neutral citation']=judgment_dict['Medium neutral citation']\n",
    "\n",
    "                    while ' 0' in judgment_dict['Medium neutral citation']:\n",
    "                        judgment_dict['Medium neutral citation'] = judgment_dict['Medium neutral citation'].replace(' 0', ' ')\n",
    "            \n",
    "            del judgment_dict['MNC']\n",
    "    \n",
    "        except:\n",
    "            pass        \n",
    "            \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30f606a-d641-4752-8fde-07f5b04d5596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:01:51.233 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Preliminary function for changing names for any PDF judgments\n",
    "\n",
    "@st.cache_data\n",
    "def fca_pdf_name_mnc_list(url_search_results, judgment_counter_bound):\n",
    "                      \n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "    #Placeholder\n",
    "    name_mnc_list = []\n",
    "\n",
    "    #Start counter\n",
    "    counter = 1\n",
    "    # Get links of first 20 results\n",
    "    #links_raw = soup.find_all(\"a\", href=re.compile(\"fca\")) #If want to search FCA only\n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            name_mnc_list.append(i['title'])\n",
    "            counter = counter + 1\n",
    "    \n",
    "    #Go beyond first 20 results\n",
    "\n",
    "    #Auxiliary list for getting more pages of search results\n",
    "    further_page_ending_list = []\n",
    "    for i in range(100):\n",
    "        further_page_ending = 20 + i\n",
    "        if ((str(further_page_ending)[-1] =='1') & (str(further_page_ending)[0] not in ['3', '5', '7', '9', '11'])):\n",
    "            further_page_ending_list.append(str(further_page_ending))\n",
    "\n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            #links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\")) #If want to search FCA only\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "    \n",
    "            #Check if stll more results\n",
    "            if len(links_next_page_raw) > 0:\n",
    "                for i in links_next_page_raw:\n",
    "                    if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "                        name_mnc_list.append(i['title'])\n",
    "                        counter = counter + 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    return name_mnc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8810eb17-ef74-4083-9801-f8c36395344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for changing names for any PDF judgments\n",
    "\n",
    "def fca_pdf_name(name_mnc_list, mnc):\n",
    "    #Placeholder\n",
    "    name = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.' \n",
    "    \n",
    "    for i in name_mnc_list:\n",
    "        if mnc in i:\n",
    "            name_raw = i.split(' ' + mnc)[0]\n",
    "            name = name_raw.replace('Cached: ', '')\n",
    "            \n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfae300-2b55-45a0-842c-83f12e8a555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ba06e-2c4c-4ae6-ac7e-06a8d84d4252",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from common_functions import check_questions_answers\n",
    "\n",
    "from gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "system_instruction = role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e8eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data\n",
    "def fca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = fca_search(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    judgments_links = fca_search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for link in judgments_links:\n",
    "\n",
    "        judgment_dict = fca_meta_judgment_dict(link)\n",
    "\n",
    "#        meta_data = meta_dict(link)  \n",
    "#        doc_link = fca_link_to_doc(link)\n",
    "#        judgment_dict = doc_link_to_dict(doc_link)\n",
    "#        judgment_dict = link_to_dict(link)\n",
    "#        judgments_all_info = { **meta_data, **judgment_dict}\n",
    "#        judgments_file.append(judgments_all_info)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Rename column titles\n",
    "    \n",
    "#    try:\n",
    "#        df_individual['Hyperlink (double click)'] = df_individual['Hyperlink'].apply(link)\n",
    "#        df_individual.pop('Hyperlink')\n",
    "#    except:\n",
    "#        pass\n",
    "\n",
    "    #Correct case names for any PDFs\n",
    "\n",
    "    name_mnc_list = fca_pdf_name_mnc_list(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for judgment_index in df_individual.index:\n",
    "        \n",
    "        if (('pdf' in df_individual.loc[judgment_index, 'Case name'].lower()) or ('.pdf' in str(df_individual.loc[judgment_index, 'Hyperlink to Federal Court Digital Law Library']).lower())):\n",
    "            try:\n",
    "                df_individual.loc[judgment_index, 'Case name'] = fca_pdf_name(name_mnc_list, df_individual.loc[judgment_index, 'Medium neutral citation'])\n",
    "            except Exception as e:\n",
    "                print(f\"{df_individual.loc[judgment_index, 'Medium neutral citation']}: cannot change case name for PDF.\")\n",
    "                print(e)\n",
    "                    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "\n",
    "    df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(df_master.loc[0, 'Metadata inclusion']) == 0:\n",
    "        for meta_label in fca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dacc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fca_search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url = fca_search(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5dcd6",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01e54f7a-0689-49e5-a6c9-39ea7ce6b7b9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions and variables\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m open_page, clear_cache_except_validation_df_master, tips\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765f659-bf18-4e59-a76c-af2c58f910a9",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "523f9d21-666d-4b2e-8749-e89692939761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:18:32.059 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    }
   ],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = True\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "    #Jurisdiction specific\n",
    "    st.session_state['df_master'].loc[0, 'Courts'] = 'Federal Court'\n",
    "    st.session_state['df_master'].loc[0, 'Case name or medium neutral citation'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Judge'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Reported citation'] = None\n",
    "    st.session_state['df_master'].loc[0, 'File number'] = None\n",
    "    st.session_state['df_master'].loc[0, 'National practice area'] = None\n",
    "    st.session_state['df_master'].loc[0, 'With all the words'] = None\n",
    "    st.session_state['df_master'].loc[0, 'With at least one of the words'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Without the words'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Phrase'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Proximity'] = None\n",
    "    st.session_state['df_master'].loc[0, 'On this date'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Decision date is after'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Decision date is before'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Legislation'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Cases cited'] = None\n",
    "    st.session_state['df_master'].loc[0, 'Catchwords']  = None\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = st.session_state['df_master'].replace({np.nan: None})\n",
    "    \n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca31b5-633d-4a11-8514-25325fbdec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If landing page is not home\n",
    "if 'page_from' not in st.session_state:\n",
    "    st.session_state['page_from'] = 'Home.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d818b-8edf-4510-adb8-a81a60a55bb6",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c683d9af",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 10:18:33.432 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'fca_courts_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m st\u001b[38;5;241m.\u001b[39mcaption(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDuring the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more judgments, courts, or tribunals.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFederal courts and tribunals to cover\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m courts_entry \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mselectbox(label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelect or type in the courts or tribunals to cover\u001b[39m\u001b[38;5;124m'\u001b[39m, options \u001b[38;5;241m=\u001b[39m fca_courts_list, index \u001b[38;5;241m=\u001b[39m fca_courts_list\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFederal Court\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     18\u001b[0m st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour search terms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFor search tips, please visit the Federal Court Digital Law Library at https://www.fedcourt.gov.au/digital-law-library/judgments/search. This section mimics their judgments search function.\u001b[39m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fca_courts_list' is not defined"
     ]
    }
   ],
   "source": [
    "if st.session_state.page_from != \"pages/FCA.py\": #Need to add in order to avoid GPT page from showing form of previous page\n",
    "\n",
    "    #Create form\n",
    "    \n",
    "    return_button = st.button('RETURN to first page')\n",
    "    \n",
    "    st.header(f\"You have selected to study :blue[judgments of the Federal Court of Australia].\")\n",
    "    \n",
    "    #    st.header(\"Judgment Search Criteria\")\n",
    "    \n",
    "    st.markdown(\"\"\"**:green[Please enter your search terms.]** This app will collect (ie scrape) the first 10 judgments returned by your search terms.\n",
    "\"\"\")\n",
    "    \n",
    "    st.caption('During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more judgments, courts, or tribunals.')\n",
    "\n",
    "    reset_button = st.button(label='RESET', type = 'primary')\n",
    "    \n",
    "    st.subheader(\"Court or tribunal to cover\")\n",
    "    \n",
    "    courts_entry = st.selectbox(label = 'Select or type in the court or tribunal to cover', options = fca_courts_list, index = fca_courts_list.index(st.session_state.df_master.loc[0, 'Courts']))\n",
    "    \n",
    "    st.write('You may select the Federal Court, tribunals administered by the Court, the Supreme Court of Norfolk Island and the Industrial Relations Court of Australia.')\n",
    "    \n",
    "    st.subheader(\"Your search terms\")\n",
    "    \n",
    "    st.markdown(\"\"\"For search tips, please visit the [Federal Court Digital Law Library](https://www.fedcourt.gov.au/digital-law-library/judgments/search). This section mimics their judgments search function.\n",
    "\"\"\")\n",
    "    \n",
    "    catchwords_entry = st.text_input(label = 'Catchwords', value = st.session_state.df_master.loc[0, 'Catchwords'] )\n",
    "    \n",
    "    legislation_entry = st.text_input(label = 'Legislation', value = st.session_state.df_master.loc[0, 'Legislation'])\n",
    "    \n",
    "    cases_cited_entry = st.text_input(label = 'Cases cited', value = st.session_state.df_master.loc[0, 'Cases cited'])\n",
    "    \n",
    "    case_name_mnc_entry = st.text_input(label = \"Case name or medium neutral citation\", value = st.session_state.df_master.loc[0, 'Case name or medium neutral citation'])\n",
    "    \n",
    "    judge_entry = st.text_input(label = 'Judge', value = st.session_state.df_master.loc[0, 'Judge'])\n",
    "    \n",
    "    reported_citation_entry = st.text_input(label = 'Reported citation', value = st.session_state.df_master.loc[0, 'Reported citation'])\n",
    "    \n",
    "    file_number_entry = st.text_input(label = 'File number', value = st.session_state.df_master.loc[0, 'File number'])\n",
    "    \n",
    "    npa_entry = st.text_input(label = 'National practice area', value = st.session_state.df_master.loc[0, 'National practice area'] )\n",
    "    \n",
    "    with_all_the_words_entry = st.text_input(label = 'With ALL the words', value = st.session_state.df_master.loc[0, 'With all the words'] )\n",
    "    \n",
    "    with_at_least_one_of_the_words_entry = st.text_input(label = 'With at least one of the words', value = st.session_state.df_master.loc[0, 'With at least one of the words'])\n",
    "    \n",
    "    without_the_words_entry = st.text_input(label = 'Without the words', value = st.session_state.df_master.loc[0, 'Without the words'])\n",
    "    \n",
    "    phrase_entry = st.text_input(label = 'Phrase', value = st.session_state.df_master.loc[0, 'Phrase'])\n",
    "    \n",
    "    proximity_entry  = st.text_input(label = 'Proximity', value = st.session_state.df_master.loc[0, 'Proximity'])\n",
    "    \n",
    "    on_this_date_entry = st.date_input(label = 'On this date', value = au_date(st.session_state.df_master.loc[0, 'On this date']), format=\"DD/MM/YYYY\", min_value = date(1976, 1, 1), max_value = datetime.now(), help = \"If you cannot change this date entry, please press :red[RESET] and try again.\")\n",
    "    \n",
    "    after_date_entry = st.date_input(label = 'Decision date is after', value = au_date(st.session_state.df_master.loc[0, 'Decision date is after']), format=\"DD/MM/YYYY\", min_value = date(1976, 1, 1), max_value = datetime.now(), help = \"If you cannot change this date entry, please press :red[RESET] and try again.\")\n",
    "    \n",
    "    before_date_entry = st.date_input(label = 'Decision date is before', value = au_date(st.session_state.df_master.loc[0, 'Decision date is before'] ), format=\"DD/MM/YYYY\", min_value = date(1976, 1, 1), max_value = datetime.now(), help = \"If you cannot change this date entry, please press :red[RESET] and try again.\")\n",
    "    \n",
    "    st.caption('[Relatively earlier](https://www.fedcourt.gov.au/digital-law-library/judgments/judgments-faq) judgments will not be collected.')\n",
    "    \n",
    "    st.markdown(\"\"\"You can preview the judgments returned by your search terms after you have entered some search terms.\n",
    "    \n",
    "You may have to unblock a popped up window, refresh this page, and re-enter your search terms.\n",
    "\"\"\")\n",
    "    \n",
    "    preview_button = st.button(label = 'PREVIEW on the Federal Court Digital Law Library (in a popped up window)', type = 'primary')\n",
    "    \n",
    "    st.subheader(\"Judgment metadata collection\")\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to obtain judgment metadata? Such data include the name of the judge, the decision date and so on. \n",
    "    \n",
    "Case name and medium neutral citation are always included with your results.\n",
    "\"\"\")\n",
    "    \n",
    "    meta_data_entry = st.checkbox(label = 'Include metadata', value = st.session_state['df_master'].loc[0, 'Metadata inclusion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a2534f-d413-4bdd-b12a-be3d43ebafcd",
   "metadata": {},
   "source": [
    "## Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5428b07e-fe2e-4854-88a1-d216fd143912",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Buttons\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m col1, col2, col3, col4 \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns(\u001b[38;5;241m4\u001b[39m, gap \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m col1:\n\u001b[1;32m      6\u001b[0m     keep_button \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mbutton(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAVE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "    #Buttons\n",
    "    \n",
    "    #col1, col2, col3, col4 = st.columns(4, gap = 'small')\n",
    "    \n",
    "    #with col1:\n",
    "    \n",
    "        #reset_button = st.button(label='RESET', type = 'primary')\n",
    "    \n",
    "    #with col4:\n",
    "    with stylable_container(\n",
    "        \"green\",\n",
    "        css_styles=\"\"\"\n",
    "        button {\n",
    "            background-color: #00FF00;\n",
    "            color: black;\n",
    "        }\"\"\",\n",
    "    ):\n",
    "        next_button = st.button(label='NEXT')\n",
    "    \n",
    "    keep_button = st.button('SAVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f71a3",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32db41fe-e24c-4a7e-bc48-197bd51d644d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preview_button' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preview_button:\n\u001b[1;32m      3\u001b[0m     df_master \u001b[38;5;241m=\u001b[39m create_df()\n\u001b[1;32m      5\u001b[0m     judgments_url \u001b[38;5;241m=\u001b[39m search_url(df_master)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preview_button' is not defined"
     ]
    }
   ],
   "source": [
    "    if preview_button:\n",
    "        \n",
    "        df_master = fca_create_df()\n",
    "        \n",
    "        judgments_url = fca_search_url(df_master)\n",
    "        \n",
    "        open_page(judgments_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4873fffb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keep_button' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_button:\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#Check whether search terms entered\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     all_search_terms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(catchwords_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(legislation_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(cases_cited_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(case_name_mnc_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(judge_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(reported_citation_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(file_number_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(npa_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(with_all_the_words_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(with_at_least_one_of_the_words_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(without_the_words_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(phrase_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(proximity_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(on_this_date_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(after_date_entry) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(before_date_entry)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m all_search_terms\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'keep_button' is not defined"
     ]
    }
   ],
   "source": [
    "    if keep_button:\n",
    "    \n",
    "        #Check whether search terms entered\n",
    "    \n",
    "        all_search_terms = str(catchwords_entry) + str(legislation_entry) + str(cases_cited_entry) + str(case_name_mnc_entry) + str(judge_entry) + str(reported_citation_entry) + str(file_number_entry) + str(npa_entry) + str(with_all_the_words_entry) + str(with_at_least_one_of_the_words_entry) + str(without_the_words_entry) + str(phrase_entry) + str(proximity_entry) + str(on_this_date_entry) + str(after_date_entry) + str(before_date_entry)\n",
    "        \n",
    "        if all_search_terms.replace('None', '') == \"\":\n",
    "    \n",
    "            st.warning('You must enter some search terms.')\n",
    "                    \n",
    "        else:\n",
    "                \n",
    "            df_master = fca_create_df()\n",
    "\n",
    "            save_input(df_master)\n",
    "            \n",
    "            responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "        \n",
    "            #Produce a file to download\n",
    "        \n",
    "            csv = convert_df_to_csv(df_master)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download as a CSV (for use in Excel etc)\", \n",
    "                data = csv,\n",
    "                file_name=responses_output_name + '.csv', \n",
    "                mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "            )\n",
    "    \n",
    "    \n",
    "            xlsx = convert_df_to_excel(df_master)\n",
    "            \n",
    "            ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                                data=xlsx,\n",
    "                                file_name=responses_output_name + '.xlsx', \n",
    "                                mime='application/vnd.ms-excel',\n",
    "                               )\n",
    "            \n",
    "            json = convert_df_to_json(df_master)\n",
    "            \n",
    "            ste.download_button(\n",
    "                label=\"Download as a JSON\", \n",
    "                data = json,\n",
    "                file_name= responses_output_name + '.json', \n",
    "                mime= \"application/json\", \n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    if return_button:\n",
    "        \n",
    "        df_master = fca_create_df()\n",
    "\n",
    "        save_input(df_master)\n",
    "\n",
    "        st.session_state[\"page_from\"] = 'pages/FCA.py'\n",
    "        \n",
    "        st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23395fa0-c2e6-4a9a-afab-fcbb62254306",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #if remove_button:\n",
    "        \n",
    "        #st.session_state.pop('df_master')\n",
    "\n",
    "        #st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reset_button' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset_button:\n\u001b[1;32m      2\u001b[0m     clear_cache_except_validation_df_master()\n\u001b[1;32m      3\u001b[0m     st\u001b[38;5;241m.\u001b[39mrerun()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reset_button' is not defined"
     ]
    }
   ],
   "source": [
    "    if reset_button:\n",
    "        st.session_state.pop('df_master')\n",
    "\n",
    "        #clear_cache()\n",
    "        st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9470438d-e485-44e4-8e10-798973642140",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "    if next_button:\n",
    "    \n",
    "        all_search_terms = str(catchwords_entry) + str(legislation_entry) + str(cases_cited_entry) + str(case_name_mnc_entry) + str(judge_entry) + str(reported_citation_entry) + str(file_number_entry) + str(npa_entry) + str(with_all_the_words_entry) + str(with_at_least_one_of_the_words_entry) + str(without_the_words_entry) + str(phrase_entry) + str(proximity_entry) + str(on_this_date_entry) + str(after_date_entry) + str(before_date_entry)\n",
    "        \n",
    "        if all_search_terms.replace('None', '') == \"\":\n",
    "    \n",
    "            st.warning('You must enter some search terms.')\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            df_master = fca_create_df()\n",
    "\n",
    "            save_input(df_master)\n",
    "\n",
    "            #Check search results\n",
    "            fca_url_to_check = fca_search_url(df_master)\n",
    "            fca_html = requests.get(fca_url_to_check)\n",
    "            fca_soup = BeautifulSoup(fca_html.content, \"lxml\")\n",
    "            if 'Display' not in str(fca_soup):\n",
    "                st.error(no_results_msg)\n",
    "\n",
    "            else:\n",
    "                        \n",
    "                st.session_state[\"page_from\"] = 'pages/FCA.py'\n",
    "                \n",
    "                st.switch_page('pages/GPT.py')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
