{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e705d6a3-cf7b-4c01-ba24-3b0190740381",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d544211f-1f96-43f6-972a-b786de9b87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31f5dfdf-2253-4937-8cf1-b724f34e80dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, au_date, list_value_check, streamlit_cloud_date_format, save_input\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, au_date, list_value_check, streamlit_cloud_date_format, streamlit_timezone, save_input\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63b76ad-0e96-49fc-a1a0-69b28b23e044",
   "metadata": {},
   "source": [
    "# AFCA search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86222e24-3f55-4e03-b2fe-957e99d1ecb2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from functions.afca_functions import browser, collection_options, product_line_options, product_category_options, product_name_options, issue_type_options, issue_options, afca_search, afca_meta_judgment_dict,  afca_meta_labels_droppable, afca_old_pdf_judgment, afca_old_element_meta, afca_old_search, afca_old_meta_labels_droppable, afca_meta_labels_droppable\n",
    "\n",
    "if streamlit_timezone() == True:\n",
    "    from functions.afca_functions import browser_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75061e0-82de-4b87-a562-7e7af9c933a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from functions.common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5821561-8f0f-467a-b4ff-c1c73f09e44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def afca_create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "    \n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "    \n",
    "    #Judgment counter bound\n",
    "    try:\n",
    "        judgments_counter_bound = judgments_counter_bound_entry\n",
    "    except:\n",
    "        print('judgments_counter_bound not entered')\n",
    "        judgments_counter_bound = default_judgment_counter_bound\n",
    "        \n",
    "    #GPT enhancement\n",
    "    try:\n",
    "        gpt_enhancement = gpt_enhancement_entry\n",
    "    except:\n",
    "        print('GPT enhancement not entered')\n",
    "        gpt_enhancement = False\n",
    "\n",
    "    #Input\n",
    "    #Template\n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': '',\n",
    "           'Your name': '', \n",
    "           'Your email address': '', \n",
    "           'Your GPT API key': '', \n",
    "            'Collection': '', \n",
    "              #Post 14 June 2024 search terms \n",
    "            'Search for published decisions': '', \n",
    "            'Search for a financial firm': '', \n",
    "           'Product line': '', \n",
    "            'Product category': '', \n",
    "            'Product name': '', \n",
    "            'Issue type': '', \n",
    "            'Issue': '', \n",
    "          #Pre 14 June 2024 search terms\n",
    "            'Include decisions made under earlier Terms of Reference': False, \n",
    "            'All these words': '', \n",
    "           'This exact wording or phrase': '', \n",
    "            'One or more of these words - 1': '', \n",
    "            'One or more of these words - 2': '', \n",
    "            'One or more of these words - 3': '', \n",
    "            'Any of these unwanted words': '', \n",
    "            'Case number': '', \n",
    "            #'Days back from now': '',\n",
    "            #'Months back from now': '',\n",
    "            #'Years back from now': '',\n",
    "            #'Date of decision from': '', \n",
    "            #'Date of decision to': '', \n",
    "            #General\n",
    "            'Date from': '', #'DD/MM/YYYY',\n",
    "            'Date to': '', #'DD/MM/YYYY', \n",
    "            'Metadata inclusion' : False,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your questions for GPT': '', \n",
    "            'Use GPT': False,\n",
    "           'Use own account': False,\n",
    "            'Use flagship version of GPT' : False\n",
    "          }\n",
    "\n",
    "    #Collection\n",
    "\n",
    "    try:\n",
    "        new_row['Collection'] = collection_entry\n",
    "\n",
    "    except:\n",
    "        print('Collection not selected.')\n",
    "        \n",
    "    #Post June 2024 input\n",
    "    try:\n",
    "        new_row['Search for published decisions'] = keywordsearch_entry\n",
    "    except:\n",
    "        print('Search for published decisions not entered.')\n",
    "    \n",
    "    try:\n",
    "        new_row['Search for a financial firm'] = ffsearch_entry\n",
    "    except:\n",
    "        print('Search for a financial firm not entered.')\n",
    "    \n",
    "    try:\n",
    "        new_row['Product line'] = product_line_entry\n",
    "    except:\n",
    "        print('Product line not entered.')\n",
    "    \n",
    "    try:\n",
    "        new_row['Product category'] = product_category_entry\n",
    "    except:\n",
    "        print('Product category not entered.')\n",
    "    \n",
    "    try:\n",
    "        new_row['Product name'] = product_name_entry\n",
    "    except:\n",
    "        print('Product name not entered.')\n",
    "    \n",
    "    try:\n",
    "        new_row['Issue type'] = issue_type_entry\n",
    "    except:\n",
    "        print('Issue type not entered.')\n",
    "    \n",
    "    try:\n",
    "        new_row['Issue'] = issue_entry\n",
    "    except:\n",
    "        print('Issue not entered.')\n",
    "\n",
    "\n",
    "    #Pre June 2024 input\n",
    "\n",
    "    try:\n",
    "        new_row['Include decisions made under earlier Terms of Reference'] = early_t_o_r_entry\n",
    "    except:\n",
    "        new_row['Include decisions made under earlier Terms of Reference'] = False\n",
    "        print('Whether to Include decisions made under earlier Terms of Reference not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['All these words'] = all_these_words_entry\n",
    "    except:\n",
    "        print('All these words not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['This exact wording or phrase'] = this_exact_wording_phrase_entry\n",
    "    except:\n",
    "        print('This exact wording or phrase not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['Any of these unwanted words'] = any_of_these_unwanted_words_entry\n",
    "    except:\n",
    "        print('Any of these unwanted words not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['One or more of these words - 1'] = one_or_more_of_these_words_1_entry\n",
    "    except:\n",
    "        print('One or more of these words - 1 not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['One or more of these words - 2'] = one_or_more_of_these_words_2_entry\n",
    "    except:\n",
    "        print('One or more of these words - 2 not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['One or more of these words - 3'] = one_or_more_of_these_words_3_entry\n",
    "    except:\n",
    "        print('One or more of these words - 3 not entered.')\n",
    "\n",
    "    try:\n",
    "        new_row['Case number'] = case_number_entry\n",
    "    except:\n",
    "        print('Case number not entered.')\n",
    "    \n",
    "    #dates\n",
    "            \n",
    "    try:\n",
    "        new_row['Date from'] = date_from_entry.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    except:\n",
    "        print('Date from not entered.')\n",
    "\n",
    "    try:\n",
    "\n",
    "        new_row['Date to'] = date_to_entry.strftime(\"%d/%m/%Y\")\n",
    "        \n",
    "    except:\n",
    "        print('Date to not entered.')\n",
    "\n",
    "    #GPT choice and entry\n",
    "    try:\n",
    "        gpt_activation_status = gpt_activation_entry\n",
    "        new_row['Use GPT'] = gpt_activation_status\n",
    "    except:\n",
    "        print('GPT activation status not entered.')\n",
    "\n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: question_characters_bound]\n",
    "        new_row['Enter your questions for GPT'] = gpt_questions\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "\n",
    "    #metadata choice\n",
    "    try:\n",
    "        meta_data_choice = meta_data_entry\n",
    "        new_row['Metadata inclusion'] = meta_data_choice\n",
    "    \n",
    "    except:\n",
    "        print('Metadata choice not entered.')\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "            \n",
    "    return df_master_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b5dbbf-0b76-4e3b-ab2d-6397cf3a9bd9",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6f8987-e2d6-43c2-ab23-a4aaf178f477",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, default_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e42c5-44b1-42b1-bce6-58dcd3cdaa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a09203-7d29-440d-9540-3f1b48be4e04",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921ea014-acd8-47d0-8fde-5d04317609c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d67e910-dc2d-4671-bf6a-094e8cf9aef5",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc955201-1a5f-45f0-8706-fc014b1e7967",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from functions.common_functions import open_page, clear_cache_except_validation_df_master, tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7dc1743-5d92-4c6c-9392-bbb0ae526fcc",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f09193-8efd-456f-970a-ad6768354276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = True\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "    #Jurisdiction specific\n",
    "\n",
    "    st.session_state.df_master.loc[0, 'Collection'] = 'Decisions published from 14 June 2024'\n",
    "    \n",
    "    st.session_state.df_master.loc[0, 'Date from'] = None \n",
    "    st.session_state.df_master.loc[0, 'Date to'] = None\n",
    "\n",
    "    #Post June 2024\n",
    "    st.session_state.df_master.loc[0, 'Search for published decisions'] = None \n",
    "    st.session_state.df_master.loc[0, 'Search for a financial firm'] = None \n",
    "    st.session_state.df_master.loc[0, 'Product line'] = None \n",
    "    st.session_state.df_master.loc[0, 'Product category'] = None \n",
    "    st.session_state.df_master.loc[0, 'Product name'] = None \n",
    "    st.session_state.df_master.loc[0, 'Issue type'] = None \n",
    "    st.session_state.df_master.loc[0, 'Issue'] = None \n",
    "\n",
    "    #Pre June 2024\n",
    "    st.session_state.df_master.loc[0, 'Include decisions made under earlier Terms of Reference'] = False\n",
    "    st.session_state.df_master.loc[0, 'All these words'] = None\n",
    "    st.session_state.df_master.loc[0, 'This exact wording or phrase'] = None\n",
    "    st.session_state.df_master.loc[0, 'One or more of these words - 1'] = None\n",
    "    st.session_state.df_master.loc[0, 'One or more of these words - 2'] = None\n",
    "    st.session_state.df_master.loc[0, 'One or more of these words - 3'] = None\n",
    "    st.session_state.df_master.loc[0, 'Any of these unwanted words'] = None\n",
    "    st.session_state.df_master.loc[0, 'Case number'] = None\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = st.session_state['df_master'].replace({np.nan: None})\n",
    "\n",
    "if 'df_individual_output' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual_output'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00917ecb-c589-4e59-aaaf-a188e51fdc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If landing page is not home\n",
    "if 'page_from' not in st.session_state:\n",
    "    st.session_state['page_from'] = 'Home.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d5cfd5-e446-4908-8b76-507745c9e953",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d15ac6-19ec-4e79-a145-9fa2ba2e2fbe",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#if st.session_state.page_from != \"pages/AFCA.py\": #Need to add in order to avoid GPT page from showing form of previous page\n",
    "\n",
    "return_button = st.button('RETURN to first page')\n",
    "\n",
    "st.header(f\"Search :blue[decisions of the Australian Financial Complaints Authority]\")\n",
    "\n",
    "st.success(f\"**Please enter your search terms.** {default_msg}\")\n",
    "\n",
    "st.caption('During the pilot stage, the number of cases to scrape is capped. Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more cases, courts, or tribunals.')\n",
    "\n",
    "if streamlit_timezone() == True:\n",
    "    st.warning('One or more Chrome window may have been launched. It must be kept open.')\n",
    "\n",
    "reset_button = st.button(label='RESET', type = 'primary')\n",
    "\n",
    "st.subheader('Case collection')\n",
    "\n",
    "collection_entry = st.selectbox(label = 'Select one to search', options = collection_options, index = collection_options.index(st.session_state.df_master.loc[0, 'Collection']))\n",
    "\n",
    "st.subheader(\"Your search terms\")\n",
    "\n",
    "if collection_entry:\n",
    "    \n",
    "    st.session_state.df_master.loc[0, 'Collection'] = collection_entry\n",
    "    \n",
    "if st.session_state.df_master.loc[0, 'Collection'] == 'Decisions published from 14 June 2024':\n",
    "\n",
    "    st.markdown(\"\"\"For search tips, please visit the [AFCA Portal](https://my.afca.org.au/searchpublisheddecisions/). This section mimics their search function.\n",
    "\"\"\")\n",
    "    \n",
    "    keywordsearch_entry = st.text_input(label = 'Search for published decisions', value = st.session_state.df_master.loc[0, 'Search for published decisions'])\n",
    "    \n",
    "    ffsearch_entry = st.text_input(label = 'Search for a financial firm', value = st.session_state.df_master.loc[0, 'Search for a financial firm'])\n",
    "    \n",
    "    product_line_entry = st.selectbox(label = 'Product line', options = list(product_line_options.keys()), index = list_value_check(list(product_line_options.keys()), st.session_state.df_master.loc[0, 'Product line']))\n",
    "    \n",
    "    product_category_entry = st.selectbox(label = 'Product category', options = list(product_category_options.keys()), index = list_value_check(list(product_category_options.keys()), st.session_state.df_master.loc[0, 'Product category']))\n",
    "    \n",
    "    product_name_entry = st.selectbox(label = 'Product name', options = list(product_name_options.keys()), index = list_value_check(list(product_name_options.keys()), st.session_state.df_master.loc[0, 'Product name']))\n",
    "    \n",
    "    issue_type_entry = st.selectbox(label = 'Issue type', options = list(issue_type_options.keys()), index = list_value_check(list(issue_type_options.keys()), st.session_state.df_master.loc[0, 'Issue type']))\n",
    "    \n",
    "    issue_entry = st.selectbox(label = 'Issue', options = list(issue_options.keys()), index = list_value_check(list(issue_options.keys()), st.session_state.df_master.loc[0, 'Issue']))\n",
    "\n",
    "else:\n",
    "    \n",
    "    st.markdown(\"\"\"For search tips, please visit [AFCA's website](https://www.afca.org.au/what-to-expect/search-published-decisions). This section largely mimics their advanced keyword search function.\n",
    "\"\"\")\n",
    "    early_t_o_r_entry = st.checkbox(label = 'Include decisions made under earlier Terms of Reference', value = st.session_state['df_master'].loc[0, 'Include decisions made under earlier Terms of Reference'])\n",
    "\n",
    "    st.write('Find decisions that have...')\n",
    "    \n",
    "    all_these_words_entry = st.text_input(label = 'all these words', value = st.session_state.df_master.loc[0, 'All these words'])\n",
    "\n",
    "    this_exact_wording_phrase_entry = st.text_input(label = 'this exact wording or phrase', value = st.session_state.df_master.loc[0, 'This exact wording or phrase'])\n",
    "    \n",
    "    one_or_more_of_these_words_1_entry = st.text_input(label = 'one or more of these words', value = st.session_state.df_master.loc[0, 'One or more of these words - 1'])\n",
    "\n",
    "    one_or_more_of_these_words_2_entry = st.text_input(label = 'Word - 2', value = st.session_state.df_master.loc[0, 'One or more of these words - 2'], label_visibility=\"collapsed\")\n",
    "\n",
    "    one_or_more_of_these_words_3_entry = st.text_input(label = 'Word - 3', value = st.session_state.df_master.loc[0, 'One or more of these words - 3'], label_visibility=\"collapsed\")\n",
    "    \n",
    "    any_of_these_unwanted_words_entry = st.text_input(label = \"But don't show decisions that have any of these unwanted words\", value = st.session_state.df_master.loc[0, 'Any of these unwanted words'])\n",
    "\n",
    "    case_number_entry = st.text_input(label = 'Case number', value = st.session_state.df_master.loc[0, 'Case number'])\n",
    "\n",
    "#Dates are applicable to both collections\n",
    "    \n",
    "date_from_entry = st.date_input('Date from', value = au_date(st.session_state.df_master.loc[0, 'Date from']), format=\"DD/MM/YYYY\", help = \"If you cannot change this date entry, please press :red[RESET] and try again.\")\n",
    "\n",
    "date_to_entry = st.date_input('Date to', value = au_date(st.session_state.df_master.loc[0, 'Date to']), format=\"DD/MM/YYYY\", help = \"If you cannot change this date entry, please press :red[RESET] and try again.\")\n",
    " \n",
    "st.info(\"\"\"You can preview the cases returned by your search terms.\"\"\")\n",
    "\n",
    "with stylable_container(\n",
    "    \"purple\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: purple;\n",
    "        color: white;\n",
    "    }\"\"\",\n",
    "):\n",
    "\n",
    "    preview_button = st.button(label = 'PREVIEW')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845028dd-18ea-4f0b-9d44-6aaccbdf02c6",
   "metadata": {},
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab654f62-c6ca-4dbb-9f13-a5d700da2034",
   "metadata": {},
   "outputs": [],
   "source": [
    "if preview_button:\n",
    "\n",
    "    if st.session_state.df_master.loc[0, 'Collection'] == 'Decisions published before 14 June 2024':\n",
    "        \n",
    "        afca_search_terms = str(all_these_words_entry) + str(this_exact_wording_phrase_entry) + str(one_or_more_of_these_words_1_entry) + str(one_or_more_of_these_words_2_entry) + str(one_or_more_of_these_words_3_entry) + str(case_number_entry)\n",
    "    else:\n",
    "    \n",
    "        afca_search_terms = str(keywordsearch_entry) + str(ffsearch_entry) + str(product_line_entry) + str(product_category_entry) + str(product_name_entry) + str(issue_type_entry) + str(issue_entry) + str(date_from_entry) + str(date_to_entry)\n",
    "        \n",
    "    if afca_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "        #quit()\n",
    "\n",
    "    else:\n",
    "\n",
    "        df_master = afca_create_df()\n",
    "\n",
    "        if st.session_state.df_master.loc[0, 'Collection'] == 'Decisions published before 14 June 2024':\n",
    "            search_results = afca_old_search(earlier_t_o_r_input = df_master.loc[0, 'Include decisions made under earlier Terms of Reference'], \n",
    "                                                all_these_words_input = df_master.loc[0, 'All these words'], \n",
    "                                                this_exact_wording_or_phrase_input = df_master.loc[0, 'This exact wording or phrase'], \n",
    "                                                one_or_more_of_these_words_1_input = df_master.loc[0, 'One or more of these words - 1'], \n",
    "                                                one_or_more_of_these_words_2_input = df_master.loc[0, 'One or more of these words - 2'], \n",
    "                                                one_or_more_of_these_words_3_input = df_master.loc[0, 'One or more of these words - 3'], \n",
    "                                                any_of_these_unwanted_words_input = df_master.loc[0, 'Any of these unwanted words'], \n",
    "                                                case_number_input = df_master.loc[0, 'Case number'], \n",
    "                                                date_from_input = df_master.loc[0, 'Date from'], \n",
    "                                                date_to_input = df_master.loc[0, 'Date to'], \n",
    "                                                judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                                            )\n",
    "\n",
    "        else:\n",
    "            search_results = afca_search(keywordsearch_input = df_master.loc[0, 'Search for published decisions'], \n",
    "                        ffsearch_input = df_master.loc[0, 'Search for a financial firm'], \n",
    "                        product_line_input = df_master.loc[0, 'Product line'], \n",
    "                        product_category_input = df_master.loc[0, 'Product category'], \n",
    "                        product_name_input = df_master.loc[0, 'Product name'], \n",
    "                        issue_type_input = df_master.loc[0, 'Issue type'], \n",
    "                        issue_input = df_master.loc[0, 'Issue'], \n",
    "                        date_from_input = df_master.loc[0, 'Date from'], \n",
    "                        date_to_input = df_master.loc[0, 'Date to'])\n",
    "        \n",
    "        if search_results['case_sum'] > 0:\n",
    "\n",
    "            df_preview = pd.DataFrame(search_results['case_list'])\n",
    "            \n",
    "            link_heading_config = {} \n",
    "      \n",
    "            link_heading_config['Hyperlink to AFCA Portal'] = st.column_config.LinkColumn(display_text = 'Click')\n",
    "    \n",
    "            st.success(f'Your search terms returned {search_results[\"case_sum\"]} result(s). Please see below for the top {min(search_results[\"case_sum\"], default_judgment_counter_bound)} result(s).')\n",
    "                        \n",
    "            st.dataframe(df_preview.head(default_judgment_counter_bound),  column_config=link_heading_config)\n",
    "    \n",
    "        else:\n",
    "            st.error(no_results_msg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547011af-4a96-4fde-b822-72100257eae5",
   "metadata": {},
   "source": [
    "## Metadata choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bc6066-fa65-4ad1-b561-1cc7b68c205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.subheader(\"Case metadata collection\")\n",
    "\n",
    "st.markdown(\"\"\"Would you like to obtain case metadata? Such data include the case number, the financial firm involved, and the decision date. \n",
    "\n",
    "Case name and hyperlinks to AFCA's website are always included with your results.\n",
    "\"\"\")\n",
    "\n",
    "meta_data_entry = st.checkbox(label = 'Include metadata', value = st.session_state['df_master'].loc[0, 'Metadata inclusion'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cca6a6-57d4-4cc3-89e4-caa8e424c551",
   "metadata": {},
   "source": [
    "## Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5428b07e-fe2e-4854-88a1-d216fd143912",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Buttons\n",
    "\n",
    "#col1, col2, col3, col4 = st.columns(4, gap = 'small')\n",
    "\n",
    "#with col1:\n",
    "\n",
    "    #reset_button = st.button(label='RESET', type = 'primary')\n",
    "\n",
    "#with col4:\n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "    next_button = st.button(label='NEXT')\n",
    "\n",
    "keep_button = st.button('SAVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cf7784-0571-4ba4-817e-d33b74e0cf9e",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45c8dd2-c29a-46e8-8cb0-ea2dceb60404",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    if st.session_state.df_master.loc[0, 'Collection'] == 'Decisions published before 14 June 2024':\n",
    "        \n",
    "        afca_search_terms = str(all_these_words_entry) + str(this_exact_wording_phrase_entry) + str(one_or_more_of_these_words_1_entry) + str(one_or_more_of_these_words_2_entry) + str(one_or_more_of_these_words_3_entry) + str(case_number_entry)\n",
    "    else:\n",
    "    \n",
    "        afca_search_terms = str(keywordsearch_entry) + str(ffsearch_entry) + str(product_line_entry) + str(product_category_entry) + str(product_name_entry) + str(issue_type_entry) + str(issue_entry) + str(date_from_entry) + str(date_to_entry)\n",
    "        \n",
    "    if afca_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "        #quit()\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        df_master = afca_create_df()\n",
    "\n",
    "        save_input(df_master)\n",
    "    \n",
    "        responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "    \n",
    "        #Produce a file to download\n",
    "    \n",
    "        csv = convert_df_to_csv(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a CSV (for use in Excel etc)\", \n",
    "            data = csv,\n",
    "            file_name=responses_output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "    #            key='download-csv'\n",
    "        )\n",
    "\n",
    "        xlsx = convert_df_to_excel(df_master)\n",
    "        \n",
    "        ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                            data=xlsx,\n",
    "                            file_name=responses_output_name + '.xlsx', \n",
    "                            mime='application/vnd.ms-excel',\n",
    "                           )\n",
    "        \n",
    "        json = convert_df_to_json(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a JSON\", \n",
    "            data = json,\n",
    "            file_name= responses_output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e547239-a842-423e-862c-990477802ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    df_master = afca_create_df()\n",
    "\n",
    "    save_input(df_master)        \n",
    "\n",
    "    st.session_state[\"page_from\"] = 'pages/AFCA.py'\n",
    "\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffffb5f8-79c4-4230-8a24-2611a0dc865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_button:\n",
    "    \n",
    "    st.session_state.pop('df_master')\n",
    "\n",
    "    #clear_cache()\n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc50b971-a689-4450-adf4-55256965f5a4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if next_button:\n",
    "\n",
    "    if st.session_state.df_master.loc[0, 'Collection'] == 'Decisions published before 14 June 2024':\n",
    "        \n",
    "        afca_search_terms = str(all_these_words_entry) + str(this_exact_wording_phrase_entry) + str(one_or_more_of_these_words_1_entry) + str(one_or_more_of_these_words_2_entry) + str(one_or_more_of_these_words_3_entry) + str(case_number_entry)\n",
    "    else:\n",
    "    \n",
    "        afca_search_terms = str(keywordsearch_entry) + str(ffsearch_entry) + str(product_line_entry) + str(product_category_entry) + str(product_name_entry) + str(issue_type_entry) + str(issue_entry) + str(date_from_entry) + str(date_to_entry)\n",
    "        \n",
    "    if afca_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "        #quit()\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        df_master = afca_create_df()\n",
    "                    \n",
    "        #Check search results\n",
    "        with st.spinner(r\"$\\textsf{\\normalsize Checking your search terms...}$\"):\n",
    "    \n",
    "            if st.session_state.df_master.loc[0, 'Collection'] == 'Decisions published before 14 June 2024':\n",
    "                search_results = afca_old_search(earlier_t_o_r_input = df_master.loc[0, 'Include decisions made under earlier Terms of Reference'], \n",
    "                                                    all_these_words_input = df_master.loc[0, 'All these words'], \n",
    "                                                    this_exact_wording_or_phrase_input = df_master.loc[0, 'This exact wording or phrase'], \n",
    "                                                    one_or_more_of_these_words_1_input = df_master.loc[0, 'One or more of these words - 1'], \n",
    "                                                    one_or_more_of_these_words_2_input = df_master.loc[0, 'One or more of these words - 2'], \n",
    "                                                    one_or_more_of_these_words_3_input = df_master.loc[0, 'One or more of these words - 3'], \n",
    "                                                    any_of_these_unwanted_words_input = df_master.loc[0, 'Any of these unwanted words'], \n",
    "                                                    case_number_input = df_master.loc[0, 'Case number'], \n",
    "                                                    date_from_input = df_master.loc[0, 'Date from'], \n",
    "                                                    date_to_input = df_master.loc[0, 'Date to'], \n",
    "                                                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                                                )\n",
    "\n",
    "            else:\n",
    "                search_results = afca_search(keywordsearch_input = df_master.loc[0, 'Search for published decisions'], \n",
    "                            ffsearch_input = df_master.loc[0, 'Search for a financial firm'], \n",
    "                            product_line_input = df_master.loc[0, 'Product line'], \n",
    "                            product_category_input = df_master.loc[0, 'Product category'], \n",
    "                            product_name_input = df_master.loc[0, 'Product name'], \n",
    "                            issue_type_input = df_master.loc[0, 'Issue type'], \n",
    "                            issue_input = df_master.loc[0, 'Issue'], \n",
    "                            date_from_input = df_master.loc[0, 'Date from'], \n",
    "                            date_to_input = df_master.loc[0, 'Date to'])\n",
    "            \n",
    "            if search_results['case_sum'] == 0:\n",
    "                \n",
    "                st.error(no_results_msg)\n",
    "\n",
    "            else:\n",
    "\n",
    "                save_input(df_master)\n",
    "\n",
    "                st.session_state[\"page_from\"] = 'pages/AFCA.py'\n",
    "                \n",
    "                st.switch_page('pages/GPT.py')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
