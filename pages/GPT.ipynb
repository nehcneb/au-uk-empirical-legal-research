{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55460cd1-57af-4b09-a2fd-2f66aef0e361",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89956fa9-e8a0-4fe0-a061-16043f2666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "import copy\n",
    "import traceback\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "#from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#aws\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "import openpyxl\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5bc9dd-db82-4e74-bba4-546e8a08a001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"LawtoData: An Empirical Legal Research Automator\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a30617e-0354-4a21-88bb-471f13902510",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, batch_mode_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, str_to_int, pdf_judgment, streamlit_timezone, save_input, download_buttons, send_notification_email, open_page, clear_cache_except_validation_df_master, clear_cache, tips, link, uploaded_file_to_df\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, list_range_check, au_date, streamlit_cloud_date_format, spinner_text, search_error_display, own_gpt_headings\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, batch_mode_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, str_to_int, pdf_judgment, streamlit_timezone, save_input, download_buttons, send_notification_email, open_page, clear_cache_except_validation_df_master, clear_cache, tips, link, uploaded_file_to_df, streamlit_timezone\n",
    "\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, list_range_check, date_parser, streamlit_cloud_date_format, spinner_text, own_gpt_headings, gpt_cost_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffeba0-33ca-4a0b-9531-ab6cdede1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to home page if this page is the first page\n",
    "if 'page_from' not in st.session_state:\n",
    "    clear_cache()\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807795e-e0d7-439c-ba6d-39622f5db1bf",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753a9bee-88ca-45e4-98d2-267b9e065ef5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_run\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, role_content, judgment_batch_cutoff \u001b[38;5;66;03m#, intro_for_GPT\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, gpt_run, batch_request_function #GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, judgment_batch_cutoff, judgment_batch_max, default_caption\n",
    "#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d29c56-a3b5-4b7b-8e38-8fd300ffd9ba",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab227daa-1c07-4b84-b2b1-f6c39c5a49e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_judgment_counter_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msecrets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgments_counter_bound\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m---> 14\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgments_counter_bound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_judgment_counter_bound\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_judgment_counter_bound' is not defined"
     ]
    }
   ],
   "source": [
    "#Module, costs and upperbounds\n",
    "\n",
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "\n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#if 'judgments_counter_bound' not in st.session_state:\n",
    "    #st.session_state['judgments_counter_bound'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091a562-d6de-416b-b437-8f495dfefbeb",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9d6c54-8e43-48cb-a915-f9d2486d84d9",
   "metadata": {},
   "source": [
    "### Function for saving entries for own account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eed4052-3a13-44eb-aeb4-8d26eea57ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for saving entries for own account:\n",
    "\n",
    "def own_account_entries_function():\n",
    "\n",
    "    if own_account_allowed() > 0:\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = own_account_entry\n",
    "\n",
    "        if st.session_state['df_master'].loc[0, 'Use own account']:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your name'] = name_entry\n",
    "    \n",
    "            st.session_state['df_master'].loc[0, 'Your email address'] = email_entry\n",
    "    \n",
    "            st.session_state['df_master'].loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "    \n",
    "            st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = gpt_enhancement_entry\n",
    "    \n",
    "            if st.session_state['df_master'].loc[0, 'Use flagship version of GPT']:\n",
    "            \n",
    "                st.session_state.gpt_model = \"gpt-4o\"\n",
    "    \n",
    "            else:\n",
    "                \n",
    "                st.session_state.gpt_model = 'gpt-4o-mini'\n",
    "    \n",
    "            st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = judgments_counter_bound_entry\n",
    "    \n",
    "        else:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "    \n",
    "            st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "        \n",
    "            st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    \n",
    "    else:\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "        st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "\n",
    "    st.session_state.estimated_waiting_secs = int(float(min(st.session_state[\"judgment_batch_cutoff\"], st.session_state['df_master'].loc[0, 'Maximum number of judgments'])))*30\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662bbb1-dbd5-482d-8602-befcb632a92c",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155575a-3f4b-4645-992d-665959c6db9b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Only for return and run buttons\n",
    "\n",
    "if st.session_state.page_from != 'pages/GPT.py':\n",
    "\n",
    "    st.session_state['jurisdiction_page'] = st.session_state.page_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8618d7ab-f38d-43ad-94a8-8c9c59908c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_judgment_counter_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour GPT API key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetadata inclusion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum number of judgments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_judgment_counter_bound\u001b[49m\n\u001b[1;32m     20\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter your questions for GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_judgment_counter_bound' is not defined"
     ]
    }
   ],
   "source": [
    "#if 'own_account' not in st.session_state:\n",
    "    #st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    df_master_dict = {'Your name': '',\n",
    "    'Your email address': '',\n",
    "    'Your GPT API key': '',\n",
    "    'Metadata inclusion': True,\n",
    "    'Maximum number of judgments': default_judgment_counter_bound,\n",
    "    'Enter your questions for GPT': '',\n",
    "    'Use GPT': False,\n",
    "    'Use own account': False,\n",
    "    'Use flagship version of GPT': False,\n",
    "    'Example': ''\n",
    "    }\n",
    "    \n",
    "    st.session_state['df_master'] = pd.DataFrame([df_master_dict])\n",
    "\n",
    "if 'Example' not in st.session_state.df_master.columns:\n",
    "    st.session_state['df_master'].loc[0, 'Example'] = ''\n",
    "\n",
    "if 'Consent' not in st.session_state.df_master.columns:\n",
    "    st.session_state['df_master'].loc[0, 'Consent'] = False\n",
    "\n",
    "if 'df_individual' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True\n",
    "\n",
    "#default_judgment_counter_bound < judgment_batch_cutoff < judgment_batch_max/2\n",
    "\n",
    "#Instant mode max/batch mode threshold\n",
    "if own_account_allowed() > 0:\n",
    "    st.session_state[\"judgment_batch_cutoff\"] = judgment_batch_cutoff\n",
    "else:\n",
    "    st.session_state[\"judgment_batch_cutoff\"] = default_judgment_counter_bound\n",
    "\n",
    "#Maximum number of judgments to process under any mode\n",
    "if \"judgment_counter_max\" not in st.session_state:\n",
    "\n",
    "    st.session_state[\"judgment_counter_max\"] = judgment_batch_cutoff\n",
    "\n",
    "if ((batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py', 'pages/HK.py', 'pages/US.py'])):\n",
    "\n",
    "    #if own_account_allowed() > 0:\n",
    "        \n",
    "    st.session_state[\"judgment_counter_max\"] = judgment_batch_max\n",
    "\n",
    "#Initalize for the purpuse of disabling multiple submissions of batch requests\n",
    "if \"batch_submitted\" not in st.session_state:\n",
    "    st.session_state[\"batch_submitted\"] = False\n",
    "\n",
    "if \"batch_ready_for_submission\" not in st.session_state:\n",
    "    st.session_state[\"batch_ready_for_submission\"] = False\n",
    "\n",
    "#For example df\n",
    "if 'df_example_to_show' not in st.session_state:\n",
    "    st.session_state[\"df_example_to_show\"] = pd.DataFrame([])\n",
    "\n",
    "#Initalize df_example_key for the purpose of removing uploaded spreadsheets programatically\n",
    "if \"df_example_key\" not in st.session_state:\n",
    "    st.session_state[\"df_example_key\"] = 0\n",
    "\n",
    "#Initialise waiting time\n",
    "if 'estimated_waiting_secs' not in st.session_state:\n",
    "    \n",
    "    st.session_state['estimated_waiting_secs'] = int(float(st.session_state[\"judgment_batch_cutoff\"]))*30\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5e72f-303c-4f68-9e6d-d420aac6625c",
   "metadata": {},
   "source": [
    "## Form for AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18c42ba5-19a1-4e50-a69b-daf68c403ebd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 07:12:32.611 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.616 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.617 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.618 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.663 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.664 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.664 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.665 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.665 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.665 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-11-08 07:12:32.665 Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'st.session_state has no key \"df_master\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:455\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:500\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m st\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:blue[Would you to ask GPT questions about the cases returned by your search terms?]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mYou can use this app without asking GPT any questions. For instance, you can extract metadata and get estimates of file length and GPT cost. \u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m gpt_activation_entry \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39mcheckbox(label \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse GPT (free by default)\u001b[39m\u001b[38;5;124m'\u001b[39m, value \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdf_master\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse GPT\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     12\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m gpt_activation_entry\n\u001b[1;32m     14\u001b[0m st\u001b[38;5;241m.\u001b[39mcaption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse of GPT is costly and funded by a grant. For the model used by default (gpt-4o-mini), Ben\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms own experience suggests that it costs approximately USD \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m$0.01 (excl GST) per case. The [exact cost](https://openai.com/pricing) depends on question length, case length, and answer length. You will be given cost estimates.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:100\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     98\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(key)\n\u001b[1;32m     99\u001b[0m require_valid_user_key(key)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_yield_callback()\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:457\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem(widget_id, key)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"df_master\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'"
     ]
    }
   ],
   "source": [
    "return_button = st.button('RETURN to the previous page')\n",
    "\n",
    "#st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "st.header(\":blue[Would you like GPT to get data or information from the cases found?]\")\n",
    "\n",
    "st.markdown(\"\"\"You don't have to use GPT. This app can extract metadata and get estimates of file length and GPT cost without using GPT. \n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox(label = 'Use GPT (free for users by default)', value = st.session_state['df_master'].loc[0, 'Use GPT'])\n",
    "\n",
    "st.session_state['df_master'].loc[0, 'Use GPT'] = gpt_activation_entry\n",
    "\n",
    "st.caption(f\"{gpt_cost_msg}\")\n",
    "\n",
    "st.subheader(\"Tell GPT what to get from each case\")\n",
    "\n",
    "st.success(\"\"\"In question form, please tell GPT what to get from each case. **Enter one question per paragraph**. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"For each case, GPT will be instructed to respond based only on information from the case itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "#if st.toggle('See the instruction given to GPT'):\n",
    "    #st.write(f\"{intro_for_GPT[0]['content']}\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "gpt_questions_entry = st.text_area(label = f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound, value = st.session_state['df_master'].loc[0, 'Enter your questions for GPT']) \n",
    "\n",
    "#if gpt_questions_entry:\n",
    "    \n",
    "st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = gpt_questions_entry\n",
    "\n",
    "st.caption(f\"By default, this app will use model gpt-4o-mini. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-4o-mini')*3/4)} words from each case.\")\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    \n",
    "    st.write(\"Please do not try to obtain personally identifiable information. Your questions and GPT's answers will be checked for potential privacy violation.\")\n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        \n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.session_state['disable_input'] = True\n",
    "        \n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "\n",
    "#Upload example\n",
    "\n",
    "st.subheader(\"Share an exemplar (optional)\")\n",
    "\n",
    "st.markdown(\"\"\"This app will produce a spreadsheet with rows of cases and columns of answers to your questions. If you have a preferred layout, please feel free to upload an example for GPT to follow.\"\"\")\n",
    "\n",
    "uploaded_file = st.file_uploader(label = \"Upload an example\", \n",
    "                                 type=['csv', 'xlsx', 'json'], \n",
    "                                 accept_multiple_files=False, \n",
    "                                  key = st.session_state[\"df_example_key\"]\n",
    "                                )\n",
    "\n",
    "if uploaded_file:\n",
    "\n",
    "    try:\n",
    "    \n",
    "        df_example_to_show = uploaded_file_to_df(uploaded_file)\n",
    "        \n",
    "        indice = df_example_to_show.index.tolist()\n",
    "    \n",
    "        if len(indice) > 0:\n",
    "    \n",
    "            for index in indice [1: ]:\n",
    "    \n",
    "                df_example_to_show.drop(index, axis=0, inplace = True)\n",
    "\n",
    "        #Create copy to show before dropping GPT stats headings\n",
    "        st.session_state.df_example_to_show = df_example_to_show.copy(deep = True)\n",
    "\n",
    "        #Drop any GPT stats headings and add example to df_master as a string of a json\n",
    "        columns = df_example_to_show.columns.tolist()\n",
    "\n",
    "        for col in columns:\n",
    "            \n",
    "            for gpt_col in own_gpt_headings:\n",
    "                \n",
    "                if ((gpt_col.lower() in col.lower()) and (col in df_example_to_show.columns)):\n",
    "                    \n",
    "                    df_example_to_show.drop(col, axis=1, inplace = True)\n",
    "                            \n",
    "        st.session_state.df_master.loc[0, 'Example'] = json.dumps(df_example_to_show.loc[0].to_json(default_handler=str))\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        st.error(f'Sorry, this app is unable to follow this example due to this error: {e}')\n",
    "\n",
    "if len(st.session_state.df_example_to_show) > 0:\n",
    "        \n",
    "    st.success('For each case, GPT will *try* to produce something like the following:')\n",
    "\n",
    "    st.dataframe(st.session_state.df_example_to_show)\n",
    "\n",
    "    #Button for removing example\n",
    "    if st.button(label = 'REMOVE the uploaded example', type = 'primary'):\n",
    "    \n",
    "        st.session_state.df_example_key += 1\n",
    "    \n",
    "        st.session_state.df_example_to_show = pd.DataFrame([])\n",
    "    \n",
    "        st.session_state.df_master.loc[0, 'Example'] = ''\n",
    "    \n",
    "        st.rerun()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441e6d16-c702-4af7-9352-31fb3c7450e9",
   "metadata": {},
   "source": [
    "## Own account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e420f7-a780-4bcd-965d-c12b21fb997b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if own_account_allowed() == 0:\n",
    "    \n",
    "    own_account_entry = False\n",
    "\n",
    "else:\n",
    "    \n",
    "#if own_account_allowed() > 0:\n",
    "    \n",
    "    st.header(':orange[Enhance app capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or change the maximum number of cases to process? You can do so with your own GPT account.\n",
    "\"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle(label = 'Use my own GPT account',  value = st.session_state['df_master'].loc[0, 'Use own account'])\n",
    "    \n",
    "    if own_account_entry:\n",
    "\n",
    "        #st.session_state['df_master'].loc[0, 'Use own account'] = own_account_entry\n",
    "        \n",
    "        #st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "\"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state['df_master'].loc[0, 'Your name'])\n",
    "\n",
    "        #if name_entry:\n",
    "            \n",
    "        #st.session_state['df_master'].loc[0, 'Your name'] = name_entry\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value =  st.session_state['df_master'].loc[0, 'Your email address'])\n",
    "\n",
    "        #if email_entry:\n",
    "            \n",
    "        #st.session_state['df_master'].loc[0, 'Your email address'] = email_entry\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state['df_master'].loc[0, 'Your GPT API key'])\n",
    "        \n",
    "        if gpt_api_key_entry:\n",
    "            \n",
    "            #st.session_state['df_master'].loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "\n",
    "            if ((len(gpt_api_key_entry) < 40) or (gpt_api_key_entry[0:2] != 'sk')):\n",
    "                \n",
    "                st.warning('This key is not valid.')\n",
    " \n",
    "        st.markdown(\"\"\"**:green[You can use the flagship version of GPT (model gpt-4o),]** which is :red[significantly more expensive] than the default model (gpt-4o-mini) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the flagship GPT model', value = st.session_state['df_master'].loc[0, 'Use flagship version of GPT'])\n",
    "        \n",
    "        st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "\n",
    "        #if gpt_enhancement_entry:\n",
    "\n",
    "            #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = True\n",
    "            \n",
    "            #st.session_state.gpt_model = \"gpt-4o\"\n",
    "\n",
    "        #else:\n",
    "            \n",
    "            #st.session_state.gpt_model = 'gpt-4o-mini'\n",
    "            #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "        st.write(f'**:green[You can change the maximum number of cases to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        judgments_counter_bound_entry = st.slider(label = f'Up to {st.session_state[\"judgment_counter_max\"]}', min_value = 1, max_value = st.session_state[\"judgment_counter_max\"], step = 1, value = str_to_int(st.session_state['df_master'].loc[0, 'Maximum number of judgments']))\n",
    "        \n",
    "        #if judgments_counter_bound_entry:\n",
    "        \n",
    "        #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = judgments_counter_bound_entry\n",
    "    \n",
    "        if judgments_counter_bound_entry > st.session_state[\"judgment_batch_cutoff\"]:\n",
    "    \n",
    "            st.warning(f\"Given more than {st.session_state['judgment_batch_cutoff']} cases may need to be processes, this app will send your requested data to your nominated email address in about **2 business days**.\")\n",
    "\n",
    "        #st.write(f\"*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each case, for up to {st.session_state['df_master'].loc[0, 'Maximum number of judgments']} case(s).*\")\n",
    "    \n",
    "    #else:\n",
    "        \n",
    "        #st.session_state[\"own_account\"] = False\n",
    "\n",
    "        #st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    \n",
    "        #st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "        #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "        #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "        \n",
    "#else:\n",
    "        #st.session_state[\"own_account\"] = False\n",
    "\n",
    "        #st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    \n",
    "        #st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "        #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "        #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7436e-0bc4-4c0e-8fa6-dd0913be35c4",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea67be1-35e1-47c0-a1d1-8f0725ba74e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m st\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBy running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m consent \u001b[38;5;241m=\u001b[39m  st\u001b[38;5;241m.\u001b[39mcheckbox(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes, I agree.\u001b[39m\u001b[38;5;124m'\u001b[39m, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, disabled \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_input\u001b[49m)\n\u001b[1;32m      7\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mIf you do not agree, then please feel free to close this form.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By using this app, you agree that the data and/or information you and/or this app provide will be temporarily stored on one or more remote servers. Any such data and/or information may also be given to an artificial intelligence provider. Any such data and/or information [will not be used to train any artificial intelligence model.](https://platform.openai.com/docs/models/how-we-use-your-data#how-we-use-your-data) \n",
    "\"\"\")\n",
    "\n",
    "consent_entry =  st.checkbox('Yes, I agree.', value = bool(st.session_state['df_master'].loc[0, 'Consent']), disabled = st.session_state.disable_input)\n",
    "\n",
    "st.session_state['df_master'].loc[0, 'Consent'] = consent_entry\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this app. \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de5f83-ef2d-4c01-b982-3bc66039be7b",
   "metadata": {},
   "source": [
    "## Save entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f011809f-8e34-4709-a9f7-69d3d27e258f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gpt_keep_button = st.button(label = 'DOWNLOAD entries')\n",
    "\n",
    "if gpt_keep_button:\n",
    "    \n",
    "    st.success('Scroll down to download your entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc0bb7-5ef8-446b-909d-1729e54adc93",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc1842da-69dd-436b-ab06-c51c84f2b085",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Next steps\")\n",
    "\n",
    "#Calculate estimating waiting time\n",
    "\n",
    "#estimated_waiting_secs = int(float(min(st.session_state[\"judgment_batch_cutoff\"], st.session_state['df_master'].loc[0, 'Maximum number of judgments'])))*30\n",
    "\n",
    "#Instructions\n",
    "st.markdown(f\"\"\"You can now press :green[PRODUCE data] to obtain a spreadsheet which hopefully has the data you seek. This app will immediately process up to {st.session_state[\"judgment_batch_cutoff\"]} cases. The estimated waiting time is **{st.session_state[\"judgment_batch_cutoff\"]*30/60} minute(s)**.\n",
    "\"\"\")\n",
    "\n",
    "#st.markdown(f\"\"\"You can now press :green[PRODUCE data] to obtain a spreadsheet which hopefully has the data you seek. This app will immediately process up to {min(st.session_state[\"judgment_batch_cutoff\"], st.session_state['df_master'].loc[0, 'Maximum number of judgments'])} cases. The estimated waiting time is **{estimated_waiting_secs/60} minute(s)**.\"\"\")\n",
    "\n",
    "if ((batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py', 'pages/HK.py', 'pages/US.py'])):\n",
    "    st.markdown(f\"\"\"Alternatively, you can press :orange[REQUEST data] to process up to {st.session_state[\"judgment_counter_max\"]} cases. Your requested data will be sent to your nominated email address in about **2 business days**. \n",
    "\"\"\")\n",
    "\n",
    "\n",
    "#Buttons\n",
    "\n",
    "gpt_reset_button = st.button(label='REMOVE data', type = 'primary', disabled = not bool(st.session_state.need_resetting))\n",
    "\n",
    "if ((batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py', 'pages/HK.py', 'pages/US.py'])):\n",
    "    with stylable_container(\n",
    "        \"orange\",\n",
    "        css_styles=\"\"\"\n",
    "        button {\n",
    "            background-color: #F9F500;\n",
    "            color: black;\n",
    "        }\"\"\",\n",
    "    ):\n",
    "        batch_button = st.button(label = 'REQUEST data', \n",
    "                                 help = 'You can only :orange[REQUEST] data once per session.', \n",
    "                                 disabled = bool((st.session_state.batch_submitted) or (st.session_state.disable_input))\n",
    "                                )#, disabled = not bool(st.session_state['df_master'].loc[0, 'Maximum number of judgments'] > default_judgment_counter_bound))\n",
    "\n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "    run_button = st.button(label = 'PRODUCE data', \n",
    "                           help = 'You must :red[REMOVE] any data previously produced before producing new data.', \n",
    "                           disabled = bool((st.session_state.need_resetting) or (st.session_state.disable_input) or (bool(st.session_state['df_master'].loc[0, 'Maximum number of judgments'] > st.session_state[\"judgment_batch_cutoff\"])))\n",
    "                          )\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "#if st.session_state.need_resetting == 1:\n",
    "    #if len(st.session_state.df_individual) > 0:\n",
    "        #st.warning('You must :red[REMOVE] the data previously produced before producing new data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f0eaf-293d-4e38-83fc-144b4bde6ddd",
   "metadata": {},
   "source": [
    "## ER only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39893be5-62af-46a8-9322-8758739f10e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#if st.session_state.gpt_model == \"gpt-4o\":\n",
    "if ((own_account_entry) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "    \n",
    "    st.markdown(\"\"\"The English Reports are available as PDFs. By default, this app will use an Optical Character Recognition (OCR) engine to extract text from the relevant PDFs, and then send such text to GPT.\n",
    "    \n",
    "Alternatively, you can send the relevant PDFs to GPT as images. This alternative approach may produce better responses for \"untidy\" PDFs, but tends to be **slower** and **costlier** than the default approach.\n",
    "\"\"\")\n",
    "    \n",
    "    #st.write('Not getting the best responses for your images? You can try a more costly')\n",
    "    #b64_help_text = 'GPT will process images directly, instead of text first extracted from images by an Optical Character Recognition engine. This only works for PNG, JPEG, JPG, GIF images.'\n",
    "    er_run_button_b64 = st.button(label = 'SEND PDFs to GPT as images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cafe13-62ac-42d7-b17e-9efa101b1c91",
   "metadata": {},
   "source": [
    "## Download entries and and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a528871-82e9-48d1-9af2-56053b82fb5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Create placeholder download buttons if previous entries and output in st.session_state:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_individual\u001b[49m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#st.subheader('Looking for your previous entries and output?')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLooking for your previously produced data?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     df_master \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_master\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#Create placeholder download buttons if previous entries and output in st.session_state:\n",
    "\n",
    "if len(st.session_state.df_individual) > 0:\n",
    "\n",
    "    #Current output\n",
    "    if st.session_state[\"page_from\"] == 'pages/GPT.py':\n",
    "\n",
    "        download_buttons(df_master = st.session_state.df_master, df_individual = st.session_state.df_individual)\n",
    "\n",
    "    #Previous entries and output\n",
    "    else:\n",
    "        download_buttons(df_master = st.session_state.df_master, df_individual = st.session_state.df_individual, saving = False, previous = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d72285-64dc-4254-804c-25fd600dc87f",
   "metadata": {},
   "source": [
    "# Run etc buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0108ebb-1002-4e99-94ee-053b30bedb3c",
   "metadata": {},
   "source": [
    "## All jurisdictions except ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a2d50e-12de-402f-9fec-134561fc4e28",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if gpt_keep_button:\n",
    "    \n",
    "    own_account_entries_function()\n",
    "    \n",
    "    download_buttons(df_master = st.session_state.df_master, df_individual = [], saving = True, previous = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a8fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "    \n",
    "    if int(consent_entry) == 0:\n",
    "        st.warning(\"You must tick 'Yes, I agree.' to use the app.\")\n",
    "\n",
    "    elif len(st.session_state.df_individual) > 0:\n",
    "        \n",
    "        st.warning('You must :red[REMOVE] the last produced data before producing new data.')\n",
    "            \n",
    "    else:\n",
    "\n",
    "        own_account_entries_function()\n",
    "        \n",
    "        if ((own_account_entry) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                st.error('Your API key is not valid.')\n",
    "                st.stop()\n",
    "                \n",
    "        #Warning\n",
    "        if gpt_activation_entry:\n",
    "            if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "                st.warning('A low-cost GPT model will process the cases found. Please be cautious.')\n",
    "                st.caption(f'Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more cases or use a better model.')\n",
    "            \n",
    "            #if st.session_state.gpt_model == \"gpt-4o\":\n",
    "                #st.warning('An expensive GPT model will process the cases found. Please be cautious.')\n",
    "    \n",
    "        spinner_text += f'The estimated waiting time has been revised to {st.session_state.estimated_waiting_secs/60} minute(s).'\n",
    "\n",
    "        with st.spinner(spinner_text):\n",
    "\n",
    "            try:\n",
    "    \n",
    "                #Create spreadsheet of responses\n",
    "                df_master = st.session_state.df_master\n",
    "\n",
    "                #st.write(f\"df_master.loc[0, 'Example'] == {df_master.loc[0, 'Example']}\")\n",
    "                \n",
    "                #Activate user's own key or mine\n",
    "                if own_account_entry:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    \n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                \n",
    "                openai.api_key = API_key\n",
    "    \n",
    "                #Produce data\n",
    "                \n",
    "                jurisdiction_page = st.session_state.jurisdiction_page\n",
    "                \n",
    "                df_individual = gpt_run(jurisdiction_page, df_master)\n",
    "                                    \n",
    "                #Keep data in session state\n",
    "                st.session_state[\"df_individual\"] = df_individual\n",
    "\n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                st.session_state[\"page_from\"] = 'pages/GPT.py'           \n",
    "\n",
    "                #Download data\n",
    "                #download_buttons(df_master, df_individual)\n",
    "\n",
    "                st.rerun()\n",
    "            \n",
    "            except Exception as e:\n",
    "    \n",
    "                st.error('Sorry, an error has occurred. Please change your questions or wait a few hours, and try again.')\n",
    "                \n",
    "                st.error(e)\n",
    "                \n",
    "                st.error(traceback.format_exc())\n",
    "\n",
    "                print(e)\n",
    "\n",
    "                print(traceback.format_exc())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    own_account_entries_function()\n",
    "    \n",
    "    st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "\n",
    "    st.switch_page(st.session_state.jurisdiction_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if gpt_reset_button:\n",
    "    \n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "    \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    \n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8a34b-2f62-48fa-b810-c6f80401922c",
   "metadata": {},
   "source": [
    "## ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5693cfe-dcc1-47dc-a7f7-bdf2de6cf58d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if ((own_account_entry) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "\n",
    "    if er_run_button_b64:\n",
    "        \n",
    "        if int(consent_entry) == 0:\n",
    "            st.warning(\"You must tick 'Yes, I agree.' to use the app.\")\n",
    "    \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            st.warning('You must :red[REMOVE] the data already produced before producing new data.')\n",
    "                \n",
    "        else:\n",
    "\n",
    "            own_account_entries_function()\n",
    "            \n",
    "            if ((own_account_entry) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                    \n",
    "                if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    st.stop()\n",
    "\n",
    "            #Warning\n",
    "            if gpt_activation_entry:\n",
    "                if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "                    st.warning('A low-cost GPT model will process the cases found. Please be cautious.')\n",
    "                    st.caption(f'Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more cases or use a better model.')\n",
    "                \n",
    "                #if st.session_state.gpt_model == \"gpt-4o\":\n",
    "                    #st.warning('An expensive GPT model will process the cases found. Please be cautious.')\n",
    "    \n",
    "            \n",
    "            #Increase waiting time\n",
    "            st.session_state.estimated_waiting_secs = st.session_state.estimated_waiting_secs*10\n",
    "            \n",
    "            spinner_text += f'The estimated waiting time has been revised to {st.session_state.estimated_waiting_secs/60} minute(s).'\n",
    "    \n",
    "            with st.spinner(spinner_text):\n",
    "\n",
    "                try:\n",
    "\n",
    "                    #Definitions and functions for ER\n",
    "                    from functions.er_functions import er_run_b64, role_content_er#, er_run, er_methods_list, er_method_types, er_search, er_search_results_to_case_link_pairs, er_judgment_text, er_meta_judgment_dict, er_judgment_tokens_b64, er_meta_judgment_dict_b64, er_GPT_b64_json, er_engage_GPT_b64_json\n",
    "\n",
    "                    #from functions.gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "                    \n",
    "                    system_instruction = role_content_er\n",
    "\n",
    "                    #Create spreadsheet of responses\n",
    "                    df_master = st.session_state.df_master\n",
    "    \n",
    "                    #Activate user's own key or mine\n",
    "                    if own_account_entry:\n",
    "                        \n",
    "                        API_key = df_master.loc[0, 'Your GPT API key']\n",
    "        \n",
    "                    else:\n",
    "                        \n",
    "                        API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                    \n",
    "                    openai.api_key = API_key\n",
    "    \n",
    "                    #Produce results\n",
    "                        \n",
    "                    df_individual = er_run_b64(df_master)\n",
    "                        \n",
    "                    #Keep data in session state\n",
    "                    st.session_state[\"df_individual\"] = df_individual\n",
    "    \n",
    "                    #Change session states\n",
    "                    st.session_state['need_resetting'] = 1\n",
    "                    st.session_state[\"page_from\"] = 'pages/GPT.py'           \n",
    "    \n",
    "                    #Download data\n",
    "                    #download_buttons(df_master, df_individual)\n",
    "\n",
    "                    st.rerun()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    st.error('Sorry, an error has occurred. Please change your questions or wait a few hours, and try again.')\n",
    "                    \n",
    "                    st.error(e)\n",
    "                    \n",
    "                    st.error(traceback.format_exc())\n",
    "    \n",
    "                    print(e)\n",
    "    \n",
    "                    print(traceback.format_exc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb3291e-a456-470f-b6db-b59cb042b625",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162dae1-76c7-455e-a935-ce6d5241a5b3",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "if ((batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py', 'pages/HK.py', 'pages/US.py'])):\n",
    "    \n",
    "    if batch_button:\n",
    "        \n",
    "        own_account_entries_function()\n",
    "        \n",
    "        batch_request_function()\n",
    "\n",
    "    if st.session_state.batch_submitted and st.session_state.need_resetting:\n",
    "        \n",
    "        st.success('Your data request has been submitted. This app will send your requested data to your nominated email address in about **2 business days**. Feel free to close this app.')\n",
    "\n",
    "        #Warning\n",
    "        if gpt_activation_entry:\n",
    "            if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "                st.warning('A low-cost GPT model will process the cases found. Please be cautious.')\n",
    "                st.caption(f'Please reach out to Ben Chen at ben.chen@sydney.edu.au should you wish to cover more cases or use a better model.')\n",
    "            \n",
    "            #if st.session_state.gpt_model == \"gpt-4o\":\n",
    "                #st.warning('An expensive GPT model will process the cases found. Please be cautious.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
