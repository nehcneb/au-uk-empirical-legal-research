{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55460cd1-57af-4b09-a2fd-2f66aef0e361",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89956fa9-e8a0-4fe0-a061-16043f2666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import PyPDF2\n",
    "import io\n",
    "from io import BytesIO\n",
    "import copy\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a30617e-0354-4a21-88bb-471f13902510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default, users are allowed to use their own account\n",
      "The pause between judgment scraping is 5 second.\n",
      "\n",
      "The lower bound on lenth of judgment text to process is 5000 tokens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, str_to_int\n",
    "#Import variables\n",
    "from common_functions import today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, list_range_check, au_date, streamlit_cloud_date_format\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be0e3466-aa47-4fdc-ac82-8b887f475fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, clear_cache, tips, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ffeba0-33ca-4a0b-9531-ab6cdede1691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 08:44:13.065 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "ename": "NoSessionContext",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSessionContext\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_from\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[1;32m      3\u001b[0m     clear_cache()\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHome.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/metrics_util.py:408\u001b[0m, in \u001b[0;36mgather_metrics.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to collect command telemetry\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnon_optional_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RerunException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# Duplicated from below, because static analysis tools get confused\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# by deferring the rethrow.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracking_activated \u001b[38;5;129;01mand\u001b[39;00m command_telemetry:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/commands/execution_control.py:144\u001b[0m, in \u001b[0;36mswitch_page\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m    140\u001b[0m ctx \u001b[38;5;241m=\u001b[39m get_script_run_ctx()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mscript_requests:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# This should never be the case\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSessionContext()\n\u001b[1;32m    146\u001b[0m page_script_hash \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(page, StreamlitPage):\n",
      "\u001b[0;31mNoSessionContext\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Go back to home page if this page is the first page\n",
    "if 'page_from' not in st.session_state:\n",
    "    clear_cache()\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807795e-e0d7-439c-ba6d-39622f5db1bf",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753a9bee-88ca-45e4-98d2-267b9e065ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, role_content #, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d29c56-a3b5-4b7b-8e38-8fd300ffd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from common_functions import check_questions_answers\n",
    "\n",
    "from gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab227daa-1c07-4b84-b2b1-f6c39c5a49e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_judgment_counter_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msecrets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgments_counter_bound\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m---> 14\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgments_counter_bound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_judgment_counter_bound\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_judgment_counter_bound' is not defined"
     ]
    }
   ],
   "source": [
    "#Module, costs and upperbounds\n",
    "\n",
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "\n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41bfb110-210d-4c98-bf34-8915ea9c982e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction and functions\n",
    "\n",
    "def gpt_run(jurisdiction_page, df_master):\n",
    "\n",
    "    if jurisdiction_page == 'pages/HCA.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.HCA import hca_run, hca_collections, hca_search, hca_search_results_to_judgment_links, hca_pdf_judgment, hca_meta_labels_droppable, hca_meta_judgment_dict, hca_meta_judgment_dict_alt, hca_mnc_to_link_browse, hca_citation_to_link, hca_mnc_to_link, hca_load_data, hca_data_url, hca_df, hca_judgment_to_exclude, hca_search_results_to_judgment_links_filtered_df\n",
    "    \n",
    "        run = copy.copy(hca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/NSW.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "\n",
    "        from nswcaselaw.search import Search\n",
    "        \n",
    "        from pages.NSW import nsw_run, nsw_meta_labels_droppable, nsw_courts, nsw_courts_positioning, nsw_default_courts, nsw_tribunals, nsw_tribunals_positioning, nsw_court_choice, nsw_tribunal_choice, nsw_date, nsw_link, nsw_short_judgment, nsw_tidying_up\n",
    "    \n",
    "        run = copy.copy(nsw_run)\n",
    "    \n",
    "    if jurisdiction_page == 'pages/FCA.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.FCA import fca_run, fca_courts, fca_courts_list, fca_search, fca_search_url, fca_search_results_to_judgment_links, fca_link_to_doc, fca_pdf_judgment, fca_metalabels, fca_metalabels_droppable, fca_meta_judgment_dict, fca_pdf_name_mnc_list, fca_pdf_name\n",
    "    \n",
    "        run = copy.copy(fca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/CA.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.CA import ca_run, ca_courts, bc_courts, ab_courts, sk_courts, mb_courts, on_courts, qc_courts, nb_courts, ns_courts, pe_courts, nl_courts, yk_courts, nt_courts, nu_courts, all_ca_jurisdiction_court_pairs, ca_court_tribunal_types, all_subjects, ca_search, ca_search_url, ca_search_results_to_judgment_links, ca_meta_labels_droppable, ca_meta_dict, ca_date  \n",
    "        \n",
    "        run = copy.copy(ca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/UK.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.UK import uk_run, uk_courts_default_list, uk_courts, uk_courts_list, uk_court_choice, uk_link, uk_search, uk_search_results_to_judgment_links, uk_meta_labels_droppable, uk_meta_judgment_dict\n",
    "        \n",
    "        run = copy.copy(uk_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/AFCA.py':\n",
    "\n",
    "        system_instruction = role_content\n",
    "                \n",
    "        from pages.AFCA import afca_run, product_line_options, product_category_options, product_name_options, issue_type_options, issue_options, afca_search, afca_meta_judgment_dict,  afca_meta_labels_droppable\n",
    "        \n",
    "        run = copy.copy(afca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/ER.py':\n",
    "\n",
    "        from pages.ER import er_run, er_run_b64, er_methods_list, er_method_types, er_search, er_search_results_to_case_link_pairs, er_judgment_text, er_meta_judgment_dict, role_content_er, er_judgment_tokens_b64, er_meta_judgment_dict_b64, er_GPT_b64_json, er_engage_GPT_b64_json\n",
    "\n",
    "        from gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "\n",
    "        system_instruction = role_content_er\n",
    "\n",
    "        run = copy.copy(er_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/KR.py':\n",
    "\n",
    "        system_instruction = role_content\n",
    "                \n",
    "        from pages.KR import kr_run, kr_methods_list, kr_method_types, kr_search, kr_search_results_to_case_link_pairs, kr_judgment_text, kr_meta_judgment_dict\n",
    "        \n",
    "        run = copy.copy(kr_run)\n",
    "\n",
    "    \n",
    "    intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]\n",
    "\n",
    "    df_individual = run(df_master)\n",
    "\n",
    "    return df_individual\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091a562-d6de-416b-b437-8f495dfefbeb",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662bbb1-dbd5-482d-8602-befcb632a92c",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8618d7ab-f38d-43ad-94a8-8c9c59908c59",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_judgment_counter_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour GPT API key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetadata inclusion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum number of judgments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_judgment_counter_bound\u001b[49m\n\u001b[1;32m     20\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter your questions for GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_judgment_counter_bound' is not defined"
     ]
    }
   ],
   "source": [
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = True\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "if 'df_individual' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eed2301-34b0-4aa6-8cf0-721e7516a42a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"page_from\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"page_from\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Only for return and run buttons\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_from\u001b[49m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpages/GPT.py\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjurisdiction_page\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mpage_from\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"page_from\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#Only for return and run buttons\n",
    "\n",
    "if st.session_state.page_from != 'pages/GPT.py':\n",
    "\n",
    "    st.session_state['jurisdiction_page'] = st.session_state.page_from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5e72f-303c-4f68-9e6d-d420aac6625c",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c42ba5-19a1-4e50-a69b-daf68c403ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 144) (3969109139.py, line 144)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 144\u001b[0;36m\u001b[0m\n\u001b[0;31m    st.write(f*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state['df_master'].loc[0, 'Maximum number of judgments']} judgments.*')\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 144)\n"
     ]
    }
   ],
   "source": [
    "return_button = st.button('RETURN to the previous page')\n",
    "\n",
    "#st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "#    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "#st.markdown(\"**:green[Would you like GPT to answer questions about the judgments returned by your search terms?]**\")\n",
    "\n",
    "st.header(\":blue[Would you GPT to answer questions about the judgments returned by your search terms?]\")\n",
    "\n",
    "st.markdown(\"\"\"Please consider trying this program without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract the judgment metadata without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox(label = 'Use GPT', value = st.session_state['df_master'].loc[0, 'Use GPT'])\n",
    "\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = gpt_activation_entry\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default (gpt-4o-mini), Ben's own experience suggests that it costs approximately USD \\$0.01 (excl GST) per judgment. The [exact cost](https://openai.com/pricing) for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced. You will be given ex-post cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your questions for each judgment\")\n",
    "\n",
    "st.markdown(\"\"\"Please enter one question **per line or per paragraph**. GPT will answer your questions for **each** judgment based only on information from **that** judgment. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "#if st.toggle('See the instruction given to GPT'):\n",
    "    #st.write(f\"{intro_for_GPT[0]['content']}\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "gpt_questions_entry = st.text_area(label = f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound, value = st.session_state['df_master'].loc[0, 'Enter your questions for GPT']) \n",
    "\n",
    "if gpt_questions_entry:\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = gpt_questions_entry\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    \n",
    "    st.write(\"Please do not try to obtain personally identifiable information. Your questions and GPT's answers will be checked for potential privacy violation.\")\n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        \n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.session_state['disable_input'] = True\n",
    "        \n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "    \n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-4o-mini. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-4o-mini')*3/4)} words from each judgment.\")\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    \n",
    "    st.subheader(':orange[Enhance program capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of judgments to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle(label = 'Use my own GPT account',  disabled = st.session_state.disable_input, value = st.session_state['df_master'].loc[0, 'Use own account'])\n",
    "    \n",
    "    if own_account_entry:\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = own_account_entry\n",
    "        \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "    \"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state['df_master'].loc[0, 'Your name'])\n",
    "\n",
    "        if name_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your name'] = name_entry\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value =  st.session_state['df_master'].loc[0, 'Your email address'])\n",
    "\n",
    "        if email_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your email address'] = email_entry\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state['df_master'].loc[0, 'Your GPT API key'])\n",
    "        \n",
    "        if gpt_api_key_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "\n",
    "            if ((len(gpt_api_key_entry) < 40) or (gpt_api_key_entry[0:2] != 'sk')):\n",
    "                \n",
    "                st.warning('This key is not valid.')\n",
    " \n",
    "        st.markdown(\"\"\"**:green[You can use the flagship version of GPT model (gpt-4o),]** which is :red[about 30 times more expensive, per character] than the default model (gpt-4o-mini) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the flagship GPT model', value = st.session_state['df_master'].loc[0, 'Use flagship version of GPT'])\n",
    "        st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "\n",
    "        if gpt_enhancement_entry:\n",
    "\n",
    "            st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "        if gpt_enhancement_entry == True:\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o\"\n",
    "            st.session_state.gpt_enhancement_entry = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "            st.session_state.gpt_model = 'gpt-4o-mini'\n",
    "            st.session_state.gpt_enhancement_entry = False\n",
    "        \n",
    "        st.write(f'**:green[You can increase the maximum number of judgments to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        #judgments_counter_bound_entry = round(st.number_input(label = 'Enter a whole number between 1 and 100', min_value=1, max_value=100, value=default_judgment_counter_bound))\n",
    "\n",
    "        #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = judgments_counter_bound_entry\n",
    "\n",
    "        #judgments_counter_bound_entry = st.text_input(label = 'Enter a whole number between 1 and 100', value=str(st.session_state['df_master'].loc[0, 'Maximum number of judgments']))\n",
    "        judgments_counter_bound_entry = st.number_input(label = 'Choose a number between 1 and 100', min_value = 1, max_value = 100, step = 1, value = str_to_int(st.session_state['df_master'].loc[0, 'Maximum number of judgments']))\n",
    "\n",
    "        if judgments_counter_bound_entry:\n",
    "\n",
    "            st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = judgments_counter_bound_entry\n",
    "\n",
    "            #wrong_number_warning = f'You have not entered a whole number between 1 and 100. The program will process up to {default_judgment_counter_bound} judgments instead.'\n",
    "            #try:\n",
    "                #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = int(judgments_counter_bound_entry)\n",
    "            #except:\n",
    "                #st.warning(wrong_number_warning)\n",
    "                #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "\n",
    "            #if ((st.session_state['df_master'].loc[0, 'Maximum number of judgments'] <= 0) or (st.session_state['df_master'].loc[0, 'Maximum number of judgments'] > 100)):\n",
    "                #st.warning(wrong_number_warning)\n",
    "                #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    \n",
    "        st.write(f\"*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state['df_master'].loc[0, 'Maximum number of judgments']} judgment(s).*\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "    \n",
    "        st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7436e-0bc4-4c0e-8fa6-dd0913be35c4",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea67be1-35e1-47c0-a1d1-8f0725ba74e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m st\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBy running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m consent \u001b[38;5;241m=\u001b[39m  st\u001b[38;5;241m.\u001b[39mcheckbox(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes, I agree.\u001b[39m\u001b[38;5;124m'\u001b[39m, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, disabled \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_input\u001b[49m)\n\u001b[1;32m      7\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mIf you do not agree, then please feel free to close this form.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False, disabled = st.session_state.disable_input)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de5f83-ef2d-4c01-b982-3bc66039be7b",
   "metadata": {},
   "source": [
    "## Save entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f011809f-8e34-4709-a9f7-69d3d27e258f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gpt_keep_button = st.button(label = 'DOWNLOAD entries')\n",
    "\n",
    "if gpt_keep_button:\n",
    "    st.success('Scroll down to download your entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc0bb7-5ef8-446b-909d-1729e54adc93",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc1842da-69dd-436b-ab06-c51c84f2b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Next steps\")\n",
    "\n",
    "st.markdown(\"\"\"You can now press :green[PRODUCE data] to obtain a spreadsheet which hopefully has the data you seek.\"\"\")\n",
    "\n",
    "#Warning\n",
    "if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "    st.warning('A low-cost GPT model will answer your questions. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you would like to use the flagship model instead.')\n",
    "\n",
    "if st.session_state.gpt_model == \"gpt-4o\":\n",
    "    st.warning('An expensive GPT model will answer your questions. Please be cautious.')\n",
    "\n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "    run_button = st.button('PRODUCE data')\n",
    "\n",
    "gpt_reset_button = st.button(label='REMOVE data', type = 'primary', disabled = not bool(st.session_state.need_resetting))\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if st.session_state.need_resetting == 1:\n",
    "    if len(st.session_state.df_individual) > 0:\n",
    "        st.warning('You must :red[REMOVE] the data previously produced before processing new search terms or questions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f0eaf-293d-4e38-83fc-144b4bde6ddd",
   "metadata": {},
   "source": [
    "## ER only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39893be5-62af-46a8-9322-8758739f10e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#if st.session_state.gpt_model == \"gpt-4o\":\n",
    "if ((st.session_state.own_account == True) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "    \n",
    "    st.markdown(\"\"\"The English Reports are available as PDFs. By default, this program will use an Optical Character Recognition (OCR) engine to extract text from the relevant PDFs, and then send such text to GPT.\n",
    "    \n",
    "Alternatively, you can send the relevant PDFs to GPT as images. This alternative approach may produce better responses for \"untidy\" PDFs, but tends to be slower and costlier than the default approach.\n",
    "\"\"\")\n",
    "    \n",
    "    #st.write('Not getting the best responses for your images? You can try a more costly')\n",
    "    #b64_help_text = 'GPT will process images directly, instead of text first extracted from images by an Optical Character Recognition engine. This only works for PNG, JPEG, JPG, GIF images.'\n",
    "    er_run_button_b64 = st.button(label = 'SEND PDFs to GPT as images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cafe13-62ac-42d7-b17e-9efa101b1c91",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a528871-82e9-48d1-9af2-56053b82fb5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Create placeholder download buttons if previous entries and output in st.session_state:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_individual\u001b[49m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#st.subheader('Looking for your previous entries and output?')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLooking for your previously produced data?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     df_master \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_master\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#Create placeholder download buttons if previous entries and output in st.session_state:\n",
    "\n",
    "if len(st.session_state.df_individual)>0:\n",
    "    \n",
    "    #st.subheader('Looking for your previous entries and output?')\n",
    "    st.subheader('Looking for your previously produced data?')\n",
    "\n",
    "    df_master = st.session_state.df_master\n",
    "\n",
    "    df_individual = st.session_state.df_individual\n",
    "    \n",
    "    #Load previous entries and output\n",
    "    \n",
    "    #st.write('Previous entries')\n",
    "\n",
    "    #entries_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_entries'\n",
    "\n",
    "    #csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    #ste.download_button(\n",
    "        #label=\"Download your previous entries as a CSV (for use in Excel etc)\", \n",
    "        #data = csv,\n",
    "        #file_name=entries_output_name + '.csv', \n",
    "        #mime= \"text/csv\", \n",
    "    #)\n",
    "\n",
    "    #xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    #ste.download_button(label='Download your previous entries as an Excel spreadsheet (XLSX)',\n",
    "                        #data=xlsx,\n",
    "                        #file_name=entries_output_name + '.xlsx', \n",
    "                        #mime='application/vnd.ms-excel',\n",
    "                       #)\n",
    "\n",
    "    #json = convert_df_to_json(df_master)\n",
    "    \n",
    "    #ste.download_button(\n",
    "        #label=\"Download your previous entries as a JSON\", \n",
    "        #data = json,\n",
    "        #file_name= entries_output_name + '.json', \n",
    "        #mime= \"application/json\", \n",
    "    #)\n",
    "\n",
    "    #st.write('previously produced data')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_output'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previously produced data as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual)\n",
    "    \n",
    "    ste.download_button(label='Download your previously produced data as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previously produced data as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your previous spreadsheet with an AI\", icon = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d72285-64dc-4254-804c-25fd600dc87f",
   "metadata": {},
   "source": [
    "# Run etc buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0108ebb-1002-4e99-94ee-053b30bedb3c",
   "metadata": {},
   "source": [
    "## All except ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a2d50e-12de-402f-9fec-134561fc4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpt_keep_button:\n",
    "\n",
    "    df_master = st.session_state.df_master\n",
    "\n",
    "    #df_master.pop(\"Your GPT API key\")\n",
    "\n",
    "    #df_master.pop(\"Processed\")\n",
    "\n",
    "    responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "\n",
    "    #Produce a file to download\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    st.subheader('Your entries are now available for download.')\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=responses_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=responses_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a JSON\", \n",
    "        data = json,\n",
    "        file_name= responses_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a8fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "    \n",
    "    if int(consent) == 0:\n",
    "        st.warning(\"You must tick '[y]es, I agree[]' to run the program.\")\n",
    "\n",
    "    elif len(st.session_state.df_individual)>0:\n",
    "        st.warning('You must :red[REMOVE] the data produced before processing new search terms or questions.')\n",
    "\n",
    "        #st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    else:\n",
    "\n",
    "        if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                st.error('Your API key is not valid.')\n",
    "                quit()\n",
    "                \n",
    "        #st.write('Your results should be available for download soon. The estimated waiting time is about 3-5 minutes per 10 judgments.')\n",
    "        #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        \n",
    "        with st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...} The estimated waiting time is about 3-5 minutes per 10 judgments.}$\"):\n",
    "            \n",
    "            try:\n",
    "\n",
    "                #Create spreadsheet of responses\n",
    "                df_master = st.session_state.df_master\n",
    "\n",
    "                #Activate user's own key or mine\n",
    "                if st.session_state.own_account == True:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                \n",
    "                openai.api_key = API_key\n",
    "\n",
    "                #Produce results\n",
    "                \n",
    "                jurisdiction_page = st.session_state.jurisdiction_page\n",
    "                \n",
    "                df_individual = gpt_run(jurisdiction_page, df_master)\n",
    "\n",
    "                if len(df_individual) == 0:\n",
    "                    st.error('Your search terms may not return any judgments. Please return to the previous page and press the PREVIEW button to double-check.')\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    #Keep results in session state\n",
    "                    st.session_state[\"df_individual\"] = df_individual\n",
    "    \n",
    "                    #Change session states\n",
    "                    st.session_state['need_resetting'] = 1\n",
    "                    st.session_state[\"page_from\"] = 'pages/GPT.py'           \n",
    "    \n",
    "                    #Write results\n",
    "            \n",
    "                    st.success(\"Your data is now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                    \n",
    "                    #Button for downloading results\n",
    "                    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "            \n",
    "                    csv_output = convert_df_to_csv(df_individual)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your data as a CSV (for use in Excel etc)\", \n",
    "                        data = csv_output,\n",
    "                        file_name= output_name + '.csv', \n",
    "                        mime= \"text/csv\", \n",
    "            #            key='download-csv'\n",
    "                    )\n",
    "            \n",
    "                    excel_xlsx = convert_df_to_excel(df_individual)\n",
    "                    \n",
    "                    ste.download_button(label='Download your data as an Excel spreadsheet (XLSX)',\n",
    "                                        data=excel_xlsx,\n",
    "                                        file_name= output_name + '.xlsx', \n",
    "                                        mime='application/vnd.ms-excel',\n",
    "                                       )\n",
    "            \n",
    "                    json_output = convert_df_to_json(df_individual)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your data as a JSON\", \n",
    "                        data = json_output,\n",
    "                        file_name= output_name + '.json', \n",
    "                        mime= \"application/json\", \n",
    "                    )\n",
    "            \n",
    "                    st.page_link('pages/AI.py', label=\"ANALYSE your data with an AI\", icon = '')\n",
    "    \n",
    "                    #Keep record on Google sheet\n",
    "                    #Obtain google spreadsheet       \n",
    "                    #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                    #df_google = conn.read()\n",
    "                    #df_google = df_google.fillna('')\n",
    "                    #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                    #df_master[\"Processed\"] = datetime.now()\n",
    "                    #df_master.pop(\"Your GPT API key\")\n",
    "                    #df_to_update = pd.concat([df_google, df_master])\n",
    "                    #conn.update(worksheet=\"CTH\", data=df_to_update, )\n",
    "                \n",
    "            except Exception as e:\n",
    "                \n",
    "                st.error('Your search terms may not return any judgments. Please return to the previous page and press the PREVIEW button to double-check.')\n",
    "                \n",
    "                st.exception(e)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if return_button:\n",
    "    \n",
    "    st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "    \n",
    "    st.switch_page(st.session_state.jurisdiction_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if gpt_reset_button:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "    \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "    #To prevent GPT page from showing content of jurisdiction page\n",
    "    st.session_state[\"page_from\"] = st.session_state.jurisdiction_page\n",
    "    \n",
    "    #st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    #st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    #st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "    #clear_cache_except_validation_df_master()\n",
    "    \n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8a34b-2f62-48fa-b810-c6f80401922c",
   "metadata": {},
   "source": [
    "## ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5693cfe-dcc1-47dc-a7f7-bdf2de6cf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((st.session_state.own_account == True) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "\n",
    "    if er_run_button_b64:\n",
    "        \n",
    "        if int(consent) == 0:\n",
    "            st.warning(\"You must tick '[y]es, I agree[]' to run the program.\")\n",
    "    \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            st.warning('You must :red[REMOVE] the data produced before processing new search terms or questions.')\n",
    "    \n",
    "            #st.session_state['need_resetting'] = 1\n",
    "                \n",
    "        else:\n",
    "    \n",
    "            if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                    \n",
    "                if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    quit()\n",
    "                    \n",
    "            #st.write('Your results should be available for download soon. The estimated waiting time is about 3-5 minutes per 10 judgments.')\n",
    "            #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "                \n",
    "            with st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...} The estimated waiting time is about 3-5 minutes per 10 judgments.}$\"):\n",
    "    \n",
    "                try:\n",
    "\n",
    "                    #Definitions and functions for ER\n",
    "                    from pages.ER import er_run, er_run_b64, er_methods_list, er_method_types, er_search, er_search_results_to_case_link_pairs, er_judgment_text, er_meta_judgment_dict, role_content_er, er_judgment_tokens_b64, er_meta_judgment_dict_b64, er_GPT_b64_json, er_engage_GPT_b64_json\n",
    "\n",
    "                    from gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "                    \n",
    "                    system_instruction = role_content_er\n",
    "\n",
    "                    #Create spreadsheet of responses\n",
    "                    df_master = st.session_state.df_master\n",
    "    \n",
    "                    #Activate user's own key or mine\n",
    "                    if st.session_state.own_account == True:\n",
    "                        \n",
    "                        API_key = df_master.loc[0, 'Your GPT API key']\n",
    "        \n",
    "                    else:\n",
    "                        API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                    \n",
    "                    openai.api_key = API_key\n",
    "    \n",
    "                    #Produce results\n",
    "                        \n",
    "                    df_individual = er_run_b64(df_master)\n",
    "\n",
    "                    if len(df_individual) == 0:\n",
    "                        \n",
    "                        st.error('Your search terms may not return any judgments. Please return to the previous page and press the PREVIEW button to double-check.')\n",
    "                    \n",
    "                    else:\n",
    "                        #Keep results in session state\n",
    "                        st.session_state[\"df_individual\"] = df_individual#.astype(str)\n",
    "                \n",
    "                        #Change session states\n",
    "                        st.session_state['need_resetting'] = 1\n",
    "                        \n",
    "                        st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "                        \n",
    "                        #Write results\n",
    "                \n",
    "                        st.success(\"Your data is now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                        \n",
    "                        #Button for downloading results\n",
    "                        output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "                \n",
    "                        csv_output = convert_df_to_csv(df_individual)\n",
    "                        \n",
    "                        ste.download_button(\n",
    "                            label=\"Download your data as a CSV (for use in Excel etc)\", \n",
    "                            data = csv_output,\n",
    "                            file_name= output_name + '.csv', \n",
    "                            mime= \"text/csv\", \n",
    "                #            key='download-csv'\n",
    "                        )\n",
    "                \n",
    "                        excel_xlsx = convert_df_to_excel(df_individual)\n",
    "                        \n",
    "                        ste.download_button(label='Download your data as an Excel spreadsheet (XLSX)',\n",
    "                                            data=excel_xlsx,\n",
    "                                            file_name= output_name + '.xlsx', \n",
    "                                            mime='application/vnd.ms-excel',\n",
    "                                           )\n",
    "                \n",
    "                        json_output = convert_df_to_json(df_individual)\n",
    "                        \n",
    "                        ste.download_button(\n",
    "                            label=\"Download your data as a JSON\", \n",
    "                            data = json_output,\n",
    "                            file_name= output_name + '.json', \n",
    "                            mime= \"application/json\", \n",
    "                        )\n",
    "                \n",
    "                        st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = '')\n",
    "        \n",
    "                            \n",
    "                        #Keep record on Google sheet\n",
    "                        #Obtain google spreadsheet       \n",
    "                        #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                        #df_google = conn.read()\n",
    "                        #df_google = df_google.fillna('')\n",
    "                        #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                        #df_master[\"Processed\"] = datetime.now()\n",
    "                        #df_master.pop(\"Your GPT API key\")\n",
    "                        #df_to_update = pd.concat([df_google, df_master])\n",
    "                        #conn.update(worksheet=\"ER\", data=df_to_update, )\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "                    st.exception(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73fd763-2d2d-4676-9502-f7bbe76cc928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
