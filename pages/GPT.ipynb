{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55460cd1-57af-4b09-a2fd-2f66aef0e361",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89956fa9-e8a0-4fe0-a061-16043f2666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "import copy\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "#from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#aws\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730f0ccb-2adc-431b-b969-188b6227c60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AWS email\n",
    "#Define send email function\n",
    "\n",
    "def send_notification_email(ULTIMATE_RECIPIENT_NAME, ULTIMATE_RECIPIENT_EMAIL):\n",
    "\n",
    "    ses = boto3.client('ses',region_name=st.secrets[\"aws\"][\"AWS_DEFAULT_REGION\"], aws_access_key_id=st.secrets[\"aws\"][\"AWS_ACCESS_KEY_ID\"], aws_secret_access_key=st.secrets[\"aws\"][\"AWS_SECRET_ACCESS_KEY\"])\n",
    "    \n",
    "    #Based on the following upon substituting various arguments, https://docs.aws.amazon.com/ses/latest/dg/send-an-email-using-sdk-programmatically.html\n",
    "    \n",
    "    # Replace sender@example.com with your \"From\" address.\n",
    "    # This address must be verified with Amazon SES.\n",
    "    SENDER = st.secrets[\"email_notifications\"][\"email_sender\"]\n",
    "    \n",
    "    # Replace recipient@example.com with a \"To\" address. If your account \n",
    "    # is still in the sandbox, this address must be verified.\n",
    "    RECIPIENT = st.secrets[\"email_notifications\"][\"email_receiver_personal\"]\n",
    "    \n",
    "    # The subject line for the email.\n",
    "    SUBJECT = f\"LawtoData: {ULTIMATE_RECIPIENT_NAME} has requested data\"\n",
    "    \n",
    "    BODY_TEXT = (\n",
    "    \n",
    "    f\"{ULTIMATE_RECIPIENT_NAME} at {ULTIMATE_RECIPIENT_EMAIL} has requested data via LawtoData.\"\n",
    "    \n",
    "    )\n",
    "      \n",
    "    # The character encoding for the email.\n",
    "    CHARSET = \"UTF-8\"\n",
    "\n",
    "    # Try to send the email.\n",
    "    try:\n",
    "        #Provide the contents of the email.\n",
    "        response = ses.send_email(\n",
    "            Destination={\n",
    "                'ToAddresses': [\n",
    "                    RECIPIENT,\n",
    "                ],\n",
    "            },\n",
    "            Message={\n",
    "                'Body': {\n",
    "                    'Text': {\n",
    "                        'Charset': CHARSET,\n",
    "                        'Data': BODY_TEXT,\n",
    "                    },\n",
    "                },\n",
    "                'Subject': {\n",
    "                    'Charset': CHARSET,\n",
    "                    'Data': SUBJECT,\n",
    "                },\n",
    "            },\n",
    "            Source=SENDER,\n",
    "        )\n",
    "    # Display an error if something goes wrong.\t\n",
    "    except ClientError as e:\n",
    "        print(e.response['Error']['Message'])\n",
    "    #else:\n",
    "        #print(\"Email sent! Message ID:\"),\n",
    "        #print(response['MessageId'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a30617e-0354-4a21-88bb-471f13902510",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, batch_mode_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, str_to_int, pdf_judgment, streamlit_timezone\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, list_range_check, au_date, streamlit_cloud_date_format, save_input\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, batch_mode_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, str_to_int, pdf_judgment, streamlit_timezone\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, list_range_check, au_date, streamlit_cloud_date_format, save_input\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between case scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of case text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e3466-aa47-4fdc-ac82-8b887f475fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from functions.common_functions import open_page, clear_cache_except_validation_df_master, clear_cache, tips, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ffeba0-33ca-4a0b-9531-ab6cdede1691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-06 08:44:13.065 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n"
     ]
    },
    {
     "ename": "NoSessionContext",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSessionContext\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpage_from\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[1;32m      3\u001b[0m     clear_cache()\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswitch_page\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHome.py\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/metrics_util.py:408\u001b[0m, in \u001b[0;36mgather_metrics.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m         _LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to collect command telemetry\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39mex)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mnon_optional_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RerunException \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;66;03m# Duplicated from below, because static analysis tools get confused\u001b[39;00m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# by deferring the rethrow.\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracking_activated \u001b[38;5;129;01mand\u001b[39;00m command_telemetry:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/commands/execution_control.py:144\u001b[0m, in \u001b[0;36mswitch_page\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m    140\u001b[0m ctx \u001b[38;5;241m=\u001b[39m get_script_run_ctx()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mscript_requests:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# This should never be the case\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NoSessionContext()\n\u001b[1;32m    146\u001b[0m page_script_hash \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(page, StreamlitPage):\n",
      "\u001b[0;31mNoSessionContext\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Go back to home page if this page is the first page\n",
    "if 'page_from' not in st.session_state:\n",
    "    clear_cache()\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807795e-e0d7-439c-ba6d-39622f5db1bf",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "753a9bee-88ca-45e4-98d2-267b9e065ef5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_run\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, role_content, judgment_batch_cutoff \u001b[38;5;66;03m#, intro_for_GPT\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_run\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, judgment_batch_cutoff, judgment_batch_max\n",
    "#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe57653-1d9f-4482-976e-c690899e4482",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if batch_mode_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use batch mode. ')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use batch mode.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d29c56-a3b5-4b7b-8e38-8fd300ffd9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab227daa-1c07-4b84-b2b1-f6c39c5a49e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_judgment_counter_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msecrets[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenai\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgments_counter_bound\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m st\u001b[38;5;241m.\u001b[39msession_state:\n\u001b[0;32m---> 14\u001b[0m     st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjudgments_counter_bound\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_judgment_counter_bound\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_judgment_counter_bound' is not defined"
     ]
    }
   ],
   "source": [
    "#Module, costs and upperbounds\n",
    "\n",
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "\n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#if 'judgments_counter_bound' not in st.session_state:\n",
    "    #st.session_state['judgments_counter_bound'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091a562-d6de-416b-b437-8f495dfefbeb",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662bbb1-dbd5-482d-8602-befcb632a92c",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9155575a-3f4b-4645-992d-665959c6db9b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Only for return and run buttons\n",
    "\n",
    "if st.session_state.page_from != 'pages/GPT.py':\n",
    "\n",
    "    st.session_state['jurisdiction_page'] = st.session_state.page_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8618d7ab-f38d-43ad-94a8-8c9c59908c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'default_judgment_counter_bound' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour GPT API key\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMetadata inclusion\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum number of judgments\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdefault_judgment_counter_bound\u001b[49m\n\u001b[1;32m     20\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEnter your questions for GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m st\u001b[38;5;241m.\u001b[39msession_state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf_master\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUse GPT\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'default_judgment_counter_bound' is not defined"
     ]
    }
   ],
   "source": [
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = True\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "if 'df_individual' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True\n",
    "\n",
    "#default_judgment_counter_bound < judgment_batch_cutoff < judgment_batch_max\n",
    "\n",
    "#Instant mode max/batch mode threshold\n",
    "if 'judgment_batch_cutoff' not in st.session_state:\n",
    "    if own_account_allowed() > 0:\n",
    "        st.session_state[\"judgment_batch_cutoff\"] = judgment_batch_cutoff\n",
    "    else:\n",
    "        st.session_state[\"judgment_batch_cutoff\"] = default_judgment_counter_bound\n",
    "\n",
    "#Maximum number of judgments to process under any mode\n",
    "if \"judgment_counter_max\" not in st.session_state:\n",
    "\n",
    "    if ((batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py',  'pages/US.py'])):\n",
    "\n",
    "        if own_account_allowed() > 0:\n",
    "            st.session_state[\"judgment_counter_max\"] = judgment_batch_max\n",
    "        \n",
    "        else:\n",
    "            st.session_state[\"judgment_counter_max\"] = judgment_batch_cutoff\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if own_account_allowed() > 0:\n",
    "            st.session_state[\"judgment_counter_max\"] = judgment_batch_cutoff\n",
    "        \n",
    "        else:\n",
    "            st.session_state[\"judgment_counter_max\"] = default_judgment_counter_bound\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5e72f-303c-4f68-9e6d-d420aac6625c",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18c42ba5-19a1-4e50-a69b-daf68c403ebd",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 144) (3969109139.py, line 144)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[22], line 144\u001b[0;36m\u001b[0m\n\u001b[0;31m    st.write(f*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state['df_master'].loc[0, 'Maximum number of judgments']} judgments.*')\u001b[0m\n\u001b[0m                                                                                                                                                                                                                                                                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 144)\n"
     ]
    }
   ],
   "source": [
    "return_button = st.button('RETURN to the previous page')\n",
    "\n",
    "#st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "st.header(\":blue[Would you to ask GPT questions about the cases returned by your search terms?]\")\n",
    "\n",
    "st.markdown(\"\"\"You can use this app without asking GPT any questions. For instance, you can extract metadata and get estimates of judgment or record length and GPT cost. \n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox(label = 'Use GPT (free by default)', value = st.session_state['df_master'].loc[0, 'Use GPT'])\n",
    "\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = gpt_activation_entry\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default (gpt-4o-mini), Ben's own experience suggests that it costs approximately USD \\$0.01 (excl GST) per case. The [exact cost](https://openai.com/pricing) depends on question length, case length, and answer length. You will be given cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your questions for each case\")\n",
    "\n",
    "st.markdown(\"\"\"Please enter one question **per line or per paragraph**. GPT will answer your questions for **each case** based only on information from the relevant judgment or record **itself**. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment or record itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "#if st.toggle('See the instruction given to GPT'):\n",
    "    #st.write(f\"{intro_for_GPT[0]['content']}\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "gpt_questions_entry = st.text_area(label = f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound, value = st.session_state['df_master'].loc[0, 'Enter your questions for GPT']) \n",
    "\n",
    "if gpt_questions_entry:\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = gpt_questions_entry\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    \n",
    "    st.write(\"Please do not try to obtain personally identifiable information. Your questions and GPT's answers will be checked for potential privacy violation.\")\n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        \n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.session_state['disable_input'] = True\n",
    "        \n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "    \n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-4o-mini. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-4o-mini')*3/4)} words from each case.\")\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    \n",
    "    st.subheader(':orange[Enhance app capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or change the maximum nunber of cases to process? You can do so with your own GPT account.\n",
    "\"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle(label = 'Use my own GPT account',  value = st.session_state['df_master'].loc[0, 'Use own account'])\n",
    "    \n",
    "    if own_account_entry:\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = own_account_entry\n",
    "        \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "\"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state['df_master'].loc[0, 'Your name'])\n",
    "\n",
    "        if name_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your name'] = name_entry\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value =  st.session_state['df_master'].loc[0, 'Your email address'])\n",
    "\n",
    "        if email_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your email address'] = email_entry\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state['df_master'].loc[0, 'Your GPT API key'])\n",
    "        \n",
    "        if gpt_api_key_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "\n",
    "            if ((len(gpt_api_key_entry) < 40) or (gpt_api_key_entry[0:2] != 'sk')):\n",
    "                \n",
    "                st.warning('This key is not valid.')\n",
    " \n",
    "        st.markdown(\"\"\"**:green[You can use the flagship version of GPT (model gpt-4o),]** which is :red[significantly more expensive] than the default model (gpt-4o-mini) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the flagship GPT model', value = st.session_state['df_master'].loc[0, 'Use flagship version of GPT'])\n",
    "        \n",
    "        st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "\n",
    "        if gpt_enhancement_entry:\n",
    "\n",
    "            st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = True\n",
    "            st.session_state.gpt_model = \"gpt-4o-2024-08-06\"\n",
    "\n",
    "        else:\n",
    "            \n",
    "            st.session_state.gpt_model = 'gpt-4o-mini'\n",
    "            st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "        st.write(f'**:green[You can change the maximum number of cases to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        judgments_counter_bound_entry = st.number_input(label = f'Up to {st.session_state[\"judgment_counter_max\"]}', min_value = 1, max_value = st.session_state[\"judgment_counter_max\"], step = 1, value = str_to_int(st.session_state['df_master'].loc[0, 'Maximum number of judgments']))\n",
    "        \n",
    "        if judgments_counter_bound_entry:\n",
    "        \n",
    "            st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = judgments_counter_bound_entry\n",
    "        \n",
    "            if judgments_counter_bound_entry > st.session_state[\"judgment_batch_cutoff\"]:\n",
    "        \n",
    "                st.warning(f\"Given more than {st.session_state['judgment_batch_cutoff']} cases need to be processes, this app will send your requested data to your nominated email address in about **2 business days**.\")\n",
    "\n",
    "        st.write(f\"*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each file, for up to {st.session_state['df_master'].loc[0, 'Maximum number of judgments']} file(s).*\")\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "        st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7436e-0bc4-4c0e-8fa6-dd0913be35c4",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ea67be1-35e1-47c0-a1d1-8f0725ba74e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m st\u001b[38;5;241m.\u001b[39mheader(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsent\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mBy running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m consent \u001b[38;5;241m=\u001b[39m  st\u001b[38;5;241m.\u001b[39mcheckbox(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYes, I agree.\u001b[39m\u001b[38;5;124m'\u001b[39m, value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, disabled \u001b[38;5;241m=\u001b[39m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_input\u001b[49m)\n\u001b[1;32m      7\u001b[0m st\u001b[38;5;241m.\u001b[39mmarkdown(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mIf you do not agree, then please feel free to close this form.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"disable_input\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By using this app, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing data. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False, disabled = st.session_state.disable_input)\n",
    "\n",
    "if consent:\n",
    "    st.session_state['df_master'].loc[0, 'Consent'] = consent\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this app. \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de5f83-ef2d-4c01-b982-3bc66039be7b",
   "metadata": {},
   "source": [
    "## Save entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f011809f-8e34-4709-a9f7-69d3d27e258f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gpt_keep_button = st.button(label = 'DOWNLOAD entries')\n",
    "\n",
    "if gpt_keep_button:\n",
    "    st.success('Scroll down to download your entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc0bb7-5ef8-446b-909d-1729e54adc93",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc1842da-69dd-436b-ab06-c51c84f2b085",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Next steps\")\n",
    "\n",
    "#Instructions\n",
    "st.markdown(f\"\"\"You can now press :green[PRODUCE data] to obtain a spreadsheet which hopefully has the data you seek. Up to {min(st.session_state[\"judgment_batch_cutoff\"], st.session_state['df_master'].loc[0, 'Maximum number of judgments'])} cases will **immediately** be processed. The estimated waiting time is 3-5 minutes per 10 cases.\n",
    "\"\"\")\n",
    "\n",
    "if ((own_account_allowed() > 0) and (batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py',  'pages/US.py'])):\n",
    "    st.markdown(f\"\"\"Alternatively, you can press :orange[REQUEST data] to process up to {st.session_state[\"judgment_counter_max\"]} cases. Your requested data will be sent to your nominated email address in about **2 business days**. \n",
    "\"\"\")\n",
    "\n",
    "#Warning\n",
    "if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "    st.warning('A low-cost GPT model will answer your questions. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you would like to use the flagship model instead.')\n",
    "\n",
    "if st.session_state.gpt_model == \"gpt-4o-2024-08-06\":\n",
    "    st.warning('An expensive GPT model will answer your questions. Please be cautious.')\n",
    "\n",
    "#Buttons\n",
    "\n",
    "gpt_reset_button = st.button(label='REMOVE data', type = 'primary', disabled = not bool(st.session_state.need_resetting))\n",
    "\n",
    "if ((own_account_allowed() > 0) and (batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py',  'pages/US.py'])):\n",
    "    with stylable_container(\n",
    "        \"orange\",\n",
    "        css_styles=\"\"\"\n",
    "        button {\n",
    "            background-color: #F9F500;\n",
    "            color: black;\n",
    "        }\"\"\",\n",
    "    ):\n",
    "        batch_button = st.button(label = 'REQUEST data')#, disabled = not bool(st.session_state['df_master'].loc[0, 'Maximum number of judgments'] > default_judgment_counter_bound))\n",
    "\n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "    run_button = st.button(label = 'PRODUCE data', disabled = bool(st.session_state['df_master'].loc[0, 'Maximum number of judgments'] > st.session_state[\"judgment_batch_cutoff\"]))\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if st.session_state.need_resetting == 1:\n",
    "    if len(st.session_state.df_individual) > 0:\n",
    "        st.warning('You must :red[REMOVE] the data previously produced before producing new data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f0eaf-293d-4e38-83fc-144b4bde6ddd",
   "metadata": {},
   "source": [
    "## ER only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39893be5-62af-46a8-9322-8758739f10e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#if st.session_state.gpt_model == \"gpt-4o\":\n",
    "if ((st.session_state.own_account == True) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "    \n",
    "    st.markdown(\"\"\"The English Reports are available as PDFs. By default, this app will use an Optical Character Recognition (OCR) engine to extract text from the relevant PDFs, and then send such text to GPT.\n",
    "    \n",
    "Alternatively, you can send the relevant PDFs to GPT as images. This alternative approach may produce better responses for \"untidy\" PDFs, but tends to be slower and costlier than the default approach.\n",
    "\"\"\")\n",
    "    \n",
    "    #st.write('Not getting the best responses for your images? You can try a more costly')\n",
    "    #b64_help_text = 'GPT will process images directly, instead of text first extracted from images by an Optical Character Recognition engine. This only works for PNG, JPEG, JPG, GIF images.'\n",
    "    er_run_button_b64 = st.button(label = 'SEND PDFs to GPT as images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cafe13-62ac-42d7-b17e-9efa101b1c91",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a528871-82e9-48d1-9af2-56053b82fb5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "st.session_state has no attribute \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:408\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:453\u001b[0m, in \u001b[0;36mSessionState._getitem\u001b[0;34m(self, widget_id, user_key)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We'll never get here\u001b[39;00m\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:127\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:98\u001b[0m, in \u001b[0;36mSessionStateProxy.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     97\u001b[0m require_valid_user_key(key)\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_session_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/safe_session_state.py:94\u001b[0m, in \u001b[0;36mSafeSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state.py:410\u001b[0m, in \u001b[0;36mSessionState.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(_missing_key_error_message(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'st.session_state has no key \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Create placeholder download buttons if previous entries and output in st.session_state:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf_individual\u001b[49m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m     \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#st.subheader('Looking for your previous entries and output?')\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     st\u001b[38;5;241m.\u001b[39msubheader(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLooking for your previously produced data?\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m     df_master \u001b[38;5;241m=\u001b[39m st\u001b[38;5;241m.\u001b[39msession_state\u001b[38;5;241m.\u001b[39mdf_master\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/streamlit/runtime/state/session_state_proxy.py:129\u001b[0m, in \u001b[0;36mSessionStateProxy.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[key]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(_missing_attr_error_message(key))\n",
      "\u001b[0;31mAttributeError\u001b[0m: st.session_state has no attribute \"df_individual\". Did you forget to initialize it? More info: https://docs.streamlit.io/develop/concepts/architecture/session-state#initialization"
     ]
    }
   ],
   "source": [
    "#Create placeholder download buttons if previous entries and output in st.session_state:\n",
    "\n",
    "if len(st.session_state.df_individual)>0:\n",
    "    \n",
    "    #st.subheader('Looking for your previous entries and output?')\n",
    "    st.subheader('Looking for your previously produced data?')\n",
    "\n",
    "    df_master = st.session_state.df_master\n",
    "\n",
    "    df_individual = st.session_state.df_individual\n",
    "    \n",
    "    #Load previous entries and output\n",
    "    \n",
    "    #st.write('Previous entries')\n",
    "\n",
    "    #entries_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_entries'\n",
    "\n",
    "    #csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    #ste.download_button(\n",
    "        #label=\"Download your previous entries as a CSV (for use in Excel etc)\", \n",
    "        #data = csv,\n",
    "        #file_name=entries_output_name + '.csv', \n",
    "        #mime= \"text/csv\", \n",
    "    #)\n",
    "\n",
    "    #xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    #ste.download_button(label='Download your previous entries as an Excel spreadsheet (XLSX)',\n",
    "                        #data=xlsx,\n",
    "                        #file_name=entries_output_name + '.xlsx', \n",
    "                        #mime='application/vnd.ms-excel',\n",
    "                       #)\n",
    "\n",
    "    #json = convert_df_to_json(df_master)\n",
    "    \n",
    "    #ste.download_button(\n",
    "        #label=\"Download your previous entries as a JSON\", \n",
    "        #data = json,\n",
    "        #file_name= entries_output_name + '.json', \n",
    "        #mime= \"application/json\", \n",
    "    #)\n",
    "\n",
    "    #st.write('previously produced data')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_output'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previously produced data as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual)\n",
    "    \n",
    "    ste.download_button(label='Download your previously produced data as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previously produced data as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your previous spreadsheet with an AI\", icon = '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d72285-64dc-4254-804c-25fd600dc87f",
   "metadata": {},
   "source": [
    "# Run etc buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0108ebb-1002-4e99-94ee-053b30bedb3c",
   "metadata": {},
   "source": [
    "## All except ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71a2d50e-12de-402f-9fec-134561fc4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpt_keep_button:\n",
    "\n",
    "    df_master = st.session_state.df_master.copy(deep=True)\n",
    "\n",
    "    if 'Your GPT API key' in df_master.columns:\n",
    "\n",
    "        df_master.pop(\"Your GPT API key\")\n",
    "\n",
    "    if 'CourtListener API token' in df_master.columns:\n",
    "        \n",
    "        df_master.pop(\"CourtListener API token\")\n",
    "\n",
    "    responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "\n",
    "    #Produce a file to download\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    st.subheader('Your entries are now available for download.')\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=responses_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=responses_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a JSON\", \n",
    "        data = json,\n",
    "        file_name= responses_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a8fa86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if run_button:\n",
    "    \n",
    "    if int(consent) == 0:\n",
    "        st.warning(\"You must tick '[y]es, I agree[]' to use the app.\")\n",
    "\n",
    "    elif len(st.session_state.df_individual)>0:\n",
    "        st.warning('You must :red[REMOVE] the data already produced before producing new data.')\n",
    "\n",
    "        #st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    else:\n",
    "\n",
    "        if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                st.error('Your API key is not valid.')\n",
    "                quit()\n",
    "                \n",
    "        #st.write('Your results should be available for download soon. The estimated waiting time is 3-5 minutes per 10 cases.')\n",
    "        #st.write('If this app produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        with st.spinner(r\"$\\textsf{\\normalsize \\textbf{In progress...} The estimated waiting time is 3-5 minutes per 10 cases.}$\"):\n",
    "            \n",
    "            try:\n",
    "\n",
    "                #Create spreadsheet of responses\n",
    "                df_master = st.session_state.df_master\n",
    "\n",
    "                #Activate user's own key or mine\n",
    "                if st.session_state.own_account == True:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                \n",
    "                openai.api_key = API_key\n",
    "\n",
    "                #Produce results\n",
    "                \n",
    "                jurisdiction_page = st.session_state.jurisdiction_page\n",
    "                \n",
    "                df_individual = gpt_run(jurisdiction_page, df_master)\n",
    "\n",
    "                if len(df_individual) == 0:\n",
    "                    st.error('Your search terms may not return any cases. Please return to the previous page and press the PREVIEW button to double-check.')\n",
    "                \n",
    "                else:\n",
    "                    \n",
    "                    #Keep results in session state\n",
    "                    st.session_state[\"df_individual\"] = df_individual\n",
    "    \n",
    "                    #Change session states\n",
    "                    st.session_state['need_resetting'] = 1\n",
    "                    st.session_state[\"page_from\"] = 'pages/GPT.py'           \n",
    "    \n",
    "                    #Write results\n",
    "            \n",
    "                    st.success(\"Your data is now available for download. Thank you for using *LawtoData*!\")\n",
    "                    \n",
    "                    #Button for downloading results\n",
    "                    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "            \n",
    "                    csv_output = convert_df_to_csv(df_individual)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your data as a CSV (for use in Excel etc)\", \n",
    "                        data = csv_output,\n",
    "                        file_name= output_name + '.csv', \n",
    "                        mime= \"text/csv\", \n",
    "            #            key='download-csv'\n",
    "                    )\n",
    "            \n",
    "                    excel_xlsx = convert_df_to_excel(df_individual)\n",
    "                    \n",
    "                    ste.download_button(label='Download your data as an Excel spreadsheet (XLSX)',\n",
    "                                        data=excel_xlsx,\n",
    "                                        file_name= output_name + '.xlsx', \n",
    "                                        mime='application/vnd.ms-excel',\n",
    "                                       )\n",
    "            \n",
    "                    json_output = convert_df_to_json(df_individual)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your data as a JSON\", \n",
    "                        data = json_output,\n",
    "                        file_name= output_name + '.json', \n",
    "                        mime= \"application/json\", \n",
    "                    )\n",
    "            \n",
    "                    st.page_link('pages/AI.py', label=\"ANALYSE your data with an AI\", icon = '')\n",
    "    \n",
    "                    #Keep record on Google sheet\n",
    "                    #Obtain google spreadsheet       \n",
    "                    #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                    #df_google = conn.read()\n",
    "                    #df_google = df_google.fillna('')\n",
    "                    #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                    #df_master[\"Processed\"] = datetime.now()\n",
    "                    #df_master.pop(\"Your GPT API key\")\n",
    "                    #df_to_update = pd.concat([df_google, df_master])\n",
    "                    #conn.update(worksheet=\"CTH\", data=df_to_update, )\n",
    "                \n",
    "            except Exception as e:\n",
    "                \n",
    "                st.error('Sorry, an error has arisen. Please press PRODUCE data again, or return to the previous page and check your search terms.')\n",
    "                \n",
    "                st.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if return_button:\n",
    "    \n",
    "    st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "\n",
    "    st.switch_page(st.session_state.jurisdiction_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if gpt_reset_button:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "    \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "    #To prevent GPT page from showing content of jurisdiction page\n",
    "    #st.session_state[\"page_from\"] = st.session_state.jurisdiction_page\n",
    "    \n",
    "    #st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    #st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    #st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "    #clear_cache_except_validation_df_master()\n",
    "    \n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8a34b-2f62-48fa-b810-c6f80401922c",
   "metadata": {},
   "source": [
    "## ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d5693cfe-dcc1-47dc-a7f7-bdf2de6cf58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ((st.session_state.own_account == True) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "\n",
    "    if er_run_button_b64:\n",
    "        \n",
    "        if int(consent) == 0:\n",
    "            st.warning(\"You must tick '[y]es, I agree[]' to use the app.\")\n",
    "    \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            st.warning('You must :red[REMOVE] the data already produced before producing new data.')\n",
    "    \n",
    "            #st.session_state['need_resetting'] = 1\n",
    "                \n",
    "        else:\n",
    "    \n",
    "            if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                    \n",
    "                if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    quit()\n",
    "                    \n",
    "            #st.write('Your results should be available for download soon. The estimated waiting time is 3-5 minutes per 10 cases.')\n",
    "            #st.write('If this app produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "                \n",
    "            with st.spinner(r\"$\\textsf{\\normalsize \\textbf{In progress...} The estimated waiting time is 3-5 minutes per 10 cases.}$\"):\n",
    "    \n",
    "                try:\n",
    "\n",
    "                    #Definitions and functions for ER\n",
    "                    from functions.er_functions import er_run, er_run_b64, er_methods_list, er_method_types, er_search, er_search_results_to_case_link_pairs, er_judgment_text, er_meta_judgment_dict, role_content_er, er_judgment_tokens_b64, er_meta_judgment_dict_b64, er_GPT_b64_json, er_engage_GPT_b64_json\n",
    "\n",
    "                    from functions.gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "                    \n",
    "                    system_instruction = role_content_er\n",
    "\n",
    "                    #Create spreadsheet of responses\n",
    "                    df_master = st.session_state.df_master\n",
    "    \n",
    "                    #Activate user's own key or mine\n",
    "                    if st.session_state.own_account == True:\n",
    "                        \n",
    "                        API_key = df_master.loc[0, 'Your GPT API key']\n",
    "        \n",
    "                    else:\n",
    "                        API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                    \n",
    "                    openai.api_key = API_key\n",
    "    \n",
    "                    #Produce results\n",
    "                        \n",
    "                    df_individual = er_run_b64(df_master)\n",
    "\n",
    "                    if len(df_individual) == 0:\n",
    "                        \n",
    "                        st.error('Your search terms may not return any cases. Please return to the previous page and press the PREVIEW button to double-check.')\n",
    "                    \n",
    "                    else:\n",
    "                        #Keep results in session state\n",
    "                        st.session_state[\"df_individual\"] = df_individual#.astype(str)\n",
    "                \n",
    "                        #Change session states\n",
    "                        st.session_state['need_resetting'] = 1\n",
    "                        \n",
    "                        st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "                        \n",
    "                        #Write results\n",
    "                \n",
    "                        st.success(\"Your data is now available for download. Thank you for using *LawtoData*!\")\n",
    "                        \n",
    "                        #Button for downloading results\n",
    "                        output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "                \n",
    "                        csv_output = convert_df_to_csv(df_individual)\n",
    "                        \n",
    "                        ste.download_button(\n",
    "                            label=\"Download your data as a CSV (for use in Excel etc)\", \n",
    "                            data = csv_output,\n",
    "                            file_name= output_name + '.csv', \n",
    "                            mime= \"text/csv\", \n",
    "                #            key='download-csv'\n",
    "                        )\n",
    "                \n",
    "                        excel_xlsx = convert_df_to_excel(df_individual)\n",
    "                        \n",
    "                        ste.download_button(label='Download your data as an Excel spreadsheet (XLSX)',\n",
    "                                            data=excel_xlsx,\n",
    "                                            file_name= output_name + '.xlsx', \n",
    "                                            mime='application/vnd.ms-excel',\n",
    "                                           )\n",
    "                \n",
    "                        json_output = convert_df_to_json(df_individual)\n",
    "                        \n",
    "                        ste.download_button(\n",
    "                            label=\"Download your data as a JSON\", \n",
    "                            data = json_output,\n",
    "                            file_name= output_name + '.json', \n",
    "                            mime= \"application/json\", \n",
    "                        )\n",
    "                \n",
    "                        st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = '')\n",
    "        \n",
    "                            \n",
    "                        #Keep record on Google sheet\n",
    "                        #Obtain google spreadsheet       \n",
    "                        #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                        #df_google = conn.read()\n",
    "                        #df_google = df_google.fillna('')\n",
    "                        #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                        #df_master[\"Processed\"] = datetime.now()\n",
    "                        #df_master.pop(\"Your GPT API key\")\n",
    "                        #df_to_update = pd.concat([df_google, df_master])\n",
    "                        #conn.update(worksheet=\"ER\", data=df_to_update, )\n",
    "                \n",
    "                except Exception as e:\n",
    "                    st.error('Sorry, an error has arisen. Please press PRODUCE data again, or return to the previous page and check your search terms.')\n",
    "                    st.exception(e)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63586fcc-1261-46e4-92d3-b025a60e273f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162dae1-76c7-455e-a935-ce6d5241a5b3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if ((own_account_allowed() > 0) and (batch_mode_allowed() > 0) and (st.session_state.jurisdiction_page in ['pages/HCA.py', 'pages/FCA.py', 'pages/NSW.py',  'pages/US.py'])):\n",
    "    \n",
    "    if batch_button:\n",
    "        \n",
    "        if int(consent) == 0:\n",
    "            st.warning(\"You must tick '[y]es, I agree[]' to use the app.\")\n",
    "    \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            st.warning('You must :red[REMOVE] the data already produced before producing new data.')\n",
    "                \n",
    "        else:\n",
    "    \n",
    "            if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                    \n",
    "                if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    quit()\n",
    "\n",
    "            #Check if valid email address entered\n",
    "            if '@' not in st.session_state['df_master'].loc[0, 'Your email address']:\n",
    "                st.error('You must enter a valid email address to receive your request data.')\n",
    "                quit()\n",
    "            \n",
    "            else:\n",
    "            \n",
    "            #st.write('Your results should be available for download soon. The estimated waiting time is 3-5 minutes per 10 cases.')\n",
    "            #st.write('If this app produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "        \n",
    "                with st.spinner(r\"$\\textsf{\\normalsize \\textbf{In progress...} Please do not close this app.}$\"):\n",
    "                    \n",
    "                    try:\n",
    "        \n",
    "                        #Create spreadsheet of responses\n",
    "                        df_master = st.session_state.df_master\n",
    "        \n",
    "                        #Activate user's own key or mine\n",
    "                        if st.session_state.own_account == True:\n",
    "                            \n",
    "                            API_key = df_master.loc[0, 'Your GPT API key']\n",
    "            \n",
    "                        else:\n",
    "                            API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                        \n",
    "                        openai.api_key = API_key\n",
    "        \n",
    "                        #Produce results\n",
    "                        \n",
    "                        jurisdiction_page = st.session_state.jurisdiction_page\n",
    "        \n",
    "                        df_master['jurisdiction_page'] = jurisdiction_page\n",
    "                        \n",
    "                        df_master['status'] = 'to_process'\n",
    "        \n",
    "                        df_master['submission_time'] = str(datetime.now())\n",
    "        \n",
    "                        #Upload to aws\n",
    "                        #Initiate aws s3\n",
    "                        s3_resource = boto3.resource('s3',region_name=st.secrets[\"aws\"][\"AWS_DEFAULT_REGION\"], aws_access_key_id=st.secrets[\"aws\"][\"AWS_ACCESS_KEY_ID\"], aws_secret_access_key=st.secrets[\"aws\"][\"AWS_SECRET_ACCESS_KEY\"])\n",
    "                        \n",
    "                        #Get a list of all files on s3\n",
    "                        bucket = s3_resource.Bucket('lawtodata')\n",
    "        \n",
    "                        #Get all_df_masters\n",
    "                        for obj in bucket.objects.all():\n",
    "                            key = obj.key\n",
    "                            if key == 'all_df_masters.csv':\n",
    "                                body = obj.get()['Body'].read()\n",
    "                                all_df_masters = pd.read_csv(BytesIO(body), index_col=0)\n",
    "                                break\n",
    "                        #Add df_master to all_df_masters \n",
    "                        all_df_masters = pd.concat([all_df_masters, df_master], ignore_index=True)\n",
    "                        #all_df_masters.reset_index(drop=True)\n",
    "        \n",
    "                        #Upload all_df_masters to aws\n",
    "                        csv_buffer = StringIO()\n",
    "                        all_df_masters.to_csv(csv_buffer)\n",
    "                        s3_resource = boto3.resource('s3',region_name=st.secrets[\"aws\"][\"AWS_DEFAULT_REGION\"], aws_access_key_id=st.secrets[\"aws\"][\"AWS_ACCESS_KEY_ID\"], aws_secret_access_key=st.secrets[\"aws\"][\"AWS_SECRET_ACCESS_KEY\"])\n",
    "                        s3_resource.Object('lawtodata', 'all_df_masters.csv').put(Body=csv_buffer.getvalue())\n",
    "                        \n",
    "                        #Keep record on Google sheet\n",
    "                        #Obtain google spreadsheet       \n",
    "                        #conn = st.connection(\"gsheets_record_df_master\", type=GSheetsConnection, ttl=0)\n",
    "                        #record_df_master = conn.read()\n",
    "                        #record_df_master = record_df_master.fillna('')\n",
    "                        #record_df_master = record_df_master[record_df_master[\"submission_time\"]!='']\n",
    "                        #df_to_update = pd.concat([record_df_master, df_master])\n",
    "                        #conn.update(worksheet=\"Sheet1\", data=df_to_update)\n",
    "                                            \n",
    "                        #Send me an email to let me know\n",
    "                        send_notification_email(ULTIMATE_RECIPIENT_NAME = st.session_state['df_master'].loc[0, 'Your name'], \n",
    "                                                ULTIMATE_RECIPIENT_EMAIL = st.session_state['df_master'].loc[0, 'Your email address']\n",
    "                                               )\n",
    "                        \n",
    "                        st.success('Your request has been submitted. This app will send your requested data to your nominated email address in about **2 business days**. Please feel free to close this app.')\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        \n",
    "                        st.error(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
