{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55460cd1-57af-4b09-a2fd-2f66aef0e361",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89956fa9-e8a0-4fe0-a061-16043f2666ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import PyPDF2\n",
    "import io\n",
    "from io import BytesIO\n",
    "import copy\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a30617e-0354-4a21-88bb-471f13902510",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel \n",
    "#Import variables\n",
    "from common_functions import today_in_nums, today, errors_list, scraper_pause_mean, judgment_text_lower_bound, list_range_check, au_date\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0e3466-aa47-4fdc-ac82-8b887f475fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions and variables\n",
    "from common_functions import open_page, clear_cache_except_validation_df_master, clear_cache, tips, link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ffeba0-33ca-4a0b-9531-ab6cdede1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go back to home page if this page is the first page\n",
    "if 'page_from' not in st.session_state:\n",
    "    clear_cache()\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d807795e-e0d7-439c-ba6d-39622f5db1bf",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "753a9bee-88ca-45e4-98d2-267b9e065ef5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound, role_content \u001b[38;5;66;03m#, intro_for_GPT\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n",
    "#Import variables\n",
    "from gpt_functions import question_characters_bound, default_judgment_counter_bound, role_content #, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d1496fa-129f-44bd-b7da-b8e0b7b0a980",
   "metadata": {},
   "outputs": [],
   "source": [
    "#String to integer\n",
    "def str_to_int(string):\n",
    "    try:\n",
    "        if '.' in string:\n",
    "            output = int(string.split('.')[0])\n",
    "        else:\n",
    "            output = int(string)\n",
    "        return output\n",
    "    except:\n",
    "        return int(default_judgment_counter_bound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab227daa-1c07-4b84-b2b1-f6c39c5a49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Module, costs and upperbounds\n",
    "\n",
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-4o-mini\"\n",
    "\n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bfb110-210d-4c98-bf34-8915ea9c982e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction and functions\n",
    "\n",
    "def gpt_run(jurisdiction_page, df_master):\n",
    "\n",
    "    if jurisdiction_page == 'pages/HCA.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.HCA import hca_run, hca_collections, hca_search, hca_search_results_to_judgment_links, hca_pdf_judgment, hca_meta_labels_droppable, hca_meta_judgment_dict, hca_meta_judgment_dict_alt, hca_mnc_to_link_browse, hca_citation_to_link, hca_mnc_to_link, hca_load_data, hca_data_url, hca_df, hca_judgment_to_exclude, hca_search_results_to_judgment_links_filtered_df\n",
    "    \n",
    "        run = copy.copy(hca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/NSW.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "\n",
    "        from nswcaselaw.search import Search\n",
    "        \n",
    "        from pages.NSW import nsw_run, nsw_meta_labels_droppable, nsw_courts, nsw_courts_positioning, nsw_default_courts, nsw_tribunals, nsw_tribunals_positioning, nsw_court_choice, nsw_tribunal_choice, nsw_date, nsw_link, nsw_short_judgment, nsw_tidying_up\n",
    "    \n",
    "        run = copy.copy(nsw_run)\n",
    "    \n",
    "    if jurisdiction_page == 'pages/FCA.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.FCA import fca_run, fca_courts, fca_courts_list, fca_search, fca_search_url, fca_search_results_to_judgment_links, fca_link_to_doc, fca_pdf_judgment, fca_metalabels, fca_metalabels_droppable, fca_meta_judgment_dict, fca_pdf_name_mnc_list, fca_pdf_name\n",
    "    \n",
    "        run = copy.copy(fca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/CA.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.CA import ca_run, ca_courts, bc_courts, ab_courts, sk_courts, mb_courts, on_courts, qc_courts, nb_courts, ns_courts, pe_courts, nl_courts, yk_courts, nt_courts, nu_courts, all_ca_jurisdiction_court_pairs, ca_court_tribunal_types, all_subjects, ca_search, ca_search_url, ca_search_results_to_judgment_links, ca_meta_labels_droppable, ca_meta_dict, ca_date  \n",
    "        \n",
    "        run = copy.copy(ca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/UK.py':\n",
    "        \n",
    "        system_instruction = role_content\n",
    "        \n",
    "        from pages.UK import uk_run, uk_courts_default_list, uk_courts, uk_courts_list, uk_court_choice, uk_link, uk_search, uk_search_results_to_judgment_links, uk_meta_labels_droppable, uk_meta_judgment_dict\n",
    "        \n",
    "        run = copy.copy(uk_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/AFCA.py':\n",
    "\n",
    "        system_instruction = role_content\n",
    "                \n",
    "        from pages.AFCA import afca_run, product_line_options, product_category_options, product_name_options, issue_type_options, issue_options, afca_search, afca_meta_judgment_dict,  afca_meta_labels_droppable\n",
    "        \n",
    "        run = copy.copy(afca_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/ER.py':\n",
    "\n",
    "        from pages.ER import er_run, er_run_b64, er_methods_list, er_method_types, er_search, er_search_results_to_case_link_pairs, er_judgment_text, er_meta_judgment_dict, role_content_er, er_judgment_tokens_b64, er_meta_judgment_dict_b64, er_GPT_b64_json, er_engage_GPT_b64_json\n",
    "\n",
    "        from gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "\n",
    "        system_instruction = role_content_er\n",
    "\n",
    "        run = copy.copy(er_run)\n",
    "\n",
    "    if jurisdiction_page == 'pages/KR.py':\n",
    "\n",
    "        system_instruction = role_content\n",
    "                \n",
    "        from pages.KR import kr_run, kr_methods_list, kr_method_types, kr_search, kr_search_results_to_case_link_pairs, kr_judgment_text, kr_meta_judgment_dict\n",
    "        \n",
    "        run = copy.copy(kr_run)\n",
    "\n",
    "    \n",
    "    intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]\n",
    "\n",
    "    df_individual = run(df_master)\n",
    "\n",
    "    return df_individual\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7091a562-d6de-416b-b437-8f495dfefbeb",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8662bbb1-dbd5-482d-8602-befcb632a92c",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8618d7ab-f38d-43ad-94a8-8c9c59908c59",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False\n",
    "\n",
    "if 'need_resetting' not in st.session_state:\n",
    "        \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "if 'df_master' not in st.session_state:\n",
    "\n",
    "    #Generally applicable\n",
    "    st.session_state['df_master'] = pd.DataFrame([])\n",
    "    st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Metadata inclusion'] = True\n",
    "    st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "if 'df_individual' not in st.session_state:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "\n",
    "#Disable toggles\n",
    "if 'disable_input' not in st.session_state:\n",
    "    st.session_state[\"disable_input\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eed2301-34b0-4aa6-8cf0-721e7516a42a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Only for return and run buttons\n",
    "\n",
    "if st.session_state.page_from != 'pages/GPT.py':\n",
    "\n",
    "    st.session_state['jurisdiction_page'] = st.session_state.page_from"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd5e72f-303c-4f68-9e6d-d420aac6625c",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c42ba5-19a1-4e50-a69b-daf68c403ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_button = st.button('RETURN to the previous page')\n",
    "\n",
    "#st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "#    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "#st.markdown(\"**:green[Would you like GPT to answer questions about the judgments returned by your search terms?]**\")\n",
    "\n",
    "st.header(\":blue[Would you GPT to answer questions about the judgments returned by your search terms?]\")\n",
    "\n",
    "st.markdown(\"\"\"Please consider trying this program without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract the judgment metadata without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox(label = 'Use GPT', value = st.session_state['df_master'].loc[0, 'Use GPT'])\n",
    "\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Use GPT'] = gpt_activation_entry\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default (gpt-4o-mini), Ben's own experience suggests that it costs approximately USD \\$0.01 (excl GST) per judgment. The [exact cost](https://openai.com/pricing) for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced. You will be given ex-post cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your questions for each judgment\")\n",
    "\n",
    "st.markdown(\"\"\"Please enter one question **per line or per paragraph**. GPT will answer your questions for **each** judgment based only on information from **that** judgment. \"\"\")\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "#if st.toggle('See the instruction given to GPT'):\n",
    "    #st.write(f\"{intro_for_GPT[0]['content']}\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "gpt_questions_entry = st.text_area(label = f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound, value = st.session_state['df_master'].loc[0, 'Enter your questions for GPT']) \n",
    "\n",
    "if gpt_questions_entry:\n",
    "    \n",
    "    st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = gpt_questions_entry\n",
    "\n",
    "#Disable toggles while prompt is not entered or the same as the last processed prompt\n",
    "if gpt_activation_entry:\n",
    "    \n",
    "    if gpt_questions_entry:\n",
    "        \n",
    "        st.session_state['disable_input'] = False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.session_state['disable_input'] = True\n",
    "        \n",
    "else:\n",
    "    st.session_state['disable_input'] = False\n",
    "    \n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-4o-mini. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-4o-mini')*3/4)} words from each judgment.\")\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    \n",
    "    st.subheader(':orange[Enhance program capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of judgments to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle(label = 'Use my own GPT account',  disabled = st.session_state.disable_input, value = st.session_state['df_master'].loc[0, 'Use own account'])\n",
    "    \n",
    "    if own_account_entry:\n",
    "\n",
    "        st.session_state['df_master'].loc[0, 'Use own account'] = own_account_entry\n",
    "        \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage [here](https://platform.openai.com/signup). You can then create and find your API key [here](https://platform.openai.com/api-keys).\n",
    "    \"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state['df_master'].loc[0, 'Your name'])\n",
    "\n",
    "        if name_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your name'] = name_entry\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value =  st.session_state['df_master'].loc[0, 'Your email address'])\n",
    "\n",
    "        if email_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your email address'] = email_entry\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state['df_master'].loc[0, 'Your GPT API key'])\n",
    "        \n",
    "        if gpt_api_key_entry:\n",
    "            \n",
    "            st.session_state['df_master'].loc[0, 'Your GPT API key'] = gpt_api_key_entry\n",
    "\n",
    "            if ((len(gpt_api_key_entry) < 40) or (gpt_api_key_entry[0:2] != 'sk')):\n",
    "                \n",
    "                st.warning('This key is not valid.')\n",
    " \n",
    "        st.markdown(\"\"\"**:green[You can use the flagship version of GPT model (gpt-4o),]** which is :red[about 30 times more expensive, per character] than the default model (gpt-4o-mini) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the flagship GPT model', value = st.session_state['df_master'].loc[0, 'Use flagship version of GPT'])\n",
    "        st.caption('Click [here](https://openai.com/api/pricing) for pricing information on different GPT models.')\n",
    "\n",
    "        if gpt_enhancement_entry:\n",
    "\n",
    "            st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "\n",
    "        if gpt_enhancement_entry == True:\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4o\"\n",
    "            st.session_state.gpt_enhancement_entry = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "            st.session_state.gpt_model = 'gpt-4o-mini'\n",
    "            st.session_state.gpt_enhancement_entry = False\n",
    "        \n",
    "        st.write(f'**:green[You can increase the maximum number of judgments to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        #judgments_counter_bound_entry = round(st.number_input(label = 'Enter a whole number between 1 and 100', min_value=1, max_value=100, value=default_judgment_counter_bound))\n",
    "\n",
    "        #st.session_state.judgments_counter_bound = judgments_counter_bound_entry\n",
    "\n",
    "        #judgments_counter_bound_entry = st.text_input(label = 'Enter a whole number between 1 and 100', value=str(st.session_state['df_master'].loc[0, 'Maximum number of judgments']))\n",
    "        judgments_counter_bound_entry = st.number_input(label = 'Choose a number between 1 and 100', min_value = 1, max_value = 100, step = 1, value = str_to_int(st.session_state['df_master'].loc[0, 'Maximum number of judgments']))\n",
    "\n",
    "        if judgments_counter_bound_entry:\n",
    "\n",
    "            st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = judgments_counter_bound_entry\n",
    "\n",
    "            #wrong_number_warning = f'You have not entered a whole number between 1 and 100. The program will process up to {default_judgment_counter_bound} judgments instead.'\n",
    "            #try:\n",
    "                #st.session_state.judgments_counter_bound = int(judgments_counter_bound_entry)\n",
    "            #except:\n",
    "                #st.warning(wrong_number_warning)\n",
    "                #st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "\n",
    "            #if ((st.session_state.judgments_counter_bound <= 0) or (st.session_state.judgments_counter_bound > 100)):\n",
    "                #st.warning(wrong_number_warning)\n",
    "                #st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "    \n",
    "        st.write(f'*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state.judgments_counter_bound} judgments.*')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-4o-mini\"\n",
    "\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "    \n",
    "        st.session_state.judgments_counter_bound = default_judgment_counter_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e7436e-0bc4-4c0e-8fa6-dd0913be35c4",
   "metadata": {},
   "source": [
    "## Consent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea67be1-35e1-47c0-a1d1-8f0725ba74e5",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running this program, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False, disabled = st.session_state.disable_input)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de5f83-ef2d-4c01-b982-3bc66039be7b",
   "metadata": {},
   "source": [
    "## Save entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011809f-8e34-4709-a9f7-69d3d27e258f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "gpt_keep_button = st.button(label = 'DOWNLOAD entries')\n",
    "\n",
    "if gpt_keep_button:\n",
    "    st.success('Scroll down to download your entries.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cc0bb7-5ef8-446b-909d-1729e54adc93",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1842da-69dd-436b-ab06-c51c84f2b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Next steps\")\n",
    "\n",
    "st.markdown(\"\"\"You can now press :green[PRODUCE data] to obtain a spreadsheet which hopefully has the data you seek.\"\"\")\n",
    "\n",
    "#Warning\n",
    "if st.session_state.gpt_model == 'gpt-4o-mini':\n",
    "    st.warning('A low-cost GPT model will answer your questions. Please reach out to Ben Chen at ben.chen@sydney.edu.au if you would like to use the flagship model instead.')\n",
    "\n",
    "if st.session_state.gpt_model == \"gpt-4o\":\n",
    "    st.warning('An expensive GPT model will answer your questions. Please be cautious.')\n",
    "\n",
    "with stylable_container(\n",
    "    \"green\",\n",
    "    css_styles=\"\"\"\n",
    "    button {\n",
    "        background-color: #00FF00;\n",
    "        color: black;\n",
    "    }\"\"\",\n",
    "):\n",
    "    run_button = st.button('PRODUCE data')\n",
    "\n",
    "gpt_reset_button = st.button(label='REMOVE data', type = 'primary', disabled = not bool(st.session_state.need_resetting))\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if st.session_state.need_resetting == 1:\n",
    "    if len(st.session_state.df_individual) > 0:\n",
    "        st.warning('You must :red[REMOVE] the data previously produced before processing new search terms or questions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088f0eaf-293d-4e38-83fc-144b4bde6ddd",
   "metadata": {},
   "source": [
    "## ER only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39893be5-62af-46a8-9322-8758739f10e4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#if st.session_state.gpt_model == \"gpt-4o\":\n",
    "if ((st.session_state.own_account == True) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "    \n",
    "    st.markdown(\"\"\"The English Reports are available as PDFs. By default, this program will use an Optical Character Recognition (OCR) engine to extract text from the relevant PDFs, and then send such text to GPT.\n",
    "    \n",
    "Alternatively, you can send the relevant PDFs to GPT as images. This alternative approach may produce better responses for \"untidy\" PDFs, but tends to be slower and costlier than the default approach.\n",
    "\"\"\")\n",
    "    \n",
    "    #st.write('Not getting the best responses for your images? You can try a more costly')\n",
    "    #b64_help_text = 'GPT will process images directly, instead of text first extracted from images by an Optical Character Recognition engine. This only works for PNG, JPEG, JPG, GIF images.'\n",
    "    er_run_button_b64 = st.button(label = 'SEND PDFs to GPT as images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cafe13-62ac-42d7-b17e-9efa101b1c91",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a528871-82e9-48d1-9af2-56053b82fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create placeholder download buttons if previous entries and output in st.session_state:\n",
    "\n",
    "if len(st.session_state.df_individual)>0:\n",
    "    \n",
    "    #st.subheader('Looking for your previous entries and output?')\n",
    "    st.subheader('Looking for your previously produced data?')\n",
    "\n",
    "    df_master = st.session_state.df_master\n",
    "\n",
    "    df_individual = st.session_state.df_individual\n",
    "    \n",
    "    #Load previous entries and output\n",
    "    \n",
    "    #st.write('Previous entries')\n",
    "\n",
    "    #entries_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_entries'\n",
    "\n",
    "    #csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    #ste.download_button(\n",
    "        #label=\"Download your previous entries as a CSV (for use in Excel etc)\", \n",
    "        #data = csv,\n",
    "        #file_name=entries_output_name + '.csv', \n",
    "        #mime= \"text/csv\", \n",
    "    #)\n",
    "\n",
    "    #xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    #ste.download_button(label='Download your previous entries as an Excel spreadsheet (XLSX)',\n",
    "                        #data=xlsx,\n",
    "                        #file_name=entries_output_name + '.xlsx', \n",
    "                        #mime='application/vnd.ms-excel',\n",
    "                       #)\n",
    "\n",
    "    #json = convert_df_to_json(df_master)\n",
    "    \n",
    "    #ste.download_button(\n",
    "        #label=\"Download your previous entries as a JSON\", \n",
    "        #data = json,\n",
    "        #file_name= entries_output_name + '.json', \n",
    "        #mime= \"application/json\", \n",
    "    #)\n",
    "\n",
    "    #st.write('previously produced data')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_output'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previously produced data as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual)\n",
    "    \n",
    "    ste.download_button(label='Download your previously produced data as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previously produced data as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your previous spreadsheet with an AI\", icon = '🤔')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d72285-64dc-4254-804c-25fd600dc87f",
   "metadata": {},
   "source": [
    "# Run etc buttons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0108ebb-1002-4e99-94ee-053b30bedb3c",
   "metadata": {},
   "source": [
    "## All except ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2d50e-12de-402f-9fec-134561fc4e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gpt_keep_button:\n",
    "\n",
    "    df_master = st.session_state.df_master\n",
    "\n",
    "    #df_master.pop(\"Your GPT API key\")\n",
    "\n",
    "    #df_master.pop(\"Processed\")\n",
    "\n",
    "    responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "\n",
    "    #Produce a file to download\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    st.subheader('Your entries are now available for download.')\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=responses_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=responses_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download as a JSON\", \n",
    "        data = json,\n",
    "        file_name= responses_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8fa86",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if run_button:\n",
    "    \n",
    "    if int(consent) == 0:\n",
    "        st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "\n",
    "    elif len(st.session_state.df_individual)>0:\n",
    "        st.warning('You must :red[REMOVE] the data produced before processing new search terms or questions.')\n",
    "\n",
    "        #st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    else:\n",
    "\n",
    "        if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                \n",
    "            if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                st.error('Your API key is not valid.')\n",
    "                quit()\n",
    "                \n",
    "        #st.write('Your results should be available for download soon. The estimated waiting time is about 3-5 minutes per 10 judgments.')\n",
    "        #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        \n",
    "        with st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...} The estimated waiting time is about 3-5 minutes per 10 judgments.}$\"):\n",
    "            \n",
    "            try:\n",
    "\n",
    "                #Create spreadsheet of responses\n",
    "                df_master = st.session_state.df_master\n",
    "\n",
    "                #Activate user's own key or mine\n",
    "                if st.session_state.own_account == True:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                \n",
    "                openai.api_key = API_key\n",
    "\n",
    "                #Produce results\n",
    "                \n",
    "                jurisdiction_page = st.session_state.jurisdiction_page\n",
    "                \n",
    "                df_individual = gpt_run(jurisdiction_page, df_master)\n",
    "        \n",
    "                #Keep results in session state\n",
    "                st.session_state[\"df_individual\"] = df_individual\n",
    "\n",
    "\n",
    "                #Change session states\n",
    "                st.session_state['need_resetting'] = 1\n",
    "                st.session_state[\"page_from\"] = 'pages/GPT.py'           \n",
    "\n",
    "                #Write results\n",
    "        \n",
    "                st.success(\"Your data is now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                \n",
    "                #Button for downloading results\n",
    "                output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "        \n",
    "                csv_output = convert_df_to_csv(df_individual)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your data as a CSV (for use in Excel etc)\", \n",
    "                    data = csv_output,\n",
    "                    file_name= output_name + '.csv', \n",
    "                    mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "                )\n",
    "        \n",
    "                excel_xlsx = convert_df_to_excel(df_individual)\n",
    "                \n",
    "                ste.download_button(label='Download your data as an Excel spreadsheet (XLSX)',\n",
    "                                    data=excel_xlsx,\n",
    "                                    file_name= output_name + '.xlsx', \n",
    "                                    mime='application/vnd.ms-excel',\n",
    "                                   )\n",
    "        \n",
    "                json_output = convert_df_to_json(df_individual)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your data as a JSON\", \n",
    "                    data = json_output,\n",
    "                    file_name= output_name + '.json', \n",
    "                    mime= \"application/json\", \n",
    "                )\n",
    "        \n",
    "                st.page_link('pages/AI.py', label=\"ANALYSE your data with an AI\", icon = '🤔')\n",
    "\n",
    "                #Keep record on Google sheet\n",
    "                #Obtain google spreadsheet       \n",
    "                #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                #df_google = conn.read()\n",
    "                #df_google = df_google.fillna('')\n",
    "                #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                #df_master[\"Processed\"] = datetime.now()\n",
    "                #df_master.pop(\"Your GPT API key\")\n",
    "                #df_to_update = pd.concat([df_google, df_master])\n",
    "                #conn.update(worksheet=\"CTH\", data=df_to_update, )\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error('Your search terms may not return any judgments. Please return to the previous page and press the PREVIEW button to double-check.')\n",
    "                st.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if return_button:\n",
    "    \n",
    "    st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "    \n",
    "    st.switch_page(st.session_state.jurisdiction_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if gpt_reset_button:\n",
    "\n",
    "    st.session_state['df_individual'] = pd.DataFrame([])\n",
    "    \n",
    "    st.session_state['need_resetting'] = 0\n",
    "\n",
    "    #To prevent GPT page from showing content of jurisdiction page\n",
    "    st.session_state[\"page_from\"] = st.session_state.jurisdiction_page\n",
    "    \n",
    "    #st.session_state['df_master'].loc[0, 'Your name'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Your email address'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Your GPT API key'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Maximum number of judgments'] = default_judgment_counter_bound\n",
    "    #st.session_state['df_master'].loc[0, 'Enter your questions for GPT'] = ''\n",
    "    #st.session_state['df_master'].loc[0, 'Use GPT'] = False\n",
    "    #st.session_state['df_master'].loc[0, 'Use own account'] = False\n",
    "    #st.session_state['df_master'].loc[0, 'Use flagship version of GPT'] = False\n",
    "    \n",
    "    #clear_cache_except_validation_df_master()\n",
    "    \n",
    "    st.rerun()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa8a34b-2f62-48fa-b810-c6f80401922c",
   "metadata": {},
   "source": [
    "## ER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5693cfe-dcc1-47dc-a7f7-bdf2de6cf58d",
   "metadata": {
    "lines_to_next_cell": 3
   },
   "outputs": [],
   "source": [
    "if ((st.session_state.own_account == True) and (st.session_state.jurisdiction_page == 'pages/ER.py')):\n",
    "\n",
    "    if er_run_button_b64:\n",
    "        \n",
    "        if int(consent) == 0:\n",
    "            st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "    \n",
    "        elif len(st.session_state.df_individual)>0:\n",
    "            st.warning('You must :red[REMOVE] the data produced before processing new search terms or questions.')\n",
    "    \n",
    "            #st.session_state['need_resetting'] = 1\n",
    "                \n",
    "        else:\n",
    "    \n",
    "            if ((st.session_state.own_account == True) and (st.session_state['df_master'].loc[0, 'Use GPT'] == True)):\n",
    "                                    \n",
    "                if is_api_key_valid(gpt_api_key_entry) == False:\n",
    "                    st.error('Your API key is not valid.')\n",
    "                    quit()\n",
    "                    \n",
    "            #st.write('Your results should be available for download soon. The estimated waiting time is about 3-5 minutes per 10 judgments.')\n",
    "            #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "                \n",
    "            with st.spinner(r\"$\\textsf{\\normalsize \\textbf{Running...} The estimated waiting time is about 3-5 minutes per 10 judgments.}$\"):\n",
    "    \n",
    "                try:\n",
    "\n",
    "                    #Definitions and functions for ER\n",
    "                    from pages.ER import er_run, er_run_b64, er_methods_list, er_method_types, er_search, er_search_results_to_case_link_pairs, er_judgment_text, er_meta_judgment_dict, role_content_er, er_judgment_tokens_b64, er_meta_judgment_dict_b64, er_GPT_b64_json, er_engage_GPT_b64_json\n",
    "\n",
    "                    from gpt_functions import get_image_dims, calculate_image_token_cost\n",
    "                    \n",
    "                    system_instruction = role_content_er\n",
    "\n",
    "                    #Create spreadsheet of responses\n",
    "                    df_master = st.session_state.df_master\n",
    "    \n",
    "                    #Activate user's own key or mine\n",
    "                    if st.session_state.own_account == True:\n",
    "                        \n",
    "                        API_key = df_master.loc[0, 'Your GPT API key']\n",
    "        \n",
    "                    else:\n",
    "                        API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                    \n",
    "                    openai.api_key = API_key\n",
    "    \n",
    "                    #Produce results\n",
    "                        \n",
    "                    df_individual = er_run_b64(df_master)\n",
    "    \n",
    "                    #Keep results in session state\n",
    "                    st.session_state[\"df_individual\"] = df_individual#.astype(str)\n",
    "            \n",
    "                    #Change session states\n",
    "                    st.session_state['need_resetting'] = 1\n",
    "                    \n",
    "                    st.session_state[\"page_from\"] = 'pages/GPT.py'\n",
    "                    \n",
    "                    #Write results\n",
    "            \n",
    "                    st.success(\"Your data is now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                    \n",
    "                    #Button for downloading results\n",
    "                    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "            \n",
    "                    csv_output = convert_df_to_csv(df_individual)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your data as a CSV (for use in Excel etc)\", \n",
    "                        data = csv_output,\n",
    "                        file_name= output_name + '.csv', \n",
    "                        mime= \"text/csv\", \n",
    "            #            key='download-csv'\n",
    "                    )\n",
    "            \n",
    "                    excel_xlsx = convert_df_to_excel(df_individual)\n",
    "                    \n",
    "                    ste.download_button(label='Download your data as an Excel spreadsheet (XLSX)',\n",
    "                                        data=excel_xlsx,\n",
    "                                        file_name= output_name + '.xlsx', \n",
    "                                        mime='application/vnd.ms-excel',\n",
    "                                       )\n",
    "            \n",
    "                    json_output = convert_df_to_json(df_individual)\n",
    "                    \n",
    "                    ste.download_button(\n",
    "                        label=\"Download your data as a JSON\", \n",
    "                        data = json_output,\n",
    "                        file_name= output_name + '.json', \n",
    "                        mime= \"application/json\", \n",
    "                    )\n",
    "            \n",
    "                    st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = '🤔')\n",
    "    \n",
    "                        \n",
    "                    #Keep record on Google sheet\n",
    "                    #Obtain google spreadsheet       \n",
    "                    #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                    #df_google = conn.read()\n",
    "                    #df_google = df_google.fillna('')\n",
    "                    #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                    #df_master[\"Processed\"] = datetime.now()\n",
    "                    #df_master.pop(\"Your GPT API key\")\n",
    "                    #df_to_update = pd.concat([df_google, df_master])\n",
    "                    #conn.update(worksheet=\"ER\", data=df_to_update, )\n",
    "            \n",
    "                except Exception as e:\n",
    "                    st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "                    st.exception(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
