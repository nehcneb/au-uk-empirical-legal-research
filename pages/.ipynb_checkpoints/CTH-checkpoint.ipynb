{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import PyPDF2\n",
    "import io\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from io import BytesIO\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'default'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Whether users are allowed to use their account\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdefault\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m own_account_allowed() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBy default, users are allowed to use their own account\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'default'"
     ]
    }
   ],
   "source": [
    "#Whether users are allowed to use their account\n",
    "from extra_functions import own_account_allowed\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb182b0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Get current directory\n",
    "current_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd94f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#today\n",
    "\n",
    "today_in_nums = str(datetime.now())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9921c6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate placeholder list of errors\n",
    "errors_list = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8964258",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "#Create function for saving responses and results\n",
    "def convert_df_to_json(df):\n",
    "    return df.to_json(orient = 'split', compression = 'infer')\n",
    "\n",
    "def convert_df_to_csv(df):\n",
    "   return df.to_csv(index=False).encode('utf-8')\n",
    "\n",
    "#Excel metadata\n",
    "excel_author = 'The Empirical Legal Research Kickstarter'\n",
    "excel_description = 'A 2022 University of Sydney Research Accelerator (SOAR) Prize partially funded the development of the Empirical Legal Research Kickstarter, which generated this spreadsheet.'\n",
    "\n",
    "def convert_df_to_excel(df):\n",
    "    output = BytesIO()\n",
    "    writer = pd.ExcelWriter(output, engine='xlsxwriter')\n",
    "    df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    workbook = writer.book\n",
    "    workbook.set_properties({\"author\": excel_author, \"comments\": excel_description})\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "#    format1 = workbook.add_format({'num_format': '0.00'}) \n",
    "    worksheet.set_column('A:A', None)#, format1)  \n",
    "    writer.save()\n",
    "    processed_data = output.getvalue()\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94f73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title of webpage\n",
    "st.set_page_config(\n",
    "   page_title=\"Empirical Legal Research Kickstarter\",\n",
    "   page_icon=\"ðŸ§Š\",\n",
    "   layout=\"centered\",\n",
    "   initial_sidebar_state=\"collapsed\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# Federal Courts search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea041f78-3427-4b39-8a16-4e8b828bed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pause between judgment scraping\n",
    "\n",
    "#scraper_pause = 5\n",
    "\n",
    "#print(f\"The pause between judgment scraping is {scraper_pause} second.\\n\")\n",
    "\n",
    "scraper_pause_mean = int((15-5)/2)\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3329d8-1716-4570-8dd0-4b5aa22aaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define format functions for headnotes choice, courts choice, and GPT questions\n",
    "\n",
    "#Create function to split a string into a list by line\n",
    "def split_by_line(x):\n",
    "    y = x.split('\\n')\n",
    "    for i in y:\n",
    "        if len(i) == 0:\n",
    "            y.remove(i)\n",
    "    return y\n",
    "\n",
    "#Create function to split a list into a dictionary for list items longer than 10 characters\n",
    "#Apply split_by_line() before the following function\n",
    "def GPT_label_dict(x_list):\n",
    "    GPT_dict = {}\n",
    "    for i in x_list:\n",
    "        if len(i) > 10:\n",
    "            GPT_index = x_list.index(i) + 1\n",
    "            i_label = 'GPT question ' + f'{GPT_index}'\n",
    "            GPT_dict.update({i_label: i})\n",
    "    return GPT_dict\n",
    "\n",
    "#Functions for tidying up\n",
    "\n",
    "#Tidy up hyperlink\n",
    "def link(x):\n",
    "    value = '=HYPERLINK(\"' + str(x) + '\")'\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f0e228-8b90-4951-83fb-7668f7010106",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to create dataframe\n",
    "def create_df():\n",
    "\n",
    "    #submission time\n",
    "    timestamp = datetime.now()\n",
    "\n",
    "\n",
    "    #Personal info entries\n",
    "\n",
    "    name = ''\n",
    "    \n",
    "    email = ''\n",
    "\n",
    "    gpt_api_key = ''\n",
    "\n",
    "    try:\n",
    "        name = name_entry\n",
    "    except:\n",
    "        print('Name not entered')\n",
    "    \n",
    "    try:\n",
    "        email = email_entry\n",
    "    except:\n",
    "        print('Email not entered')\n",
    "\n",
    "    try:\n",
    "        gpt_api_key = gpt_api_key_entry\n",
    "    except:\n",
    "        print('API key not entered')\n",
    "\n",
    "    \n",
    "    #Own account status\n",
    "    own_account = st.session_state.own_account\n",
    "    \n",
    "    #Judgment counter bound\n",
    "    judgments_counter_bound = st.session_state.judgments_counter_bound\n",
    "\n",
    "    #GPT enhancement\n",
    "    gpt_enhancement = st.session_state.gpt_enhancement_entry\n",
    "    \n",
    "    #dates\n",
    "    \n",
    "    on_this_date = ''\n",
    "\n",
    "    if on_this_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            #on_this_date = on_this_date_entry.strftime('%d/%m/%Y') + on_this_date_entry.strftime('%d') + on_this_date_entry.strftime('%B').lower()[:3] + on_this_date_entry.strftime('Y')\n",
    "\n",
    "            on_this_date = str(on_this_date_entry.strftime('%d')) + str(on_this_date_entry.strftime('%B')).lower()[:3] + str(on_this_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    \n",
    "    before_date = ''\n",
    "\n",
    "    if before_date_entry != 'None':\n",
    "\n",
    "        try:\n",
    "\n",
    "            before_date = str(before_date_entry.strftime('%d')) + str(before_date_entry.strftime('%B')).lower()[:3] + str(before_date_entry.strftime('%Y'))\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    \n",
    "    after_date = ''\n",
    "\n",
    "    if after_date_entry != 'None':\n",
    "        \n",
    "        try:\n",
    "            after_date = str(after_date_entry.strftime('%d')) + str(after_date_entry.strftime('%B')).lower()[:3] + str(after_date_entry.strftime('%Y'))\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "\n",
    "    #Other entries\n",
    "    case_name_mnc = case_name_mnc_entry\n",
    "    judge =  judge_entry\n",
    "    reported_citation = reported_citation_entry\n",
    "    file_number = file_number_entry\n",
    "    npa = npa_entry\n",
    "    with_all_the_words = with_all_the_words_entry\n",
    "    with_at_least_one_of_the_words = with_at_least_one_of_the_words_entry\n",
    "    without_the_words = without_the_words_entry\n",
    "    phrase = phrase_entry\n",
    "    proximity = proximity_entry\n",
    "    legislation = legislation_entry\n",
    "    cases_cited = cases_cited_entry\n",
    "    catchwords = catchwords_entry \n",
    "    \n",
    "    #GPT choice and entry\n",
    "    gpt_activation_status = gpt_activation_entry\n",
    "    \n",
    "    gpt_questions = ''\n",
    "    \n",
    "    try:\n",
    "        gpt_questions = gpt_questions_entry[0: 1000]\n",
    "    \n",
    "    except:\n",
    "        print('GPT questions not entered.')\n",
    "\n",
    "    #metadata choice\n",
    "\n",
    "    meta_data_choice = meta_data_entry\n",
    "    \n",
    "    new_row = {'Processed': '',\n",
    "           'Timestamp': timestamp,\n",
    "           'Your name': name, \n",
    "           'Your email address': email, \n",
    "           'Your GPT API key': gpt_api_key, \n",
    "           'Case name or medium neutral citation': case_name_mnc, \n",
    "           'Judge' : judge, \n",
    "            'Reported citation' : reported_citation, \n",
    "            'File number': file_number,\n",
    "            'National practice area': npa,\n",
    "            'With all the words': with_all_the_words,\n",
    "            'With at least one of the words': with_at_least_one_of_the_words,\n",
    "            'Without the words': without_the_words,\n",
    "            'Phrase': phrase,\n",
    "            'Proximity': proximity,\n",
    "            'On this date': on_this_date,\n",
    "            'After date': after_date,\n",
    "            'Before date': before_date,\n",
    "            'Legislation': legislation,\n",
    "            'Cases cited': cases_cited,\n",
    "            'Catchwords' : catchwords, \n",
    "            'Metadata inclusion' : meta_data_choice,\n",
    "           'Maximum number of judgments': judgments_counter_bound, \n",
    "           'Enter your question(s) for GPT': gpt_questions, \n",
    "            'Use GPT': gpt_activation_status,\n",
    "           'Use own account': own_account,\n",
    "            'Use latest version of GPT' : gpt_enhancement\n",
    "          }\n",
    "\n",
    "    df_master_new = pd.DataFrame(new_row, index = [0])\n",
    "    \n",
    "#    df_master_new.to_json(current_dir + '/df_master.json', orient = 'split', compression = 'infer')\n",
    "#    df_master_new.to_excel(current_dir + '/df_master.xlsx', index=False)\n",
    "\n",
    "#    if len(df_master_new) > 0:\n",
    "        \n",
    "    return df_master_new\n",
    "\n",
    "#    else:\n",
    "#        return 'Error: spreadsheet of reponses NOT generated.' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url\n",
    "def fca_search(case_name_mnc= '', \n",
    "               judge ='', \n",
    "               reported_citation ='', \n",
    "               file_number ='', \n",
    "               npa = '', \n",
    "               with_all_the_words = '', \n",
    "               with_at_least_one_of_the_words = '', \n",
    "               without_the_words = '', \n",
    "               phrase = '', \n",
    "               proximity = '', \n",
    "               on_this_date = '', \n",
    "               after_date = '', \n",
    "               before_date = '', \n",
    "               legislation = '', \n",
    "               cases_cited = '', \n",
    "               catchwords = ''):\n",
    "    base_url = \"https://search2.fedcourt.gov.au/s/search.html?collection=judgments&sort=date&meta_v_phrase_orsand=judgments%2FJudgments%2Ffca\"\n",
    "    params = {'meta_2' : case_name_mnc, \n",
    "              'meta_A' : judge, \n",
    "              'meta_z' : reported_citation, \n",
    "              'meta_3' : file_number, \n",
    "              'meta_n_phrase_orsand' : npa, \n",
    "              'query_sand' : with_all_the_words, \n",
    "              'query_or' : with_at_least_one_of_the_words, \n",
    "              'query_not' : without_the_words, \n",
    "              'query_phrase' : phrase, \n",
    "              'query_prox' : proximity, \n",
    "              'meta_d' : on_this_date, \n",
    "              'meta_d1' : after_date, \n",
    "              'meta_d2' : before_date, \n",
    "              'meta_7' : legislation, \n",
    "              'meta_4' : cases_cited, \n",
    "              'meta_B' : catchwords}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    # Process the response (e.g., extract relevant information)\n",
    "    # Your code here...\n",
    "    return response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary list for getting more pages of search results\n",
    "further_page_ending_list = []\n",
    "for i in range(100):\n",
    "    further_page_ending = 20 + i\n",
    "    if ((str(further_page_ending)[-1] =='1') & (str(further_page_ending)[0] not in ['3', '5', '7', '9', '11'])):\n",
    "        further_page_ending_list.append(str(further_page_ending))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6321d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function turning search results url to links to judgments\n",
    "def search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "\n",
    "    counter = 1\n",
    "    \n",
    "    # Get links of first 20 results\n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"fca\"))\n",
    "    links = []\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            remove_title = str(i).split('\" title=')[0]\n",
    "            remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "            if 'a class=' not in remove_leading_words:\n",
    "                links.append(remove_leading_words)\n",
    "                counter = counter + 1\n",
    "\n",
    "    #Go beyond first 20 results\n",
    "\n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\"))\n",
    "\n",
    "            #Check if stll more results\n",
    "            if len(links_next_page_raw) > 0:\n",
    "                for i in links_next_page_raw:\n",
    "                    if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "                        remove_title = str(i).split('\" title=')[0]\n",
    "                        remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "                        if 'a class=' not in remove_leading_words:\n",
    "                            links.append(remove_leading_words)\n",
    "                            counter = counter + 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15def0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#judgment url to word document\n",
    "#NOT in use\n",
    "def link_to_doc(url_judgment):\n",
    "    page_judgment = requests.get(url_judgment)\n",
    "    soup_judgment = BeautifulSoup(page_judgment.content, \"lxml\")\n",
    "    link_word_raw = soup_judgment.find_all('a', string=re.compile('Word'))\n",
    "    if len(link_word_raw)> 0:\n",
    "        link_to_word = str(link_word_raw).split('>')[0].replace('[<a href=\"', '')\n",
    "        return link_to_word\n",
    "    else:\n",
    "        return url_judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8407a3-5fa9-488b-a775-a9ef9c47cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for judgment link containing PDF\n",
    "def pdf_judgment(url):\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    remote_file_bytes = io.BytesIO(r.content)\n",
    "    pdfdoc_remote = PyPDF2.PdfReader(remote_file_bytes)\n",
    "    text_list = []\n",
    "\n",
    "    for page in pdfdoc_remote.pages:\n",
    "        text_list.append(page.extract_text())\n",
    "    \n",
    "    return str(text_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962fad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "meta_labels = ['MNC', 'Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published', 'Appeal_to']\n",
    "meta_labels_droppable = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published', 'Appeal_to', 'Order']\n",
    "\n",
    "def meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to FCA Digital Law Library' : '', \n",
    "                'MNC' : '',  \n",
    "                 'Year' : '',  \n",
    "                 'Appeal' : '',  \n",
    "                 'File_Number' : '',  \n",
    "                 'Judge' : '',  \n",
    "                 'Judgment_Dated' : '',  \n",
    "                 'Catchwords' : '',  \n",
    "                 'Subject' : '',  \n",
    "                 'Words_Phrases' : '',  \n",
    "                 'Legislation' : '',  \n",
    "                 'Cases_Cited' : '',  \n",
    "                 'Division' : '',  \n",
    "                 'NPA' : '',  \n",
    "                'Sub_NPA' : '', \n",
    "                 'Pages' : '',  \n",
    "                 'All_Parties' : '',  \n",
    "                 'Jurisdiction' : '',  \n",
    "                 'Reported' : '',  \n",
    "                 'Summary' : '',  \n",
    "                 'Corrigenda' : '',  \n",
    "                 'Parties' : '',  'FileName' : '',  \n",
    "                 'Asset_ID' : '',  \n",
    "                 'Date.published' : '', \n",
    "                'Appeal_to' : '', \n",
    "                'Order': '',\n",
    "                'Judgment' : ''\n",
    "                }\n",
    "\n",
    "    \n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink to FCA Digital Law Library'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    meta_tags = soup.find_all(\"meta\")\n",
    "\n",
    "    #Attach meta tags\n",
    "    if len(meta_tags)>0:\n",
    "        for tag_index in range(len(meta_tags)):\n",
    "            meta_name = meta_tags[tag_index].get(\"name\")\n",
    "            if meta_name in meta_labels:\n",
    "                meta_content = meta_tags[tag_index].get(\"content\")\n",
    "                judgment_dict[meta_name] = meta_content\n",
    "\n",
    "    #Check if not gets taken to a PDF\n",
    "\n",
    "    if '.pdf' not in judgment_url.lower():\n",
    "    \n",
    "        try:\n",
    "            judgment_dict['Case name'] = judgment_dict['MNC'].split('[')[0]\n",
    "            judgment_dict['Medium neutral citation'] = '[' + judgment_dict['MNC'].split('[')[1]\n",
    "            del judgment_dict['MNC']\n",
    "    \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #Attach order_text and judgment\n",
    "    \n",
    "        judgment_text = ''\n",
    "        order_text = ''\n",
    "    \n",
    "        try:\n",
    "            judgment_raw = ''\n",
    "            judgment_raw = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "            above_reasons_for_judgment = str(re.split(\"REASONS FOR JUDGMENT\", judgment_raw, flags=re.IGNORECASE)[0])\n",
    "    \n",
    "            below_reasons_for_judgment = str(re.split(\"REASONS FOR JUDGMENT\", judgment_raw, flags=re.IGNORECASE)[1:])\n",
    "    \n",
    "            order_text = \"BETWEEEN:\" + str(re.split(\"BETWEEN:\", above_reasons_for_judgment, flags=re.IGNORECASE)[1:])[2:][:-2]\n",
    "    \n",
    "            judgment_text = below_reasons_for_judgment\n",
    "    \n",
    "        except:\n",
    "            try:\n",
    "                judgment_text = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "            except:\n",
    "                judgment_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "        \n",
    "        judgment_dict['Judgment'] = judgment_text\n",
    "        judgment_dict['Order'] = order_text\n",
    "\n",
    "    #Check if gets taken to a PDF\n",
    "\n",
    "    else:\n",
    "        #Attach case name\n",
    "        judgment_dict['Case name'] = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.'\n",
    "\n",
    "        #Attach judgment pdf text\n",
    "        try:\n",
    "            judgment_pdf_raw = pdf_judgment(judgment_url)\n",
    "            judgment_dict['Judgment'] = judgment_pdf_raw\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        #Attach medium neutral citation\n",
    "        try:\n",
    "            mnc_raw = judgment_url.split('/')[-1].replace('.pdf', '')\n",
    "\n",
    "            for court_i in ['fca', 'fcafc']:\n",
    "                if court_i in mnc_raw.lower():\n",
    "                    mnc_list = mnc_raw.lower().split(court_i)\n",
    "                    judgment_dict['Medium neutral citation'] = '[' + mnc_list[0] + '] ' + court_i.upper()  + ' ' +  mnc_list[1]\n",
    "                    judgment_dict['Medium neutral citation']=judgment_dict['Medium neutral citation']\n",
    "\n",
    "                    while ' 0' in judgment_dict['Medium neutral citation']:\n",
    "                        judgment_dict['Medium neutral citation'] = judgment_dict['Medium neutral citation'].replace(' 0', ' ')\n",
    "            \n",
    "            del judgment_dict['MNC']\n",
    "    \n",
    "        except:\n",
    "            pass        \n",
    "        \n",
    "    \n",
    "    return judgment_dict\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30f606a-d641-4752-8fde-07f5b04d5596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary function for changing names for any PDF judgments\n",
    "def pdf_name_mnc_list(url_search_results, judgment_counter_bound):\n",
    "                      \n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "    #Placeholder\n",
    "    name_mnc_list = []\n",
    "\n",
    "    #Start counter\n",
    "    counter = 1\n",
    "    # Get links of first 20 results\n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"fca\"))\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            name_mnc_list.append(i['title'])\n",
    "            counter = counter + 1\n",
    "    \n",
    "    #Go beyond first 20 results\n",
    "    \n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\"))\n",
    "    \n",
    "            #Check if stll more results\n",
    "            if len(links_next_page_raw) > 0:\n",
    "                for i in links_next_page_raw:\n",
    "                    if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "                        name_mnc_list.append(i['title'])\n",
    "                        counter = counter + 1\n",
    "    \n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    return name_mnc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810eb17-ef74-4083-9801-f8c36395344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for changing names for any PDF judgments\n",
    "\n",
    "def pdf_name(name_mnc_list, mnc):\n",
    "    #Placeholder\n",
    "    name = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.' \n",
    "    \n",
    "    for i in name_mnc_list:\n",
    "        if mnc in i:\n",
    "            name_raw = i.split(' ' + mnc)[0]\n",
    "            name = name_raw.replace('Cached: ', '')\n",
    "            \n",
    "    return name\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a703f4-8159-4066-a50d-60068e76a072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check validity of API key\n",
    "\n",
    "def is_api_key_valid(key_to_check):\n",
    "    openai.api_key = key_to_check\n",
    "    \n",
    "    try:\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0125\",\n",
    "            messages=[{\"role\": \"user\", \"content\": 'Who is Taylor Swift?'}], \n",
    "            max_tokens = 5\n",
    "        )\n",
    "    except:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03e8eaf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Module, costs and upperbounds\n",
    "\n",
    "#Initialize default GPT settings\n",
    "\n",
    "if 'gpt_model' not in st.session_state:\n",
    "    st.session_state['gpt_model'] = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "#Upperbound on number of engagements with GPT\n",
    "\n",
    "#GPT_use_bound = 3\n",
    "\n",
    "#print(f\"\\nPrior number of GPT uses is capped at {GPT_use_bound} times.\")\n",
    "\n",
    "#Define input and output costs, token caps and maximum characters\n",
    "#each token is about 4 characters\n",
    "\n",
    "def gpt_input_cost(gpt_model):\n",
    "    if gpt_model == \"gpt-3.5-turbo-0125\":\n",
    "        gpt_input_cost = 1/1000000*0.5\n",
    "        \n",
    "    if gpt_model == \"gpt-4-turbo\":\n",
    "        gpt_input_cost = 1/1000000*10\n",
    "    return gpt_input_cost\n",
    "\n",
    "def gpt_output_cost(gpt_model):\n",
    "    if gpt_model == \"gpt-3.5-turbo-0125\":\n",
    "        gpt_output_cost = 1/1000000*0.5\n",
    "        \n",
    "    if gpt_model == \"gpt-4-turbo\":\n",
    "        gpt_output_cost = 1/1000000*10\n",
    "        \n",
    "    return gpt_output_cost\n",
    "\n",
    "def tokens_cap(gpt_model):\n",
    "    \n",
    "    if gpt_model == \"gpt-3.5-turbo-0125\":\n",
    "        tokens_cap = int(16385 - 2000) #For GPT-3.5-turbo, token limit covering both input and output is 16385,  while the output limit is 4096.\n",
    "    \n",
    "    if gpt_model == \"gpt-4-turbo\":\n",
    "        tokens_cap = int(128000 - 6000) #For GPT-4-turbo, token limit covering both input and output is 128000, while the output limit is 4096.\n",
    "\n",
    "    return tokens_cap\n",
    "    \n",
    "#Initialize API key\n",
    "if 'gpt_api_key' not in st.session_state:\n",
    "\n",
    "    st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "\n",
    "#Upperbound on the length of questions for GPT\n",
    "#if 'question_characters_bound' not in st.session_state:\n",
    "#    st.session_state['question_characters_bound'] = 1000\n",
    "\n",
    "question_characters_bound = 1000\n",
    "\n",
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "\n",
    "#Upperbound on number of judgments to scrape\n",
    "\n",
    "#Default judgment counter bound\n",
    "\n",
    "default_judgment_counter_bound = 10\n",
    "\n",
    "if 'judgments_counter_bound' not in st.session_state:\n",
    "    st.session_state['judgments_counter_bound'] = default_judgment_counter_bound\n",
    "\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e463db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function to determine eligibility for GPT use\n",
    "\n",
    "#Define a list of privileged email addresses with unlimited GPT uses\n",
    "\n",
    "privileged_emails = st.secrets[\"secrets\"][\"privileged_emails\"].replace(' ', '').split(',')\n",
    "\n",
    "\n",
    "def prior_GPT_uses(email_address, df_online):\n",
    "    # df_online variable should be the online df_online\n",
    "    prior_use_counter = 0\n",
    "    for i in df_online.index:\n",
    "        if ((df_online.loc[i, \"Your email address\"] == email_address) \n",
    "            and (int(df_online.loc[i, \"Use GPT\"]) > 0) \n",
    "            and (len(df_online.loc[i, \"Processed\"])>0)\n",
    "           ):\n",
    "            prior_use_counter += 1\n",
    "    if email_address in privileged_emails:\n",
    "        return 0\n",
    "    else:\n",
    "        return prior_use_counter\n",
    "\n",
    "#Define function to check whether email is educational or government\n",
    "def check_edu_gov(email_address):\n",
    "    #Return 1 if educational or government, return 0 otherwise\n",
    "    end=email_address.split('@')[1]\n",
    "    if (('.gov' in end) or ('.edu' in end) or ('.ac' in end)):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef483929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokens estimate preliminaries\n",
    "#encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "#encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "#Tokens estimate function\n",
    "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "#Define judgment input function for JSON approach\n",
    "\n",
    "#Token limit covering both GTP input and GPT output is 16385, each token is about 4 characters\n",
    "#characters_limit_half = int((16385*4)/2-1500)\n",
    "\n",
    "def judgment_prompt_json(judgment_json, gpt_model):\n",
    "                \n",
    "    judgment_content = 'Based on the metadata and judgment in the following JSON: \"\"\"'+ str(judgment_json) + '\"\"\"'\n",
    "\n",
    "    judgment_content_tokens = num_tokens_from_string(judgment_content, \"cl100k_base\")\n",
    "    \n",
    "    if judgment_content_tokens <= tokens_cap(gpt_model):\n",
    "        \n",
    "        return judgment_content\n",
    "\n",
    "    else:\n",
    "        \n",
    "        meta_data_len = judgment_content_tokens - num_tokens_from_string(judgment_json['Judgment'], \"cl100k_base\")\n",
    "        \n",
    "        judgment_chars_capped = int((tokens_cap(gpt_model) - meta_data_len)*4)\n",
    "        \n",
    "        judgment_string_trimmed = judgment_json['Judgment'][ :int(judgment_chars_capped/2)] + judgment_json['Judgment'][-int(judgment_chars_capped/2): ]\n",
    "\n",
    "        judgment_json[\"Judgment\"] = judgment_string_trimmed     \n",
    "        \n",
    "        judgment_content_capped = 'Based on the metadata and judgment in the following JSON:  \"\"\"'+ str(judgment_json) + '\"\"\"'\n",
    "        \n",
    "        return judgment_content_capped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f7af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define system role content for GPT\n",
    "role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from a specific paragraph in the judgment, provide the paragraph number as part of your answer. If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\".'\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": role_content}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d95be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT answer function for answers in json form, YES TOKENS\n",
    "#IN USE\n",
    "\n",
    "def GPT_json_tokens(questions_json, judgment_json, gpt_model):\n",
    "    #'question_json' variable is a json of questions to GPT\n",
    "    #'jugdment' variable is a judgment_json   \n",
    "    \n",
    "    judgment_for_GPT = [{\"role\": \"user\", \"content\": judgment_prompt_json(judgment_json, gpt_model)}]\n",
    "\n",
    "    json_direction = [{\"role\": \"user\", \"content\": 'You will be given questions to answer in JSON form.'}]\n",
    "        \n",
    "    #Create answer format\n",
    "    \n",
    "    q_keys = [*questions_json]\n",
    "    \n",
    "    answers_json = {}\n",
    "    \n",
    "    for q_index in q_keys:\n",
    "        answers_json.update({q_index: 'Your answer to the question with index ' + q_index + '. State specific paragraph numbers in the judgment or specific sections in the metadata.'})\n",
    "    \n",
    "    #Create questions, which include the answer format\n",
    "    \n",
    "    question_for_GPT = [{\"role\": \"user\", \"content\": str(questions_json).replace(\"\\'\", '\"') + ' Give responses in the following JSON form: ' + str(answers_json).replace(\"\\'\", '\"')}]\n",
    "    \n",
    "    #Create messages in one prompt for GPT\n",
    "    messages_for_GPT = intro_for_GPT + judgment_for_GPT + json_direction + question_for_GPT\n",
    "    \n",
    "#   return messages_for_GPT\n",
    "\n",
    "            \n",
    "    #os.environ[\"OPENAI_API_KEY\"] = API_key\n",
    "\n",
    "    openai.api_key = API_key\n",
    "    \n",
    "    #client = OpenAI()\n",
    "    \n",
    "    try:\n",
    "        #completion = client.chat.completions.create(\n",
    "        completion = openai.chat.completions.create(\n",
    "            model=gpt_model,\n",
    "            messages=messages_for_GPT, \n",
    "            response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "        \n",
    "#        return completion.choices[0].message.content #This gives answers as a string containing a dictionary\n",
    "        \n",
    "        #To obtain a json directly, use below\n",
    "        answers_dict = json.loads(completion.choices[0].message.content)\n",
    "        \n",
    "        #Obtain tokens\n",
    "        output_tokens = completion.usage.completion_tokens\n",
    "        \n",
    "        prompt_tokens = completion.usage.prompt_tokens\n",
    "        \n",
    "        return [answers_dict, output_tokens, prompt_tokens]\n",
    "\n",
    "    except Exception as error:\n",
    "        \n",
    "        for q_index in q_keys:\n",
    "            answers_json[q_index] = error\n",
    "        \n",
    "        return [answers_json, 0, 0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80714830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define GPT function for each respondent's dataframe, index by judgment then question, with input and output tokens given by GPT itself\n",
    "#IN USE\n",
    "\n",
    "#The following function DOES NOT check for existence of questions for GPT\n",
    "    # To so check, active line marked as #*\n",
    "def engage_GPT_json_tokens(questions_json, df_individual, GPT_activation, gpt_model):\n",
    "    # Variable questions_json refers to the json of questions\n",
    "    # Variable df_individual refers to each respondent's df\n",
    "    # Variable activation refers to status of GPT activation (real or test)\n",
    "    # The output is a new JSON for the relevant respondent with new columns re:\n",
    "        # f\"Judgment length in tokens (up to {tokens_cap(gpt_model)}  given to GPT)\"\n",
    "        # 'GPT cost estimate (USD excl GST)'\n",
    "        # 'GPT time estimate (seconds)'\n",
    "        # GPT questions/answers\n",
    "\n",
    "    #os.environ[\"OPENAI_API_KEY\"] = API_key\n",
    "\n",
    "    openai.api_key = API_key\n",
    "    \n",
    "    #client = OpenAI()\n",
    "    \n",
    "    question_keys = [*questions_json]\n",
    "    \n",
    "    for judgment_index in df_individual.index:\n",
    "        \n",
    "        judgment_json = df_individual.to_dict('index')[judgment_index]\n",
    "        \n",
    "        #Calculate and append number of tokens of judgment, regardless of whether given to GPT\n",
    "        judgment_tokens = num_tokens_from_string(str(judgment_json), \"cl100k_base\")\n",
    "        df_individual.loc[judgment_index, f\"Judgment length in tokens (up to {tokens_cap(gpt_model)}  given to GPT)\"] = judgment_tokens       \n",
    "\n",
    "        #Indicate whether judgment truncated\n",
    "        \n",
    "        df_individual.loc[judgment_index, \"Judgment truncated (if given to GPT)?\"] = ''       \n",
    "        \n",
    "        if judgment_tokens <= tokens_cap(gpt_model):\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"Judgment truncated (if given to GPT)?\"] = 'No'\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"Judgment truncated (if given to GPT)?\"] = 'Yes'\n",
    "\n",
    "        #Create columns for respondent's GPT cost, time\n",
    "        df_individual.loc[judgment_index, 'GPT cost estimate (USD excl GST)'] = ''\n",
    "        df_individual.loc[judgment_index, 'GPT time estimate (seconds)'] = ''\n",
    "                \n",
    "        #Calculate GPT start time\n",
    "\n",
    "        GPT_start_time = datetime.now()\n",
    "\n",
    "        #Depending on activation status, apply GPT_json function to each judgment, gives answers as a string containing a dictionary\n",
    "\n",
    "        if int(GPT_activation) > 0:\n",
    "            GPT_output_list = GPT_json_tokens(questions_json, judgment_json, gpt_model) #Gives [answers as a JSON, output tokens, input tokens]\n",
    "            answers_dict = GPT_output_list[0]\n",
    "\n",
    "            #Calculate and append GPT finish time and time difference to individual df\n",
    "            GPT_finish_time = datetime.now()\n",
    "            \n",
    "            GPT_time_difference = GPT_finish_time - GPT_start_time\n",
    "    \n",
    "            df_individual.loc[judgment_index, 'GPT time estimate (seconds)'] = GPT_time_difference.total_seconds()        \n",
    "        \n",
    "        else:\n",
    "            answers_dict = {}    \n",
    "            for q_index in question_keys:\n",
    "                #Increases judgment index by 2 to ensure consistency with Excel spreadsheet\n",
    "                answer = 'Placeholder answer for ' + ' judgment ' + str(int(judgment_index) + 2) + ' ' + str(q_index)\n",
    "                answers_dict.update({q_index: answer})\n",
    "            \n",
    "            #Own calculation of GPT costs for Placeholder answer fors\n",
    "\n",
    "            #Calculate capped judgment tokens\n",
    "\n",
    "            judgment_capped_tokens = num_tokens_from_string(judgment_prompt_json(judgment_json, gpt_model), \"cl100k_base\")\n",
    "\n",
    "            #Calculate questions tokens and cost\n",
    "\n",
    "            questions_tokens = num_tokens_from_string(str(questions_json), \"cl100k_base\")\n",
    "\n",
    "            #Calculate other instructions' tokens\n",
    "\n",
    "            other_instructions = role_content + 'you will be given questions to answer in JSON form.' + ' Give responses in the following JSON form: '\n",
    "\n",
    "            other_tokens = num_tokens_from_string(other_instructions, \"cl100k_base\") + len(question_keys)*num_tokens_from_string(\"GPT question x:  Your answer to the question with index GPT question x. State specific paragraph numbers in the judgment or specific sections in the metadata.\", \"cl100k_base\")\n",
    "\n",
    "            #Calculate number of tokens of answers\n",
    "            answers_tokens = num_tokens_from_string(str(answers_dict), \"cl100k_base\")\n",
    "\n",
    "            input_tokens = judgment_capped_tokens + questions_tokens + other_tokens\n",
    "            \n",
    "            GPT_output_list = [answers_dict, answers_tokens, input_tokens]\n",
    "\n",
    "\n",
    "    \t#Create GPT question headings, append answers to individual spreadsheets, and remove template/erroneous answers\n",
    "\n",
    "        for question_index in question_keys:\n",
    "            question_heading = question_index + ': ' + questions_json[question_index]\n",
    "            df_individual.loc[judgment_index, question_heading] = answers_dict[question_index]\n",
    "            \n",
    "            if 'Your answer to the question with index GPT question' in str(answers_dict[question_index]):\n",
    "                df_individual.loc[judgment_index, question_heading] = f'Error for judgment {str(int(judgment_index)+2)}, GPT question {question_index}. Please try again.'\n",
    "\n",
    "        #Calculate GPT costs\n",
    "\n",
    "        GPT_cost = GPT_output_list[1]*gpt_output_cost(gpt_model) + GPT_output_list[2]*gpt_input_cost(gpt_model)\n",
    "\n",
    "        #Calculate and append GPT cost to individual df\n",
    "        df_individual.loc[judgment_index, 'GPT cost estimate (USD excl GST)'] = GPT_cost\n",
    "    \n",
    "    return df_individual\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "def run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your question(s) for GPT'] = df_master['Enter your question(s) for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your question(s) for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = fca_search(case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'After date'], \n",
    "                     before_date = df_master.loc[0, 'Before date'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    judgments_links = search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for link in judgments_links:\n",
    "\n",
    "        judgment_dict = meta_judgment_dict(link)\n",
    "\n",
    "#        meta_data = meta_dict(link)  \n",
    "#        doc_link = link_to_doc(link)\n",
    "#        judgment_dict = doc_link_to_dict(doc_link)\n",
    "#        judgment_dict = link_to_dict(link)\n",
    "#        judgments_all_info = { **meta_data, **judgment_dict}\n",
    "#        judgments_file.append(judgments_all_info)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Rename column titles\n",
    "    \n",
    "#    try:\n",
    "#        df_individual['Hyperlink (double click)'] = df_individual['Hyperlink'].apply(link)\n",
    "#        df_individual.pop('Hyperlink')\n",
    "#    except:\n",
    "#        pass\n",
    "\n",
    "    #Correct case names for any PDFs\n",
    "\n",
    "    name_mnc_list = pdf_name_mnc_list(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for judgment_index in df_individual.index:\n",
    "        \n",
    "        if (('pdf' in df_individual.loc[judgment_index, 'Case name'].lower()) or ('.pdf' in str(df_individual.loc[judgment_index, 'Hyperlink to FCA Digital Law Library']).lower())):\n",
    "            try:\n",
    "                df_individual.loc[judgment_index, 'Case name'] = pdf_name(name_mnc_list, df_individual.loc[judgment_index, 'Medium neutral citation'])\n",
    "            except Exception as e:\n",
    "                print(f\"{df_individual.loc[judgment_index, 'Medium neutral citation']}: cannot change case name for PDF.\")\n",
    "                print(e)\n",
    "                    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use latest version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4-turbo\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json_tokens(questions_json, df_individual, GPT_activation, gpt_model)\n",
    "\n",
    "    df_updated.pop('Judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(df_master.loc[0, 'Metadata inclusion']) == 0:\n",
    "        for meta_label in meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc31ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url = fca_search(case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'After date'], \n",
    "                     before_date = df_master.loc[0, 'Before date'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d5dcd6",
   "metadata": {},
   "source": [
    "# Streamlit form, functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9160326-0222-4983-9ae8-9f6f1feaa317",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db2c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to open url\n",
    "def open_page(url):\n",
    "    open_script= \"\"\"\n",
    "        <script type=\"text/javascript\">\n",
    "            window.open('%s', '_blank').focus();\n",
    "        </script>\n",
    "    \"\"\" % (url)\n",
    "    html(open_script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283964a-ff4b-48a5-8522-a55ad124b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_cache_except_validation_df_master():\n",
    "    keys = list(st.session_state.keys())\n",
    "    if 'gpt_api_key_validity' in keys:\n",
    "        keys.remove('gpt_api_key_validity')\n",
    "    if 'df_master' in keys:\n",
    "        keys.remove('df_master')\n",
    "    for key in keys:\n",
    "        st.session_state.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb02d7-b112-4705-b445-0c351cef21c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tips():\n",
    "    st.markdown(\"\"\":green[**DO's**:]\n",
    "- :green[Do break down complex tasks into simple sub-tasks.]\n",
    "- :green[Do give clear and detailed instructions (eg specify steps required to complete a task).]\n",
    "- :green[Do use the same terminology as the relevant judgments themselves.]\n",
    "- :green[Do give exemplar answers.]\n",
    "- :green[Do manually check some or all answers.]\n",
    "- :green[Do revise questions to get better answers.]\n",
    "- :green[Do evaluate answers on the same sample of judgments (ie the \"training\" sample).]\n",
    "\"\"\")\n",
    "\n",
    "    st.markdown(\"\"\":red[**Don'ts**:]\n",
    "- :red[Don't ask questions which go beyond the relevant judgment itself.]\n",
    "- :red[Don't ask difficult maths questions.]\n",
    "- :red[Don't skip manual evaluation.]\n",
    "\"\"\")\n",
    "\n",
    "    st.markdown(\"\"\":orange[**Maybe's**:]\n",
    "- :orange[Maybe ask for reasoning.]\n",
    "- :orange[Maybe re-run the same questions and manually check for inconsistency.]\n",
    "\"\"\")\n",
    "\n",
    "    st.caption('For more tips, please see https://platform.openai.com/docs/guides/prompt-engineering.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c765f659-bf18-4e59-a76c-af2c58f910a9",
   "metadata": {},
   "source": [
    "## Initialize session states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523f9d21-666d-4b2e-8749-e89692939761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize default values\n",
    "\n",
    "if 'gpt_enhancement_entry' not in st.session_state:\n",
    "    st.session_state['gpt_enhancement_entry'] = False\n",
    "\n",
    "if 'gpt_api_key_validity' not in st.session_state:\n",
    "    st.session_state['gpt_api_key_validity'] = False\n",
    "\n",
    "if 'own_account' not in st.session_state:\n",
    "    st.session_state['own_account'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaeece-b45b-4d88-a6b6-c4d8278b07e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try to carry over previously entered personal details    \n",
    "try:\n",
    "    st.session_state['gpt_api_key_entry'] = st.session_state.df_master.loc[0, 'Your GPT API key']\n",
    "except:\n",
    "    st.session_state['gpt_api_key_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['name_entry'] = st.session_state.df_master.loc[0, 'Your name']\n",
    "except:\n",
    "    st.session_state['name_entry'] = ''\n",
    "\n",
    "try:\n",
    "    st.session_state['email_entry'] = st.session_state.df_master.loc[0, 'Your email address']\n",
    "    \n",
    "except:\n",
    "    st.session_state['email_entry'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4d818b-8edf-4510-adb8-a81a60a55bb6",
   "metadata": {},
   "source": [
    "## Form before AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c683d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create form\n",
    "\n",
    "return_button = st.button('RETURN to first page')\n",
    "\n",
    "st.header(f\"You have selected to study :blue[judgments of the Federal Court of Australia].\")\n",
    "\n",
    "#    st.header(\"Judgment Search Criteria\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[Please enter your search terms.]** This program will collect (ie scrape) the first 10 judgments returned by your search terms.\n",
    "\n",
    "For search tips, please visit the Federal Court Digital Law Library at https://www.fedcourt.gov.au/digital-law-library/judgments/search. This section mimics their judgments search function.\n",
    "\"\"\")\n",
    "st.caption('During the pilot stage, the number of judgments to scrape is capped. Please reach out to Ben at ben.chen@sydney.edu.au should you wish to cover more judgments, courts, or tribunals.')\n",
    "\n",
    "st.subheader(\"Your search terms\")\n",
    "\n",
    "catchwords_entry = st.text_input('Catchwords')\n",
    "\n",
    "legislation_entry = st.text_input('Legislation')\n",
    "\n",
    "cases_cited_entry = st.text_input('Cases cited')\n",
    "\n",
    "case_name_mnc_entry = st.text_input(\"Case name or medium neutral citation\")\n",
    "\n",
    "judge_entry = st.text_input('Judge')\n",
    "\n",
    "reported_citation_entry = st.text_input('Reported citation')\n",
    "\n",
    "file_number_entry = st.text_input('File number')\n",
    "\n",
    "npa_entry = st.text_input('National practice area')\n",
    "\n",
    "with_all_the_words_entry = st.text_input('With ALL the words')\n",
    "\n",
    "with_at_least_one_of_the_words_entry = st.text_input('With at least one of the words')\n",
    "\n",
    "without_the_words_entry = st.text_input('Without the words')\n",
    "\n",
    "phrase_entry = st.text_input('Phrase')\n",
    "\n",
    "proximity_entry  = st.text_input('Proximity')\n",
    "\n",
    "on_this_date_entry = st.date_input('On this date', value = None, format=\"DD/MM/YYYY\", min_value = date(1800, 1, 1))\n",
    "\n",
    "after_date_entry = st.date_input('After date', value = None, format=\"DD/MM/YYYY\")\n",
    "\n",
    "before_date_entry = st.date_input('Before date', value = None, format=\"DD/MM/YYYY\")\n",
    "\n",
    "st.caption('Relatively earlier judgments will not be collected. For information about judgment availability, please visit https://www.fedcourt.gov.au/digital-law-library/judgments/judgments-faq.')\n",
    "\n",
    "st.markdown(\"\"\"You can preview the judgments returned by your search terms on the Federal Court Digital Law Library after you have entered some search terms.\n",
    "\n",
    "You may have to unblock a popped up window, refresh this page, and re-enter your search terms.\n",
    "\"\"\")\n",
    "\n",
    "preview_button = st.button('PREVIEW on the Federal Court Digital Law Library (in a popped up window)')\n",
    "\n",
    "st.subheader(\"Judgment metadata collection\")\n",
    "\n",
    "st.markdown(\"\"\"Would you like to obtain judgment metadata? Such data include the name of the judge, the decision date and so on. \n",
    "\n",
    "Case name and medium neutral citation are always included with your results.\n",
    "\"\"\")\n",
    "\n",
    "meta_data_entry = st.checkbox('Include metadata', value = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fd466b-8924-44a8-97ff-aec1b36da9c7",
   "metadata": {},
   "source": [
    "## Form for AI and account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c42ba5-19a1-4e50-a69b-daf68c403ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Use GPT as your research assistant\")\n",
    "\n",
    "#    st.markdown(\"**You have three (3) opportunities to engage with GPT through the Empirical Legal Research Kickstarter. Would you like to use one (1) of these opportunities now?**\")\n",
    "\n",
    "st.markdown(\"**:green[Would you like GPT to answer questions about the judgments returned by your search terms?]**\")\n",
    "\n",
    "st.markdown(\"\"\"Please consider trying this program without asking GPT any questions first. You can, for instance, obtain the judgments satisfying your search criteria and extract the judgment metadata without using GPT.\n",
    "\"\"\")\n",
    "\n",
    "gpt_activation_entry = st.checkbox('Use GPT', value = False)\n",
    "\n",
    "st.caption(\"Use of GPT is costly and funded by a grant. For the model used by default, Ben's own experience suggests that it costs approximately USD \\$0.003-\\$0.008 (excl GST) per judgment. The exact cost for answering a question about a judgment depends on the length of the question, the length of the judgment, and the length of the answer produced (as elaborated at https://openai.com/pricing for model gpt-3.5-turbo-0125). You will be given ex-post cost estimates.\")\n",
    "\n",
    "st.subheader(\"Enter your question(s) for each judgment\")\n",
    "\n",
    "st.markdown(\"\"\"GPT will answer your question(s) for **each** judgment based only on information from **that** judgment. \n",
    "\n",
    "*Please enter one question per line or per paragraph.*\"\"\")\n",
    "\n",
    "gpt_questions_entry = st.text_area(f\"You may enter at most {question_characters_bound} characters.\", height= 200, max_chars=question_characters_bound) \n",
    "\n",
    "st.caption(f\"By default, answers to your questions will be generated by model gpt-3.5-turbo-0125. Due to a technical limitation, this model will read up to approximately {round(tokens_cap('gpt-3.5-turbo-0125')*3/4)} words from each judgment.\")\n",
    "\n",
    "if st.toggle('Tips for using GPT'):\n",
    "    tips()\n",
    "\n",
    "st.markdown(\"\"\"GPT is instructed to avoid giving answers which cannot be obtained from the relevant judgment itself. This is to minimise the risk of giving incorrect information (ie hallucination).\"\"\")\n",
    "\n",
    "if st.toggle('See the instruction given to GPT'):\n",
    "    st.write(f\"*{intro_for_GPT[0]['content']}*\")\n",
    "\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "\n",
    "    st.subheader(':orange[Enhance program capabilities]')\n",
    "    \n",
    "    st.markdown(\"\"\"Would you like to increase the quality and accuracy of answers from GPT, or increase the maximum nunber of judgments to process? You can do so with your own GPT account.\n",
    "    \"\"\")\n",
    "    \n",
    "    own_account_entry = st.toggle('Use my own GPT account')\n",
    "    \n",
    "    if own_account_entry:\n",
    "    \n",
    "        st.session_state[\"own_account\"] = True\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[Please enter your name, email address and API key.]** You can sign up for a GPT account and pay for your own usage at https://platform.openai.com/signup. You can then find your API key at https://platform.openai.com/api-keys.\n",
    "    \"\"\")\n",
    "            \n",
    "        name_entry = st.text_input(label = \"Your name\", value = st.session_state.name_entry)\n",
    "        \n",
    "        email_entry = st.text_input(label = \"Your email address\", value = st.session_state.email_entry)\n",
    "        \n",
    "        gpt_api_key_entry = st.text_input(label = \"Your GPT API key (mandatory)\", value = st.session_state.gpt_api_key_entry)\n",
    "        \n",
    "        valdity_check = st.button('VALIDATE your API key')\n",
    "    \n",
    "        if valdity_check:\n",
    "            \n",
    "            api_key_valid = is_api_key_valid(gpt_api_key_entry)\n",
    "                    \n",
    "            if api_key_valid == False:\n",
    "                st.session_state['gpt_api_key_validity'] = False\n",
    "                st.error('Your API key is not valid.')\n",
    "                \n",
    "            else:\n",
    "                st.session_state['gpt_api_key_validity'] = True\n",
    "                st.success('Your API key is valid.')\n",
    "    \n",
    "        st.markdown(\"\"\"**:green[You can use the latest version of GPT model (gpt-4-turbo),]** which is :red[20 times more expensive, per character] than the default model (gpt-3.5-turbo) which you can use for free.\"\"\")  \n",
    "        \n",
    "        gpt_enhancement_entry = st.checkbox('Use the latest GPT model', value = False)\n",
    "        st.caption('For more on pricing for different GPT models, please see https://openai.com/api/pricing.')\n",
    "        \n",
    "        if gpt_enhancement_entry == True:\n",
    "        \n",
    "            st.session_state.gpt_model = \"gpt-4-turbo\"\n",
    "            st.session_state.gpt_enhancement_entry = True\n",
    "\n",
    "        else:\n",
    "            \n",
    "            st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "            st.session_state.gpt_enhancement_entry = False\n",
    "        \n",
    "        st.write(f'**:green[You can increase the maximum number of judgments to process.]** The default maximum is {default_judgment_counter_bound}.')\n",
    "        \n",
    "        judgments_counter_bound_entry = round(st.number_input(label = 'Enter the maximum number of judgments up to 100', min_value=1, max_value=100, value=default_judgment_counter_bound))\n",
    "    \n",
    "        st.session_state.judgments_counter_bound = judgments_counter_bound_entry\n",
    "    \n",
    "        st.write(f'*GPT model {st.session_state.gpt_model} will answer any questions based on up to approximately {round(tokens_cap(st.session_state.gpt_model)*3/4)} words from each judgment, for up to {st.session_state.judgments_counter_bound} judgments.*')\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        st.session_state[\"own_account\"] = False\n",
    "    \n",
    "        st.session_state.gpt_model = \"gpt-3.5-turbo-0125\"\n",
    "\n",
    "        st.session_state.gpt_enhancement_entry = False\n",
    "\n",
    "    \n",
    "        st.session_state.judgments_counter_bound = default_judgment_counter_bound\n",
    "    \n",
    "        #st.session_state['gpt_api_key'] = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "    \n",
    "    #judgments_counter_bound_entry = round(judgments_counter_bound_entry_raw)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d157be-355a-49d3-ac0f-b7b735191be9",
   "metadata": {},
   "source": [
    "## Consent and next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1842da-69dd-436b-ab06-c51c84f2b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "st.header(\"Consent\")\n",
    "\n",
    "st.markdown(\"\"\"By running the Empirical Legal Research Kickstarter, you agree that the data and/or information this form provides will be temporarily stored on one or more remote servers for the purpose of producing an output containing data in relation to judgments. Any such data and/or information may also be given to an artificial intelligence provider for the same purpose.\"\"\")\n",
    "\n",
    "consent =  st.checkbox('Yes, I agree.', value = False)\n",
    "\n",
    "st.markdown(\"\"\"If you do not agree, then please feel free to close this form.\"\"\")\n",
    "\n",
    "st.header(\"Next steps\")\n",
    "\n",
    "st.markdown(\"\"\"**:green[You can now run the Empirical Legal Research Kickstarter.]** A spreadsheet which hopefully has the data you seek will be available for download in about 2-3 minutes.\n",
    "\n",
    "You can also download a record of your responses.\n",
    "\"\"\")\n",
    "\n",
    "#Warning\n",
    "#if st.session_state.gpt_model == 'gpt-3.5-turbo-0125':\n",
    "    #st.warning('A low-cost AI will answer your question(s). Please check at least some of the answers.')\n",
    "\n",
    "#if st.session_state.gpt_model == \"gpt-4-turbo\":\n",
    "    #st.warning('An expensive AI will answer your question(s). Please be cautious.')\n",
    "\n",
    "run_button = st.button('RUN the program')\n",
    "\n",
    "keep_button = st.button('DOWNLOAD your form responses')\n",
    "\n",
    "reset_button = st.button(label='RESET to start afresh', type = 'primary',  help = \"Press to process new search terms or questions.\")\n",
    "\n",
    "#Display need resetting message if necessary\n",
    "if 'need_resetting' in st.session_state:\n",
    "#if st.session_state.need_resetting == 1:\n",
    "    st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5868728-8697-4c05-8532-bc4c77589a5a",
   "metadata": {},
   "source": [
    "## Previous responses and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a528871-82e9-48d1-9af2-56053b82fb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create placeholder download buttons if previous responses and results in st.session_state:\n",
    "\n",
    "if (('df_master' in st.session_state) and ('df_individual_output' in st.session_state)):\n",
    "\n",
    "    #Load previous responses and results\n",
    "    \n",
    "    df_master = st.session_state.df_master\n",
    "    df_individual_output = st.session_state.df_individual_output\n",
    "\n",
    "    #Buttons for downloading responses\n",
    "    st.subheader('Looking for your previous form responses?')\n",
    "\n",
    "    responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "\n",
    "    csv = convert_df_to_csv(df_master)\n",
    "\n",
    "    ste.download_button(\n",
    "        label=\"Download your previous responses as a CSV (for use in Excel etc)\", \n",
    "        data = csv,\n",
    "        file_name=responses_output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    xlsx = convert_df_to_excel(df_master)\n",
    "    \n",
    "    ste.download_button(label='Download your previous responses as an Excel spreadsheet (XLSX)',\n",
    "                        data=xlsx,\n",
    "                        file_name=responses_output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "\n",
    "    json = convert_df_to_json(df_master)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous responses as a JSON\", \n",
    "        data = json,\n",
    "        file_name= responses_output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    #Button for downloading results\n",
    "\n",
    "    st.subheader('Looking for your previous results?')\n",
    "\n",
    "    output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "\n",
    "    csv_output = convert_df_to_csv(df_individual_output)\n",
    "\n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a CSV (for use in Excel etc)\", \n",
    "        data = csv_output,\n",
    "        file_name= output_name + '.csv', \n",
    "        mime= \"text/csv\", \n",
    "#            key='download-csv'\n",
    "    )\n",
    "\n",
    "    excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "    \n",
    "    ste.download_button(label='Download your previous results as an Excel spreadsheet (XLSX)',\n",
    "                        data=excel_xlsx,\n",
    "                        file_name= output_name + '.xlsx', \n",
    "                        mime='application/vnd.ms-excel',\n",
    "                       )\n",
    "    \n",
    "    json_output = convert_df_to_json(df_individual_output)\n",
    "    \n",
    "    ste.download_button(\n",
    "        label=\"Download your previous results as a JSON\", \n",
    "        data = json_output,\n",
    "        file_name= output_name + '.json', \n",
    "        mime= \"application/json\", \n",
    "    )\n",
    "\n",
    "    st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = 'ðŸ¤”')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f71a3",
   "metadata": {},
   "source": [
    "# Save and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d89e4a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if preview_button:\n",
    "    \n",
    "    df_master = create_df()\n",
    "\n",
    "    judgments_url =  fca_search(case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'After date'], \n",
    "                     before_date = df_master.loc[0, 'Before date'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "\n",
    "    open_page(judgments_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8fa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    all_search_terms = str(catchwords_entry) + str(legislation_entry) + str(cases_cited_entry) + str(case_name_mnc_entry) + str(judge_entry) + str(reported_citation_entry) + str(file_number_entry) + str(npa_entry) + str(with_all_the_words_entry) + str(with_at_least_one_of_the_words_entry) + str(without_the_words_entry) + str(phrase_entry) + str(proximity_entry) + str(on_this_date_entry) + str(after_date_entry) + str(before_date_entry)\n",
    "    \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "    \n",
    "    elif int(consent) == 0:\n",
    "        st.warning(\"You must click on 'Yes, I agree.' to run the program.\")\n",
    "\n",
    "    elif (('df_master' in st.session_state) and ('df_individual_output' in st.session_state)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "\n",
    "        if 'need_resetting' not in st.session_state:\n",
    "            st.session_state['need_resetting'] = 1\n",
    "            \n",
    "\n",
    "    elif ((st.session_state.own_account == True) and (st.session_state.gpt_api_key_validity == False)):\n",
    "            \n",
    "        st.warning('You have not validated your API key.')\n",
    "        quit()\n",
    "\n",
    "    elif ((st.session_state.own_account == True) and (len(gpt_api_key_entry) < 20)):\n",
    "\n",
    "        st.warning('You have not entered a valid API key.')\n",
    "        quit()  \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        st.write('Your results will be available for download soon. The estimated waiting time is about 2-3 minutes per 10 judgments.')\n",
    "        #st.write('If this program produces an error or an unexpected spreadsheet, please double-check your search terms and try again.')\n",
    "\n",
    "        with st.spinner('Running...'):\n",
    "\n",
    "            try:\n",
    "        \n",
    "                #Create spreadsheet of responses\n",
    "                df_master = create_df()\n",
    "\n",
    "                #Activate user's own key or mine\n",
    "                if st.session_state.own_account == True:\n",
    "                    \n",
    "                    API_key = df_master.loc[0, 'Your GPT API key']\n",
    "    \n",
    "                else:\n",
    "                    API_key = st.secrets[\"openai\"][\"gpt_api_key\"]\n",
    "                \n",
    "            \n",
    "                #Produce results\n",
    "                df_individual_output = run(df_master)\n",
    "        \n",
    "                #Keep results in session state\n",
    "                if \"df_individual_output\" not in st.session_state:\n",
    "                    st.session_state[\"df_individual_output\"] = df_individual_output\n",
    "        \n",
    "                if \"df_master\" not in st.session_state:\n",
    "                    st.session_state[\"df_master\"] = df_master\n",
    "                \n",
    "                st.session_state[\"page_from\"] = 'pages/CTH.py'\n",
    "        \n",
    "                #Write results\n",
    "        \n",
    "                st.success(\"Your results are now available for download. Thank you for using the Empirical Legal Research Kickstarter!\")\n",
    "                \n",
    "                #Button for downloading results\n",
    "                output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_results'\n",
    "        \n",
    "                csv_output = convert_df_to_csv(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a CSV (for use in Excel etc)\", \n",
    "                    data = csv_output,\n",
    "                    file_name= output_name + '.csv', \n",
    "                    mime= \"text/csv\", \n",
    "        #            key='download-csv'\n",
    "                )\n",
    "        \n",
    "                excel_xlsx = convert_df_to_excel(df_individual_output)\n",
    "                \n",
    "                ste.download_button(label='Download your results as an Excel spreadsheet (XLSX)',\n",
    "                                    data=excel_xlsx,\n",
    "                                    file_name= output_name + '.xlsx', \n",
    "                                    mime='application/vnd.ms-excel',\n",
    "                                   )\n",
    "        \n",
    "                json_output = convert_df_to_json(df_individual_output)\n",
    "                \n",
    "                ste.download_button(\n",
    "                    label=\"Download your results as a JSON\", \n",
    "                    data = json_output,\n",
    "                    file_name= output_name + '.json', \n",
    "                    mime= \"application/json\", \n",
    "                )\n",
    "        \n",
    "                st.page_link('pages/AI.py', label=\"ANALYSE your spreadsheet with an AI\", icon = 'ðŸ¤”')\n",
    "\n",
    "                    \n",
    "                #Keep record on Google sheet\n",
    "                #Obtain google spreadsheet       \n",
    "                #conn = st.connection(\"gsheets_nsw\", type=GSheetsConnection)\n",
    "                #df_google = conn.read()\n",
    "                #df_google = df_google.fillna('')\n",
    "                #df_google=df_google[df_google[\"Processed\"]!='']\n",
    "                #df_master[\"Processed\"] = datetime.now()\n",
    "                #df_master.pop(\"Your GPT API key\")\n",
    "                #df_to_update = pd.concat([df_google, df_master])\n",
    "                #conn.update(worksheet=\"CTH\", data=df_to_update, )\n",
    "            \n",
    "            except Exception as e:\n",
    "                st.error('Your search terms may not return any judgments. Please press the PREVIEW button above to double-check.')\n",
    "                st.exception(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873fffb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if keep_button:\n",
    "\n",
    "    #Check whether search terms entered\n",
    "\n",
    "    all_search_terms = str(catchwords_entry) + str(legislation_entry) + str(cases_cited_entry) + str(case_name_mnc_entry) + str(judge_entry) + str(reported_citation_entry) + str(file_number_entry) + str(npa_entry) + str(with_all_the_words_entry) + str(with_at_least_one_of_the_words_entry) + str(without_the_words_entry) + str(phrase_entry) + str(proximity_entry) + str(on_this_date_entry) + str(after_date_entry) + str(before_date_entry)\n",
    "    \n",
    "    if all_search_terms.replace('None', '') == \"\":\n",
    "\n",
    "        st.warning('You must enter some search terms.')\n",
    "    \n",
    "    elif (('df_master' in st.session_state) and ('df_individual_output' in st.session_state)):\n",
    "        st.warning('You must :red[RESET] the program before processing new search terms or questions. Please press the :red[RESET] button above.')\n",
    "        \n",
    "        if 'need_resetting' not in st.session_state:\n",
    "            \n",
    "            st.session_state['need_resetting'] = 1\n",
    "            \n",
    "    else:\n",
    "            \n",
    "        df_master = create_df()\n",
    "    \n",
    "        df_master.pop(\"Your GPT API key\")\n",
    "    \n",
    "        df_master.pop(\"Processed\")\n",
    "    \n",
    "        responses_output_name = str(df_master.loc[0, 'Your name']) + '_' + str(today_in_nums) + '_responses'\n",
    "    \n",
    "        #Produce a file to download\n",
    "    \n",
    "        csv = convert_df_to_csv(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a CSV (for use in Excel etc)\", \n",
    "            data = csv,\n",
    "            file_name=responses_output_name + '.csv', \n",
    "            mime= \"text/csv\", \n",
    "    #            key='download-csv'\n",
    "        )\n",
    "\n",
    "\n",
    "        xlsx = convert_df_to_excel(df_master)\n",
    "        \n",
    "        ste.download_button(label='Download as an Excel spreadsheet (XLSX)',\n",
    "                            data=xlsx,\n",
    "                            file_name=responses_output_name + '.xlsx', \n",
    "                            mime='application/vnd.ms-excel',\n",
    "                           )\n",
    "        \n",
    "        json = convert_df_to_json(df_master)\n",
    "        \n",
    "        ste.download_button(\n",
    "            label=\"Download as a JSON\", \n",
    "            data = json,\n",
    "            file_name= responses_output_name + '.json', \n",
    "            mime= \"application/json\", \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9837b934-f6e5-4db5-851c-0d4e48b85482",
   "metadata": {},
   "outputs": [],
   "source": [
    "if return_button:\n",
    "\n",
    "    st.switch_page(\"Home.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f2fc5-c22d-4f00-a3f4-f063c2c9594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reset_button:\n",
    "    clear_cache_except_validation_df_master()\n",
    "    st.rerun()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
