{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import urllib.request\n",
    "import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "import pdf2image\n",
    "#from PIL import Image\n",
    "#import math\n",
    "#from math import ceil\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36b77045-bdcc-4ee1-a9a4-b7dd03b6bfd4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, save_input\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, save_input\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, default_judgment_counter_bound, no_results_msg, search_error_note"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# English Reports search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "151727b0-e03c-4ab1-be18-4fd113d064af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'common_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m link\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'common_functions'"
     ]
    }
   ],
   "source": [
    "from functions.common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f2f670-342c-44ab-a87b-58aa2b023b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of search methods\n",
    "\n",
    "er_methods_list = ['using autosearch', 'this Boolean query', 'any of these words', 'all of these words', 'this phrase', 'this case name']\n",
    "er_method_types = ['auto', 'boolean', 'any', 'all', 'phrase', 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 11:14:01.664 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Function turning search terms to search results url\n",
    "#@st.cache_data(show_spinner = False)\n",
    "def er_search(query= '', \n",
    "              method = ''\n",
    "             ):\n",
    "    base_url = \"http://www.commonlii.org/cgi-bin/sinosrch.cgi?\" #+ method\n",
    "\n",
    "    method_index = er_methods_list.index(method)\n",
    "    method_type = er_method_types[method_index]\n",
    "\n",
    "    query_text = query\n",
    "\n",
    "    params = {'meta' : '/commonlii', \n",
    "              'mask_path' : '+uk/cases/EngR+', \n",
    "              'method' : method_type,\n",
    "              'query' : query_text\n",
    "             }\n",
    "\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    \n",
    "    return {'results_url': response.url, 'soup': soup}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6321d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 11:14:03.533 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function turning search results url to case_link_pairs to judgments\n",
    "\n",
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def er_search_results_to_case_link_pairs(_soup, url_search_results, judgment_counter_bound):\n",
    "    #_soup, url_search_results are from er_search\n",
    "\n",
    "    hrefs = _soup.find_all('a', href=True)\n",
    "    case_link_pairs = []\n",
    "\n",
    "    #number of search results\n",
    "    docs_found_string = str(_soup.find_all('span', {'class' : 'ndocs'})).split('Documents found:')[1].split('<')[0].replace(' ', '').replace(',', '')\n",
    "    docs_found = int(float(docs_found_string))\n",
    "    \n",
    "    #Start counter\n",
    "    counter = 1\n",
    "    \n",
    "    for link in hrefs:\n",
    "        if ((counter <= judgment_counter_bound) and (' ER ' in str(link)) and ('cases' in str(link))):\n",
    "#        if ((counter <= judgment_counter_bound) and ('commonlii' in str(link)) and ('cases/EngR' in str(link)) and ('LawCite' not in str(link))):\n",
    "            case = link.get_text()\n",
    "            link_direct = link.get('href')\n",
    "            sub_link = link_direct.replace('.html', '.pdf').split('cases')[1].split('.pdf')[0]\n",
    "            pdf_link = 'http://www.commonlii.org/uk/cases' + sub_link + '.pdf'\n",
    "            dict_object = {'case':case, 'link_direct': pdf_link}\n",
    "            case_link_pairs.append(dict_object)\n",
    "            counter = counter + 1\n",
    "        \n",
    "    for ending in range(20, docs_found, 20):\n",
    "        if counter <= min(judgment_counter_bound, docs_found):\n",
    "            url_next_page = url_search_results + ';offset=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            \n",
    "            hrefs_next_page = soup_judgment_next_page.find_all('a', href=True)\n",
    "            for extra_link in hrefs_next_page:\n",
    "                if ((counter <= judgment_counter_bound) and (' ER ' in str(extra_link)) and ('cases' in str(extra_link))):\n",
    "#                if ((counter <= judgment_counter_bound) and ('commonlii' in str(extra_link)) and ('cases/EngR' in str(extra_link)) and ('LawCite' not in str(extra_link))):\n",
    "                    case = extra_link.get_text()\n",
    "                    extra_link_direct = extra_link.get('href')\n",
    "                    sub_extra_link = extra_link_direct.replace('.html', '.pdf').split('cases')[1].split('.pdf')[0]\n",
    "                    pdf_extra_link = 'http://www.commonlii.org/uk/cases' + sub_extra_link + '.pdf'\n",
    "                    dict_object = {'case':case, 'link_direct': pdf_extra_link}\n",
    "                    case_link_pairs.append(dict_object)\n",
    "                    counter = counter + 1\n",
    "\n",
    "            pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #If no need to get rid of repetitions\n",
    "    #return case_link_pairs\n",
    "    \n",
    "    #Get rid of repetitions\n",
    "    case_link_pairs_no_repeats = []\n",
    "\n",
    "    for case_link_pair in case_link_pairs:\n",
    "        if  case_link_pair not in case_link_pairs_no_repeats:\n",
    "            case_link_pairs_no_repeats.append(case_link_pair)\n",
    "            \n",
    "    return case_link_pairs_no_repeats\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a72562c-8dce-4d9e-a2f4-c7a14a5877a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 11:14:05.212 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Convert case-link pairs to judgment text\n",
    "\n",
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def er_judgment_text(case_link_pair):\n",
    "    url = case_link_pair['link_direct']\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    remote_file_bytes = io.BytesIO(r.content)\n",
    "    pdfdoc_remote = pypdf.PdfReader(remote_file_bytes)\n",
    "    \n",
    "    text_list = []\n",
    "    \n",
    "    for page in pdfdoc_remote.pages:\n",
    "        text_list.append(page.extract_text())\n",
    "    \n",
    "    return str(text_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86a85223-64ca-4d1b-998c-1c2769c5a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#@st.cache_data(show_spinner = False)\n",
    "def er_meta_judgment_dict(case_link_pair):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                     'Medium neutral citation' : '', \n",
    "                     'English Reports': '', \n",
    "                     'Nominate Reports': '', \n",
    "                     'Hyperlink to CommonLII': '', \n",
    "                     'Year' : '', \n",
    "                     'judgment': ''\n",
    "                    }\n",
    "\n",
    "    try:\n",
    "        case_name = case_link_pair['case']\n",
    "        year = case_link_pair['link_direct'].split('EngR/')[-1][0:4]\n",
    "        case_num = case_link_pair['link_direct'].split('/')[-1].replace('.pdf', '')\n",
    "        mnc = '[' + year + ']' + ' EngR ' + case_num\n",
    "    \n",
    "        er_cite = ''\n",
    "        nr_cite = ''\n",
    "            \n",
    "        try:\n",
    "            case_name = case_link_pair['case'].split('[')[0][:-1]\n",
    "            nr_cite = case_link_pair['case'].split(';')[-2][1:]\n",
    "            er_cite = case_link_pair['case'].split(';')[-1][1:]\n",
    "\n",
    "            if ('ER' not in er_cite) and ('E.R.' not in er_cite):\n",
    "\n",
    "                try:\n",
    "                    \n",
    "                    er_cite_raw = re.findall(r'(\\d+\\sE\\.?R\\.?\\s\\d+((\\s\\(\\w+\\))?))', case_link_pair['case'])[0]\n",
    "    \n",
    "                    if isinstance(er_cite_raw, tuple):\n",
    "                        er_cite = er_cite_raw[0]\n",
    "                    else:\n",
    "                        er_cite = str(er_cite_raw)\n",
    "\n",
    "                except:\n",
    "                    print(f\"{mnc}: can't get ER cite.\")\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        judgment_dict['Case name'] = case_name\n",
    "        judgment_dict['Medium neutral citation'] = mnc\n",
    "        judgment_dict['English Reports'] = er_cite\n",
    "        judgment_dict['Nominate Reports'] = nr_cite\n",
    "        judgment_dict['Year'] = year\n",
    "        judgment_dict['Hyperlink to CommonLII'] = link(case_link_pair['link_direct'])\n",
    "        judgment_dict['judgment'] = er_judgment_text(case_link_pair)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{judgment_dict['Case name']}: judgment not scrapped\")\n",
    "        print(e)\n",
    "                \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a63874-213d-4ef7-b756-348bd5d35ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@st.cache_data(show_spinner = False)\n",
    "def er_search_url(df_master):\n",
    "\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_soup = er_search(query= df_master.loc[0, 'Enter search query'],\n",
    "                    method= df_master.loc[0, 'Find (method)']\n",
    "                   )\n",
    "\n",
    "    return {'results_url': url_soup['results_url'], 'soup': url_soup['soup']}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24172f8-acaf-4be0-ac0c-dd0dfc6737a9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import basic_model, flagship_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecf1d9d-6f84-4ec2-976f-73a4fc752235",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, GPT_answers_check, unanswered_questions, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2292028-93db-41f6-b886-0fcee71ad703",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "\n",
    "role_content_er = \"\"\"You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. \n",
    "Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from a part of the judgment or metadata, include a reference to that part of the judgment or metadata. \n",
    "If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". \n",
    "The \"judgment\" field of the JSON given to you sometimes contains judgments for multiple cases. If you detect multiple judgments in the \"judgment\" field, please provide answers only for the specific case identified in the \"Case name\" field of the JSON given to you. \n",
    "\"\"\"\n",
    "\n",
    "#Respond in JSON form. In your response, produce as many keys as you need. \n",
    "\n",
    "#system_instruction = role_content_er\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def er_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "\n",
    "    results_url_soup = er_search(query= df_master.loc[0, 'Enter search query'], \n",
    "                                   method = df_master.loc[0, 'Find (method)']\n",
    "                                  )     \n",
    "    url_search_results = results_url_soup['results_url']\n",
    "\n",
    "    soup = results_url_soup['soup']\n",
    "\n",
    "    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_link_pairs = er_search_results_to_case_link_pairs(soup, url_search_results, judgment_counter_bound)\n",
    "\n",
    "    for case_link_pair in case_link_pairs:\n",
    "\n",
    "        judgment_dict = er_meta_judgment_dict(case_link_pair)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))\n",
    "\n",
    "        print(f\"Scrapped {len(judgments_file)}/{judgment_counter_bound} judgments.\")\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    if (pop_judgment() > 0) and ('judgment' in df_updated.columns):\n",
    "        df_updated.pop('judgment')\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb4142-30d3-4dfa-a2b1-0317592f5704",
   "metadata": {},
   "source": [
    "# For vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "021bbaaf-a520-4113-a22b-c6206ff44680",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_image_dims, calculate_image_token_cost\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import get_image_dims, calculate_image_token_cost, GPT_b64_json, engage_GPT_b64_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9ed9ee2-0dea-4f6a-840b-bb5ed83eca08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert case-link pairs to judgment_b64 text\n",
    "\n",
    "#@st.cache_data(show_spinner = False)\n",
    "def er_judgment_tokens_b64(case_link_pair):\n",
    "\n",
    "    output_b64 = {'judgment_b64':[], 'tokens_raw': 0}\n",
    "    \n",
    "    url = case_link_pair['link_direct']\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(url, headers=headers)\n",
    "    bytes_data = io.BytesIO(r.content)\n",
    "    \n",
    "    images = pdf2image.convert_from_bytes(bytes_data.read(), timeout=30, fmt=\"jpeg\")\n",
    "    \n",
    "    for image in images[ : len(images)]:\n",
    "\n",
    "        output = BytesIO()\n",
    "        image.save(output, format='JPEG')\n",
    "        im_data = output.getvalue()\n",
    "        \n",
    "        image_data = base64.b64encode(im_data)\n",
    "        if not isinstance(image_data, str):\n",
    "            # Python 3, decode from bytes to string\n",
    "            image_data = image_data.decode()\n",
    "        data_url = 'data:image/jpg;base64,' + image_data\n",
    "\n",
    "        #b64 = base64.b64encode(image_raw).decode('utf-8')\n",
    "\n",
    "        b64_to_attach = data_url\n",
    "        #b64_to_attach = f\"data:image/png;base64,{b64}\"\n",
    "\n",
    "        output_b64['judgment_b64'].append(b64_to_attach)\n",
    "    \n",
    "    for image_b64 in output_b64['judgment_b64']:\n",
    "\n",
    "        output_b64['tokens_raw'] = output_b64['tokens_raw'] + calculate_image_token_cost(image_b64, detail=\"auto\")\n",
    "    \n",
    "    return output_b64\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a95d7b4-0db7-4e5f-84e4-a6e937420034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment_b64 combined\n",
    "\n",
    "def er_meta_judgment_dict_b64(case_link_pair):\n",
    "\n",
    "    try:\n",
    "        judgment_dict = {'Case name': '',\n",
    "                         'Medium neutral citation' : '', \n",
    "                         'English Reports': '', \n",
    "                         'Nominate Reports': '', \n",
    "                         'Hyperlink to CommonLII': '', \n",
    "                         'Year' : '', \n",
    "                         'judgment_b64': '', \n",
    "                         'tokens_raw': 0\n",
    "                        }\n",
    "    \n",
    "        case_name = case_link_pair['case']\n",
    "        year = case_link_pair['link_direct'].split('EngR/')[-1][0:4]\n",
    "        case_num = case_link_pair['link_direct'].split('/')[-1].replace('.pdf', '')\n",
    "        mnc = '[' + year + ']' + ' EngR ' + case_num\n",
    "    \n",
    "        er_cite = ''\n",
    "        nr_cite = ''\n",
    "            \n",
    "        try:\n",
    "            case_name = case_link_pair['case'].split('[')[0][:-1]\n",
    "            nr_cite = case_link_pair['case'].split(';')[1][1:]\n",
    "            er_cite = case_link_pair['case'].split(';')[2][1:]\n",
    "        except:\n",
    "            pass\n",
    "                    \n",
    "        judgment_dict['Case name'] = case_name\n",
    "        judgment_dict['Medium neutral citation'] = mnc\n",
    "        judgment_dict['English Reports'] = er_cite\n",
    "        judgment_dict['Nominate Reports'] = nr_cite\n",
    "        judgment_dict['Year'] = year\n",
    "        judgment_dict['Hyperlink to CommonLII'] = link(case_link_pair['link_direct'])\n",
    "        judgment_dict['judgment_b64'] = er_judgment_tokens_b64(case_link_pair)['judgment_b64']\n",
    "        judgment_dict['tokens_raw'] = er_judgment_tokens_b64(case_link_pair)['tokens_raw']\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{judgment_dict['Case name']}: judgment_b64 not scrapped\")\n",
    "        print(e)\n",
    "    \n",
    "    return judgment_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d3046c1e-5d6f-463a-92e4-84897573bf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For vision\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def er_run_b64(df_master):\n",
    "\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "\n",
    "    results_url_soup = er_search(query= df_master.loc[0, 'Enter search query'], \n",
    "                                   method = df_master.loc[0, 'Find (method)']\n",
    "                                  )     \n",
    "    url_search_results = results_url_soup['results_url']\n",
    "\n",
    "    soup = results_url_soup['soup']\n",
    "\n",
    "    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_link_pairs = er_search_results_to_case_link_pairs(soup, url_search_results, judgment_counter_bound)\n",
    "\n",
    "    for case_link_pair in case_link_pairs:\n",
    "\n",
    "        judgment_dict = er_meta_judgment_dict_b64(case_link_pair)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))\n",
    "\n",
    "        print(f\"Scrapped {len(judgments_file)}/{judgment_counter_bound} judgments.\")\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "            \n",
    "    #apply GPT_individual to each respondent's judgment_b64 spreadsheet\n",
    "\n",
    "    df_updated = engage_GPT_b64_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    #Remove redundant columns\n",
    "\n",
    "    for column in ['tokens_raw', 'judgment_b64']:\n",
    "        try:\n",
    "            df_updated.pop(column)\n",
    "        except:\n",
    "            print(f\"No {column} column.\")\n",
    "\n",
    "    return df_updated"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
