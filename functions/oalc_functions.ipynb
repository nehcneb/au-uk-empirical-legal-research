{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a61c3bc-1c80-4a47-a2e9-b40870f4d8d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#from datasets import DatasetInfo\n",
    "#from datasets import load_dataset_builder\n",
    "#from datasets import get_dataset_split_names\n",
    "from datasets import load_from_disk\n",
    "import os\n",
    "import streamlit as st\n",
    "import requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80066088-77dc-4b37-b56b-e5d177170170",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_title_mnc, judgment_text_lower_bound, huggingface\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#from common_functions import split_title_mnc\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "from functions.common_functions import split_title_mnc, judgment_text_lower_bound, huggingface\n",
    "#from common_functions import split_title_mnc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7e8a3-f98d-4594-9f6c-b9fd118e8574",
   "metadata": {},
   "source": [
    "# Download corpus then search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69baa871-b38e-4f02-bd6b-7677a6385537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load corpus\n",
    "\n",
    "@st.cache_resource(show_spinner = False)\n",
    "def load_corpus():\n",
    "\n",
    "    #Determine whether to load corpus remotely or locally\n",
    "    current_dir = ''\n",
    "    try:\n",
    "        current_dir = os.getcwd()\n",
    "        print(f\"current_dir == {current_dir}\")\n",
    "    except Exception as e:\n",
    "        print(f\"current_dir not generated.\")\n",
    "        print(e)\n",
    "    \n",
    "    if 'Users/Ben' not in current_dir: #If running on Huggingface or Github Actions\n",
    "        corpus = load_dataset('nehcneb/oalc_cases', split='train', revision='refs/convert/parquet')#, streaming=True)\n",
    "    else:        \n",
    "        #If running locally\n",
    "        corpus = load_from_disk(st.secrets['huggingface']['oalc_cases_local_path']) #keep_in_memory=False, \n",
    "\n",
    "    return corpus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fcba2e-89fc-4295-b8db-e8586d2c075a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting texts from a list of cases then match with the mnc\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def get_judgment_from_oalc_direct(mnc_list):\n",
    "\n",
    "    #Load corpus\n",
    "    corpus = load_corpus()\n",
    "\n",
    "    #Get judgments from corpus\n",
    "    mnc_judgment_dict = {}\n",
    "    for mnc in mnc_list:\n",
    "        mnc_judgment_dict.update({mnc: ''})\n",
    "        \n",
    "    records = corpus.filter(lambda x: split_title_mnc(x['citation'])[1] in mnc_list)\n",
    "\n",
    "    for record in records:\n",
    "        mnc = split_title_mnc(record['citation'])[1]\n",
    "        if mnc in mnc_judgment_dict.keys():\n",
    "            judgment = record['text']\n",
    "            mnc_judgment_dict[mnc] = judgment\n",
    "\n",
    "    #Remove any blank or very short judgments\n",
    "    mncs_to_pop = []\n",
    "    \n",
    "    for mnc in mnc_judgment_dict.keys():\n",
    "        if len(mnc_judgment_dict[mnc]) < judgment_text_lower_bound*4: #judgment_text_lower_bound is in tokens, each token ~= 4 characters\n",
    "            mncs_to_pop.append(mnc)\n",
    "\n",
    "    for mnc in mncs_to_pop:\n",
    "        mnc_judgment_dict.pop(mnc)\n",
    "    \n",
    "    return mnc_judgment_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed62e458-d893-403c-95fe-db838ef65740",
   "metadata": {},
   "source": [
    "# Search without downloading corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11943431-90ca-4a23-af2a-e2bed2c31ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Based on https://huggingface.co/docs/dataset-viewer/en/filter\n",
    "\n",
    "def oalc_filter(dataset, split, config = 'default', where = None, orderby = None, offset = None, length = None):\n",
    "\n",
    "    base_url = \"https://datasets-server.huggingface.co/filter\"\n",
    "\n",
    "    try: #If running locally\n",
    "        HF_TOKEN = st.secrets[\"huggingface\"][\"hf_token\"]\n",
    "        \n",
    "    except: #If running on Huggingface or Github Actions\n",
    "        HF_TOKEN = os.environ['HF_TOKEN']\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "    params = {\n",
    "    'dataset':dataset, #the dataset name, for example nyu-mll/glue or mozilla-foundation/common_voice_10_0\n",
    "    'config': config, #the subset name, for example cola\n",
    "    'split': split, #the split name, for example train\n",
    "    'where': where, #the filter condition\n",
    "    'orderby': orderby, #the order-by clause\n",
    "    'no_answer': 'true', \n",
    "    'offset': offset, #the offset of the slice, for example 150\n",
    "    'length': length\n",
    "        }\n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "\n",
    "    #print(response.url)\n",
    "    \n",
    "    return response.json()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f50a43e-0a10-4222-8b7a-3c70b0bcd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting texts from a list of cases then match with the mnc, without downloading\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def get_judgment_from_oalc(mnc_list):\n",
    "\n",
    "\n",
    "    #Figure out jurisdiction\n",
    "    subset = 'default'\n",
    "    #ENABLE after splitting corpus into jurisdiction subsets\n",
    "    if 'nsw' in mnc_list[0].lower():\n",
    "        subset = 'nsw_caselaw'\n",
    "    \n",
    "    if 'fca' in mnc_list[0].lower():\n",
    "        subset = 'federal_court_of_australia'\n",
    "    \n",
    "    if 'hca' in mnc_list[0].lower():\n",
    "        subset = 'high_court_of_australia'\n",
    "    \n",
    "    #Create list of mncs for use in the where argument of oalc_filter\n",
    "    where_list = []\n",
    "\n",
    "    for mnc in mnc_list:\n",
    "        search_str = f\"\"\"\n",
    "        \"citation\" ILIKE '%{mnc}'\n",
    "        \"\"\"\n",
    "        where_list.append(search_str)\n",
    "\n",
    "    where_str = ' OR '.join(where_list)\n",
    "\n",
    "    #Get judgments from corpus online\n",
    "    data = oalc_filter(dataset = 'nehcneb/oalc_cases', \n",
    "                 split = 'train', \n",
    "               config = subset, \n",
    "                where = where_str, \n",
    "                 #where = \"\"\"\n",
    "                 #(\"citation\" ILIKE '%[1995] FCA 23' OR \"citation\" ILIKE '%[1995] HCA 1')\n",
    "                 #\"\"\", \n",
    "                 #orderby = '\"date\" DESC NULLS LAST', \n",
    "                 length = len(mnc_list))\n",
    "\n",
    "    #Create dict of mncs and judgments\n",
    "\n",
    "    mnc_judgment_dict = {}\n",
    "    for mnc in mnc_list:\n",
    "        mnc_judgment_dict.update({mnc: ''})\n",
    "\n",
    "    try:\n",
    "        for case in data[\"rows\"]:\n",
    "            citation = case['row']['citation']\n",
    "            mnc = split_title_mnc(citation)[1]\n",
    "            if mnc in mnc_judgment_dict.keys():\n",
    "                judgment = case['row']['text']\n",
    "                mnc_judgment_dict[mnc] = judgment\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    \n",
    "    #Remove any blank or very short judgments\n",
    "    mncs_to_pop = []\n",
    "    \n",
    "    for mnc in mnc_judgment_dict.keys():\n",
    "        if len(mnc_judgment_dict[mnc]) < judgment_text_lower_bound*4: #judgment_text_lower_bound is in tokens, each token ~= 4 characters\n",
    "            mncs_to_pop.append(mnc)\n",
    "\n",
    "    for mnc in mncs_to_pop:\n",
    "        mnc_judgment_dict.pop(mnc)\n",
    "    \n",
    "    return mnc_judgment_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ceeb1a3b-7f88-4bc6-8b17-f4cb191fb5ef",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Based on  https://huggingface.co/docs/dataset-viewer/en/search\n",
    "\n",
    "#NOT IN USE\n",
    "\n",
    "def oalc_search(dataset, split, config = 'default', query = None, orderby = None, offset = None, length = None):\n",
    "\n",
    "    base_url = \"https://datasets-server.huggingface.co/search\"\n",
    "\n",
    "    try: #If running locally\n",
    "        HF_TOKEN = st.secrets[\"huggingface\"][\"hf_token\"]\n",
    "        \n",
    "    except: #If running on Huggingface or Github Actions\n",
    "        HF_TOKEN = os.environ['HF_TOKEN']\n",
    "\n",
    "    headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\"}\n",
    "    params = {\n",
    "    'dataset':dataset, #the dataset name, for example nyu-mll/glue or mozilla-foundation/common_voice_10_0\n",
    "    'config': config, #the subset name, for example cola\n",
    "    'split': split, #the split name, for example train\n",
    "    'query': query, #the filter condition\n",
    "    'orderby': orderby, #the order-by clause\n",
    "    'no_answer': 'true', \n",
    "    'offset': offset, #the offset of the slice, for example 150\n",
    "    'length': length\n",
    "        }\n",
    "    \n",
    "    response = requests.get(base_url, params=params, headers=headers)\n",
    "    \n",
    "    return response.json()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
