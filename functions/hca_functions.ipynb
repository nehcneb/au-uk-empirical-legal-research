{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface == True\n",
      "By default, users are allowed to use their own account\n",
      "The pause between judgment scraping is 5 second.\n",
      "\n",
      "The lower bound on lenth of judgment text to process is 4000 tokens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, save_input\n",
    "#Import variables\n",
    "from functions.common_functions import huggingface, today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# High Court of Australia search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3329d8-1716-4570-8dd0-4b5aa22aaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.common_functions import link, is_date, list_value_check, au_date, split_title_mnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca5f1d2-b354-45be-b365-0f01233c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collections available\n",
    "hca_collections = ['Judgments 2000-present', 'Judgments 1948-1999', '1 CLR - 100 CLR (judgments 1903-1958)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url AND number of search results\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_search(collection = hca_collections[0], \n",
    "               quick_search = '', \n",
    "               #citation = '', \n",
    "                full_text = ''):\n",
    "    #Default base url is for judgments 2000-current\n",
    "    #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "    base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "    \n",
    "    if collection == 'Judgments 2000-present':\n",
    "    \n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=1&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=1'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=2&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=2'\n",
    "    \n",
    "    params = {'qsrch-term': quick_search, \n",
    "              #'Citation_ST': citation, \n",
    "              'srch-term': full_text\n",
    "             }\n",
    "\n",
    "    #Get response page\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    #Get url_search_results\n",
    "    url_search_results = response.url\n",
    "\n",
    "    #Get number of search results and soup\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    number_of_results = soup.find(\"span\", id=\"itemTotal\").text\n",
    "    results_count = int(float(number_of_results.replace(',', '')))\n",
    "                        \n",
    "    return {'results_url': url_search_results, 'results_count': results_count, 'soup': soup}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e95d9963-c3b6-46f0-a1ea-c30c63e5aba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 12:42:14.026 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function turning search results url to cases_w_mnc_links to judgments\n",
    "#NOT IN USE\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    \n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    #Get number of pages\n",
    "    #There are up to 20 pages per page\n",
    "    number_of_pages = soup.find(\"span\", id=\"lastItem\").text\n",
    "    \n",
    "    #Start cases_w_mnc_links list\n",
    "    cases_w_mnc_links = []\n",
    "    \n",
    "    #Get first page of results\n",
    "    raw_links = soup.find_all(class_='case')\n",
    "\n",
    "    #Get list of catchwords\n",
    "    catchwords_list = soup.find_all(\"div\", {\"class\": \"well\"})\n",
    "        \n",
    "    null_result = soup.find_all('div', {'class' : 'well', 'id': 'top'})\n",
    "    \n",
    "    for result in null_result:\n",
    "        if result in catchwords_list:\n",
    "            catchwords_list.remove(result)\n",
    "    \n",
    "    if len(raw_links) > 0:\n",
    "    \n",
    "        for raw_link in raw_links:\n",
    "            raw_link_index = raw_links.index(raw_link)\n",
    "            if counter < judgment_counter_bound:\n",
    "                link = 'https://eresources.hcourt.gov.au' + raw_link['href']\n",
    "                case_name_mnc = split_title_mnc(raw_link.get_text().strip())\n",
    "                case_name = case_name_mnc[0]\n",
    "                mnc = case_name_mnc[1]\n",
    "\n",
    "                catchwords = ''\n",
    "\n",
    "                try:               \n",
    "                    catchwords = catchwords_list[raw_link_index].get_text(strip = True)\n",
    "\n",
    "                except:\n",
    "                    print(f\"{case['Case name']}: can't get 'Catchwords'\")\n",
    "\n",
    "                cases_w_mnc_links.append({'Case name': case_name, 'Medium neutral citation': mnc, 'Hyperlink to High Court Judgments Database': link, 'Catchwords': catchwords})\n",
    "                \n",
    "                counter += 1\n",
    "                #print(counter)\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #Go to next page if still below judgment_counter_bound\n",
    "        \n",
    "    if int(number_of_pages) > 1:\n",
    "            \n",
    "        if counter < judgment_counter_bound:\n",
    "\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            \n",
    "            for page_raw in range(1, int(number_of_pages)):\n",
    "                page = page_raw + 1\n",
    "                url_search_results_new_page = url_search_results + f'&page={page}'\n",
    "                page_new_page = requests.get(url_search_results_new_page)\n",
    "                soup_new_page = BeautifulSoup(page_new_page.content, \"lxml\")\n",
    "                raw_links_new_page = soup_new_page.find_all(class_='case')\n",
    "            \n",
    "                if len(raw_links_new_page) > 0:\n",
    "\n",
    "                    #Get list of catchwords\n",
    "                    catchwords_list = soup.find_all(\"div\", {\"class\": \"well\"})\n",
    "                    null_result = soup.find_all('div', {'class' : 'well', 'id': 'top'})\n",
    "                    \n",
    "                    for result in null_result:\n",
    "                        if result in catchwords_list:\n",
    "                            catchwords_list.remove(result)\n",
    "                \n",
    "                    for raw_link in raw_links_new_page:\n",
    "                        if counter < judgment_counter_bound:\n",
    "                            link = 'https://eresources.hcourt.gov.au' + raw_link['href']\n",
    "\n",
    "                            case_name_mnc = split_title_mnc(raw_link.get_text().strip())\n",
    "                            case_name = case_name_mnc[0]\n",
    "                            mnc = case_name_mnc[1]\n",
    "\n",
    "                            catchwords = ''\n",
    "            \n",
    "                            try:               \n",
    "                                catchwords = catchwords_list[raw_link_index].get_text(strip = True)\n",
    "            \n",
    "                            except:\n",
    "                                print(f\"{case['Case name']}: can't get 'Catchwords'\")\n",
    "            \n",
    "                            cases_w_mnc_links.append({'Case name': case_name, 'Medium neutral citation': mnc, 'Hyperlink to High Court Judgments Database': link, 'Catchwords': catchwords})\n",
    "\n",
    "                            counter += 1\n",
    "                            #print(counter)\n",
    "                        else:\n",
    "                            break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "    #Get more metadata\n",
    "    for case in cases_w_mnc_links:\n",
    "        mnc = case['Medium neutral citation']\n",
    "\n",
    "        index_list = hca_df.index[hca_df['mnc'].str.contains(mnc, case=False, na=False, regex=False)].tolist()\n",
    "\n",
    "        if len(index_list) > 0:\n",
    "            index = index_list[0]\n",
    "    \n",
    "            for meta in ['Date', 'Before', 'Reported']:\n",
    "                try:\n",
    "                    case.update({meta: hca_df.loc[int(index), meta.lower()]})\n",
    "                except:\n",
    "                    print(f\"{case['Case name']}: can't get '{meta}'\")\n",
    "    \n",
    "                try:\n",
    "                    case.update({'Case number': hca_df.loc[int(index), 'case_number']})\n",
    "                except:\n",
    "                    print(f\"{case['Case name']}: can't get 'Case number'\")\n",
    "        else:\n",
    "            print(f\"{case['Case name']}: can't get 'Date', 'Before', 'Reported' and 'Case number'\")\n",
    "\n",
    "    return cases_w_mnc_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90302a99-07e1-4516-bd21-4b6f9c33e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 12:42:14.029 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function for judgment link containing PDF\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_pdf_judgment(url):\n",
    "    pdf_url = url.replace('showCase', 'downloadPdf')\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(pdf_url, headers=headers)\n",
    "    remote_file_bytes = io.BytesIO(r.content)\n",
    "    pdfdoc_remote = pypdf.PdfReader(remote_file_bytes)\n",
    "    text_list = []\n",
    "\n",
    "    for page in pdfdoc_remote.pages:\n",
    "        text_list.append(page.extract_text())\n",
    "    \n",
    "    return str(text_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d93cfb-26fb-436a-bddf-eb20e1095d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "hca_meta_labels_droppable = ['Reported', 'Date', 'Case number', 'Before', 'Catchwords', 'Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632eaa5c-4f2b-47af-8c7f-c0a575d895f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 12:42:14.036 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#If judgment link contains 'showCase'\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                 'Catchwords' : '',  \n",
    "                'Order': '', \n",
    "                'judgment' : ''\n",
    "                }\n",
    "    \n",
    "    try:\n",
    "        #Attach hyperlink\n",
    "    \n",
    "        judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "        \n",
    "        page = requests.get(judgment_url)\n",
    "        soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "        #Case name\n",
    "        judgment_dict['Case name'] = soup.find('title').text\n",
    "    \n",
    "        #Medium neutral citation\n",
    "        year = judgment_url.split('showCase/')[1][0:4]\n",
    "        num = judgment_url.split('HCA/')[1]\n",
    "        \n",
    "        judgment_dict['Medium neutral citation'] = f'[{year}] HCA {num}'\n",
    "    \n",
    "        #Reported, decision date, before\n",
    "    \n",
    "        h2_tags = soup.find_all('h2')\n",
    "    \n",
    "        if len(h2_tags) > 0:\n",
    "            \n",
    "            for h2 in soup.find_all('h2'):\n",
    "                if 'clr' in h2.text.lower():\n",
    "                    \n",
    "                    judgment_dict['Reported'] = h2.text\n",
    "        \n",
    "                elif is_date(h2.text, fuzzy=False):\n",
    "        \n",
    "                    judgment_dict['Date'] = h2.text\n",
    "        \n",
    "                elif 'before' in h2.text.lower():\n",
    "                    judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "        \n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        #Case number\n",
    "    \n",
    "        case_number_list = soup.find_all(string=re.compile('Case Number'))\n",
    "    \n",
    "        if len(case_number_list) > 0:\n",
    "            \n",
    "            judgment_dict['Case number'] = case_number_list[0].split('Case Number')[1].replace(': ', '')\n",
    "    \n",
    "        #Checking\n",
    "    \n",
    "        if len(str(judgment_dict['Reported'])) < 5:\n",
    "    \n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Reported'] = hca_df.loc[int(index), 'reported']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get reported for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if is_date(str(judgment_dict['Date']), fuzzy=False) == False:\n",
    "    \n",
    "            try:\n",
    "                \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Date'] = hca_df.loc[index, 'date']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get date for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Before'])) < 3:\n",
    "    \n",
    "            try:\n",
    "        \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Before'] = hca_df.loc[int(index), 'before']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get before for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Case number'])) < 3:\n",
    "    \n",
    "            try:\n",
    "    \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Case number'] = hca_df.loc[int(index), 'case_number']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get case number for {judgment_dict['Medium neutral citation']}\")\n",
    "        \n",
    "        #Catchwords\n",
    "    \n",
    "        catchwords_list = soup.find_all('div', class_='well')\n",
    "    \n",
    "        if len(catchwords_list) > 0:\n",
    "            \n",
    "            judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "    \n",
    "        #Judgment text\n",
    "        judgment_dict['judgment'] = hca_pdf_judgment(judgment_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{judgment_dict['Case name']}: judgment not scrapped\")\n",
    "        print(e)\n",
    "        \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf3f7be-addd-4f87-82f7-b286f2b1fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 12:42:14.043 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#If judgment link contains 'showbyHandle'\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_meta_judgment_dict_alt(judgment_url):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                 'Catchwords' : '',\n",
    "                'Order': '',\n",
    "                'judgment' : ''\n",
    "                }\n",
    "\n",
    "    try:\n",
    "        #Attach hyperlink\n",
    "    \n",
    "        judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "        \n",
    "        page = requests.get(judgment_url)\n",
    "        soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "        #Case name\n",
    "        judgment_dict['Case name'] = soup.find('title').text\n",
    "    \n",
    "        #Judgment text\n",
    "    \n",
    "        judgment_list = soup.find_all(\"div\", {\"class\": \"opinion\"})\n",
    "        \n",
    "        judgment_pdfs_list = soup.find_all('a', {'class': 'btn btn-success'})\n",
    "        \n",
    "        if len(judgment_list) > 0:\n",
    "    \n",
    "            judgment_dict['judgment'] = judgment_list[0].text\n",
    "    \n",
    "        elif len(judgment_pdfs_list) > 0:\n",
    "            raw_link = judgment_pdfs_list[0]['href']\n",
    "            pdf_link = 'https://eresources.hcourt.gov.au' + raw_link\n",
    "            judgment_dict['judgment'] = hca_pdf_judgment(pdf_link)\n",
    "    \n",
    "        else:\n",
    "            judgment_dict['judgment'] = ''\n",
    "                \n",
    "        #Catchwords\n",
    "    \n",
    "        catchwords_list = soup.find_all(\"div\", {\"class\": \"Catchphrases\"})\n",
    "    \n",
    "        if len(catchwords_list) > 0:\n",
    "            judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "        \n",
    "        #Medium neutral citation meta tag\n",
    "        mnc_list = soup.find_all(\"div\", {\"class\": \"MNC\"})\n",
    "    \n",
    "        if len(mnc_list):\n",
    "    \n",
    "            judgment_dict['Medium neutral citation'] = mnc_list[0].text\n",
    "    \n",
    "        elif len(judgment_pdfs_list) > 0:\n",
    "    \n",
    "            mnc_raw = judgment_pdfs_list[0]['href'].replace('/downloadPdf/', '').replace('/', '')\n",
    "    \n",
    "            year = mnc_raw.lower().split('hca')[0]\n",
    "    \n",
    "            num = mnc_raw.lower().split('hca')[1]\n",
    "    \n",
    "            judgment_dict['Medium neutral citation'] = f\"[{year}] HCA {num}\"\n",
    "    \n",
    "        #Before\n",
    "        judges_list = soup.find_all(\"div\", {\"class\": \"judges-title\"})\n",
    "    \n",
    "        if len(judges_list) > 0:\n",
    "    \n",
    "            judgment_dict['Before'] = judges_list[0].text\n",
    "    \n",
    "    \n",
    "        #Order\n",
    "        order_list = soup.find_all(\"div\", {\"class\": \"order-text\"})\n",
    "    \n",
    "        if len(order_list) > 0:\n",
    "    \n",
    "            order = order_list[0].text#.replace('\\n            ', '')\n",
    "    \n",
    "            judgment_dict['Order'] = order\n",
    "    \n",
    "        #Reported, decision date, before\n",
    "    \n",
    "        h2_tags = soup.find_all('h2')\n",
    "    \n",
    "        if len(h2_tags) > 0:\n",
    "            \n",
    "            for h2 in soup.find_all('h2'):\n",
    "                if 'clr' in h2.text.lower():\n",
    "                    \n",
    "                    judgment_dict['Reported'] = h2.text\n",
    "        \n",
    "                elif is_date(h2.text, fuzzy=False):\n",
    "        \n",
    "                    judgment_dict['Date'] = h2.text\n",
    "        \n",
    "                elif 'before' in h2.text.lower():\n",
    "                    judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "        \n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "        #Checking\n",
    "    \n",
    "        if len(str(judgment_dict['Reported'])) < 5:\n",
    "    \n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Reported'] = hca_df.loc[int(index), 'reported']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get reported for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if is_date(str(judgment_dict['Date']), fuzzy=False) == False:\n",
    "    \n",
    "            try:\n",
    "                \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Date'] = hca_df.loc[index, 'date']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get date for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Before'])) < 3:\n",
    "    \n",
    "            try:\n",
    "        \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Before'] = hca_df.loc[int(index), 'before']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get before for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Case number'])) < 3:\n",
    "    \n",
    "            try:\n",
    "    \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Case number'] = hca_df.loc[int(index), 'case_number']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get case number for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{judgment_dict['Case name']}: judgment not scrapped\")\n",
    "        print(e)\n",
    "    \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d2e602-2dc9-4d8b-abc3-856d2cca791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 12:42:14.048 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Slow way of finding a case from mnc\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_mnc_to_link_browse(collection, year, num):\n",
    "\n",
    "    #Default judgment without the prefix https://eresources.hcourt.gov.au\n",
    "    judgment_url_raw = ''\n",
    "\n",
    "    if collection == 'Judgments 2000-present':\n",
    "                    \n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=0&facets=dateDecided'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=1&facets=dateDecided'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        \n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=2&facets=dateDecided'\n",
    "    \n",
    "    params = {'srch-term': year}\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "    pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Get list of pages\n",
    "\n",
    "    pages_list = []\n",
    "    \n",
    "    options = soup.find_all('option')\n",
    "        \n",
    "    for option in options:\n",
    "        if len(option.text) < 4:\n",
    "            pages_list.append(option.text)\n",
    "    \n",
    "    for page in pages_list:\n",
    "        \n",
    "        page_start = (int(page) - 1)*20\n",
    "\n",
    "        params_page = {'srch-term': year, 'page': page_start}\n",
    "\n",
    "        response_page = requests.get(base_url, params=params_page)\n",
    "        \n",
    "        response_page.raise_for_status()\n",
    "        \n",
    "        soup_page = BeautifulSoup(response_page.content, \"lxml\")\n",
    "\n",
    "        cases_list = soup_page.find_all(class_='case')\n",
    "\n",
    "        for case in cases_list:\n",
    "\n",
    "            if f'HCA {num}' in str(case):\n",
    "                judgment_url_raw = case['href']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if (('showbyHandle' in judgment_url_raw) or ('showCase' in judgment_url_raw)):\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            continue\n",
    "\n",
    "    return 'https://eresources.hcourt.gov.au' + judgment_url_raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb9ee624-ec1c-4752-97cf-9b1faa6b521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning citation to judgment_url\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_citation_to_link(collection, citation):\n",
    "\n",
    "    #Placeholder error url\n",
    "    judgment_url = f'https://eresources.hcourt.gov.au/showCase/1900/HCA/1'\n",
    "    \n",
    "    #Use mnc if entered\n",
    "    if 'hca' in citation.lower():\n",
    "       \n",
    "        try:\n",
    "            citation_formatted = citation.replace(' ', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            year = citation_formatted.lower().split('hca')[0]\n",
    "            \n",
    "            num = citation_formatted.lower().split('hca')[1]\n",
    "            \n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "            \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "\n",
    "        except Exception as e:\n",
    "            print('MNC entered but error.')\n",
    "            print(e)\n",
    "\n",
    "    else: #Get mnc from hca_df if not entered\n",
    "        try:\n",
    "            index_list = hca_df.index[hca_df['reported'].str.contains(citation, case=False, na=False)].tolist()\n",
    "            index = index_list[0]            \n",
    "        except:\n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['name'].str.contains(citation, case=False, na=False)].tolist()\n",
    "                index = index_list[0]\n",
    "            except:\n",
    "                try:\n",
    "                    index_list = hca_df.index[hca_df['date'].str.contains(citation, case=False, na=False)].tolist()\n",
    "                    index = index_list[0]\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print('Citation entered but not found.')\n",
    "                    print(e)\n",
    "                \n",
    "        try:\n",
    "            mnc = hca_df.loc[int(index), 'mnc']\n",
    "    \n",
    "            citation_formatted = mnc.replace(' ', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "            year = citation_formatted.lower().split('hca')[0]\n",
    "            \n",
    "            num = citation_formatted.lower().split('hca')[1]\n",
    "    \n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "    \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "            \n",
    "            return judgment_url\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Citation entered but error.')\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    #Check if judgment_url works\n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "        return judgment_url\n",
    "\n",
    "    else:\n",
    "        #Check if direct link to PDF works\n",
    "        try:\n",
    "            pdf_url = judgment_url.replace('showCase', 'downloadPdf')\n",
    "            \n",
    "            page = requests.get(pdf_url)\n",
    "        \n",
    "            soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "            if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "    \n",
    "                return pdf_url\n",
    "    \n",
    "            else:\n",
    "                #Try to use HCA's browse function to get link to case\n",
    "                judgment_url = hca_mnc_to_link_browse(collection, year, num)\n",
    "    \n",
    "                return judgment_url\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(\"Can't get case url for citation\")\n",
    "            print(e)\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21a2914b-388f-469d-9dba-2a66152f03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning mnc to judgment_url\n",
    "def hca_mnc_to_link(collection, mnc):\n",
    "#NOT in use\n",
    "    \n",
    "    mnc_formatted = mnc.replace(' ', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "    if 'HCA' in mnc_formatted:\n",
    "\n",
    "        year = mnc_formatted.split('HCA')[0]\n",
    "        \n",
    "        num = mnc_formatted.split('HCA')[1]\n",
    "       \n",
    "        try:\n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "            \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "\n",
    "            page = requests.get(judgment_url)\n",
    "            \n",
    "            soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "            if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "                return judgment_url\n",
    "\n",
    "            else:\n",
    "                \n",
    "                judgment_url = f'https://eresources.hcourt.gov.au/downloadPdf/{year_int}/HCA/{num_int}'\n",
    "\n",
    "                page = requests.get(judgment_url)\n",
    "            \n",
    "                soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "                if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "                    return judgment_url\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    judgment_url = hca_mnc_to_link_browse(collection, year, num)\n",
    "\n",
    "                    return judgment_url\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return ''\n",
    "            \n",
    "    else:\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65a4564a-abad-4e9b-a6da-e8291e51f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load hca_data\n",
    "\n",
    "@st.cache_resource(show_spinner = False)\n",
    "def hca_load_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "hca_data_url = 'https://raw.githubusercontent.com/nehcneb/au-uk-empirical-legal-research/main/hca_data.csv'\n",
    "\n",
    "#response = requests.get(hca_data_url)\n",
    "\n",
    "#hca_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "hca_df = hca_load_data(hca_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe05822c-ac9d-48b6-9fdf-1690bb2daaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to excluding unwanted jugdments\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_judgment_to_exclude(case_info,\n",
    "                        collection, \n",
    "                        own_parties_include, \n",
    "                        own_parties_exclude, \n",
    "                        after_date, \n",
    "                        before_date, \n",
    "                        #own_case_numbers_include = [], \n",
    "                        #own_case_numbers_exclude = [], \n",
    "                        own_judges_include, \n",
    "                        own_judges_exclude\n",
    "                       ):\n",
    "\n",
    "    #Default status is not to exclude\n",
    "    exclude_status = False\n",
    "\n",
    "    #Exclude parties\n",
    "\n",
    "    parties_to_include = str(own_parties_include).replace(';', ',').split(',')\n",
    "\n",
    "    if 'None' in parties_to_include:\n",
    "        parties_to_include.remove('None')\n",
    "\n",
    "    if '' in parties_to_include:\n",
    "        parties_to_include.remove('')\n",
    "    \n",
    "    #st.write(f\"parties_to_include == {parties_to_include}\")\n",
    "    \n",
    "    if len(parties_to_include) > 0:\n",
    "        \n",
    "        party_inclusion_counter = 0\n",
    "        \n",
    "        for party in parties_to_include:\n",
    "            \n",
    "            if ((len(party) > 0) and (party.lower() in case_info['Case name'].lower())):\n",
    "    \n",
    "                party_inclusion_counter += 1\n",
    "\n",
    "        #st.write(f\"party_inclusion_counter=={party_inclusion_counter}\")\n",
    "        \n",
    "        if party_inclusion_counter == 0:\n",
    "        \n",
    "            #st.write(f'Excluded based on party')\n",
    "            \n",
    "            exclude_status = True\n",
    "\n",
    "    parties_to_exclude = str(own_parties_exclude).replace(';', ',').split(',')\n",
    "\n",
    "    if 'None' in parties_to_exclude:\n",
    "        parties_to_exclude.remove('None')\n",
    "\n",
    "    if '' in parties_to_exclude:\n",
    "        parties_to_exclude.remove('')\n",
    "    \n",
    "    #st.write(f\"parties_to_exclude == {parties_to_exclude}\")\n",
    "\n",
    "    if len(parties_to_exclude) > 0:\n",
    "    \n",
    "        for party in parties_to_exclude:\n",
    "            \n",
    "            if ((len(party) > 0) and (party.lower() in case_info['Case name'].lower())):\n",
    "\n",
    "\n",
    "                #st.write(f'Excluded based on party == {party}')\n",
    "\n",
    "                exclude_status = True\n",
    "            \n",
    "                break\n",
    "\n",
    "    #Exclude Date\n",
    "\n",
    "    if is_date(case_info['Date'], fuzzy=False):\n",
    "        \n",
    "        date_datetime = parser.parse(case_info['Date'], dayfirst=True)\n",
    "        \n",
    "        #if collection != 'Judgments 2000-present':\n",
    "            #Reducing 100 because if year is 2 digits, parser assumes current century\n",
    "            \n",
    "            #date_datetime = date_datetime - relativedelta(years = 100) \n",
    "\n",
    "        if is_date(after_date, fuzzy=False):\n",
    "\n",
    "            after_date_datetime = parser.parse(after_date,dayfirst=True)\n",
    "    \n",
    "            if date_datetime < after_date_datetime:\n",
    "    \n",
    "                exclude_status = True\n",
    "\n",
    "        if is_date(before_date, fuzzy=False):\n",
    "\n",
    "            before_date_datetime = parser.parse(before_date, dayfirst=True)\n",
    "    \n",
    "            if date_datetime > before_date_datetime:\n",
    "    \n",
    "                exclude_status = True\n",
    "\n",
    "    #Exclude year\n",
    "\n",
    "    #potential_year_list = []\n",
    "\n",
    "    #potential_year_raw_list = case_info['Case name'].split('[')\n",
    "\n",
    "    #for potential_year in potential_year_raw_list:\n",
    "\n",
    "        #try:\n",
    "            #year_decided_raw = int(potential_year[0:4])\n",
    "            \n",
    "            #potential_year_list.append(year_decided_raw)\n",
    "\n",
    "        #except:\n",
    "            \n",
    "            #print('Potential year value is not integer')\n",
    "\n",
    "    #if len(potential_year_list) > 0:\n",
    "    #Defining year_decided here to avoid the possibility of year not being picked up\n",
    "        #year_decided = potential_year_list[-1]\n",
    "\n",
    "        #if len(own_min_year) >= 4:\n",
    "    \n",
    "            #try:       \n",
    "    \n",
    "                #if year_decided < int(own_min_year):\n",
    "        \n",
    "                    #exclude_status = True\n",
    "            \n",
    "            #except:\n",
    "                #print('Case not excluded for earlier than min year')\n",
    "    \n",
    "        #if len(own_max_year) >= 4:\n",
    "    \n",
    "            #try:        \n",
    "    \n",
    "                #if year_decided > int(own_max_year):\n",
    "        \n",
    "                    #exclude_status = True\n",
    "    \n",
    "            #except:\n",
    "                #print('Case not excluded for later than max year')\n",
    "\n",
    "    #Exclude judges\n",
    "\n",
    "    if type(case_info['Before']) == str:\n",
    "\n",
    "        judges_to_include = str(own_judges_include).replace(';', ',').split(',')\n",
    "\n",
    "        if 'None' in judges_to_include:\n",
    "            judges_to_include.remove('None')\n",
    "\n",
    "        if '' in judges_to_include:\n",
    "            judges_to_include.remove('')\n",
    "        \n",
    "        #st.write(f\"judges_to_include == {judges_to_include}\")\n",
    "\n",
    "        if len(judges_to_include) > 0:\n",
    "        \n",
    "            judge_inclusion_counter = 0\n",
    "                    \n",
    "            for judge in judges_to_include:\n",
    "    \n",
    "                judge = judge.lower().replace('.', '').replace(' j', '').replace(' cj', '').replace(' acj', '').replace(' jj', '')\n",
    "                \n",
    "                if ((len(judge) > 2) and (judge.lower() in case_info['Before'].lower())):\n",
    "    \n",
    "                    judge_inclusion_counter += 1\n",
    "\n",
    "            #st.write(f\"judge_inclusion_counter=={judge_inclusion_counter}\")\n",
    "            \n",
    "            if judge_inclusion_counter == 0:\n",
    "    \n",
    "                #st.write(f'Excluded based on judge')\n",
    "    \n",
    "                exclude_status = True\n",
    "        \n",
    "        judges_to_exclude = str(own_judges_exclude).replace(';', ',').split(',')\n",
    "\n",
    "        if 'None' in judges_to_exclude:\n",
    "            \n",
    "            judges_to_exclude.remove('None')\n",
    "\n",
    "        if '' in judges_to_exclude:\n",
    "            judges_to_exclude.remove('')\n",
    "        \n",
    "        #st.write(f\"judges_to_exclude == {judges_to_exclude}\")\n",
    "\n",
    "        if len(judges_to_exclude) > 0:\n",
    "        \n",
    "            for judge in judges_to_exclude:\n",
    "    \n",
    "                judge = judge.lower().replace('.', '').replace(' j', '').replace(' cj', '').replace(' acj', '').replace(' jj', '')\n",
    "                \n",
    "                if ((len(judge) > 2) and (judge.lower() in case_info['Before'].lower())):\n",
    "                \n",
    "                    exclude_status = True\n",
    "    \n",
    "                    #st.write(f'Excluded based on judge == {judge}')\n",
    "                \n",
    "                    break\n",
    "\n",
    "    #st.write(f\"exclude_status == {exclude_status}\")\n",
    "    \n",
    "    return exclude_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2a3ad28-bcbb-4b65-9c09-5a015afdf724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-26 12:42:14.370 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Function to get judgment links with filters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_search_results_to_judgment_links_filtered_df(_soup, \n",
    "                                                     url_search_results, \n",
    "                                     judgment_counter_bound,\n",
    "                                      collection, \n",
    "                                    #hca_df, \n",
    "                                    own_parties_include, \n",
    "                                    own_parties_exclude, \n",
    "                                    #own_min_year, \n",
    "                                    #own_max_year, \n",
    "                                    after_date, \n",
    "                                     before_date, \n",
    "                                    #own_case_numbers_include, \n",
    "                                    #own_case_numbers_exclude, \n",
    "                                    own_judges_include, \n",
    "                                    own_judges_exclude\n",
    "                                                ):\n",
    "    #Soup, url_search_results are from hca_search\n",
    "        \n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    #Get number of pages\n",
    "    #There are up to 20 pages per page\n",
    "    number_of_pages = _soup.find(\"span\", id=\"lastItem\").text\n",
    "\n",
    "    #Start links list\n",
    "    #links = []\n",
    "\n",
    "    case_infos = []\n",
    "\n",
    "    for page_raw in range(0, int(number_of_pages)):\n",
    "        \n",
    "        if counter <= judgment_counter_bound:\n",
    "                        \n",
    "            page = page_raw + 1\n",
    "\n",
    "            #First page already scraped\n",
    "            if page == 1:\n",
    "                soup_page = _soup\n",
    "            else:\n",
    "                url_search_results_page = url_search_results + f'&page={page}'\n",
    "        \n",
    "                page_page = requests.get(url_search_results_page)\n",
    "        \n",
    "                soup_page = BeautifulSoup(page_page.content, \"lxml\")\n",
    "    \n",
    "            #Get raw links and names of cases\n",
    "            \n",
    "            raw_links = soup_page.find_all(class_='case')\n",
    "\n",
    "            for raw_link in raw_links:\n",
    "\n",
    "                if counter <= judgment_counter_bound:\n",
    "\n",
    "                    index = raw_links.index(raw_link)\n",
    "                    #mnc = '[' + raw_link.text.split('[')[-1]\n",
    "                    case_name_mnc = split_title_mnc(raw_link.get_text().strip())\n",
    "                    case_name = case_name_mnc[0]\n",
    "                    mnc = case_name_mnc[1]\n",
    "\n",
    "                    #Try to get case info from hca_df\n",
    "                    try:\n",
    "                        index_list = hca_df.index[hca_df['mnc'].str.contains(mnc, case=False, na=False, regex=False)].tolist()\n",
    "                        index = index_list[0]\n",
    "                        \n",
    "                        case_info = {'Case name': case_name, #hca_df.loc[int(index), 'case'], \n",
    "                                     'Medium neutral citation': mnc, #New\n",
    "                                     'Hyperlink to High Court Judgments Database': 'https://eresources.hcourt.gov.au' + raw_link['href'], \n",
    "                                     'Reported': hca_df.loc[int(index), 'reported'],\n",
    "                                     'Before': hca_df.loc[int(index), 'before'],\n",
    "                                     'Date': hca_df.loc[index, 'date']\n",
    "                                    }\n",
    "\n",
    "                        #st.write(case_info)\n",
    "                        \n",
    "                        if hca_judgment_to_exclude(case_info, \n",
    "                            collection, \n",
    "                            own_parties_include, \n",
    "                            own_parties_exclude, \n",
    "                            after_date, \n",
    "                           before_date, \n",
    "                            #own_case_numbers_include = [], \n",
    "                            #own_case_numbers_exclude = [], \n",
    "                            own_judges_include, \n",
    "                            own_judges_exclude\n",
    "                           ) == False:\n",
    "                            \n",
    "                            #links.append(case_info['Hyperlink to High Court Judgments Database'])\n",
    "                            case_infos.append(case_info)\n",
    "\n",
    "\n",
    "                            #st.write(f'{mnc} included.')\n",
    "                            \n",
    "                            counter += 1 \n",
    "    \n",
    "                            #case_infos.append(case_info)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Can't get case info for {mnc}.\")\n",
    "                        print(e)\n",
    "                \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            break    \n",
    "\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    return case_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "44e31d5c-afba-4dd0-9164-bb36bf1f7ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to getting a list of years for adding to search terms\n",
    "def hca_year_range(collection, after_date, before_date):\n",
    "\n",
    "    years_list = []\n",
    "\n",
    "    #Get year start and end depending on collection\n",
    "    if len(after_date) > 0:\n",
    "        year_start = int(after_date.split('-')[-1])\n",
    "    else:\n",
    "        for year in ['2000', '1948', '1903']:\n",
    "            if year in collection:\n",
    "                year_start = int(year)\n",
    "                break\n",
    "            \n",
    "    if len(before_date) > 0:\n",
    "        year_end = before_date.split('-')[-1]\n",
    "    else:\n",
    "        if '2000' in collection:\n",
    "            year_end = datetime.now().year\n",
    "        else:\n",
    "            for year in ['1999', '1958']:\n",
    "                if year in collection:\n",
    "                    year_end = int(year)\n",
    "                    break\n",
    "\n",
    "    if len(after_date) + len(before_date) > 0:\n",
    "        try:    \n",
    "            years = list(range(int(year_start), int(year_end) + 1))\n",
    "            years_list = sorted(years, reverse = True)\n",
    "        except:\n",
    "            print(\"after_date or before_date given but can't get year range.\")\n",
    "\n",
    "    return years_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6de11e59-3345-4cc0-83c9-04f494461e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to getting a list of judges for adding to search terms\n",
    "def hca_judge_list(collection, own_judges_include, own_judges_exclude):\n",
    "\n",
    "    judges_list = []\n",
    "    \n",
    "    if '1903' not in collection:\n",
    "        \n",
    "        if len(str(own_judges_include)) > 0:\n",
    "    \n",
    "            judges_list_raw = str(own_judges_include).replace(';', ',').split(',')\n",
    "\n",
    "            if 'None' in judges_list_raw:\n",
    "                judges_list_raw.remove('None')\n",
    "\n",
    "            if '' in judges_list_raw:\n",
    "                judges_list_raw.remove('')\n",
    "            \n",
    "            for judge in judges_list_raw:\n",
    "                \n",
    "                if isinstance(judge, tuple):\n",
    "                    judge = judge[0]\n",
    "                \n",
    "                if judge.lower() not in ['cj', 'acj', 'j', 'jj']:\n",
    "                    \n",
    "                    judges_list.append(judge)\n",
    "                \n",
    "        if len(str(own_judges_exclude)) > 0:\n",
    "    \n",
    "            judges_list_raw = str(own_judges_exclude).replace(';', ',').split(',')\n",
    "\n",
    "            if 'None' in judges_list_raw:\n",
    "                judges_list_raw.remove('None')\n",
    "\n",
    "            if '' in judges_list_raw:\n",
    "                judges_list_raw.remove('')\n",
    "            \n",
    "            for judge in judges_list_raw:\n",
    "\n",
    "                if isinstance(judge, tuple):\n",
    "                    \n",
    "                    judge = judge[0]\n",
    "\n",
    "                if judge.lower() not in ['cj', 'acj', 'j', 'jj']:\n",
    "                    \n",
    "                    if judge in judges_list:\n",
    "                        \n",
    "                        judges_list.remove(judge)\n",
    "    \n",
    "    return judges_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ab8ee-56cf-4adf-99f3-a2c5fb03bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to getting a list of parties for adding to search terms\n",
    "def hca_party_list(collection, own_parties_include, own_parties_exclude):\n",
    "\n",
    "    parties_list = []\n",
    "\n",
    "    if '1903' not in collection:\n",
    "        \n",
    "        if len(str(own_parties_include)) > 0:\n",
    "    \n",
    "            parties_list_raw = str(own_parties_include).replace(';', ',').split(',')\n",
    "\n",
    "            if 'None' in parties_list_raw:\n",
    "                parties_list_raw.remove('None')\n",
    "\n",
    "            if '' in parties_list_raw:\n",
    "                parties_list_raw.remove('')\n",
    "            \n",
    "            for party in parties_list_raw:\n",
    "                \n",
    "                if isinstance(party, tuple):\n",
    "                    party = party[0]\n",
    "                                    \n",
    "                parties_list.append(party)\n",
    "                \n",
    "        if len(str(own_parties_exclude)) > 0:\n",
    "    \n",
    "            parties_list_raw = str(own_parties_exclude).replace(';', ',').split(',')\n",
    "\n",
    "            if 'None' in parties_list_raw:\n",
    "                parties_list_raw.remove('None')\n",
    "\n",
    "            if '' in parties_list_raw:\n",
    "                parties_list_raw.remove('')\n",
    "            \n",
    "            for party in parties_list_raw:\n",
    "\n",
    "                if isinstance(party, tuple):\n",
    "                    party = party[0]\n",
    "\n",
    "                if party in parties_list:\n",
    "                \n",
    "                    parties_list.remove(party)\n",
    "\n",
    "    return parties_list\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018e54e-8b27-4719-9683-5eaec9010d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to getting a list of years, judges or parties for adding to search terms\n",
    "def hca_terms_to_add(years_list, parties_list):\n",
    "    \n",
    "    terms_to_add = []\n",
    "\n",
    "    if ((len(years_list) == 0) and (len(parties_list) == 0)):\n",
    "        \n",
    "        print(\"Filtering by years and parties not entered.\")\n",
    "\n",
    "    elif ((len(years_list) > 0) and (len(parties_list) == 0)):\n",
    "\n",
    "        for year in years_list:\n",
    "            \n",
    "            term = str(year)\n",
    "            \n",
    "            if term not in terms_to_add:\n",
    "                \n",
    "                terms_to_add.append(term)\n",
    "\n",
    "    elif ((len(years_list) > 0) and (len(parties_list) > 0)):\n",
    "\n",
    "        for year in years_list:\n",
    "\n",
    "            for party in parties_list:\n",
    "\n",
    "                term = f\"{str(year)} {party}\"\n",
    "    \n",
    "                if term not in terms_to_add:\n",
    "                    \n",
    "                    terms_to_add.append(term)\n",
    "\n",
    "    else: #((len(years_list) == 0)and (len(parties_list) > 0)):\n",
    "\n",
    "            for party in parties_list:\n",
    "            \n",
    "                term = f\"{party}\"\n",
    "\n",
    "                if term not in terms_to_add:\n",
    "                    \n",
    "                    terms_to_add.append(term)\n",
    "\n",
    "    return terms_to_add\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ca9a5-9531-4863-948a-f962f50e404a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Search function for adding year and judge, if entered, to search terms \n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_enhanced_search(collection, \n",
    "               quick_search, \n",
    "               #citation = '', \n",
    "                full_text,\n",
    "                judgments_counter_bound,\n",
    "                own_parties_include, \n",
    "                own_parties_exclude, \n",
    "                #own_min_year, \n",
    "                #own_max_year, \n",
    "                after_date, \n",
    "                 before_date, \n",
    "                #own_case_numbers_include, \n",
    "                #own_case_numbers_exclude, \n",
    "                own_judges_include, \n",
    "                own_judges_exclude\n",
    "                ):\n",
    "\n",
    "    #Initialise return list\n",
    "    case_infos = []\n",
    "\n",
    "    #st.write(f'collection == {collection}. after_date == {after_date}. own_judges_include == {own_judges_include}.')\n",
    "    \n",
    "    #Get lists of years, judges and parties to loop through if entered  \n",
    "    years_list = hca_year_range(collection = collection, after_date = after_date, before_date = before_date)\n",
    "    parties_list = hca_party_list(collection = collection, own_parties_include = own_parties_include, own_parties_exclude = own_parties_exclude)\n",
    "\n",
    "    terms_to_add = hca_terms_to_add(years_list = years_list, parties_list = parties_list)\n",
    "\n",
    "    #st.write(f'years_list == {years_list}. parties_list == {parties_list}.')\n",
    "\n",
    "    #st.write(f'terms_to_add == {terms_to_add}.')\n",
    "\n",
    "    #Determine whether need to loop through lists of years or parties\n",
    "    if len(terms_to_add) == 0:\n",
    "\n",
    "        print(f'Searching based on collection == {collection}, quick_search = {quick_search}, full_text = {full_text}')\n",
    "        \n",
    "        soup_url = hca_search(collection = collection, \n",
    "                                quick_search = quick_search, \n",
    "                                full_text = full_text\n",
    "                                )\n",
    "    \n",
    "        soup = soup_url['soup']\n",
    "    \n",
    "        search_results_url = soup_url['results_url']\n",
    "                    \n",
    "        case_infos = hca_search_results_to_judgment_links_filtered_df(soup, \n",
    "                                                                    search_results_url, \n",
    "                                                                    judgments_counter_bound,\n",
    "                                                                    collection, \n",
    "                                                                    #hca_df, \n",
    "                                                                    own_parties_include, \n",
    "                                                                    own_parties_exclude, \n",
    "                                                                    #own_min_year, \n",
    "                                                                    #own_max_year, \n",
    "                                                                    after_date, \n",
    "                                                                    before_date, \n",
    "                                                                    #own_case_numbers_include, \n",
    "                                                                    #own_case_numbers_exclude, \n",
    "                                                                    own_judges_include, \n",
    "                                                                    own_judges_exclude\n",
    "                                                                    )\n",
    "        \n",
    "    else: #len(terms_to_add) > 0:\n",
    "        \n",
    "        for term in terms_to_add:\n",
    "\n",
    "            if len(case_infos) < judgments_counter_bound:\n",
    "            \n",
    "                quick_search_w_extra = f'{quick_search} {term}'\n",
    "\n",
    "                print(f'Searching based on collection == {collection}, quick_search = {quick_search_w_extra}, full_text = {full_text}')\n",
    "                \n",
    "                #st.write(f\"quick_search_w_extra == {quick_search_w_extra}\")\n",
    "                \n",
    "                soup_url = hca_search(collection = collection, \n",
    "                            quick_search = quick_search_w_extra, \n",
    "                            full_text = full_text\n",
    "                            )\n",
    "    \n",
    "                soup = soup_url['soup']\n",
    "            \n",
    "                search_results_url = soup_url['results_url']\n",
    "    \n",
    "                #st.write(f\"search_results_url == {search_results_url}\")\n",
    "                \n",
    "                case_infos_w_extra = hca_search_results_to_judgment_links_filtered_df(soup, \n",
    "                                                                            search_results_url, \n",
    "                                                                            judgments_counter_bound,\n",
    "                                                                            collection, \n",
    "                                                                            #hca_df, \n",
    "                                                                            own_parties_include, \n",
    "                                                                            own_parties_exclude, \n",
    "                                                                            #own_min_year, \n",
    "                                                                            #own_max_year, \n",
    "                                                                            after_date, \n",
    "                                                                            before_date, \n",
    "                                                                            #own_case_numbers_include, \n",
    "                                                                            #own_case_numbers_exclude, \n",
    "                                                                            own_judges_include, \n",
    "                                                                            own_judges_exclude\n",
    "                                                                            )\n",
    "                    \n",
    "                for case_info in case_infos_w_extra:\n",
    "                    \n",
    "                    if case_info not in case_infos:\n",
    "                        \n",
    "                        case_infos.append(case_info)\n",
    "                \n",
    "                pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    return case_infos\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c68fb87a-a71c-4007-b309-6d5cbbe37719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get link to search results and number of results\n",
    "\n",
    "@st.cache_resource(show_spinner = False)\n",
    "def hca_search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    results_url_count = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search']\n",
    "                        )\n",
    "    results_url = results_url_count['results_url']\n",
    "    results_count = results_url_count['results_count']\n",
    "    \n",
    "    #If mnc entered\n",
    "    if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "        #direct_link = hca_mnc_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "        direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "\n",
    "        if len(direct_link) > 0:\n",
    "            \n",
    "            url = direct_link\n",
    "\n",
    "            results_count = '1'\n",
    "    \n",
    "    search_results_soup = results_url_count['soup']\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'soup': search_results_soup}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_batch_input\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112bbe4-0051-41ab-ac85-87047d2059c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "#hca_role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from specific paragraphs, pages or sections, provide the paragraph or page numbers or section names as part of your answer. If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". '\n",
    "\n",
    "system_instruction = role_content #hca_role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For getting judgments directly from the High Court without searching in OALC first\n",
    "#NOT IN USE\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_run_direct(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_infos = hca_enhanced_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search'],\n",
    "                    judgments_counter_bound = judgments_counter_bound,\n",
    "                    own_parties_include = df_master.loc[0, 'Parties include'], \n",
    "                    own_parties_exclude = df_master.loc[0, 'Parties do not include'], \n",
    "                    #own_min_year, \n",
    "                    #own_max_year, \n",
    "                    after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                    #own_case_numbers_include, \n",
    "                    #own_case_numbers_exclude, \n",
    "                    own_judges_include = df_master.loc[0, 'Judges include'], \n",
    "                    own_judges_exclude = df_master.loc[0, 'Judges do not include']\n",
    "                    )\n",
    "\n",
    "    #Get judgments from HCA database\n",
    "    for case in case_infos:\n",
    "        judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "        \n",
    "        if 'showbyHandle' in judgment_link:\n",
    "            \n",
    "            judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "\n",
    "        else: #If 'showCase' in judgment_link:\n",
    "\n",
    "            judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "\n",
    "        for key in judgment_dict.keys():\n",
    "            if key not in case.keys():\n",
    "                case.update({key: judgment_dict[key]}) \n",
    "        \n",
    "        judgments_file.append(case)\n",
    "        \n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Add judgment if mnc entered\n",
    "\n",
    "    if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "        direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "\n",
    "        if len(direct_link) > 0:\n",
    "            \n",
    "            judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "            \n",
    "            judgments_file.append(judgment_dict_direct)\n",
    "\n",
    "    #Make judgment_link clickable\n",
    "    for decision in judgments_file:\n",
    "        if '=HYPERLINK' not in decision['Hyperlink to High Court Judgments Database']:\n",
    "            clickable_link =  link(decision['Hyperlink to High Court Judgments Database'])\n",
    "            decision.update({'Hyperlink to High Court Judgments Database': clickable_link})\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    if 'judgment' in df_updated.columns:\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89684638-c8ee-4643-bc5b-d4792b6b7a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For getting judgments directly from the High Court if not available in OALC\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_infos = hca_enhanced_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search'],\n",
    "                    judgments_counter_bound = judgments_counter_bound,\n",
    "                    own_parties_include = df_master.loc[0, 'Parties include'], \n",
    "                    own_parties_exclude = df_master.loc[0, 'Parties do not include'], \n",
    "                    #own_min_year, \n",
    "                    #own_max_year, \n",
    "                    after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                    #own_case_numbers_include, \n",
    "                    #own_case_numbers_exclude, \n",
    "                    own_judges_include = df_master.loc[0, 'Judges include'], \n",
    "                    own_judges_exclude = df_master.loc[0, 'Judges do not include']\n",
    "                    )\n",
    "    \n",
    "    if huggingface == False: #If not running on HuggingFace\n",
    "        \n",
    "        #Get judgments from HCA database\n",
    "        for case in case_infos:\n",
    "            judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "            \n",
    "            if 'showbyHandle' in judgment_link:\n",
    "                \n",
    "                judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "    \n",
    "            else: #If 'showCase' in judgment_link:\n",
    "    \n",
    "                judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "    \n",
    "            for key in judgment_dict.keys():\n",
    "                if key not in case.keys():\n",
    "                    case.update({key: judgment_dict[key]}) \n",
    "            \n",
    "            judgments_file.append(case)\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "        #Add judgment if mnc entered\n",
    "    \n",
    "        if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "            \n",
    "            direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "    \n",
    "            if len(direct_link) > 0:\n",
    "                \n",
    "                judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "                \n",
    "                judgments_file.append(judgment_dict_direct)\n",
    "            \n",
    "    else: #If running on HuggingFace\n",
    "        \n",
    "        #Load oalc\n",
    "        from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "\n",
    "        #Create a list of mncs for HuggingFace:\n",
    "        mnc_list = []\n",
    "\n",
    "        for case in case_infos:\n",
    "\n",
    "            #add search results to json\n",
    "            judgments_file.append(case)\n",
    "\n",
    "            #Add mnc to list for HuggingFace\n",
    "            mnc_list.append(case['Medium neutral citation'])\n",
    "\n",
    "        #Get judgments from oalc first\n",
    "        mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "    \n",
    "        #Append judgment to judgments_file \n",
    "        for decision in judgments_file:\n",
    "            \n",
    "            #Append judgments from oalc first\n",
    "            if decision['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                \n",
    "                decision.update({'judgment': mnc_judgment_dict[decision['Medium neutral citation']]})\n",
    "\n",
    "                print(f\"{decision['Case name']} {decision['Medium neutral citation']}: got judgment from OALC\")\n",
    "                \n",
    "            else: #Get judgment from HCA if can't get from oalc\n",
    "                \n",
    "                direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], decision['Medium neutral citation'])\n",
    "        \n",
    "                if len(direct_link) > 0:\n",
    "                    \n",
    "                    judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "\n",
    "                    for key in judgment_dict_direct.keys():\n",
    "                        if key not in decision.keys():\n",
    "                            decision.update({key: judgment_dict_direct[key]})\n",
    "\n",
    "                    print(f\"{decision['Case name']} {decision['Medium neutral citation']}: got judgment from the High Court directly\")\n",
    "                    \n",
    "                    pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Make judgment_link clickable\n",
    "    for decision in judgments_file:\n",
    "        if '=HYPERLINK' not in decision['Hyperlink to High Court Judgments Database']:\n",
    "            clickable_link =  link(decision['Hyperlink to High Court Judgments Database'])\n",
    "            decision.update({'Hyperlink to High Court Judgments Database': clickable_link})\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    if 'judgment' in df_updated.columns:\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacc31ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Obtain parameters\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;129m@st\u001b[39m\u001b[38;5;241m.\u001b[39mcache_data(show_spinner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhca_batch\u001b[39m(df_master):\n\u001b[1;32m      5\u001b[0m     df_master \u001b[38;5;241m=\u001b[39m df_master\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#Apply split and format functions for headnotes choice, court choice and GPT questions\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Conduct search\n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_infos = hca_enhanced_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search'],\n",
    "                    judgments_counter_bound = judgments_counter_bound,\n",
    "                    own_parties_include = df_master.loc[0, 'Parties include'], \n",
    "                    own_parties_exclude = df_master.loc[0, 'Parties do not include'], \n",
    "                    #own_min_year, \n",
    "                    #own_max_year, \n",
    "                    after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                    #own_case_numbers_include, \n",
    "                    #own_case_numbers_exclude, \n",
    "                    own_judges_include = df_master.loc[0, 'Judges include'], \n",
    "                    own_judges_exclude = df_master.loc[0, 'Judges do not include']\n",
    "                    )\n",
    "    \n",
    "    if huggingface == False: #If not running on HuggingFace\n",
    "        \n",
    "        #Get judgments from HCA database\n",
    "        for case in case_infos:\n",
    "            judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "            \n",
    "            if 'showbyHandle' in judgment_link:\n",
    "                \n",
    "                judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "    \n",
    "            else: #If 'showCase' in judgment_link:\n",
    "    \n",
    "                judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "    \n",
    "            for key in judgment_dict.keys():\n",
    "                if key not in case.keys():\n",
    "                    case.update({key: judgment_dict[key]}) \n",
    "            \n",
    "            judgments_file.append(case)\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "        #Add judgment if mnc entered\n",
    "    \n",
    "        if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "            \n",
    "            direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "    \n",
    "            if len(direct_link) > 0:\n",
    "                \n",
    "                judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "                \n",
    "                judgments_file.append(judgment_dict_direct)\n",
    "            \n",
    "    else: #If running on HuggingFace\n",
    "        \n",
    "        #Load oalc\n",
    "        from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "\n",
    "        #Create a list of mncs for HuggingFace:\n",
    "        mnc_list = []\n",
    "\n",
    "        for case in case_infos:\n",
    "\n",
    "            #add search results to json\n",
    "            judgments_file.append(case)\n",
    "\n",
    "            #Add mnc to list for HuggingFace\n",
    "            mnc_list.append(case['Medium neutral citation'])\n",
    "\n",
    "        #Get judgments from oalc first\n",
    "        mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "    \n",
    "        #Append judgment to judgments_file \n",
    "        for decision in judgments_file:\n",
    "            \n",
    "            #Append judgments from oalc first\n",
    "            if decision['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                \n",
    "                decision.update({'judgment': mnc_judgment_dict[decision['Medium neutral citation']]})\n",
    "                \n",
    "                print(f\"{decision['Case name']} {decision['Medium neutral citation']}: got judgment from OALC\")\n",
    "\n",
    "            else: #Get judgment from HCA if can't get from oalc\n",
    "                \n",
    "                direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], decision['Medium neutral citation'])\n",
    "        \n",
    "                if len(direct_link) > 0:\n",
    "                    \n",
    "                    judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "\n",
    "                    for key in judgment_dict_direct.keys():\n",
    "                        if key not in decision.keys():\n",
    "                            decision.update({key: judgment_dict_direct[key]})\n",
    "\n",
    "                    print(f\"{decision['Case name']} {decision['Medium neutral citation']}: got judgment from the High Court directly\")\n",
    "\n",
    "                    pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Make judgment_link clickable\n",
    "    for decision in judgments_file:\n",
    "        if '=HYPERLINK' not in decision['Hyperlink to High Court Judgments Database']:\n",
    "            clickable_link =  link(decision['Hyperlink to High Court Judgments Database'])\n",
    "            decision.update({'Hyperlink to High Court Judgments Database': clickable_link})\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9843d7-c7ea-42aa-9c80-2826d2512e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
