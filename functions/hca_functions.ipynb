{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface == True\n",
      "Running locally or on Streamlit\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, save_input, pdf_judgment, link, is_date, split_title_mnc\n",
    "#Import variables\n",
    "from functions.common_functions import huggingface, today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# High Court of Australia search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1b993f-13e5-4681-8652-1c14a6c7cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load hca_data\n",
    "\n",
    "@st.cache_resource(show_spinner = False)\n",
    "def hca_load_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "hca_data_url = 'https://raw.githubusercontent.com/nehcneb/au-uk-empirical-legal-research/main/hca_data.csv'\n",
    "\n",
    "#response = requests.get(hca_data_url)\n",
    "\n",
    "#hca_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "hca_df = hca_load_data(hca_data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2217c2-6d14-4551-a177-efce61446228",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ca5f1d2-b354-45be-b365-0f01233c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collections available\n",
    "hca_collections = ['Judgments 2000-present', 'Judgments 1948-1999', '1 CLR - 100 CLR (judgments 1903-1958)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "091680eb-093d-4829-866a-74eff679d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parties include categories\n",
    "parties_include_categories = {'include': 'contains', \n",
    "                             'do not include': 'notcontains'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0008ccc2-88bd-4972-a203-2e05aafc6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Year is categories\n",
    "year_is_categories = {'is': 'contains', \n",
    "                    'is not': 'notcontains'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fef7ce31-5d10-406b-b5d3-a76bc8826ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Judges include categories\n",
    "judge_includes_categories = {'includes': 'contains', \n",
    "                             'does not include': 'notcontains'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ef57b-8eff-481e-95ef-2e9c08d76505",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3655fb19-11a4-42c2-90eb-fbc0f5e17ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape javascript\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait as Wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--no-sandbox')  \n",
    "options.add_argument('--disable-dev-shm-usage')  \n",
    "\n",
    "#@st.cache_resource(show_spinner = False, ttl=600)\n",
    "def get_driver():\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "try:\n",
    "    browser = get_driver()\n",
    "    \n",
    "    #browser.implicitly_wait(5)\n",
    "    #browser.set_page_load_timeout(15)\n",
    "\n",
    "    #browser.quit()\n",
    "    \n",
    "except Exception as e:\n",
    "    st.error('Sorry, your internet connection is not stable enough for this app. Please check or change your internet connection and try again.')\n",
    "    print(e)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a541dce0-c0dc-4531-a513-6c570169d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get judgment links with filters\n",
    "\n",
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hca_soup_to_judgments(_soup, \n",
    "                          collection, \n",
    "                         judgment_counter_bound,\n",
    "                        ):\n",
    "        \n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    #Start links list\n",
    "    case_infos = []\n",
    "    \n",
    "    if counter <= judgment_counter_bound:\n",
    "\n",
    "        #Get raw links and names of cases\n",
    "        raw_links = _soup.find_all(class_='case')\n",
    "\n",
    "        #Get catchwords\n",
    "        catchwords_list = _soup.find_all('div', class_='well')\n",
    "        #The first element of catchwords_list is not catchwords\n",
    "        \n",
    "        for raw_link in raw_links:\n",
    "\n",
    "            if counter <= judgment_counter_bound:\n",
    "\n",
    "                index = raw_links.index(raw_link)\n",
    "                #mnc = '[' + raw_link.text.split('[')[-1]\n",
    "                case_name_mnc = split_title_mnc(raw_link.get_text().strip())\n",
    "                case_name = case_name_mnc[0]\n",
    "                mnc = case_name_mnc[1]\n",
    "\n",
    "                catchwords = ''\n",
    "                if collection != hca_collections[-1]:\n",
    "                    try:\n",
    "                        catchwords = catchwords_list[counter].get_text()\n",
    "                    except Exception as e:\n",
    "                        f\"{mnc}: can't get catchwords due to error: {e}\"\n",
    "\n",
    "                case_info = {'Case name': case_name, #hca_df.loc[int(index), 'case'], \n",
    "                             'Medium neutral citation': mnc, #New\n",
    "                             'Hyperlink to High Court Judgments Database': 'https://eresources.hcourt.gov.au' + raw_link['href'],\n",
    "                             'Catchwords': catchwords\n",
    "                            }\n",
    "\n",
    "                #Try to get case info from hca_df\n",
    "                try:\n",
    "                    index_list = hca_df.index[hca_df['mnc'].str.contains(mnc, case=False, na=False, regex=False)].tolist()\n",
    "                    index = index_list[0]\n",
    "\n",
    "                    case_info.update({'Reported': hca_df.loc[int(index), 'reported']})\n",
    "\n",
    "                    case_info.update({'Before': hca_df.loc[int(index), 'before']})\n",
    "\n",
    "                    case_info.update({'Date': hca_df.loc[index, 'date']})\n",
    "                                        \n",
    "                except Exception as e:\n",
    "                    print(f\"{mnc}: can't get case info from hca_df.\")\n",
    "                    print(e)\n",
    "\n",
    "                case_infos.append(case_info)\n",
    "                \n",
    "                counter += 1 \n",
    "            \n",
    "            else:\n",
    "                break\n",
    "\n",
    "    #pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    return case_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ea1c02f2-7156-4e01-844e-14310ee428a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hca_search(collection = hca_collections[0], \n",
    "               quick_search = '',\n",
    "               citation = '', \n",
    "                full_text = '', \n",
    "                parties_include = list(parties_include_categories.keys())[0],\n",
    "                parties = '',\n",
    "                year_is = list(year_is_categories.keys())[0],\n",
    "                year = '', \n",
    "                case_number = '', \n",
    "                judge_includes = list(judge_includes_categories.keys())[0],\n",
    "                judge = '',\n",
    "                judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "    \n",
    "    #Default base url is for judgments 2000-current\n",
    "    #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "    base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "    \n",
    "    if collection == 'Judgments 2000-present':\n",
    "    \n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=1&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=1'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=2&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=2'\n",
    "\n",
    "    #Get elements\n",
    "    #base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "    browser.get(base_url)\n",
    "    browser.refresh()\n",
    "\n",
    "    #Clear button\n",
    "    clear_button = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//button[@value='Clear']\")))\n",
    "    \n",
    "    #Clear input\n",
    "    clear_button.click()\n",
    "\n",
    "    #Quick search\n",
    "    #quick_search = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'qsrch-term')))\n",
    "    quick_search_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='qsrch-term']\")))\n",
    "    \n",
    "    #Search for citation\n",
    "    #citation = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'id_filter_type_13')))\n",
    "    citation_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='id_filter_type_13']\")))\n",
    "\n",
    "    #Parties include/not include\n",
    "    parties_include_input = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'id_filter_relational_operator_2')))\n",
    "    parties_include_category = Select(parties_include_input)\n",
    "    \n",
    "    #Parties\n",
    "    parties_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='id_filter_2']\")))\n",
    "    \n",
    "    #Year is/is not\n",
    "    year_is_input = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'id_filter_relational_operator_4')))\n",
    "    year_is_category = Select(year_is_input)\n",
    "    \n",
    "    #Year\n",
    "    year_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='id_filter_4']\")))\n",
    "\n",
    "    if collection != hca_collections[-1]:\n",
    "\n",
    "        #Full text search\n",
    "        #full_text = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'srch-term')))\n",
    "        full_text_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='srch-term']\")))\n",
    "        \n",
    "        #case number\n",
    "        case_number_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='id_filter_5']\")))\n",
    "        \n",
    "        #Judge includes/does not include\n",
    "        judge_includes_input = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'id_filter_relational_operator_6')))\n",
    "        judge_includes_category = Select(judge_includes_input)\n",
    "        \n",
    "        #Judge\n",
    "        judge_input = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//input[@id='id_filter_6']\")))\n",
    "\n",
    "    #Search button\n",
    "    search_button = Wait(browser, 20).until(EC.visibility_of_element_located((By.ID, 'apply_filter')))\n",
    "    \n",
    "    #Enter input\n",
    "    #Quick search\n",
    "    if ((quick_search != None) and (quick_search != '')):\n",
    "        \n",
    "        quick_search_input.send_keys(quick_search)\n",
    "\n",
    "    #Citation\n",
    "    if ((citation != None) and (citation != '')):\n",
    "        \n",
    "        citation_input.send_keys(citation)\n",
    "\n",
    "    #Parties\n",
    "    parties_include_category_value = parties_include_categories[parties_include]\n",
    "    parties_include_category.select_by_value(parties_include_category_value)\n",
    "\n",
    "    if ((parties != None) and (parties != '')):\n",
    "        \n",
    "        parties_input.send_keys(parties)\n",
    "\n",
    "    #Year\n",
    "    year_is_category_value = year_is_categories[year_is]\n",
    "    year_is_category.select_by_value(year_is_category_value)\n",
    "\n",
    "    if ((year != None) and (year != '')):\n",
    "        \n",
    "        year_input.send_keys(year)\n",
    "\n",
    "    if collection != hca_collections[-1]:\n",
    "    \n",
    "        #Full text\n",
    "        if ((full_text != None) and (full_text != '')):\n",
    "            \n",
    "            full_text_input.send_keys(full_text)\n",
    "    \n",
    "        #Case number\n",
    "        if ((case_number != None) and (case_number != '')):\n",
    "            \n",
    "            case_number_input.send_keys(case_number)\n",
    "    \n",
    "        #Judge\n",
    "        judge_includes_category_value = judge_includes_categories[judge_includes]\n",
    "        judge_includes_category.select_by_value(judge_includes_category_value)\n",
    "    \n",
    "        if ((judge != None) and (judge != '')):\n",
    "            \n",
    "            judge_input.send_keys(judge)\n",
    "\n",
    "    #Get search results\n",
    "    search_button.click()\n",
    "\n",
    "    #Results count\n",
    "    results_count_text = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='postsearch']\")))\n",
    "    results_count_raw = results_count_text.text.split('\\n')[1]\n",
    "    results_count = int(re.findall(r'\\d+', results_count_raw)[0])\n",
    "\n",
    "    #Page bound\n",
    "    page_bound = int(re.findall(r'\\d+', results_count_text.text)[-1])\n",
    "\n",
    "    #Set page counter\n",
    "    page_counter = 1\n",
    "    \n",
    "    #print(f'Searching page {page_counter}')\n",
    "\n",
    "    #Report on search terms\n",
    "    print(results_count_text.text.strip())\n",
    "\n",
    "    #Get case_infos from first page\n",
    "    soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "    case_infos = hca_soup_to_judgments(soup, collection, judgment_counter_bound)\n",
    "\n",
    "    #Next page if available and needed\n",
    "    while (page_counter < page_bound) and (len(case_infos) < min(judgment_counter_bound, results_count)):\n",
    "\n",
    "        #Pause to avoid getting kicked out\n",
    "        pause.seconds(np.random.randint(5, 10))\n",
    "        \n",
    "        #Increase page count\n",
    "        page_counter += 1\n",
    "\n",
    "        #print(f'Searching page {page_counter}')\n",
    "\n",
    "        #Get and click button for next page\n",
    "        next_page_button = Wait(browser, 20).until(EC.element_to_be_clickable((By.XPATH, \"//a[@href='javascript:newPage(2)']\")))\n",
    "    \n",
    "        browser.execute_script(\"arguments[0].click();\",next_page_button)\n",
    "\n",
    "        #Wait for next page to load\n",
    "        pause.seconds(np.random.randint(5, 10))\n",
    "        \n",
    "        Wait(browser, 20).until(EC.text_to_be_present_in_element((By.XPATH, \"//div[@id='postsearch']\"), f'{str(page_counter)[-1]} (of'))\n",
    "\n",
    "        #Report on search terms\n",
    "        results_count_text = Wait(browser, 20).until(EC.visibility_of_element_located((By.XPATH, \"//div[@id='postsearch']\")))\n",
    "        print(results_count_text.text.strip())\n",
    "\n",
    "        #Get soup for next page\n",
    "        soup_next_page = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "        #Get case_infos from next page\n",
    "        case_infos_next_page = hca_soup_to_judgments(soup_next_page, collection, judgment_counter_bound)\n",
    "\n",
    "        #Add case_infos from next page to all case_infos\n",
    "        for case_info in case_infos_next_page:\n",
    "            if len(case_infos) < min(judgment_counter_bound, results_count):\n",
    "                case_infos.append(case_info)\n",
    "\n",
    "    return {'results_count': results_count, 'case_infos': case_infos}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40d93cfb-26fb-436a-bddf-eb20e1095d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "hca_meta_labels_droppable = ['Reported', 'Date', 'Case number', 'Before', 'Catchwords', 'Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "632eaa5c-4f2b-47af-8c7f-c0a575d895f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If judgment link contains 'showCase'\n",
    "\n",
    "#@st.cache_data(show_spinner = False)\n",
    "def hca_meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Catchwords' : '',                       \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                'Order': '', \n",
    "                'judgment' : ''\n",
    "                }\n",
    "    \n",
    "    try:\n",
    "        #Attach hyperlink\n",
    "    \n",
    "        judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "        \n",
    "        page = requests.get(judgment_url)\n",
    "        soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "        #Case name\n",
    "        judgment_dict['Case name'] = soup.find('title').text\n",
    "    \n",
    "        #Medium neutral citation\n",
    "        year = judgment_url.split('showCase/')[1][0:4]\n",
    "        num = judgment_url.split('HCA/')[1]\n",
    "        \n",
    "        judgment_dict['Medium neutral citation'] = f'[{year}] HCA {num}'\n",
    "    \n",
    "        #Reported, decision date, before\n",
    "    \n",
    "        h2_tags = soup.find_all('h2')\n",
    "    \n",
    "        if len(h2_tags) > 0:\n",
    "            \n",
    "            for h2 in soup.find_all('h2'):\n",
    "                if 'clr' in h2.text.lower():\n",
    "                    \n",
    "                    judgment_dict['Reported'] = h2.text\n",
    "        \n",
    "                elif is_date(h2.text, fuzzy=False):\n",
    "        \n",
    "                    judgment_dict['Date'] = h2.text\n",
    "        \n",
    "                elif 'before' in h2.text.lower():\n",
    "                    judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "        \n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        #Case number\n",
    "    \n",
    "        case_number_list = soup.find_all(string=re.compile('Case Number'))\n",
    "    \n",
    "        if len(case_number_list) > 0:\n",
    "            \n",
    "            judgment_dict['Case number'] = case_number_list[0].split('Case Number')[1].replace(': ', '')\n",
    "    \n",
    "        #Checking\n",
    "    \n",
    "        if len(str(judgment_dict['Reported'])) < 5:\n",
    "    \n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Reported'] = hca_df.loc[int(index), 'reported']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get reported for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if is_date(str(judgment_dict['Date']), fuzzy=False) == False:\n",
    "    \n",
    "            try:\n",
    "                \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Date'] = hca_df.loc[index, 'date']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get date for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Before'])) < 3:\n",
    "    \n",
    "            try:\n",
    "        \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Before'] = hca_df.loc[int(index), 'before']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get before for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Case number'])) < 3:\n",
    "    \n",
    "            try:\n",
    "    \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Case number'] = hca_df.loc[int(index), 'case_number']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get case number for {judgment_dict['Medium neutral citation']}\")\n",
    "        \n",
    "        #Catchwords\n",
    "    \n",
    "        catchwords_list = soup.find_all('div', class_='well')\n",
    "    \n",
    "        if len(catchwords_list) > 0:\n",
    "            \n",
    "            judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "    \n",
    "        #Judgment text\n",
    "        judgment_url = judgment_url.replace('showCase', 'downloadPdf')\n",
    "        judgment_dict['judgment'] = pdf_judgment(judgment_url)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{judgment_dict['Case name']}: judgment not scrapped\")\n",
    "        print(e)\n",
    "        \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf3f7be-addd-4f87-82f7-b286f2b1fb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If judgment link contains 'showbyHandle'\n",
    "\n",
    "#@st.cache_data(show_spinner = False)\n",
    "def hca_meta_judgment_dict_alt(judgment_url):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                  'Catchwords' : '',\n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                'Order': '',\n",
    "                'judgment' : ''\n",
    "                }\n",
    "\n",
    "    try:\n",
    "        #Attach hyperlink\n",
    "    \n",
    "        judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "        \n",
    "        page = requests.get(judgment_url)\n",
    "        soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "        #Case name\n",
    "        judgment_dict['Case name'] = soup.find('title').text\n",
    "    \n",
    "        #Judgment text\n",
    "    \n",
    "        judgment_list = soup.find_all(\"div\", {\"class\": \"opinion\"})\n",
    "        \n",
    "        judgment_pdfs_list = soup.find_all('a', {'class': 'btn btn-success'})\n",
    "        \n",
    "        if len(judgment_list) > 0:\n",
    "    \n",
    "            judgment_dict['judgment'] = judgment_list[0].text\n",
    "    \n",
    "        elif len(judgment_pdfs_list) > 0:\n",
    "            raw_link = judgment_pdfs_list[0]['href']\n",
    "            pdf_link = 'https://eresources.hcourt.gov.au' + raw_link\n",
    "            pdf_link = pdf_link.replace('showCase', 'downloadPdf')\n",
    "            judgment_dict['judgment'] = pdf_judgment(pdf_link)\n",
    "    \n",
    "        else:\n",
    "            judgment_dict['judgment'] = ''\n",
    "                \n",
    "        #Catchwords\n",
    "    \n",
    "        catchwords_list = soup.find_all(\"div\", {\"class\": \"Catchphrases\"})\n",
    "    \n",
    "        if len(catchwords_list) > 0:\n",
    "            judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "        \n",
    "        #Medium neutral citation meta tag\n",
    "        mnc_list = soup.find_all(\"div\", {\"class\": \"MNC\"})\n",
    "    \n",
    "        if len(mnc_list):\n",
    "    \n",
    "            judgment_dict['Medium neutral citation'] = mnc_list[0].text\n",
    "    \n",
    "        elif len(judgment_pdfs_list) > 0:\n",
    "    \n",
    "            mnc_raw = judgment_pdfs_list[0]['href'].replace('/downloadPdf/', '').replace('/', '')\n",
    "    \n",
    "            year = mnc_raw.lower().split('hca')[0]\n",
    "    \n",
    "            num = mnc_raw.lower().split('hca')[1]\n",
    "    \n",
    "            judgment_dict['Medium neutral citation'] = f\"[{year}] HCA {num}\"\n",
    "    \n",
    "        #Before\n",
    "        judges_list = soup.find_all(\"div\", {\"class\": \"judges-title\"})\n",
    "    \n",
    "        if len(judges_list) > 0:\n",
    "    \n",
    "            judgment_dict['Before'] = judges_list[0].text\n",
    "    \n",
    "    \n",
    "        #Order\n",
    "        order_list = soup.find_all(\"div\", {\"class\": \"order-text\"})\n",
    "    \n",
    "        if len(order_list) > 0:\n",
    "    \n",
    "            order = order_list[0].text#.replace('\\n            ', '')\n",
    "    \n",
    "            judgment_dict['Order'] = order\n",
    "    \n",
    "        #Reported, decision date, before\n",
    "    \n",
    "        h2_tags = soup.find_all('h2')\n",
    "    \n",
    "        if len(h2_tags) > 0:\n",
    "            \n",
    "            for h2 in soup.find_all('h2'):\n",
    "                if 'clr' in h2.text.lower():\n",
    "                    \n",
    "                    judgment_dict['Reported'] = h2.text\n",
    "        \n",
    "                elif is_date(h2.text, fuzzy=False):\n",
    "        \n",
    "                    judgment_dict['Date'] = h2.text\n",
    "        \n",
    "                elif 'before' in h2.text.lower():\n",
    "                    judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "        \n",
    "                else:\n",
    "                    continue\n",
    "    \n",
    "        #Checking\n",
    "    \n",
    "        if len(str(judgment_dict['Reported'])) < 5:\n",
    "    \n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Reported'] = hca_df.loc[int(index), 'reported']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get reported for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if is_date(str(judgment_dict['Date']), fuzzy=False) == False:\n",
    "    \n",
    "            try:\n",
    "                \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Date'] = hca_df.loc[index, 'date']\n",
    "    \n",
    "            except:\n",
    "                print(f\"Can't get date for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Before'])) < 3:\n",
    "    \n",
    "            try:\n",
    "        \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Before'] = hca_df.loc[int(index), 'before']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get before for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "        if len(str(judgment_dict['Case number'])) < 3:\n",
    "    \n",
    "            try:\n",
    "    \n",
    "                index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "                index = index_list[0]\n",
    "        \n",
    "                judgment_dict['Case number'] = hca_df.loc[int(index), 'case_number']\n",
    "    \n",
    "        \n",
    "            except:\n",
    "                print(f\"Can't get case number for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{judgment_dict['Case name']}: judgment not scrapped\")\n",
    "        print(e)\n",
    "    \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:37:39.832 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.833 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.834 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.835 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.836 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_batch_input\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, basic_model, flagship_model#, role_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d112bbe4-0051-41ab-ac85-87047d2059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "#hca_role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from specific paragraphs, pages or sections, provide the paragraph or page numbers or section names as part of your answer. If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". '\n",
    "\n",
    "#system_instruction = role_content #hca_role_content\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89684638-c8ee-4643-bc5b-d4792b6b7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:37:39.848 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#For getting judgments directly from the High Court if not available in OALC\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_infos = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                   quick_search = df_master.loc[0, 'Quick search'],\n",
    "                   citation = df_master.loc[0, 'Search for citation'], \n",
    "                    full_text = df_master.loc[0, 'Full text search'], \n",
    "                    parties_include = df_master.loc[0, 'Parties include/do not include'],\n",
    "                    parties = df_master.loc[0, 'Parties'],\n",
    "                    year_is = df_master.loc[0, 'Year is/is not'],\n",
    "                    year = df_master.loc[0, 'Year'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    judge_includes = df_master.loc[0, 'Judge includes/does not include'],\n",
    "                    judge = df_master.loc[0, 'Judge'],\n",
    "                    judgment_counter_bound = judgment_counter_bound\n",
    "                    )['case_infos']\n",
    "    \n",
    "    if huggingface == False: #If not running on HuggingFace\n",
    "        \n",
    "        #Get judgments from HCA database\n",
    "        for case in case_infos:\n",
    "            judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "            \n",
    "            if 'showbyHandle' in judgment_link:\n",
    "                \n",
    "                judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "    \n",
    "            else: #If 'showCase' in judgment_link:\n",
    "    \n",
    "                judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "    \n",
    "            for key in judgment_dict.keys():\n",
    "                if key not in case.keys():\n",
    "                    case.update({key: judgment_dict[key]}) \n",
    "            \n",
    "            judgments_file.append(case)\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    else: #If running on HuggingFace\n",
    "        \n",
    "        #Load oalc\n",
    "        from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "\n",
    "        #Create a list of mncs for HuggingFace:\n",
    "        mnc_list = []\n",
    "\n",
    "        for case in case_infos:\n",
    "\n",
    "            #Add mnc to list for HuggingFace\n",
    "            mnc_list.append(case['Medium neutral citation'])\n",
    "\n",
    "        #Get judgments from oalc first\n",
    "        mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "    \n",
    "        #Append OALC judgment to judgments_file \n",
    "        for case in case_infos:\n",
    "            \n",
    "            #Append judgments from oalc first\n",
    "            if case['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                \n",
    "                case.update({'judgment': mnc_judgment_dict[case['Medium neutral citation']]})\n",
    "\n",
    "                judgments_file.append(case)\n",
    "\n",
    "                print(f\"{case['Case name']} {case['Medium neutral citation']}: got judgment from OALC\")\n",
    "\n",
    "            else:\n",
    "            #Get remaining judgments from HCA database\n",
    "    \n",
    "                judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "                \n",
    "                if 'showbyHandle' in judgment_link:\n",
    "                    \n",
    "                    judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "        \n",
    "                else: #If 'showCase' in judgment_link:\n",
    "        \n",
    "                    judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "        \n",
    "                for key in judgment_dict.keys():\n",
    "                    if key not in case.keys():\n",
    "                        case.update({key: judgment_dict[key]}) \n",
    "                \n",
    "                judgments_file.append(case)\n",
    "\n",
    "                print(f\"{case['Case name']} {case['Medium neutral citation']}: got judgment from HCA directly.\")\n",
    "                \n",
    "                pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Make judgment_link clickable\n",
    "    for decision in judgments_file:\n",
    "        if '=HYPERLINK' not in decision['Hyperlink to High Court Judgments Database']:\n",
    "            clickable_link =  link(decision['Hyperlink to High Court Judgments Database'])\n",
    "            decision.update({'Hyperlink to High Court Judgments Database': clickable_link})\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    if (pop_judgment() > 0) and ('judgment' in df_updated.columns):\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dacc31ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:37:39.855 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hca_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Conduct search\n",
    "    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    case_infos = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                   quick_search = df_master.loc[0, 'Quick search'],\n",
    "                   citation = df_master.loc[0, 'Search for citation'], \n",
    "                    full_text = df_master.loc[0, 'Full text search'], \n",
    "                    parties_include = df_master.loc[0, 'Parties include/do not include'],\n",
    "                    parties = df_master.loc[0, 'Parties'],\n",
    "                    year_is = df_master.loc[0, 'Year is/is not'],\n",
    "                    year = df_master.loc[0, 'Year'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    judge_includes = df_master.loc[0, 'Judge includes/does not include'],\n",
    "                    judge = df_master.loc[0, 'Judge'],\n",
    "                    judgment_counter_bound = judgment_counter_bound\n",
    "                    )['case_infos']\n",
    "    \n",
    "    if huggingface == False: #If not running on HuggingFace\n",
    "        \n",
    "        #Get judgments from HCA database\n",
    "        for case in case_infos:\n",
    "            judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "            \n",
    "            if 'showbyHandle' in judgment_link:\n",
    "                \n",
    "                judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "    \n",
    "            else: #If 'showCase' in judgment_link:\n",
    "    \n",
    "                judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "    \n",
    "            for key in judgment_dict.keys():\n",
    "                if key not in case.keys():\n",
    "                    case.update({key: judgment_dict[key]}) \n",
    "            \n",
    "            judgments_file.append(case)\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    else: #If running on HuggingFace\n",
    "        \n",
    "        #Load oalc\n",
    "        from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "\n",
    "        #Create a list of mncs for HuggingFace:\n",
    "        mnc_list = []\n",
    "\n",
    "        for case in case_infos:\n",
    "\n",
    "            #add search results to json\n",
    "            #judgments_file.append(case)\n",
    "\n",
    "            #Add mnc to list for HuggingFace\n",
    "            mnc_list.append(case['Medium neutral citation'])\n",
    "\n",
    "        #Get judgments from oalc first\n",
    "        mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "    \n",
    "        #Append judgment to judgments_file \n",
    "        for case in case_infos: #judgments_file:\n",
    "            \n",
    "            #Append judgment from oalc first\n",
    "            if case['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                \n",
    "                case.update({'judgment': mnc_judgment_dict[case['Medium neutral citation']]})\n",
    "\n",
    "                judgments_file.append(case)\n",
    "                \n",
    "                print(f\"{case['Case name']} {case['Medium neutral citation']}: got judgment from OALC\")\n",
    "\n",
    "            else:\n",
    "            #Get remaining judgment from HCA database\n",
    "        \n",
    "                judgment_link = case['Hyperlink to High Court Judgments Database']\n",
    "                \n",
    "                if 'showbyHandle' in judgment_link:\n",
    "                    \n",
    "                    judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "        \n",
    "                else: #If 'showCase' in judgment_link:\n",
    "        \n",
    "                    judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "        \n",
    "                for key in judgment_dict.keys():\n",
    "                    if key not in case.keys():\n",
    "                        case.update({key: judgment_dict[key]}) \n",
    "                \n",
    "                judgments_file.append(case)\n",
    "\n",
    "                print(f\"{case['Case name']} {case['Medium neutral citation']}: got judgment from HCA directly.\")\n",
    "                \n",
    "                pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Make judgment_link clickable\n",
    "    for decision in judgments_file:\n",
    "        if '=HYPERLINK' not in decision['Hyperlink to High Court Judgments Database']:\n",
    "            clickable_link =  link(decision['Hyperlink to High Court Judgments Database'])\n",
    "            decision.update({'Hyperlink to High Court Judgments Database': clickable_link})\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "        \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "\n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9843d7-c7ea-42aa-9c80-2826d2512e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
