{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "import math\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface == True\n",
      "Running locally or on Streamlit\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, save_input, link, is_date, split_title_mnc, pdf_judgment, pdf_image_judgment\n",
    "#Import variables\n",
    "from functions.common_functions import huggingface, today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# High Court of Australia search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3216f28-326d-4a77-8f31-787d762ba871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait as Wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium_stealth import stealth\n",
    "\n",
    "options = Options()\n",
    "#options.add_argument(\"--disable-gpu\")\n",
    "#options.add_argument(\"--headless\")\n",
    "#options.add_argument('--no-sandbox')  \n",
    "#options.add_argument('--disable-dev-shm-usage')  \n",
    "\n",
    "download_dir = os.getcwd() + '/HCA_PDFs'\n",
    "\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "options.add_experimental_option('useAutomationExtension', False)\n",
    "\n",
    "options.add_experimental_option('prefs', {\n",
    "\"download.default_directory\": download_dir, #Change default directory for downloads\n",
    "\"download.prompt_for_download\": False, #To auto download the file\n",
    "\"download.directory_upgrade\": True,\n",
    "\"plugins.always_open_pdf_externally\": True #It will not show PDF directly in chrome\n",
    "})\n",
    "\n",
    "if 'Users/Ben' not in os.getcwd(): \n",
    "\n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    display = Display(visible=0, size=(1200, 1600))  \n",
    "    display.start()\n",
    "\n",
    "    options.add_argument(\"window-size=1200x600\")\n",
    "\n",
    "#@st.cache_resource(show_spinner = False, ttl=600)\n",
    "def get_driver():\n",
    "\n",
    "    browser = webdriver.Chrome(options=options)\n",
    "\n",
    "    browser.implicitly_wait(15)\n",
    "    browser.set_page_load_timeout(30)\n",
    "\n",
    "    stealth(browser,\n",
    "    \n",
    "            languages=[\"en-US\", \"en\"],\n",
    "    \n",
    "            vendor=\"Google Inc.\",\n",
    "    \n",
    "            platform=\"Win32\",\n",
    "    \n",
    "            webgl_vendor=\"Intel Inc.\",\n",
    "    \n",
    "            renderer=\"Intel Iris OpenGL Engine\",\n",
    "    \n",
    "            webdriver=False,\n",
    "    \n",
    "            fix_hairline=True)\n",
    "    \n",
    "    if 'Users/Ben' in os.getcwd():\n",
    "        browser.minimize_window()\n",
    "    \n",
    "    return browser\n",
    "\n",
    "#try:\n",
    "    \n",
    "    #browser = get_driver()\n",
    "    \n",
    "#except Exception as e:\n",
    "    #st.error('Sorry, your internet connection is not stable enough for this app. Please check or change your internet connection and try again.')\n",
    "    #print(e)\n",
    "    #quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1b993f-13e5-4681-8652-1c14a6c7cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load hca_data\n",
    "\n",
    "@st.cache_resource(show_spinner = False)\n",
    "def hca_load_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "hca_data_url = 'https://raw.githubusercontent.com/nehcneb/au-uk-empirical-legal-research/main/hca_data.csv'\n",
    "\n",
    "#response = requests.get(hca_data_url)\n",
    "\n",
    "#hca_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "hca_df = hca_load_data(hca_data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2217c2-6d14-4551-a177-efce61446228",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca5f1d2-b354-45be-b365-0f01233c7537",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Collections available\n",
    "hca_collections_dict = {\n",
    "'Judgments 2000-present': 'judgments-2000-current',\n",
    "'Commonwealth Law Reports, volumes 1-100': '1-clr-100-clr',\n",
    "'Single Justice Judgments': 'single-justice-judgments',\n",
    "'Unreported Judgments': 'unreported-judgments'\n",
    "}\n",
    "\n",
    "\n",
    "hca_collections_years_dict = {\n",
    "'Judgments 2000-present': [str(x) for x in range(datetime.now().year, 2000-1, -1)],\n",
    "'Commonwealth Law Reports, volumes 1-100': [str(x) for x in range(1903, 1958 + 1)],\n",
    "'Single Justice Judgments': [str(x) for x in range(datetime.now().year, 2024-1, -1)],\n",
    "'Unreported Judgments': [str(x) for x in (list(range(1994, 1921-1, -1)) + ['1906'])],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e17213a-b1c7-4ae9-bf9d-3cf8840ceb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_clr_volumns = [str(x) for x in range(1, 100+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb4f3244-82b9-4c5f-93b9-a6d0e569cd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_collections = list(hca_collections_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34145376-adae-4aa3-8d28-cc7f0fa5fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "hca_meta_labels_droppable = ['Date', 'Case number', 'Before', 'Catchwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4e9e27-f130-404b-b5ae-df573716a16d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Get judges and years dicts\n",
    "#judges_dict = {}\n",
    "#years_dict = {}\n",
    "\n",
    "#search_url = 'https://www.hcourt.gov.au/cases-and-judgments/judgments/judgments-2000-current?'\n",
    "#search_url = 'https://www.hcourt.gov.au/cases-and-judgments/judgments/single-justice-judgments?'#For single judges\n",
    "#search_url = 'https://www.hcourt.gov.au/cases-and-judgments/judgments/unreported-judgments'#For unreported judgments\n",
    "#search_page = requests.get(search_url)\n",
    "\n",
    "#search_soup = BeautifulSoup(search_page.content, \"lxml\")\n",
    "#judges = search_soup.find_all('li', class_ = 'facet-item')\n",
    "\n",
    "#for judge in judges:\n",
    "    #key = judge.get_text(strip = True)\n",
    "\n",
    "    #code = judge.find('a', href = True)['href'].split('=')[-1]\n",
    "\n",
    "    #if not re.search(r'\\d', key):\n",
    "    \n",
    "        #judges_dict.update({key: code})\n",
    "\n",
    "    #else:\n",
    "        \n",
    "        #years_dict.update({key: code})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "788250ea-f175-43a9-b555-a952afe8f6fc",
   "metadata": {
    "lines_to_next_cell": 2,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unreported_judges_dict = {'Aickin': 'justices:Aickin',\n",
    " 'Barwick': 'justices:Barwick',\n",
    " 'Brennan': 'justices:Brennan',\n",
    " 'Dawson': 'justices:Dawson',\n",
    " 'Deane': 'justices:Deane',\n",
    " 'Dixon': 'justices:Dixon',\n",
    " 'Duffy': 'justices:Duffy',\n",
    " 'Evatt': 'justices:Evatt',\n",
    " 'Fullagar': 'justices:Fullagar',\n",
    " 'Gaudron': 'justices:Gaudron',\n",
    " 'Gavan Duffy': 'justices:Gavan%20Duffy',\n",
    " 'Gibbs': 'justices:Gibbs',\n",
    " 'Griffith': 'justices:Griffith',\n",
    " 'Higgins': 'justices:Higgins',\n",
    " 'Isaacs': 'justices:Isaacs',\n",
    " 'Jacobs': 'justices:Jacobs',\n",
    " 'Kitto': 'justices:Kitto',\n",
    " 'Knox': 'justices:Knox',\n",
    " 'Latham': 'justices:Latham',\n",
    " 'Markell': 'justices:Markell',\n",
    " 'Mason': 'justices:Mason',\n",
    " 'McHugh': 'justices:McHugh',\n",
    " 'McTiernan': 'justices:McTiernan',\n",
    " 'Menzies': 'justices:Menzies',\n",
    " 'Murphy': 'justices:Murphy',\n",
    " 'Owen': 'justices:Owen',\n",
    " 'Rich': 'justices:Rich',\n",
    " 'Starke': 'justices:Starke',\n",
    " 'Stephen': 'justices:Stephen',\n",
    " 'Taylor': 'justices:Taylor',\n",
    " 'Toohey': 'justices:Toohey',\n",
    " 'Walsh': 'justices:Walsh',\n",
    " 'Webb': 'justices:Webb',\n",
    " 'Williams': 'justices:Williams',\n",
    " 'Wilson': 'justices:Wilson',\n",
    " 'Windeyer': 'justices:Windeyer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a37973-0446-4362-84c2-b0b78eac82c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_judges_dict = {'Beech-Jones': 'justices:BeechJones',\n",
    " 'Edelman': 'justices:Edelman',\n",
    " 'Gleeson': 'justices:Gleeson',\n",
    " 'Gordon': 'justices:Gordon',\n",
    " 'Jagot': 'justices:Jagot',\n",
    " 'Steward': 'justices:Steward'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a27c22-d1cd-4ab7-b35d-fc965ef21be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "judges_dict = {'Beech-Jones': 'justices:BeechJones',\n",
    " 'Bell': 'justices:Bell',\n",
    " 'Callinan': 'justices:Callinan',\n",
    " 'Crennan': 'justices:Crennan',\n",
    " 'Edelman': 'justices:Edelman',\n",
    " 'French': 'justices:French',\n",
    " 'Gageler': 'justices:Gageler',\n",
    " 'Gaudron': 'justices:Gaudron',\n",
    " 'Gleeson': 'justices:Gleeson',\n",
    " 'Gordon': 'justices:Gordon',\n",
    " 'Gummow': 'justices:Gummow',\n",
    " 'Hayne': 'justices:Hayne',\n",
    " 'Heydon': 'justices:Heydon',\n",
    " 'Jagot': 'justices:Jagot',\n",
    " 'Keane': 'justices:Keane',\n",
    " 'Kiefel': 'justices:Kiefel',\n",
    " 'Kirby': 'justices:Kirby',\n",
    " 'McHugh': 'justices:McHugh',\n",
    " 'Nettle': 'justices:Nettle',\n",
    " 'Steward': 'justices:Steward'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "348d611c-8e95-4cde-bae0-67cab820edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_judges = list(judges_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b4fe661-a83c-49d8-a10a-c1b3e461b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_hca_judges = list(single_judges_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e39405fa-6a51-4bbd-9b97-8b766adef08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unreported_hca_judges = list(unreported_judges_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "316f7fe0-e961-439c-94ac-584f9bcdf504",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_judges_dict = judges_dict | single_judges_dict | unreported_judges_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d65ea10-5a84-4434-bf79-2c69f8a1e953",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_collections_judges_dict = {\n",
    "'Judgments 2000-present': hca_judges,\n",
    "'Commonwealth Law Reports, volumes 1-100': None,\n",
    "'Single Justice Judgments': single_hca_judges,\n",
    "'Unreported Judgments': unreported_hca_judges,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1b8e599-4b9c-4d26-9567-9aadf041cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hca_search_methods_dict = {\n",
    "'Judgments 2000-present': [\"Keywords, case number, Justices, year or Citation\"], #[\"Keywords or case number\", \"Justices or year\", \"Citation\"],\n",
    "'Commonwealth Law Reports, volumes 1-100': [\"Keywords, CLR volumn or year\"], #[\"Keywords\", \"CLR volumn or year\"],\n",
    "'Single Justice Judgments': [\"Keywords, case number, Justices, year or Citation\"], #[\"Keywords or case number\", \"Justices or year\", \"Citation\"],\n",
    "'Unreported Judgments': [\"Keywords, case number, Justices, year or Citation\"], #[\"Keywords or case number\", \"Justices or year\", \"Citation\"],    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5ef57b-8eff-481e-95ef-2e9c08d76505",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c32a9545-61a1-46ee-a226-f8994d030101",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hca_search_tool:\n",
    "\n",
    "    def __init__(self, \n",
    "                 collection = hca_collections[0],\n",
    "                 method = hca_search_methods_dict[hca_collections[0]][0],\n",
    "                 keywords = '',\n",
    "                 case_number = '', \n",
    "                 judge = None,\n",
    "                 clr = None,                 \n",
    "                 year = None,\n",
    "                citation = '',\n",
    "                judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "\n",
    "        #Initialise parameters\n",
    "        self.collection = collection\n",
    "        self.method = method\n",
    "        self.keywords = keywords\n",
    "        self.case_number = case_number\n",
    "        self.judge = judge\n",
    "        self.clr = clr\n",
    "        self.year = year\n",
    "        self.citation = citation\n",
    "\n",
    "        self.judgment_counter_bound = judgment_counter_bound\n",
    "        \n",
    "        self.page = 1\n",
    "        \n",
    "        self.results_count = 0\n",
    "\n",
    "        self.total_pages = 1\n",
    "        \n",
    "        self.results_url = ''\n",
    "\n",
    "        self.results_url_to_show = ''\n",
    "        \n",
    "        self.soup = None\n",
    "        \n",
    "        self.case_infos = []\n",
    "\n",
    "        #For getting judgment directly from HCA database if can't get from OALC\n",
    "        self.case_infos_direct = []\n",
    "\n",
    "    #Function for getting search results\n",
    "    def search(self):\n",
    "\n",
    "        #Reset infos of cases found\n",
    "        self.case_infos = []\n",
    "        \n",
    "        params_raw = []\n",
    "        \n",
    "        base_url = f'https://www.hcourt.gov.au/cases-and-judgments/judgments/{hca_collections_dict[self.collection]}?'\n",
    "\n",
    "        #Url for selenium to start\n",
    "\n",
    "        self.results_url = base_url\n",
    "        \n",
    "        #Before entering year, justice or CLR, must enter keywords or case number first, then load\n",
    "\n",
    "        browser = get_driver()\n",
    "        \n",
    "        browser.get(self.results_url)\n",
    "\n",
    "        if len(self.keywords) > 0:\n",
    "            \n",
    "            keywords_input = Wait(browser,  20).until(EC.visibility_of_element_located((By.XPATH, '//input[@id=\"edit-keywords--2\"]')))\n",
    "            keywords_input.send_keys(self.keywords)\n",
    "\n",
    "            params_raw.append(('keywords', self.keywords))\n",
    "\n",
    "        if len(self.case_number) > 0:\n",
    "\n",
    "            case_number_input = Wait(browser,  20).until(EC.visibility_of_element_located((By.XPATH, '//input[@id=\"edit-case-number--2\"]')))\n",
    "            keywords_input.send_keys(self.case_number)\n",
    "\n",
    "            params_raw.append(('case_number', self.case_number))\n",
    "        \n",
    "        elif (len(self.case_number) == 0) and (len(self.citation) > 0):\n",
    "\n",
    "            print(f\"Trying to infer case_number from self.citation == {self.citation}\")\n",
    "            \n",
    "            hca_case_number = hca_df[hca_df['mnc'].isin([self.citation])]\n",
    "            \n",
    "            if len(hca_case_number) > 0:\n",
    "\n",
    "                hca_case_number.reset_index(inplace = True)\n",
    "\n",
    "                case_number = hca_case_number.loc[0, 'case_number']\n",
    "                \n",
    "                if isinstance(case_number, str):\n",
    "    \n",
    "                    if len(case_number) > 0:\n",
    "\n",
    "                        for puncutation in [' ', ',', ';']:\n",
    "\n",
    "                            if puncutation in case_number:\n",
    "\n",
    "                                case_number = case_number.split(puncutation)[0]\n",
    "\n",
    "                        print(f\"Inferred case_number == {case_number} from self.citation == {self.citation}\")\n",
    "\n",
    "            case_number_input = Wait(browser,  20).until(EC.visibility_of_element_located((By.XPATH, '//input[@id=\"edit-case-number--2\"]')))\n",
    "            keywords_input.send_keys(case_number)\n",
    "\n",
    "            params_raw.append(('case_number', case_number))\n",
    "\n",
    "        #Select 100 results per page\n",
    "        items_per_page_menu = Wait(browser,  20).until(EC.visibility_of_element_located((By.ID, 'edit-items-per-page--2')))\n",
    "        items_per_page_menu_input = Select(items_per_page_menu)\n",
    "        \n",
    "        items_per_page_menu_input.select_by_value('100')\n",
    "\n",
    "        #Click apply button and load\n",
    "        apply_button = Wait(browser, 20).until(EC.visibility_of_element_located((By.ID, 'edit-submit-judgments--2')))\n",
    "        apply_button.click()\n",
    "\n",
    "        #Wait until any search results present       \n",
    "        loaded = Wait(browser, 15).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='views-element-container']\")))\n",
    "        \n",
    "        #Update results_url\n",
    "        params = urllib.parse.urlencode(params_raw, quote_via=urllib.parse.quote)\n",
    "        self.results_url = base_url + '&' + params + '&items_per_page=100'\n",
    "        \n",
    "        #Enter year, justice or CLR if selected\n",
    "        selection_counter = 0\n",
    "\n",
    "        for selection in [self.judge, self.year, self.clr]:\n",
    "\n",
    "            if (not pd.isna(selection)) and (not selection == None) and (not str(selection) == 'None'):\n",
    "\n",
    "                if isinstance(selection, float) or isinstance(selection, int) or isinstance(selection, int):\n",
    "\n",
    "                    selection = str(int(selection))\n",
    "\n",
    "                if isinstance(selection, str):\n",
    "\n",
    "                    if len(selection) > 0:\n",
    "\n",
    "                        #If year\n",
    "                        if re.search(r'\\d{4}', selection):\n",
    "        \n",
    "                            selection = f\"d:{selection}\"\n",
    "\n",
    "                        #If CLR volumn\n",
    "                        elif re.search(r'\\d+', selection):\n",
    "        \n",
    "                            selection = f\"volume:{selection}\"\n",
    "\n",
    "                        #If judge\n",
    "                        else:\n",
    "                            selection = all_judges_dict[selection]\n",
    "                            \n",
    "                        params_raw.append((f'f[{selection_counter}]', selection))\n",
    "\n",
    "                        selection_counter += 1\n",
    "\n",
    "                        #Update self.results_url then reload selenium\n",
    "                        params = urllib.parse.urlencode(params_raw, quote_via=urllib.parse.quote)\n",
    "                \n",
    "                        self.results_url = base_url + '&' + params + '&items_per_page=100'\n",
    "        \n",
    "                        #Pause to avoid getting kicked out\n",
    "                        pause.seconds(np.random.randint(10, 15))\n",
    "\n",
    "                        print(f\"Given '{selection}' entered, loading {self.results_url} \")\n",
    "                        \n",
    "                        browser.get(self.results_url)\n",
    "\n",
    "                        #Wait until any search results present\n",
    "                        loaded = Wait(browser, 15).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='views-element-container']\")))\n",
    "\n",
    "        print(f\"Loaded search results from self.results_url == {self.results_url}\")\n",
    "                \n",
    "        self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "        #Get results count\n",
    "        if 'displaying' in self.soup.text.lower():\n",
    "            \n",
    "            results_count_raw = self.soup.find('div', class_ = 'view-summary')\n",
    "            \n",
    "            if re.search(r'\\d+', results_count_raw.text):\n",
    "                \n",
    "                self.results_count = int(re.findall(r'\\d+', results_count_raw.text)[-1])\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            self.results_count = 0\n",
    "\n",
    "        #Get page count\n",
    "        self.total_pages = math.ceil(self.results_count/100)\n",
    "\n",
    "        print(f\"Found {self.results_count} results on {self.total_pages} pages\")\n",
    "        \n",
    "        if self.results_count > 0:\n",
    "\n",
    "            for page in range(0, self.total_pages):\n",
    "\n",
    "                if len(self.case_infos) < min(self.results_count, self.judgment_counter_bound):\n",
    "                    #Update self.soup from new page if necessary\n",
    "                    if page > 0:\n",
    "    \n",
    "                        #Pause to avoid getting kicked out\n",
    "                        pause.seconds(np.random.randint(10, 15))\n",
    "\n",
    "                        next_page_url = self.results_url + f\"&page={page}\"\n",
    "\n",
    "                        browser = get_driver()\n",
    "                        browser.get(self.next_page_url)\n",
    "                        #browser.delete_all_cookies() #Don't\n",
    "                        #browser.refresh() #Don't\n",
    "\n",
    "                        #Wait until search results present, if any\n",
    "                        loaded = Wait(browser, 15).until(EC.presence_of_element_located((By.XPATH, \"//div[@class='views-element-container']\")))\n",
    "\n",
    "                        self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "                        browser.quit()\n",
    "        \n",
    "                    print(f\"Getting results from page {page} (0 denotes first page)\")\n",
    "                    \n",
    "                    results = self.soup.find_all('div', class_ = 'views-row')\n",
    "\n",
    "                    for result in results:\n",
    "\n",
    "                        if len(self.case_infos) < min(self.results_count, self.judgment_counter_bound):\n",
    "\n",
    "                            case_info = {'Case name': '',\n",
    "                                         'Hyperlink to High Court Judgments Database': '',\n",
    "                                         'Reported': '',\n",
    "                                         'Medium neutral citation': '',\n",
    "                                          'Case number': '',\n",
    "                                         'Before': '',\n",
    "                                         'Date': '', \n",
    "                                        }\n",
    "\n",
    "                            try:\n",
    "                                link = 'https://www.hcourt.gov.au' + result.find('a', class_ = 'views-row-item views-row-item-judgement')['href']\n",
    "                                case_info['Hyperlink to High Court Judgments Database'] = link\n",
    "                            except:\n",
    "                                print(f\"Can't get link\")\n",
    "\n",
    "                            try:\n",
    "                                case_name = result.find('div', class_ = 'field field--title text-bold').get_text(strip = True)\n",
    "                                case_info['Case name'] = case_name\n",
    "                            except:\n",
    "                                print(f\"{case_info['Hyperlink to High Court Judgments Database']}: can't get case_name\")\n",
    "\n",
    "                            try:\n",
    "\n",
    "                                reported_list = []\n",
    "                                \n",
    "                                citations = result.find_all('div', class_ = 'field field--citation')\n",
    "\n",
    "                                for citation in citations:\n",
    "\n",
    "                                    citation = citation.get_text(strip = True)\n",
    "                                    \n",
    "                                    if ':' in citation:\n",
    "                                    \n",
    "                                        citation = citation.split(':')[-1]\n",
    "\n",
    "                                    #print(citation)\n",
    "\n",
    "                                    if re.search(r'\\[\\d{4}\\]', citation):\n",
    "                                        \n",
    "                                        case_info['Medium neutral citation'] = citation\n",
    "\n",
    "                                    else:\n",
    "\n",
    "                                        reported_list.append(citation)\n",
    "\n",
    "                                case_info['Reported'] = '; '.join(reported_list)\n",
    "                            \n",
    "                            except:\n",
    "                                \n",
    "                                print(f\"{case_info['Case name']}: can't get citation\")\n",
    "\n",
    "                            try:\n",
    "\n",
    "                                #before = ''\n",
    "                                \n",
    "                                if 'field field--name-field-hca-justices field--type-string field--label-above field__item' in str(result):\n",
    "                                \n",
    "                                    before = result.find('div', class_ = 'field field--name-field-hca-justices field--type-string field--label-above field__item').get_text(strip = True)\n",
    "                                \n",
    "                                elif 'field field--legacy-before' in str(result):\n",
    "\n",
    "                                    before = result.find('div', class_ = 'field field--legacy-before').get_text(strip = True)\n",
    "\n",
    "                                if ':' in before:\n",
    "                                \n",
    "                                    before = before.split(':')[-1]\n",
    "\n",
    "                                case_info['Before'] = before\n",
    "                                \n",
    "                            except:\n",
    "                                \n",
    "                                print(f\"{case_info['Case name']}: can't get before\")\n",
    "\n",
    "                            try:\n",
    "                                \n",
    "                                date = result.find('div', class_ = 'field field--hca-date-issued').get_text(strip = True)\n",
    "                                \n",
    "                                if ':' in date:\n",
    "                                \n",
    "                                    date = date.split(':')[-1]\n",
    "\n",
    "                                case_info['Date'] = date\n",
    "\n",
    "                            except:\n",
    "                                \n",
    "                                print(f\"{case_info['Case name']}: can't get date\")\n",
    "\n",
    "                            try:\n",
    "                                case_number = result.find('div', class_ = 'field field--hca-matter-number').get_text(strip = True)\n",
    "                                \n",
    "                                if ':' in case_number:\n",
    "                                \n",
    "                                    case_number = case_number.split(':')[-1]\n",
    "\n",
    "                                case_info['Case number'] = case_number\n",
    "\n",
    "                            except:\n",
    "                                \n",
    "                                print(f\"{case_info['Case name']}: can't get case_number\")\n",
    "\n",
    "                            self.case_infos.append(case_info)\n",
    "\n",
    "                        else:\n",
    "                            #Got enough results, break results per page loop\n",
    "                            break\n",
    "\n",
    "                else:\n",
    "                    #Got enough results, break out of page loop\n",
    "                    break\n",
    "\n",
    "        browser.quit()\n",
    "\n",
    "    #Function for attaching judgment text to case_info dict\n",
    "    def attach_judgment(self, case_info):\n",
    "\n",
    "        catchwords = ''\n",
    "        \n",
    "        judgment_text = ''\n",
    "        \n",
    "        judgment_url = case_info['Hyperlink to High Court Judgments Database']\n",
    "\n",
    "        browser = get_driver()\n",
    "    \n",
    "        browser.get(judgment_url)\n",
    "        #browser.delete_all_cookies() #Don't\n",
    "        #browser.refresh() #Don't\n",
    "        \n",
    "        #Wait until pdf link present\n",
    "        pdf_link_present = Wait(browser, 15).until(EC.presence_of_element_located((By.XPATH, \"//span[@class='file file--mime-application-pdf file--application-pdf']\")))\n",
    "\n",
    "        result_soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "        \n",
    "        #Get catchwords\n",
    "\n",
    "        if 'text-content clearfix field field--name-field-hca-catchwords field--type-text-long field--label-above' in str(result_soup):\n",
    "            \n",
    "            try:\n",
    "                catchwords = result_soup.find('div', class_ = 'text-content clearfix field field--name-field-hca-catchwords field--type-text-long field--label-above')\n",
    "                catchwords = catchwords.text\n",
    "    \n",
    "            except Exception as e:\n",
    "                \n",
    "                print(f\"{case_info['Case name']}: Can't get catchwords due to error: {e}\")\n",
    "\n",
    "        #Get judgment text\n",
    "        \n",
    "        try:\n",
    "\n",
    "            #Stat downloading judgment pdf\n",
    "            pdf_link_present.click()\n",
    "                \n",
    "            #Get path to most recent downloaded file\n",
    "            \n",
    "            pdf_link = result_soup.find('span', class_ = 'file file--mime-application-pdf file--application-pdf')\n",
    "        \n",
    "            pdf_link = 'https://www.hcourt.gov.au' + pdf_link.find('a', href=True)['href']\n",
    "\n",
    "            pdf_file = pdf_link.split('/')[-1]    \n",
    "\n",
    "            pdf_file = urllib.parse.unquote(pdf_file)\n",
    "            \n",
    "            pdf_path = f\"{download_dir}/{pdf_file}\"\n",
    "\n",
    "            #Limiting waiting time for downloading PDF to 1 min\n",
    "            \n",
    "            waiting_counter = 0\n",
    "            \n",
    "            while ((not os.path.exists(pdf_path)) and (waiting_counter < 10)):\n",
    "                pause.seconds(5)\n",
    "                waiting_counter += 1\n",
    "                            \n",
    "            #print(f\"{case_info['Case name']}: Trying to OCR pdf from pdf_path == {pdf_path}\")\n",
    "\n",
    "            if ('2000' in self.collection) or ('Single' in self.collection):\n",
    "\n",
    "                judgment_text = pdf_judgment(url_or_path = pdf_path, url_given = False)\n",
    "                                                                \n",
    "            else:\n",
    "                \n",
    "                judgment_text = pdf_image_judgment(url_or_path = pdf_path, url_given = False)\n",
    "\n",
    "            #MUST remove pdf from download folder automatically or manually\n",
    "            os.remove(pdf_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"{case_info['Case name']}: Can't get judgment_text due to error: {e}\")\n",
    "\n",
    "        case_info.update({'Catchwords': catchwords})\n",
    "        case_info.update({'judgment': judgment_text})\n",
    "        \n",
    "        browser.quit()\n",
    "        \n",
    "        return case_info\n",
    "    \n",
    "    #Function for getting all requested judgments\n",
    "    def get_judgments(self):\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "\n",
    "        #Search if not done yet\n",
    "        if len(self.case_infos) == 0:\n",
    "\n",
    "            self.search()\n",
    "\n",
    "        #If huggingface enabled\n",
    "        if huggingface == True:\n",
    "\n",
    "            #Load oalc\n",
    "            from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "    \n",
    "            #Create a list of mncs for HuggingFace:\n",
    "            mnc_list = []\n",
    "    \n",
    "            for case_info in self.case_infos:\n",
    "    \n",
    "                #Add mnc to list for HuggingFace\n",
    "                mnc_list.append(case_info['Medium neutral citation'])\n",
    "    \n",
    "            #Get judgments from oalc first\n",
    "            mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "        \n",
    "            #Append OALC judgment \n",
    "            for case_info in self.case_infos:\n",
    "                \n",
    "                #Append judgments from oalc first\n",
    "                if case_info['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                    \n",
    "                    case_info.update({'judgment': mnc_judgment_dict[case_info['Medium neutral citation']]})\n",
    "\n",
    "                    #Make link clickable\n",
    "                    judgment_url = case_info['Hyperlink to High Court Judgments Database']\n",
    "                    case_info.update({'Hyperlink to High Court Judgments Database': link(judgment_url)})\n",
    "\n",
    "                    #Add case_info to self.case_infos_w_judgments\n",
    "                    self.case_infos_w_judgments.append(case_info)\n",
    "    \n",
    "                    print(f\"{case_info['Case name']} {case_info['Medium neutral citation']}: got judgment from OALC\")\n",
    "    \n",
    "                else:\n",
    "                    \n",
    "                    #To get from HCA database directly if can't get from OALC\n",
    "                    self.case_infos_direct.append(case_info)\n",
    "\n",
    "            print(f\"Scrapped {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)} judgments from OALC\")\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #If huggingface not enabled\n",
    "            self.case_infos_direct = copy.deepcopy(self.case_infos)\n",
    "        \n",
    "        #Get judgments from HCA database directly\n",
    "        for case_info in self.case_infos_direct:\n",
    "\n",
    "            #Pause to avoid getting kicked out\n",
    "            pause.seconds(np.random.randint(10, 15))\n",
    "\n",
    "            case_info = self.attach_judgment(case_info)\n",
    "\n",
    "            #Make link clickable\n",
    "            judgment_url = case_info['Hyperlink to High Court Judgments Database']\n",
    "            case_info.update({'Hyperlink to High Court Judgments Database': link(judgment_url)})\n",
    "\n",
    "            #Add case_info to self.case_infos_w_judgments\n",
    "\n",
    "            self.case_infos_w_judgments.append(case_info)\n",
    "            \n",
    "            print(f\"{case_info['Case name']} {case_info['Medium neutral citation']}: got judgment from HCA directly\")\n",
    "            \n",
    "            print(f\"Scrapped {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)} judgments\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dfc3c96-6697-44b0-90c7-0aef95217769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hca_search_preview(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Conduct search\n",
    "\n",
    "    hca_search = hca_search_tool(collection = df_master.loc[0, 'Collection'], \n",
    "                                 method = df_master.loc[0, 'Search method'], \n",
    "                   keywords = df_master.loc[0, 'Keyword search'],\n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    judge = df_master.loc[0, 'Justices'],\n",
    "                    clr = df_master.loc[0, 'Filter by CLR volume'],\n",
    "                    year = df_master.loc[0, 'Year'],    \n",
    "                    citation = df_master.loc[0, 'Medium neutral citation'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                    )\n",
    "\n",
    "    hca_search.search()\n",
    "    \n",
    "    results_count = hca_search.results_count\n",
    "    \n",
    "    case_infos = hca_search.case_infos\n",
    "\n",
    "    results_url = hca_search.results_url\n",
    "\n",
    "    #st.write(results_url)\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'case_infos': case_infos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:37:39.832 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.833 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.834 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.835 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-01-31 17:37:39.836 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_batch_input\n",
    "#Import variables\n",
    "from functions.gpt_functions import basic_model, flagship_model#, role_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d112bbe4-0051-41ab-ac85-87047d2059c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "#hca_role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from specific paragraphs, pages or sections, provide the paragraph or page numbers or section names as part of your answer. If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". '\n",
    "\n",
    "#system_instruction = role_content #hca_role_content\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89684638-c8ee-4643-bc5b-d4792b6b7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:37:39.848 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#For getting judgments directly from the High Court if not available in OALC\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    hca_search = hca_search_tool(collection = df_master.loc[0, 'Collection'], \n",
    "                                 method = df_master.loc[0, 'Search method'], \n",
    "                   keywords = df_master.loc[0, 'Keyword search'],\n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    judge = df_master.loc[0, 'Justices'],\n",
    "                    clr = df_master.loc[0, 'Filter by CLR volume'],\n",
    "                    year = df_master.loc[0, 'Year'],    \n",
    "                    citation = df_master.loc[0, 'Medium neutral citation'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                    )\n",
    "\n",
    "    hca_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in hca_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_individual.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    if (pop_judgment() > 0) and ('judgment' in df_updated.columns):\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dacc31ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-31 17:37:39.855 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hca_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Conduct search\n",
    "    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    hca_search = hca_search_tool(collection = df_master.loc[0, 'Collection'], \n",
    "                                 method = df_master.loc[0, 'Search method'], \n",
    "                   keywords = df_master.loc[0, 'Keyword search'],\n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    judge = df_master.loc[0, 'Justices'],\n",
    "                    clr = df_master.loc[0, 'Filter by CLR volume'],\n",
    "                    year = df_master.loc[0, 'Year'],    \n",
    "                    citation = df_master.loc[0, 'Medium neutral citation'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                    )\n",
    "\n",
    "    hca_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in hca_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_individual.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "        \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "\n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9843d7-c7ea-42aa-9c80-2826d2512e15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
