{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "from io import StringIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner, save_input\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# High Court of Australia search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f3329d8-1716-4570-8dd0-4b5aa22aaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.common_functions import link, is_date, list_value_check, au_date, split_title_mnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ca5f1d2-b354-45be-b365-0f01233c7537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collections available\n",
    "hca_collections = ['Judgments 2000-present', 'Judgments 1948-1999', '1 CLR - 100 CLR (judgments 1903-1958)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url AND number of search results\n",
    "def hca_search(collection = '', \n",
    "               quick_search = '', \n",
    "               #citation = '', \n",
    "                full_text = ''):\n",
    "    #Default base url is for judgments 2000-current\n",
    "    #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "    base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "    \n",
    "    if collection == 'Judgments 2000-present':\n",
    "    \n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=0&facets=&srch-Term='\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=0'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=1&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=1'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        #base_url = 'https://eresources.hcourt.gov.au/search?col=2&facets=&srch-Term='\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/search?col=2'\n",
    "    \n",
    "    params = {'qsrch-term': quick_search, \n",
    "              #'Citation_ST': citation, \n",
    "              'srch-term': full_text\n",
    "             }\n",
    "\n",
    "    #Get response page\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    #Get url_search_results\n",
    "    url_search_results = response.url\n",
    "\n",
    "    #Get number of search results\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "    number_of_results = soup.find(\"span\", id=\"itemTotal\").text\n",
    "        \n",
    "    return {'url': url_search_results, 'results_num': number_of_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e95d9963-c3b6-46f0-a1ea-c30c63e5aba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:31.195 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function turning search results url to cases_w_mnc_links to judgments\n",
    "#NOT IN USE\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    \n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    #Get number of pages\n",
    "    #There are up to 20 pages per page\n",
    "    number_of_pages = soup.find(\"span\", id=\"lastItem\").text\n",
    "    \n",
    "    #Start cases_w_mnc_links list\n",
    "    cases_w_mnc_links = []\n",
    "    \n",
    "    #Get first page of results\n",
    "    raw_links = soup.find_all(class_='case')\n",
    "    \n",
    "    if len(raw_links) > 0:\n",
    "    \n",
    "        for raw_link in raw_links:\n",
    "            if counter <= judgment_counter_bound:\n",
    "                link = 'https://eresources.hcourt.gov.au' + raw_link['href']\n",
    "                case_name_mnc = split_title_mnc(raw_links.get_text().strip())\n",
    "                case_name = case_name_mnc[0]\n",
    "                mnc = case_name_mnc[1]\n",
    "                cases_w_mnc_links.append({'Case name': case_name, 'Medium neutral citation': mnc, 'Hyperlink to High Court Judgments Database': link})\n",
    "                counter += 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    #Go to next page if still below judgment_counter_bound\n",
    "    if counter <= judgment_counter_bound:\n",
    "        if int(number_of_pages) > 1:\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            for page_raw in range(1, int(number_of_pages)):\n",
    "                page = page_raw + 1\n",
    "                url_search_results_new_page = url_search_results + f'&page={page}'\n",
    "                page_new_page = requests.get(url_search_results_new_page)\n",
    "                soup_new_page = BeautifulSoup(page_new_page.content, \"lxml\")\n",
    "                raw_links_new_page = soup_new_page.find_all(class_='case')\n",
    "            \n",
    "                if len(raw_links_new_page) > 0:\n",
    "                \n",
    "                    for raw_link in raw_links_new_page:\n",
    "                        if counter <= judgment_counter_bound:\n",
    "                            link = 'https://eresources.hcourt.gov.au' + raw_link['href']\n",
    "                            case_name = case_name_mnc[0]\n",
    "                            mnc = case_name_mnc[1]\n",
    "                            cases_w_mnc_links.append({'Case name': case_name, 'Medium neutral citation': mnc, 'Hyperlink to High Court Judgments Database': link})\n",
    "                            counter += 1\n",
    "                        else:\n",
    "                            break\n",
    "                else:\n",
    "                    break\n",
    "    \n",
    "    return cases_w_mnc_links\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90302a99-07e1-4516-bd21-4b6f9c33e2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:39.044 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function for judgment link containing PDF\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_pdf_judgment(url):\n",
    "    pdf_url = url.replace('showCase', 'downloadPdf')\n",
    "    headers = {'User-Agent': 'whatever'}\n",
    "    r = requests.get(pdf_url, headers=headers)\n",
    "    remote_file_bytes = io.BytesIO(r.content)\n",
    "    pdfdoc_remote = pypdf.PdfReader(remote_file_bytes)\n",
    "    text_list = []\n",
    "\n",
    "    for page in pdfdoc_remote.pages:\n",
    "        text_list.append(page.extract_text())\n",
    "    \n",
    "    return str(text_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40d93cfb-26fb-436a-bddf-eb20e1095d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "hca_meta_labels_droppable = ['Reported', 'Date', 'Case number', 'Before', 'Catchwords', 'Order']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "632eaa5c-4f2b-47af-8c7f-c0a575d895f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:40.044 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#If judgment link contains 'showCase'\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                 'Catchwords' : '',  \n",
    "                'Order': '', \n",
    "                'judgment' : ''\n",
    "                }\n",
    "    \n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Case name\n",
    "    judgment_dict['Case name'] = soup.find('title').text\n",
    "\n",
    "    #Medium neutral citation\n",
    "    year = judgment_url.split('showCase/')[1][0:4]\n",
    "    num = judgment_url.split('HCA/')[1]\n",
    "    \n",
    "    judgment_dict['Medium neutral citation'] = f'[{year}] HCA {num}'\n",
    "\n",
    "    #Reported, decision date, before\n",
    "\n",
    "    h2_tags = soup.find_all('h2')\n",
    "\n",
    "    if len(h2_tags) > 0:\n",
    "        \n",
    "        for h2 in soup.find_all('h2'):\n",
    "            if 'clr' in h2.text.lower():\n",
    "                \n",
    "                judgment_dict['Reported'] = h2.text\n",
    "    \n",
    "            elif is_date(h2.text, fuzzy=False):\n",
    "    \n",
    "                judgment_dict['Date'] = h2.text\n",
    "    \n",
    "            elif 'before' in h2.text.lower():\n",
    "                judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "    \n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    #Case number\n",
    "\n",
    "    case_number_list = soup.find_all(string=re.compile('Case Number'))\n",
    "\n",
    "    if len(case_number_list) > 0:\n",
    "        \n",
    "        judgment_dict['Case number'] = case_number_list[0].split('Case Number')[1].replace(': ', '')\n",
    "\n",
    "    #Checking\n",
    "\n",
    "    if len(str(judgment_dict['Reported'])) < 5:\n",
    "\n",
    "        try:\n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Reported'] = hca_df.loc[int(index), 'reported']\n",
    "\n",
    "        except:\n",
    "            print(f\"Can't get reported for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    if is_date(str(judgment_dict['Date']), fuzzy=False) == False:\n",
    "\n",
    "        try:\n",
    "            \n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Date'] = hca_df.loc[index, 'date']\n",
    "\n",
    "        except:\n",
    "            print(f\"Can't get date for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    if len(str(judgment_dict['Before'])) < 3:\n",
    "\n",
    "        try:\n",
    "    \n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Before'] = hca_df.loc[int(index), 'before']\n",
    "\n",
    "    \n",
    "        except:\n",
    "            print(f\"Can't get before for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    if len(str(judgment_dict['Case number'])) < 3:\n",
    "\n",
    "        try:\n",
    "\n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Case number'] = hca_df.loc[int(index), 'case_number']\n",
    "\n",
    "    \n",
    "        except:\n",
    "            print(f\"Can't get case number for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "    #Catchwords\n",
    "\n",
    "    catchwords_list = soup.find_all('div', class_='well')\n",
    "\n",
    "    if len(catchwords_list) > 0:\n",
    "        \n",
    "        judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "\n",
    "    #Judgment text\n",
    "    try:\n",
    "\n",
    "        judgment_dict['judgment'] = hca_pdf_judgment(judgment_url)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        judgment_dict['judgment'] = 'Error. Judgment not available or not downloaded.'\n",
    "        judgment_dict['Case name'] = judgment_dict['Case name'] + '. Error. Judgment not available or not downloaded.'\n",
    "\n",
    "    return judgment_dict\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf3f7be-addd-4f87-82f7-b286f2b1fb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:40.854 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#If judgment link contains 'showbyHandle'\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_meta_judgment_dict_alt(judgment_url):\n",
    "    \n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to High Court Judgments Database' : '', \n",
    "                 'Reported': '', \n",
    "                 'Date' : '',  \n",
    "                 'Case number' : '',  \n",
    "                 'Before' : '',  \n",
    "                 'Catchwords' : '',\n",
    "                'Order': '',\n",
    "                'judgment' : ''\n",
    "                }\n",
    "    \n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_dict['Hyperlink to High Court Judgments Database'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Case name\n",
    "    judgment_dict['Case name'] = soup.find('title').text\n",
    "\n",
    "    #Judgment text\n",
    "\n",
    "    judgment_list = soup.find_all(\"div\", {\"class\": \"opinion\"})\n",
    "    \n",
    "    judgment_pdfs_list = soup.find_all('a', {'class': 'btn btn-success'})\n",
    "    \n",
    "    if len(judgment_list) > 0:\n",
    "\n",
    "        judgment_dict['judgment'] = judgment_list[0].text\n",
    "\n",
    "    elif len(judgment_pdfs_list) > 0:\n",
    "        raw_link = judgment_pdfs_list[0]['href']\n",
    "        pdf_link = 'https://eresources.hcourt.gov.au' + raw_link\n",
    "        judgment_dict['judgment'] = hca_pdf_judgment(pdf_link)\n",
    "\n",
    "    else:\n",
    "        judgment_dict['judgment'] = 'Error. Judgment not available or not downloaded.'\n",
    "        \n",
    "        judgment_dict['Case name'] = judgment_dict['Case name'] + '. Error. Judgment not available or not downloaded.'\n",
    "\n",
    "    #Catchwords\n",
    "\n",
    "    catchwords_list = soup.find_all(\"div\", {\"class\": \"Catchphrases\"})\n",
    "\n",
    "    if len(catchwords_list) > 0:\n",
    "        judgment_dict['Catchwords'] = catchwords_list[0].text\n",
    "    \n",
    "    #Medium neutral citation meta tag\n",
    "    mnc_list = soup.find_all(\"div\", {\"class\": \"MNC\"})\n",
    "\n",
    "    if len(mnc_list):\n",
    "\n",
    "        judgment_dict['Medium neutral citation'] = mnc_list[0].text\n",
    "\n",
    "    elif len(judgment_pdfs_list) > 0:\n",
    "\n",
    "        mnc_raw = judgment_pdfs_list[0]['href'].replace('/downloadPdf/', '').replace('/', '')\n",
    "\n",
    "        year = mnc_raw.lower().split('hca')[0]\n",
    "\n",
    "        num = mnc_raw.lower().split('hca')[1]\n",
    "\n",
    "        judgment_dict['Medium neutral citation'] = f\"[{year}] HCA {num}\"\n",
    "\n",
    "    #Before\n",
    "    judges_list = soup.find_all(\"div\", {\"class\": \"judges-title\"})\n",
    "\n",
    "    if len(judges_list) > 0:\n",
    "\n",
    "        judgment_dict['Before'] = judges_list[0].text\n",
    "\n",
    "\n",
    "    #Order\n",
    "    order_list = soup.find_all(\"div\", {\"class\": \"order-text\"})\n",
    "\n",
    "    if len(order_list) > 0:\n",
    "\n",
    "        order = order_list[0].text#.replace('\\n            ', '')\n",
    "\n",
    "        judgment_dict['Order'] = order\n",
    "\n",
    "    #Reported, decision date, before\n",
    "\n",
    "    h2_tags = soup.find_all('h2')\n",
    "\n",
    "    if len(h2_tags) > 0:\n",
    "        \n",
    "        for h2 in soup.find_all('h2'):\n",
    "            if 'clr' in h2.text.lower():\n",
    "                \n",
    "                judgment_dict['Reported'] = h2.text\n",
    "    \n",
    "            elif is_date(h2.text, fuzzy=False):\n",
    "    \n",
    "                judgment_dict['Date'] = h2.text\n",
    "    \n",
    "            elif 'before' in h2.text.lower():\n",
    "                judgment_dict['Before'] = h2.text.replace('Before', '').replace('before', '').replace('Catchwords', '').replace('catchwords', '').replace('\\n', '').replace('\\t', '').replace('  ', '')\n",
    "    \n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    #Checking\n",
    "\n",
    "    if len(str(judgment_dict['Reported'])) < 5:\n",
    "\n",
    "        try:\n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Reported'] = hca_df.loc[int(index), 'reported']\n",
    "\n",
    "        except:\n",
    "            print(f\"Can't get reported for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    if is_date(str(judgment_dict['Date']), fuzzy=False) == False:\n",
    "\n",
    "        try:\n",
    "            \n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Date'] = hca_df.loc[index, 'date']\n",
    "\n",
    "        except:\n",
    "            print(f\"Can't get date for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    if len(str(judgment_dict['Before'])) < 3:\n",
    "\n",
    "        try:\n",
    "    \n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Before'] = hca_df.loc[int(index), 'before']\n",
    "\n",
    "    \n",
    "        except:\n",
    "            print(f\"Can't get before for {judgment_dict['Medium neutral citation']}\")\n",
    "\n",
    "    if len(str(judgment_dict['Case number'])) < 3:\n",
    "\n",
    "        try:\n",
    "\n",
    "            index_list = hca_df.index[hca_df['mnc'].str.contains(judgment_dict['Medium neutral citation'], case=False, na=False, regex=False)].tolist()\n",
    "            index = index_list[0]\n",
    "    \n",
    "            judgment_dict['Case number'] = hca_df.loc[int(index), 'case_number']\n",
    "\n",
    "    \n",
    "        except:\n",
    "            print(f\"Can't get case number for {judgment_dict['Medium neutral citation']}\")\n",
    "    \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9d2e602-2dc9-4d8b-abc3-856d2cca791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:41.670 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Slow way of finding a case from mnc\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_mnc_to_link_browse(collection, year, num):\n",
    "\n",
    "    #Default judgment without the prefix https://eresources.hcourt.gov.au\n",
    "    judgment_url_raw = ''\n",
    "\n",
    "    if collection == 'Judgments 2000-present':\n",
    "                    \n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=0&facets=dateDecided'\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "\n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=1&facets=dateDecided'\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "        \n",
    "        base_url = 'https://eresources.hcourt.gov.au/browse?col=2&facets=dateDecided'\n",
    "    \n",
    "    params = {'srch-term': year}\n",
    "    \n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "    pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Get list of pages\n",
    "\n",
    "    pages_list = []\n",
    "    \n",
    "    options = soup.find_all('option')\n",
    "        \n",
    "    for option in options:\n",
    "        if len(option.text) < 4:\n",
    "            pages_list.append(option.text)\n",
    "    \n",
    "    for page in pages_list:\n",
    "        \n",
    "        page_start = (int(page) - 1)*20\n",
    "\n",
    "        params_page = {'srch-term': year, 'page': page_start}\n",
    "\n",
    "        response_page = requests.get(base_url, params=params_page)\n",
    "        \n",
    "        response_page.raise_for_status()\n",
    "        \n",
    "        soup_page = BeautifulSoup(response_page.content, \"lxml\")\n",
    "\n",
    "        cases_list = soup_page.find_all(class_='case')\n",
    "\n",
    "        for case in cases_list:\n",
    "\n",
    "            if f'HCA {num}' in str(case):\n",
    "                judgment_url_raw = case['href']\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        if (('showbyHandle' in judgment_url_raw) or ('showCase' in judgment_url_raw)):\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            continue\n",
    "\n",
    "    return 'https://eresources.hcourt.gov.au' + judgment_url_raw\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb9ee624-ec1c-4752-97cf-9b1faa6b521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning citation to judgment_url\n",
    "def hca_citation_to_link(collection, citation):\n",
    "\n",
    "    #Placeholder error url\n",
    "    judgment_url = f'https://eresources.hcourt.gov.au/showCase/1900/HCA/1'\n",
    "    \n",
    "    #Use mnc if entered\n",
    "    if 'hca' in citation.lower():\n",
    "       \n",
    "        try:\n",
    "            citation_formatted = citation.replace(' ', '').replace('[', '').replace(']', '')\n",
    "\n",
    "            year = citation_formatted.lower().split('hca')[0]\n",
    "            \n",
    "            num = citation_formatted.lower().split('hca')[1]\n",
    "            \n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "            \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "\n",
    "        except Exception as e:\n",
    "            print('MNC entered but error.')\n",
    "            print(e)\n",
    "\n",
    "    else: #Get mnc from hca_df if not entered\n",
    "        try:\n",
    "            index_list = hca_df.index[hca_df['reported'].str.contains(citation, case=False, na=False)].tolist()\n",
    "            index = index_list[0]            \n",
    "        except:\n",
    "            try:\n",
    "                index_list = hca_df.index[hca_df['name'].str.contains(citation, case=False, na=False)].tolist()\n",
    "                index = index_list[0]\n",
    "            except:\n",
    "                try:\n",
    "                    index_list = hca_df.index[hca_df['date'].str.contains(citation, case=False, na=False)].tolist()\n",
    "                    index = index_list[0]\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print('Citation entered but not found.')\n",
    "                    print(e)\n",
    "                \n",
    "        try:\n",
    "            mnc = hca_df.loc[int(index), 'mnc']\n",
    "    \n",
    "            citation_formatted = mnc.replace(' ', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "            year = citation_formatted.lower().split('hca')[0]\n",
    "            \n",
    "            num = citation_formatted.lower().split('hca')[1]\n",
    "    \n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "    \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "            \n",
    "            return judgment_url\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('Citation entered but error.')\n",
    "            print(e)\n",
    "\n",
    "\n",
    "    #Check if judgment_url works\n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "        return judgment_url\n",
    "\n",
    "    else:\n",
    "        #Check if direct link to PDF works\n",
    "        try:\n",
    "            pdf_url = judgment_url.replace('showCase', 'downloadPdf')\n",
    "            \n",
    "            page = requests.get(pdf_url)\n",
    "        \n",
    "            soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "            if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "    \n",
    "                return pdf_url\n",
    "    \n",
    "            else:\n",
    "                #Try to use HCA's browse function to get link to case\n",
    "                judgment_url = hca_mnc_to_link_browse(collection, year, num)\n",
    "    \n",
    "                return judgment_url\n",
    "    \n",
    "        except Exception as e:\n",
    "            print(\"Can't get case url for citation\")\n",
    "            print(e)\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21a2914b-388f-469d-9dba-2a66152f03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning mnc to judgment_url\n",
    "def hca_mnc_to_link(collection, mnc):\n",
    "#NOT in use\n",
    "    \n",
    "    mnc_formatted = mnc.replace(' ', '').replace('[', '').replace(']', '')\n",
    "    \n",
    "    if 'HCA' in mnc_formatted:\n",
    "\n",
    "        year = mnc_formatted.split('HCA')[0]\n",
    "        \n",
    "        num = mnc_formatted.split('HCA')[1]\n",
    "       \n",
    "        try:\n",
    "            #Checking if year and num are indeed integers\n",
    "            year_int = int(year)\n",
    "            num_int = int(num)\n",
    "            \n",
    "            judgment_url = f'https://eresources.hcourt.gov.au/showCase/{year_int}/HCA/{num_int}'\n",
    "\n",
    "            page = requests.get(judgment_url)\n",
    "            \n",
    "            soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "            if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "                return judgment_url\n",
    "\n",
    "            else:\n",
    "                \n",
    "                judgment_url = f'https://eresources.hcourt.gov.au/downloadPdf/{year_int}/HCA/{num_int}'\n",
    "\n",
    "                page = requests.get(judgment_url)\n",
    "            \n",
    "                soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "                if (('The case could not be found on the database.' not in soup.text) and ('There were no matching cases.'  not in soup.text)):\n",
    "\n",
    "                    return judgment_url\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    judgment_url = hca_mnc_to_link_browse(collection, year, num)\n",
    "\n",
    "                    return judgment_url\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            return ''\n",
    "            \n",
    "    else:\n",
    "        return ''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac32bb1-b57f-4c14-b1b9-d96b49b2e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for minimum and maximum year\n",
    "\n",
    "def hca_min_max_year(collection):\n",
    "#NOT IN USE\n",
    "    \n",
    "    if collection == 'Judgments 2000-present':\n",
    "\n",
    "        min_year = int(2000)\n",
    "\n",
    "        max_year = datetime.now().year\n",
    "\n",
    "    if collection == 'Judgments 1948-1999':\n",
    "        \n",
    "        min_year = int(1948)\n",
    "\n",
    "        max_year = int(1999)\n",
    "    \n",
    "    if collection == '1 CLR - 100 CLR (judgments 1903-1958)':\n",
    "\n",
    "        min_year = int(1903)\n",
    "\n",
    "        max_year = int(1958)\n",
    "\n",
    "    return {'min_year': min_year, 'max_year': max_year}\n",
    "\n",
    "def hca_year_check(year_entry):\n",
    "#NOT IN USE\n",
    "\n",
    "\n",
    "    #Default validity\n",
    "    validity = False\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if (len(str(int(year_entry))) == 4):     \n",
    "            \n",
    "            validity = True\n",
    "\n",
    "    except:\n",
    "        print('Year entry invalid.')\n",
    "        \n",
    "    return validity\n",
    "\n",
    "def hca_min_year_validity(collection, min_year_entry):\n",
    "    #NOT IN USE\n",
    "\n",
    "    if hca_year_check(min_year_entry) == False:\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    elif int(min_year_entry) <= hca_min_max_year(collection)['min_year']:\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        return True\n",
    "\n",
    "def hca_max_year_validity(collection, max_year_entry):\n",
    "    #NOT IN USE\n",
    "\n",
    "    if hca_year_check(max_year_entry) == False:\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    elif int(max_year_entry) >= hca_min_max_year(collection)['max_year']:\n",
    "        \n",
    "        return False\n",
    "        \n",
    "    else:\n",
    "        return True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65a4564a-abad-4e9b-a6da-e8291e51f491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:45.085 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/Ben/anaconda3/lib/python3.11/site-packages/ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "#Load hca_data\n",
    "\n",
    "@st.cache_resource(show_spinner = False)\n",
    "def hca_load_data(url):\n",
    "    df = pd.read_csv(url)\n",
    "    return df\n",
    "\n",
    "hca_data_url = 'https://raw.githubusercontent.com/nehcneb/au-uk-empirical-legal-research/main/hca_data.csv'\n",
    "\n",
    "#response = requests.get(hca_data_url)\n",
    "\n",
    "#hca_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "hca_df = hca_load_data(hca_data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54f8abaa-bab8-4a19-be59-1cec553bc2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to excluding unwanted jugdments\n",
    "\n",
    "def hca_judgment_to_exclude(case_info = {},\n",
    "                        collection = '', \n",
    "                        own_parties_include = '', \n",
    "                        own_parties_exclude = '', \n",
    "                        after_date = '', \n",
    "                        before_date = '', \n",
    "                        #own_case_numbers_include = [], \n",
    "                        #own_case_numbers_exclude = [], \n",
    "                        own_judges_include = '', \n",
    "                        own_judges_exclude = ''\n",
    "                       ):\n",
    "\n",
    "    #Default status is not to exclude\n",
    "    exclude_status = False\n",
    "\n",
    "    #Exclude parties\n",
    "\n",
    "    for party in own_parties_include.replace(';', ',').split(','):\n",
    "        \n",
    "        if ((len(party) > 0) and (party.lower() not in case_info['Case name'].lower())):\n",
    "        \n",
    "            exclude_status = True\n",
    "        \n",
    "            break\n",
    "\n",
    "    for party in own_parties_exclude.replace(';', ',').split(','):\n",
    "        \n",
    "        if ((len(party) > 0) and (party.lower() in case_info['Case name'].lower())):\n",
    "        \n",
    "            exclude_status = True\n",
    "        \n",
    "            break\n",
    "\n",
    "    #Exclude Date\n",
    "\n",
    "    if is_date(case_info['Date'], fuzzy=False):\n",
    "        \n",
    "        date_datetime = parser.parse(case_info['Date'], dayfirst=True)\n",
    "        \n",
    "        #if collection != 'Judgments 2000-present':\n",
    "            #Reducing 100 because if year is 2 digits, parser assumes current century\n",
    "            \n",
    "            #date_datetime = date_datetime - relativedelta(years = 100) \n",
    "\n",
    "        if is_date(after_date, fuzzy=False):\n",
    "\n",
    "            after_date_datetime = parser.parse(after_date,dayfirst=True)\n",
    "    \n",
    "            if date_datetime < after_date_datetime:\n",
    "    \n",
    "                exclude_status = True\n",
    "\n",
    "        if is_date(before_date, fuzzy=False):\n",
    "\n",
    "            before_date_datetime = parser.parse(before_date, dayfirst=True)\n",
    "    \n",
    "            if date_datetime > before_date_datetime:\n",
    "    \n",
    "                exclude_status = True\n",
    "\n",
    "    #Exclude year\n",
    "\n",
    "    #potential_year_list = []\n",
    "\n",
    "    #potential_year_raw_list = case_info['Case name'].split('[')\n",
    "\n",
    "    #for potential_year in potential_year_raw_list:\n",
    "\n",
    "        #try:\n",
    "            #year_decided_raw = int(potential_year[0:4])\n",
    "            \n",
    "            #potential_year_list.append(year_decided_raw)\n",
    "\n",
    "        #except:\n",
    "            \n",
    "            #print('Potential year value is not integer')\n",
    "\n",
    "    #if len(potential_year_list) > 0:\n",
    "    #Defining year_decided here to avoid the possibility of year not being picked up\n",
    "        #year_decided = potential_year_list[-1]\n",
    "\n",
    "        #if len(own_min_year) >= 4:\n",
    "    \n",
    "            #try:       \n",
    "    \n",
    "                #if year_decided < int(own_min_year):\n",
    "        \n",
    "                    #exclude_status = True\n",
    "            \n",
    "            #except:\n",
    "                #print('Case not excluded for earlier than min year')\n",
    "    \n",
    "        #if len(own_max_year) >= 4:\n",
    "    \n",
    "            #try:        \n",
    "    \n",
    "                #if year_decided > int(own_max_year):\n",
    "        \n",
    "                    #exclude_status = True\n",
    "    \n",
    "            #except:\n",
    "                #print('Case not excluded for later than max year')\n",
    "\n",
    "    #Exclude judges\n",
    "\n",
    "    if type(case_info['Before']) == str:\n",
    "        \n",
    "        #if len(case_info['Before']) > 2:\n",
    "    \n",
    "        for judge in own_judges_include.replace(';', ',').split(','):\n",
    "\n",
    "            judge = judge.replace('.', '').replace(' J', '').replace(' CJ', '').replace(' ACJ', '').replace(' JJ', '')\n",
    "            \n",
    "            if ((len(judge) > 2) and (judge.lower() not in case_info['Before'].lower())):\n",
    "            \n",
    "                exclude_status = True\n",
    "            \n",
    "                break\n",
    "    \n",
    "        for judge in own_judges_exclude.replace(';', ',').split(','):\n",
    "\n",
    "            judge = judge.replace('.', '').replace(' J', '').replace(' CJ', '').replace(' ACJ', '').replace(' JJ', '')\n",
    "            \n",
    "            if ((len(judge) > 2) and (judge.lower() in case_info['Before'].lower())):\n",
    "            \n",
    "                exclude_status = True\n",
    "            \n",
    "                break\n",
    "    \n",
    "    return exclude_status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d2a3ad28-bcbb-4b65-9c09-5a015afdf724",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:13:46.852 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Function to get judgment links with filters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_search_results_to_judgment_links_filtered_df(url_search_results, \n",
    "                                     judgment_counter_bound,\n",
    "                                      collection, \n",
    "                                    #hca_df, \n",
    "                                    own_parties_include, \n",
    "                                    own_parties_exclude, \n",
    "                                    #own_min_year, \n",
    "                                    #own_max_year, \n",
    "                                    after_date, \n",
    "                                     before_date, \n",
    "                                    #own_case_numbers_include, \n",
    "                                    #own_case_numbers_exclude, \n",
    "                                    own_judges_include, \n",
    "                                    own_judges_exclude\n",
    "                                                ):\n",
    "    \n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "        \n",
    "    #Start counter\n",
    "    \n",
    "    counter = 1\n",
    "    \n",
    "    #Get number of pages\n",
    "    #There are up to 20 pages per page\n",
    "    number_of_pages = soup.find(\"span\", id=\"lastItem\").text\n",
    "\n",
    "    #Start links list\n",
    "    #links = []\n",
    "\n",
    "    case_infos = []\n",
    "\n",
    "    for page_raw in range(0, int(number_of_pages)):\n",
    "        \n",
    "        if counter <= judgment_counter_bound:\n",
    "                        \n",
    "            page = page_raw + 1\n",
    "            \n",
    "            url_search_results_page = url_search_results + f'&page={page}'\n",
    "    \n",
    "            page_page = requests.get(url_search_results_page)\n",
    "    \n",
    "            soup_page = BeautifulSoup(page_page.content, \"lxml\")\n",
    "    \n",
    "            #Get raw links and names of cases\n",
    "            \n",
    "            raw_links = soup_page.find_all(class_='case')\n",
    "\n",
    "            for raw_link in raw_links:\n",
    "\n",
    "                if counter <= judgment_counter_bound:\n",
    "\n",
    "                    index = raw_links.index(raw_link)\n",
    "                    #mnc = '[' + raw_link.text.split('[')[-1]\n",
    "                    case_name_mnc = split_title_mnc(raw_link.get_text().strip())\n",
    "                    case_name = case_name_mnc[0]\n",
    "                    mnc = case_name_mnc[1]\n",
    "\n",
    "                    #Try to get case info from hca_df\n",
    "                    try:\n",
    "                        index_list = hca_df.index[hca_df['mnc'].str.contains(mnc, case=False, na=False, regex=False)].tolist()\n",
    "                        index = index_list[0]\n",
    "                        \n",
    "                        case_info = {'Case name': case_name, #hca_df.loc[int(index), 'case'], \n",
    "                                     'Medium neutral citation': mnc, #New\n",
    "                                     'Hyperlink to High Court Judgments Database': 'https://eresources.hcourt.gov.au' + raw_link['href'], \n",
    "                                     'Reported': hca_df.loc[int(index), 'reported'],\n",
    "                                     'Before': hca_df.loc[int(index), 'before'],\n",
    "                                     'Date': hca_df.loc[index, 'date']\n",
    "                                    }\n",
    "    \n",
    "                        if hca_judgment_to_exclude(case_info, \n",
    "                            collection, \n",
    "                            own_parties_include, \n",
    "                            own_parties_exclude, \n",
    "                            after_date, \n",
    "                           before_date, \n",
    "                            #own_case_numbers_include = [], \n",
    "                            #own_case_numbers_exclude = [], \n",
    "                            own_judges_include, \n",
    "                            own_judges_exclude\n",
    "                           ) == False:\n",
    "                        \n",
    "                            #links.append(case_info['Hyperlink to High Court Judgments Database'])\n",
    "                            case_infos.append(case_info)\n",
    "                            \n",
    "                            counter += 1 \n",
    "    \n",
    "                            #case_infos.append(case_info)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"Can't get case info for {mnc}.\")\n",
    "                        print(e)\n",
    "                \n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        else:\n",
    "            break    \n",
    "\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    return case_infos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fb87a-a71c-4007-b309-6d5cbbe37719",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get link to search results and number of results\n",
    "\n",
    "def hca_search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_num_dict = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search']\n",
    "                        )\n",
    "    url = url_num_dict['url']\n",
    "    results_num = url_num_dict['results_num']\n",
    "    \n",
    "    #If mnc entered\n",
    "\n",
    "    if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "        #direct_link = hca_mnc_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "        direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "\n",
    "        if len(direct_link) > 0:\n",
    "            \n",
    "            url = direct_link\n",
    "\n",
    "            results_num = '1'\n",
    "    \n",
    "    return {'url': url, 'results_num': results_num}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_batch_input\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfae300-2b55-45a0-842c-83f12e8a555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d112bbe4-0051-41ab-ac85-87047d2059c3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "#hca_role_content = 'You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from specific paragraphs, pages or sections, provide the paragraph or page numbers or section names as part of your answer. If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". '\n",
    "\n",
    "system_instruction = role_content #hca_role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search']\n",
    "                        )['url']\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "    \n",
    "    #Use the following if want to filter results.\n",
    "    case_infos = hca_search_results_to_judgment_links_filtered_df(url_search_results, \n",
    "                                     judgments_counter_bound,\n",
    "                                    #hca_df, \n",
    "                                    df_master.loc[0, 'Collection'], \n",
    "                                    df_master.loc[0, 'Parties include'], \n",
    "                                    df_master.loc[0, 'Parties do not include'], \n",
    "                                    df_master.loc[0, 'Decision date is after'],\n",
    "                                      df_master.loc[0, 'Decision date is before'], \n",
    "                                    #df_master.loc[0, 'Case numbers include'], \n",
    "                                    #df_master.loc[0, 'Case numbers do not include'], \n",
    "                                    df_master.loc[0, 'Judges include'], \n",
    "                                    df_master.loc[0, 'Judges do not include'])\n",
    "    \n",
    "    #Create list of direct judgment links\n",
    "    judgments_links  = []\n",
    "\n",
    "    for case in case_infos:\n",
    "        judgments_links.append(case['Hyperlink to High Court Judgments Database'])\n",
    "    \n",
    "    for judgment_link in judgments_links:\n",
    "\n",
    "        if 'showbyHandle' in judgment_link:\n",
    "            \n",
    "            judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\n",
    "\n",
    "        else: #If 'showCase' in judgment_link:\n",
    "\n",
    "            judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "    \n",
    "        judgments_file.append(judgment_dict)\n",
    "        \n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Add judgment if mnc entered\n",
    "\n",
    "    if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "        direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "\n",
    "        if len(direct_link) > 0:\n",
    "            \n",
    "            judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "            \n",
    "            judgments_file.append(judgment_dict_direct)\n",
    "                    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "\n",
    "    if 'judgment' in df_updated.columns:\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_meta_labels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc31ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def hca_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = hca_search(collection = df_master.loc[0, 'Collection'], \n",
    "                        quick_search = df_master.loc[0, 'Quick search'], \n",
    "                        full_text = df_master.loc[0, 'Full text search']\n",
    "                        )['url']\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "    \n",
    "    #Use the following if want to filter results.\n",
    "    case_infos = hca_search_results_to_judgment_links_filtered_df(url_search_results, \n",
    "                                     judgments_counter_bound,\n",
    "                                    #hca_df, \n",
    "                                    df_master.loc[0, 'Collection'], \n",
    "                                    df_master.loc[0, 'Parties include'], \n",
    "                                    df_master.loc[0, 'Parties do not include'], \n",
    "                                    df_master.loc[0, 'Decision date is after'],\n",
    "                                      df_master.loc[0, 'Decision date is before'], \n",
    "                                    #df_master.loc[0, 'Case numbers include'], \n",
    "                                    #df_master.loc[0, 'Case numbers do not include'], \n",
    "                                    df_master.loc[0, 'Judges include'], \n",
    "                                    df_master.loc[0, 'Judges do not include'])\n",
    "\n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "        \n",
    "    #Check if running on HuggingFace\n",
    "    from functions.oalc_functions import huggingface\n",
    "    \n",
    "    if huggingface == False: #If not running on HuggingFace\n",
    "        \n",
    "        #Create list of direct judgment links\n",
    "        judgments_links  = []\n",
    "    \n",
    "        for case in case_infos:\n",
    "            judgments_links.append(case['Hyperlink to High Court Judgments Database'])\n",
    "    \n",
    "        for judgment_link in judgments_links:\n",
    "    \n",
    "            if 'showbyHandle' in judgment_link:\n",
    "                \n",
    "                judgment_dict = hca_meta_judgment_dict_alt(judgment_link)\\\n",
    "    \n",
    "            else: #If 'showCase' in judgment_link:\n",
    "    \n",
    "                judgment_dict = hca_meta_judgment_dict(judgment_link)\n",
    "        \n",
    "            judgments_file.append(judgment_dict)\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "        #Add judgment if mnc entered\n",
    "    \n",
    "        if len(df_master.loc[0, 'Search for medium neutral citation']) > 0:\n",
    "            \n",
    "            direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], df_master.loc[0, 'Search for medium neutral citation'])\n",
    "    \n",
    "            if len(direct_link) > 0:\n",
    "                \n",
    "                judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "                \n",
    "                judgments_file.append(judgment_dict_direct)\n",
    "            \n",
    "    else: #If running on HuggingFace\n",
    "        \n",
    "        #Load oalc\n",
    "        from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "\n",
    "        #Create a list of mncs for HuggingFace:\n",
    "        mnc_list = []\n",
    "\n",
    "        for case in case_infos:\n",
    "\n",
    "            #add search results to json\n",
    "            judgments_file.append(case)\n",
    "\n",
    "            #Add mnc to list for HuggingFace\n",
    "            mnc_list.append(case['Medium neutral citation'])\n",
    "\n",
    "        #Get judgments from oalc first\n",
    "        mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "    \n",
    "        #Append judgment to judgments_file \n",
    "        for decision in judgments_file:\n",
    "            \n",
    "            #Append judgments from oalc first\n",
    "            if decision['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                \n",
    "                decision.update({'judgment': mnc_judgment_dict[decision['Medium neutral citation']]})\n",
    "\n",
    "                #Make judgment_link clickable\n",
    "                decision['Hyperlink to High Court Judgments Database'] = link(decision['Hyperlink to High Court Judgments Database'])\n",
    "                \n",
    "            else: #Get judgment from HCA if can't get from oalc\n",
    "                \n",
    "                direct_link = hca_citation_to_link(df_master.loc[0, 'Collection'], decision['Medium neutral citation'])\n",
    "        \n",
    "                if len(direct_link) > 0:\n",
    "                    \n",
    "                    judgment_dict_direct = hca_meta_judgment_dict(direct_link)\n",
    "\n",
    "                    for key in judgment_dict_direct.keys():\n",
    "                        if key not in decision.keys():\n",
    "                            decision.update({key: judgment_dict_direct[key]})\n",
    "                    \n",
    "                    pause.seconds(np.random.randint(5, 15))\n",
    "        \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in hca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
