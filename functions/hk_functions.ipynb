{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import math\n",
    "import mammoth\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb\n",
    "\n",
    "#Conversion to text\n",
    "#import fitz\n",
    "#from io import StringIO\n",
    "#from io import BytesIO\n",
    "#import mammoth\n",
    "#from doc2docx import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_value_check, list_range_check, save_input, date_parser, pdf_judgment, docx_judgment, str_to_int\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_value_check, list_range_check, save_input, date_parser, pdf_judgment, docx_judgment, str_to_int\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# HK search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ac824a-8e0b-4d42-87ca-12d66c0fdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape javascript\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait as Wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--no-sandbox')  \n",
    "options.add_argument('--disable-dev-shm-usage')  \n",
    "\n",
    "#@st.cache_resource(show_spinner = False, ttl=600)\n",
    "def get_driver():\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "try:\n",
    "    browser = get_driver()\n",
    "    \n",
    "    #browser.implicitly_wait(5)\n",
    "    #browser.set_page_load_timeout(15)\n",
    "\n",
    "    #browser.quit()\n",
    "    \n",
    "except Exception as e:\n",
    "    st.error('Sorry, your internet connection is not stable enough for this app. Please check or change your internet connection and try again.')\n",
    "    print(e)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950f19c-6439-4b3a-b56f-eb631b93f5d8",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89492a96-fa02-4555-83a7-ba8f038daa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of times to click away alerts\n",
    "alert_bound = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15fabc67-27ea-4315-ab5b-a1433198c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_sortby_dict = {'Relevance': '1', 'Date': '0', 'Title': '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e3fd03a-055e-4efb-bc41-7225e429b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_sortby_keys = [*hk_sortby_dict.keys()]\n",
    "hk_sortby_values = [*hk_sortby_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a74e934-127f-4baf-a829-88efd55e4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 means True, 0 means False\n",
    "#hk_stemming_dict = {1: '1', 0: ''}\n",
    "#hk_stemming_keys = [*hk_stemming_dict.keys()]\n",
    "#hk_stemming_values = [*hk_stemming_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea0798bb-0cb5-40f8-9597-ec871ab93cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_courts_dict = {'Court of Final Appeal': 'FA',\n",
    " 'Court of Appeal': 'CA',\n",
    " 'Court of First Instance': 'HC',\n",
    " 'Competition Tribunal': 'CT',\n",
    " 'District Court': 'DC',\n",
    " 'Family Court': 'FC',\n",
    " 'Lands Tribunal': 'LD',\n",
    " 'Other Court Levels': 'OT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56dfa7e2-e57e-46f8-9616-328ef5023b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_courts_keys = [*hk_courts_dict.keys()]\n",
    "hk_courts_values = [*hk_courts_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6afff2b-b71e-4bb6-a33b-e060f8d68f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_ca = {'Application for Review': 'AR',\n",
    "\"Attorney General's Reference\": 'AG',\n",
    "'Civil Appeal': 'CV',\n",
    "'Criminal Appeal': 'CC',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Reservation of Question of Law': 'QL',\n",
    "\"Secretary for Justice's Reference\": 'SJ'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f9b14a-6877-4a13-b146-8552e91af0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_hc = {'Admiralty Action': 'AJ',\n",
    "'Adoption Application': 'AD',\n",
    "'Application for Grant': 'AG',\n",
    "'Application to set aside a Statutory Demand (under Bankruptcy Ordinance)': 'SD',\n",
    "'Applications under the Mental Health Ordinance': 'MH',\n",
    "'Bankruptcy Proceedings': 'B',\n",
    "'Bill of Sale Registration': 'BS',\n",
    "'Bookdebt Registration': 'BD',\n",
    "'Caveat': 'CA',\n",
    "'Citation Application': 'CI',\n",
    "'Civil Action': 'A',\n",
    "'Commercial Action': 'CL',\n",
    "'Companies Winding-up Proceedings': 'CW',\n",
    "'Confidential Miscellaneous Proceedings': 'CM',\n",
    "'Constitutional and Administrative Law Proceedings': 'AL',\n",
    "'Construction and Arbitration Proceedings': 'CT',\n",
    "'Criminal Case': 'CC',\n",
    "'Estate Duty Appeal': 'ED',\n",
    "'Ex-parte Application': 'EA',\n",
    "'High Court Bankruptcy Interim Order': 'BI',\n",
    "'Inland Revenue Appeal': 'IA',\n",
    "'Intellectual Property Case': 'IP',\n",
    "'Intended Action': 'ZZ',\n",
    "'Labour Tribunal Appeal': 'LA',\n",
    "'Legal Aid Appeal': 'AA',\n",
    "'Magistracy Appeal': 'MA',\n",
    "'Matrimonial Causes': 'MC',\n",
    "'Minor Employment Claims Appeal': 'ME',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Miscellaneous Proceedings (Criminal)': 'CP',\n",
    "'Obscene Articles Tribunal Appeal': 'OA',\n",
    "'Personal Injuries Action': 'PI',\n",
    "'Probate Action': 'AP',\n",
    "'Reciprocal Enforcement Case': 'RE',\n",
    "'Referral Case': 'RC',\n",
    "'Small Claims Tribunal Appeal': 'SA',\n",
    "'Stop Notice': 'SN',\n",
    "'Trade Unions Appeal': 'UA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d63a8f61-169b-4811-8f28-f7b002b5e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_dc = {'Civil Action': 'CJ',\n",
    "'Criminal Case': 'CC',\n",
    "'Distraint Case': 'DT',\n",
    "'District Court Tax Claim': 'TC',\n",
    "\"Employee's Compensation Case\": 'EC',\n",
    "'Equal Opportunities Action': 'EO',\n",
    "'Intended Action': 'ZZ',\n",
    "'Miscellaneous Appeals': 'MA',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Occupational Deafness (Compensation) Appeal': 'OA',\n",
    "'Personal Injuries Action': 'PI',\n",
    "'Pneumoconiosis (Compensation) Appeal': 'PA',\n",
    "'Stamp Duty Appeal': 'SA',\n",
    "'Stop Notice': 'SN'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08cc12a5-d904-4134-8a3f-76435e0b42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_fc = {'Joint application': 'JA',\n",
    "'Matrimonial Causes': 'MC',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Reciprocal Enforcement Proceedings': 'RE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a18794f-d707-4121-bed5-b478e6400502",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_databases_dict = {'Judgments': 'JU',\n",
    "'Reasons for Verdict': 'RV',\n",
    "'Reasons for Sentence': 'RS',\n",
    "'Practice Directions': 'PD'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c51f547-cd2d-4558-97aa-3016f67dca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_databases_keys = [*hk_databases_dict.keys()]\n",
    "hk_databases_values = [*hk_databases_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0ea5ce8-d089-413e-a047-17cb1a60bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_appeal_dict = {'Court of Appeal': hk_appeals_from_ca,\n",
    "'Court of First Instance': hk_appeals_from_hc,\n",
    "'District Court': hk_appeals_from_dc,\n",
    "'Family Court': hk_appeals_from_fc\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb20cc-89d1-43e6-a1ee-6f29ddab2149",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e527ab6-2d04-4d85-a4cf-8a4ebef5bc3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m link\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "from functions.common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87137e31-baca-41a5-a69e-ec49f0376ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hk_search_tool:\n",
    "\n",
    "    def __init__(self, \n",
    "                any_of_these_words = '', \n",
    "                these_words_in_any_order = '', \n",
    "                this_phrase = '', \n",
    "                stemming = True, \n",
    "                date_of_judgment = None,\n",
    "                coram = '',\n",
    "                parties = '', \n",
    "                representation = '', \n",
    "                offence = '',\n",
    "                court_levels_filter = hk_courts_keys, \n",
    "                on_appeal_from_court = '',\n",
    "                on_appeal_from_type = '', \n",
    "                medium_neutral_citation = '', \n",
    "                case_number = '', \n",
    "                reported_citation = '', \n",
    "                databases = hk_databases_keys, \n",
    "                sortby = hk_sortby_keys[0],\n",
    "                judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "\n",
    "        #Initialise parameters\n",
    "        self.any_of_these_words = any_of_these_words \n",
    "        self.these_words_in_any_order = these_words_in_any_order\n",
    "        self.this_phrase = this_phrase \n",
    "        self.stemming = stemming \n",
    "        self.date_of_judgment = date_of_judgment \n",
    "        self.coram = coram\n",
    "        self.parties = parties \n",
    "        self.representation = representation \n",
    "        self.offence = offence\n",
    "        self.court_levels_filter = court_levels_filter\n",
    "        self.on_appeal_from_court = on_appeal_from_court\n",
    "        self.on_appeal_from_type = on_appeal_from_type \n",
    "        self.medium_neutral_citation = medium_neutral_citation \n",
    "        self.case_number = case_number \n",
    "        self.reported_citation = reported_citation \n",
    "        self.databases = databases\n",
    "        self.sortby = sortby\n",
    "        \n",
    "        self.judgment_counter_bound = judgment_counter_bound\n",
    "        \n",
    "        self.page = 1\n",
    "        \n",
    "        self.results_count = 0\n",
    "\n",
    "        self.total_pages = 1\n",
    "        \n",
    "        self.results_url = ''\n",
    "        \n",
    "        self.soup = None\n",
    "        \n",
    "        self.case_infos = []\n",
    "    \n",
    "    #Function for getting search results\n",
    "    def search(self):\n",
    "\n",
    "        #Reset infos of cases found\n",
    "        self.case_infos = []\n",
    "        \n",
    "        params_raw = []\n",
    "\n",
    "        params_raw.append(('txtselectopt', '1'))\n",
    "\n",
    "        params_raw.append(('txtSearch', self.any_of_these_words))\n",
    "\n",
    "        params_raw.append(('txtselectopt1', '2'))\n",
    "\n",
    "        params_raw.append(('txtSearch1', self.these_words_in_any_order))\n",
    "\n",
    "        params_raw.append(('txtselectopt2', '3'))\n",
    "        \n",
    "        params_raw.append(('txtSearch2', self.this_phrase))\n",
    "\n",
    "        #stemming_param = int(float(self.stemming))\n",
    "\n",
    "        stemming_param = str_to_int(self.stemming)\n",
    "\n",
    "        if stemming_param == 1:\n",
    "\n",
    "            params_raw.append(('stem', stemming_param))\n",
    "\n",
    "        params_raw.append(('txtselectopt3', '5'))\n",
    "\n",
    "        #st.write(f\"self.date_of_judgment == {self.date_of_judgment}\")\n",
    "\n",
    "        date_entered = None\n",
    "\n",
    "        if isinstance(self.date_of_judgment, datetime):\n",
    "\n",
    "            date_entered = self.date_of_judgment\n",
    "        \n",
    "        elif self.date_of_judgment != [None, '']:\n",
    "            \n",
    "            date_entered = date_parser(self.date_of_judgment)\n",
    "\n",
    "        #st.write(f\"date_entered == {date_entered}\")\n",
    "\n",
    "        if isinstance(date_entered, datetime):\n",
    "\n",
    "            day = date_entered.day\n",
    "            month = date_entered.month\n",
    "            year = date_entered.year\n",
    "                            \n",
    "            params_raw.append(('txtSearch3', f'{day}/{month}/{year}'))\n",
    "\n",
    "        else:\n",
    "\n",
    "            day = '0'\n",
    "            month = '0'\n",
    "            year = '0' \n",
    "\n",
    "            #Enter incomplete date if given\n",
    "            date_list = self.date_of_judgment.split('/')\n",
    "\n",
    "            if len(date_list) == 3:\n",
    "            \n",
    "                if len(date_list[0]) > 0:\n",
    "                    day = date_list[0]\n",
    "            \n",
    "                if len(date_list[1]) > 0:\n",
    "                    month = date_list[1]\n",
    "            \n",
    "                if len(date_list[2]) > 0:\n",
    "                    year = date_list[2]\n",
    "\n",
    "            txtSearch3_param = ''\n",
    "\n",
    "            for info in [day, month, year]:\n",
    "\n",
    "                if info != '0':\n",
    "\n",
    "                    txtSearch3_param += f'{info}/'\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    txtSearch3_param += f'/'\n",
    "\n",
    "            \n",
    "            if txtSearch3_param == '///':\n",
    "\n",
    "                txtSearch3_param = ''\n",
    "            \n",
    "            params_raw.append(('txtSearch3', f'{txtSearch3_param}'))\n",
    "\n",
    "        #st.write(f\"day == {day}, month = {month}, year = {year}\")\n",
    "        \n",
    "        params_raw.append(('day1', day))\n",
    "\n",
    "        params_raw.append(('month', month))\n",
    "\n",
    "        params_raw.append(('year', year))\n",
    "\n",
    "        params_raw.append(('txtselectopt4', '6'))\n",
    "\n",
    "        params_raw.append(('txtSearch4', self.coram))\n",
    "\n",
    "        params_raw.append(('txtselectopt5', '7'))\n",
    "\n",
    "        params_raw.append(('txtSearch5', self.parties))\n",
    "\n",
    "        params_raw.append(('txtselectopt6', '8'))\n",
    "        \n",
    "        params_raw.append(('txtSearch6', self.representation))\n",
    "\n",
    "        params_raw.append(('txtselectopt7', '9'))\n",
    "        \n",
    "        params_raw.append(('txtSearch7', self.offence))\n",
    "\n",
    "        if self.court_levels_filter != [None, '']:\n",
    "            \n",
    "            if isinstance(self.court_levels_filter, str):\n",
    "                \n",
    "                self.court_levels_filter = ast.literal_eval(self.court_levels_filter)\n",
    "    \n",
    "            if len(self.court_levels_filter) == 0:\n",
    "    \n",
    "                params_raw.append(('selSchct', hk_courts_values[0]))\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                if len(self.court_levels_filter) == len(hk_courts_keys):\n",
    "    \n",
    "                    params_raw.append(('selallct', '1'))\n",
    "                \n",
    "                for court in self.court_levels_filter:\n",
    "                    \n",
    "                    params_raw.append(('selSchct', hk_courts_dict[court]))\n",
    "        \n",
    "        else:\n",
    "            params_raw.append(('selSchct', hk_courts_values[0]))\n",
    "\n",
    "        try:# self.on_appeal_from_court != [None, '']:\n",
    "        \n",
    "            params_raw.append(('selcourtname', hk_courts_dict[self.on_appeal_from_court]))\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"on_appeal_from_court not entered.\")\n",
    "            \n",
    "            params_raw.append(('selcourtname', ''))\n",
    "\n",
    "        #st.write(f\"self.on_appeal_from_court == {self.on_appeal_from_court}\")\n",
    "\n",
    "        #st.write(f\"self.on_appeal_from_type == {self.on_appeal_from_type}\")\n",
    "        \n",
    "        #if (self.on_appeal_from_type != [None, '']) and (self.on_appeal_from_court != [None, '']):\n",
    "        try:\n",
    "            \n",
    "            params_raw.append(('selcourtype', hc_appeal_dict[self.on_appeal_from_court][self.on_appeal_from_type]))\n",
    "        \n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"on_appeal_from_type not entered.\")\n",
    "            \n",
    "            params_raw.append(('selcourtype', ''))\n",
    "    \n",
    "        params_raw.append(('txtselectopt8', '10'))\n",
    "\n",
    "        params_raw.append(('txtSearch8', self.medium_neutral_citation))\n",
    "\n",
    "        params_raw.append(('txtselectopt9', '4'))\n",
    "\n",
    "        params_raw.append(('txtSearch9', self.case_number))\n",
    "\n",
    "        params_raw.append(('txtselectopt10', '12'))\n",
    "        \n",
    "        params_raw.append(('txtSearch10', self.reported_citation))\n",
    "\n",
    "        if self.databases != [None, '']:\n",
    "\n",
    "            if isinstance(self.databases, str):\n",
    "                \n",
    "                self.databases = ast.literal_eval(self.databases)\n",
    "    \n",
    "            if len(self.databases) == 0:\n",
    "    \n",
    "                params_raw.append(('selDatabase2', hk_databases_values[0]))\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                if len(self.databases) == len(hk_databases_keys):\n",
    "    \n",
    "                    params_raw.append(('selall2', '1'))\n",
    "                \n",
    "                for database in self.databases:\n",
    "                    \n",
    "                    params_raw.append(('selDatabase2', hk_databases_dict[database]))\n",
    "        \n",
    "        else:\n",
    "            params_raw.append(('selDatabase2', hk_databases_values[0]))\n",
    "\n",
    "        params_raw.append(('order', hk_sortby_dict[self.sortby]))        \n",
    "\n",
    "        params_raw.append(('SHC', ''))        \n",
    "\n",
    "        params_raw.append(('page', self.page))        \n",
    "        \n",
    "        #Save params\n",
    "        params = urllib.parse.urlencode(params_raw, quote_via=urllib.parse.quote)\n",
    "        \n",
    "        #API url\n",
    "        base_url = 'https://legalref.judiciary.hk/lrs/common/search/search_result_form.jsp?isadvsearch=1'\n",
    "\n",
    "        #Get results page\n",
    "        #response = requests.get(base_url, params = params, headers= {'User-Agent': 'whatever'}, allow_redirects=True)\n",
    "\n",
    "        #Update return values\n",
    "        #self.results_url = response.url\n",
    "\n",
    "        self.results_url = base_url + '&' + params\n",
    "        \n",
    "        #Try to get search results a few times\n",
    "\n",
    "        try_counter = 0\n",
    "        try_success = False\n",
    "\n",
    "        while (try_counter < 3) and (not try_success):\n",
    "\n",
    "            try_counter += 1\n",
    "            \n",
    "            #try:\n",
    "                \n",
    "            #Pause to avoid getting kicked out\n",
    "            pause.seconds(np.random.randint(5, 10))\n",
    "            \n",
    "            browser.get(self.results_url)\n",
    "            #browser.delete_all_cookies()\n",
    "            browser.refresh()\n",
    "    \n",
    "            #self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "            \n",
    "            results_count_list = Wait(browser, 10).until(EC.presence_of_all_elements_located((By.ID, \"searchresult-total\")))\n",
    "            \n",
    "            self.results_count = int(results_count_list[0].text)\n",
    "    \n",
    "            page_count_list = Wait(browser, 10).until(EC.presence_of_all_elements_located((By.ID, \"searchresult-totalpages\")))\n",
    "    \n",
    "            self.total_pages = int(page_count_list[0].text)\n",
    "                            \n",
    "            self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "    \n",
    "            #Get case infos from search results page\n",
    "            \n",
    "            case_numbers_list_raw = self.soup.find_all('a', {'class': 'searchfont result-caseno'})\n",
    "            \n",
    "            link_mnc_list_raw = self.soup.find_all('div', {'class': 'col-md-6 pl-1'}) #Every second item in this list is redundant\n",
    "\n",
    "            #st.write(f\"link_mnc_list_raw == {link_mnc_list_raw}\")\n",
    "            \n",
    "            date_list_raw = self.soup.find_all('div', {'class': 'col-md-4 pl-1'})\n",
    "            \n",
    "            case_names_list_raw = self.soup.find_all('div', {'class': 'col-md-12 pl-1'})\n",
    "            \n",
    "            case_numbers_list = []\n",
    "\n",
    "            reported_list = []\n",
    "            \n",
    "            mnc_list = []\n",
    "            \n",
    "            judgment_urls_list = []\n",
    "            \n",
    "            date_list = []\n",
    "            \n",
    "            case_names_list = []\n",
    "            \n",
    "            for case_number_raw in case_numbers_list_raw:\n",
    "                case_number = case_number_raw.get_text(strip = True)\n",
    "                case_numbers_list.append(case_number)\n",
    "            \n",
    "            mnc_counter = 0\n",
    "            \n",
    "            for link_mnc_raw in link_mnc_list_raw:\n",
    "\n",
    "                if mnc_counter % 2 == 0:\n",
    "                    \n",
    "                    #link_mnc_raw = link_mnc_raw.get_text(strip = True) #This doesn't work on Streamlit Cloud\n",
    "                    \n",
    "                    link_mnc_raw = str(link_mnc_raw)\n",
    "                    \n",
    "                    #st.write(f\"link_mnc_raw == {link_mnc_raw}\")\n",
    "\n",
    "                    if re.search(r'\\[\\d{4}\\].+\\d+', link_mnc_raw):\n",
    "                        \n",
    "                        mnc = re.findall(r'\\[\\d{4}\\].+\\d+', link_mnc_raw)[0]\n",
    "                    \n",
    "                    else:\n",
    "                        \n",
    "                        mnc = ''\n",
    "            \n",
    "                    if re.search(r\"\\'DIS.+\\'\", link_mnc_raw):\n",
    "                    \n",
    "                        judgment_url = re.findall(r\"\\'DIS.+\\'\", link_mnc_raw)[0]\n",
    "                    \n",
    "                    else:\n",
    "                        \n",
    "                        judgment_url = ''\n",
    "                    \n",
    "                    judgment_url =  \"https://legalref.judiciary.hk/lrs/common/search/search_result_detail_frame.jsp?\" + judgment_url.replace(\"'\", \"\")\n",
    "                        \n",
    "                    mnc_list.append(mnc)\n",
    "            \n",
    "                    judgment_urls_list.append(judgment_url)\n",
    "                \n",
    "                mnc_counter += 1\n",
    "            \n",
    "            for date_raw in date_list_raw:\n",
    "                \n",
    "                date = date_raw.get_text(strip = True)\n",
    "            \n",
    "                if ':' in date:\n",
    "                    date = date.split(':')[-1]\n",
    "            \n",
    "                date = date.replace(' ', '')\n",
    "                    \n",
    "                date_list.append(date)\n",
    "            \n",
    "            for case_name_raw in case_names_list_raw:\n",
    "                \n",
    "                case_name = case_name_raw.get_text(strip = True)\n",
    "\n",
    "                reported = ''\n",
    "\n",
    "                if 'Reported in' in case_name:\n",
    "                    \n",
    "                    case_name_reported = case_name.split('Reported in')\n",
    "\n",
    "                    case_name = case_name_reported[0]\n",
    "                    \n",
    "                    while case_name[-1] in [';', ' ']:\n",
    "                        case_name = case_name[:-1]\n",
    "\n",
    "                    reported = case_name_reported[1]\n",
    "\n",
    "                    while reported[0] in [':', ' ']:\n",
    "                        reported = reported[1:]\n",
    "                \n",
    "                case_names_list.append(case_name)\n",
    "\n",
    "                reported_list.append(reported)\n",
    "                \n",
    "            for case_name in case_names_list:\n",
    "    \n",
    "                if len(self.case_infos) < self.judgment_counter_bound:\n",
    "    \n",
    "                    counter = len(self.case_infos)\n",
    "    \n",
    "                    judgment_url = judgment_urls_list[counter]\n",
    "    \n",
    "                    mnc = mnc_list[counter]\n",
    "\n",
    "                    reported = reported_list[counter]\n",
    "                    \n",
    "                    case_number = case_numbers_list[counter]\n",
    "    \n",
    "                    date = date_list[counter]\n",
    "                    \n",
    "                    case_info = {'Case name': case_name,\n",
    "                                'Hyperlink to the Hong Kong Legal Reference System': judgment_url, \n",
    "                                 'Medium neutral citation': mnc,\n",
    "                                 'Reported': reported,\n",
    "                                'Case number': case_number,\n",
    "                                'Date': date\n",
    "                                }\n",
    "    \n",
    "                    self.case_infos.append(case_info)\n",
    "    \n",
    "            #browser.delete_all_cookies()\n",
    "            #browser.close()\n",
    "\n",
    "            try_success = True\n",
    "\n",
    "            #print(f\"Got {self.results_count} search results based on page {self.page}.\")\n",
    "                \n",
    "            #except Exception as e:\n",
    "\n",
    "                #print(f\"Failed to get search results due to error: {e}\")\n",
    "    \n",
    "    #Function for attaching judgment text to case_info dict\n",
    "    def attach_judgment_text_and_urls(self, case_info):\n",
    "\n",
    "        #Initialise urls for docx, pdf, and Chinese translation and English original, and for judgment text\n",
    "        docx_url = ''\n",
    "        pdf_url = ''\n",
    "        chinese_url = ''\n",
    "        english_url = ''        \n",
    "        judgment_text = ''\n",
    "        alert = ''\n",
    "\n",
    "        case_number = case_info['Case number']\n",
    "        \n",
    "        #Try to get judgment from html first\n",
    "        try:\n",
    "\n",
    "            judgment_url = case_info['Hyperlink to the Hong Kong Legal Reference System']\n",
    "\n",
    "            browser.get(judgment_url)\n",
    "            \n",
    "            #Click away potentially multiple alerts\n",
    "            alert_counter = 1\n",
    "            while alert_counter <= alert_bound:\n",
    "                try:\n",
    "                    Wait(browser, 10).until(EC.alert_is_present())\n",
    "                    alert += f\"{browser.switch_to.alert.text}\\n\\n\"\n",
    "                    \n",
    "                    try:\n",
    "                        browser.switch_to.alert.accept()\n",
    "                    except:\n",
    "                        browser.switch_to.alert.dismiss()\n",
    "                        \n",
    "                    print(f'{case_number}: clicked away alert {alert_counter}.')\n",
    "\n",
    "                except TimeoutException:\n",
    "                    print(f'{case_number}: no more alert.')\n",
    "                    alert_counter += alert_bound\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f'{case_number}: failed to click away alert {alert_counter} due to error {e}.')\n",
    "\n",
    "                alert_counter += 1\n",
    "            \n",
    "            #Get urls for docx, pdf, and Chinese translation/English original if available\n",
    "            browser.switch_to.frame(\"topFrame\")\n",
    "            \n",
    "            hrefs = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "            \n",
    "            top_buttons_dict = {}\n",
    "            \n",
    "            for elem in hrefs:\n",
    "                button_name = elem.text\n",
    "                button_link = elem.get_attribute('href')\n",
    "                \n",
    "                top_buttons_dict.update({button_name.lower(): button_link})\n",
    "            \n",
    "            for key in top_buttons_dict.keys():\n",
    "            \n",
    "                if 'word' in key:\n",
    "                    docx_url = top_buttons_dict[key]\n",
    "            \n",
    "                if 'pdf' in key:\n",
    "                    pdf_url = top_buttons_dict[key]\n",
    "\n",
    "                    pdf_url = re.sub(r'lan\\=\\w{1,2}\\&', '', pdf_url.replace('gotoPdf', 'loadPdf')) + '&mobile=N'\n",
    "                \n",
    "                if 'chinese' in key:\n",
    "                    chinese_url = top_buttons_dict[key]\n",
    "                    \n",
    "                if 'english' in key:\n",
    "                    english_url = top_buttons_dict[key]\n",
    "\n",
    "            #Redirect to English original if available\n",
    "            if len(english_url) > 0:\n",
    "            \n",
    "                judgment_url = english_url\n",
    "                \n",
    "                print(f\"{case_number}: redirecting to Englsh original\")\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(5, 10))\n",
    "                \n",
    "                browser.get(judgment_url)\n",
    "\n",
    "                #Click away potentially multiple alerts\n",
    "                alert_counter = 1\n",
    "                while alert_counter <= alert_bound:\n",
    "                    try:\n",
    "                        Wait(browser, 10).until(EC.alert_is_present())\n",
    "                        alert += f\"{browser.switch_to.alert.text}\\n\\n\"\n",
    "                        \n",
    "                        try:\n",
    "                            browser.switch_to.alert.accept()\n",
    "                        except:\n",
    "                            browser.switch_to.alert.dismiss()\n",
    "                            \n",
    "                        print(f'{case_number}: clicked away alert {alert_counter}.')\n",
    "\n",
    "                    except TimeoutException:\n",
    "                        print(f'{case_number}: no more alert.')\n",
    "                        alert_counter += alert_bound\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f'{case_number}: failed to click away alert {alert_counter} due to error {e}.')\n",
    "\n",
    "                    alert_counter += 1\n",
    "\n",
    "                #Get urls for docx, pdf, and Chinese translation for the English original\n",
    "                browser.switch_to.frame(\"topFrame\")\n",
    "                \n",
    "                hrefs = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "                \n",
    "                english_top_buttons_dict = {}\n",
    "                \n",
    "                for elem in hrefs:\n",
    "                    button_name = elem.text\n",
    "                    button_link = elem.get_attribute('href')\n",
    "                    \n",
    "                    english_top_buttons_dict.update({button_name.lower(): button_link})\n",
    "                \n",
    "                for key in top_buttons_dict.keys():\n",
    "                \n",
    "                    if 'word' in key:\n",
    "                        docx_url = english_top_buttons_dict[key]\n",
    "                \n",
    "                    if 'pdf' in key:\n",
    "                        pdf_url = english_top_buttons_dict[key]\n",
    "\n",
    "                        pdf_url = re.sub(r'lan\\=\\w{1,2}\\&', '', pdf_url.replace('gotoPdf', 'loadPdf')) + '&mobile=N'\n",
    "                    \n",
    "                    if 'chinese' in key:\n",
    "                        chinese_url = english_top_buttons_dict[key]\n",
    "\n",
    "                browser.switch_to.default_content()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                browser.switch_to.default_content()\n",
    "            \n",
    "            browser.switch_to.frame(\"mainFrame\")\n",
    "\n",
    "            judgment_text = BeautifulSoup(browser.page_source, \"lxml\").get_text()\n",
    "\n",
    "            print(f\"{case_number}: Got judgment from html.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"{case_number}: Failed to get judgment from html.\")\n",
    "        \n",
    "        #Get judgment text from pdf if necessary\n",
    "        if len(judgment_text) == 0:\n",
    "        \n",
    "            try:\n",
    "                \n",
    "                judgment_text = pdf_judgment(url_or_path = pdf_url, url_given = True)\n",
    "                \n",
    "                print(f\"{case_number}: Got judgment from pdf.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                print(f\"{case_number}: Can't get judgment from pdf.\")\n",
    "\n",
    "        #Get judgment text from docx if necessary\n",
    "        if len(judgment_text) == 0:\n",
    "        \n",
    "            try:\n",
    "                \n",
    "                judgment_text = docx_judgment(docx_url)\n",
    "                \n",
    "                print(f\"{case_number}: Got judgment from docx.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                print(f\"{case_number}: Can't get judgment from docx.\")\n",
    "        \n",
    "        #Create updated case_info dict with judgment text and links to Chinese translation, English original\n",
    "        case_info_w_judgment = {'Case name': case_info['Case name'],\n",
    "                                'Hyperlink to the Hong Kong Legal Reference System': case_info['Hyperlink to the Hong Kong Legal Reference System'],\n",
    "                                'Hyperlink to Chinese translation (if any)': chinese_url,\n",
    "                                'Hyperlink to English original (if any)': english_url, \n",
    "                                 'Medium neutral citation': case_info['Medium neutral citation'],\n",
    "                                 'Reported': case_info['Reported'],\n",
    "                                'Case number': case_info['Case number'],\n",
    "                                'Date': case_info['Date'], \n",
    "                                'Alert': alert,\n",
    "                                'judgment': judgment_text\n",
    "                                }\n",
    "\n",
    "        #Get appendices (eg corrigendum) if any\n",
    "        \n",
    "        browser.switch_to.default_content()\n",
    "        \n",
    "        browser.switch_to.frame(\"bottomFrame\")\n",
    "        \n",
    "        hrefs = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "        \n",
    "        appendices_dict = {}\n",
    "        \n",
    "        bottom_buttons_dict = {}\n",
    "        \n",
    "        for elem in hrefs:\n",
    "            button_name = elem.text\n",
    "            button_link = elem.get_attribute('href')\n",
    "        \n",
    "            if 'javascript' not in button_link:\n",
    "            \n",
    "                bottom_buttons_dict.update({button_name.lower(): button_link})\n",
    "        \n",
    "        for key in bottom_buttons_dict.keys():\n",
    "        \n",
    "            try:\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(5, 10))\n",
    "                \n",
    "                app_url = bottom_buttons_dict[key]\n",
    "                browser.get(app_url)\n",
    "                \n",
    "                browser.switch_to.frame(\"mainFrame\")\n",
    "\n",
    "                app_text = str(BeautifulSoup(browser.page_source, \"lxml\"))\n",
    "                \n",
    "                #Enable to get text instead of all html\n",
    "                #app_text = BeautifulSoup(browser.page_source, \"lxml\").get_text()\n",
    "                \n",
    "                print(f\"{case_number}: Got appendix {key} from html.\")\n",
    "        \n",
    "                appendices_dict.update({f'{key}': app_text})\n",
    "            except:\n",
    "                print(f\"{case_number}: Can't get appendix {key} from html.\")\n",
    "\n",
    "        #Append any appendices to case_info_w_judgment\n",
    "        if len(appendices_dict) > 0:\n",
    "            for app_key in appendices_dict.keys():\n",
    "                app_text = appendices_dict[app_key]\n",
    "                case_info_w_judgment.update({f'appendix: {app_key}': app_text})\n",
    "\n",
    "        #Make links clickable\n",
    "        for key in case_info_w_judgment:\n",
    "            if 'Hyperlink' in key:\n",
    "                case_info_w_judgment[key] = link(case_info_w_judgment[key])\n",
    "                break\n",
    "\n",
    "        #case_info_w_judgment['Hyperlink to the Hong Kong Legal Reference System'] = link(case_info['Hyperlink to the Hong Kong Legal Reference System'])\n",
    "        \n",
    "        return case_info_w_judgment\n",
    "        \n",
    "    #Function for getting all requested judgments\n",
    "    def get_judgments(self):\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "\n",
    "        #Search if not done yet\n",
    "        if len(self.case_infos) == 0:\n",
    "\n",
    "            self.search()\n",
    "        \n",
    "        #Get judgments from cases shown on the initial page (page 1)\n",
    "        for case_info in self.case_infos:\n",
    "            \n",
    "            if len(self.case_infos_w_judgments) < min(self.results_count, self.judgment_counter_bound):\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(5, 10))\n",
    "\n",
    "                #Attach judgment text and urls to case_info dict\n",
    "                case_info_w_judgment = self.attach_judgment_text_and_urls(case_info)\n",
    "        \n",
    "                self.case_infos_w_judgments.append(case_info_w_judgment)\n",
    "                \n",
    "                print(f\"Scraped {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)} judgments.\")\n",
    "\n",
    "        #Scrape the next page if necessary and available\n",
    "        while (len(self.case_infos_w_judgments) < min(self.results_count, self.judgment_counter_bound)) and (self.page < self.total_pages):\n",
    "            \n",
    "            self.page += 1\n",
    "\n",
    "            #Pause to avoid getting kicked out\n",
    "            pause.seconds(np.random.randint(5, 10))\n",
    "        \n",
    "            #Get cases on subsequent page\n",
    "            self.search()\n",
    "\n",
    "            #Get judgments from cases shown on the initial page (page 1)\n",
    "            for case_info in self.case_infos:\n",
    "                \n",
    "                if len(self.case_infos_w_judgments) < min(self.results_count, self.judgment_counter_bound):\n",
    "    \n",
    "                    #Pause to avoid getting kicked out\n",
    "                    pause.seconds(np.random.randint(5, 10))\n",
    "\n",
    "                    #Attach judgment text and urls to case_info dict\n",
    "                    case_info_w_judgment = self.attach_judgment_text_and_urls(case_info)\n",
    "\n",
    "                    self.case_infos_w_judgments.append(case_info_w_judgment)\n",
    "                    \n",
    "                    print(f\"Scraped {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)} judgments.\")\n",
    "    \n",
    "        #browser.delete_all_cookies()\n",
    "        #browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367cefda-29f4-43da-9456-f6f87f3c7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hk_search_function(\n",
    "                    any_of_these_words, \n",
    "                    these_words_in_any_order, \n",
    "                    this_phrase, \n",
    "                    stemming, \n",
    "                    date_of_judgment,\n",
    "                    coram,\n",
    "                    parties, \n",
    "                    representation, \n",
    "                    offence,\n",
    "                    court_levels_filter, \n",
    "                    on_appeal_from_court,\n",
    "                    on_appeal_from_type, \n",
    "                    medium_neutral_citation, \n",
    "                    case_number, \n",
    "                    reported_citation, \n",
    "                    databases, \n",
    "                    sortby,\n",
    "                    judgment_counter_bound,\n",
    "                ):\n",
    "\n",
    "    #Conduct search\n",
    "\n",
    "    hk_search = hk_search_tool(\n",
    "                    any_of_these_words = any_of_these_words, \n",
    "                    these_words_in_any_order = these_words_in_any_order, \n",
    "                    this_phrase = this_phrase, \n",
    "                    stemming = stemming, \n",
    "                    date_of_judgment = date_of_judgment,\n",
    "                    coram = coram,\n",
    "                    parties = parties, \n",
    "                    representation = representation, \n",
    "                    offence = offence,\n",
    "                    court_levels_filter = court_levels_filter, \n",
    "                    on_appeal_from_court = on_appeal_from_court,\n",
    "                    on_appeal_from_type = on_appeal_from_type, \n",
    "                    medium_neutral_citation = medium_neutral_citation, \n",
    "                    case_number = case_number, \n",
    "                    reported_citation = reported_citation, \n",
    "                    databases = databases, \n",
    "                    sortby = sortby,\n",
    "                    judgment_counter_bound = judgment_counter_bound,\n",
    "                )\n",
    "        \n",
    "    hk_search.search()\n",
    "    \n",
    "    return hk_search\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a97e723-4286-4231-bfd3-d18f5ab44ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hk_search_preview(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "            \n",
    "    #Conduct search\n",
    "\n",
    "    hk_search = hk_search_tool(\n",
    "                    any_of_these_words = df_master.loc[0, 'Any of these words'], \n",
    "                    these_words_in_any_order = df_master.loc[0, 'These words in any order'], \n",
    "                    this_phrase = df_master.loc[0, 'This phrase'], \n",
    "                    stemming = df_master.loc[0, 'Stemming'], \n",
    "                    date_of_judgment = df_master.loc[0, 'Date of judgment'],\n",
    "                    coram = df_master.loc[0, 'Coram'],\n",
    "                    parties = df_master.loc[0, 'Parties'], \n",
    "                    representation = df_master.loc[0, 'Representation'], \n",
    "                    offence = df_master.loc[0, 'Offence'],\n",
    "                    court_levels_filter = df_master.loc[0, 'Court level(s) filter'], \n",
    "                    on_appeal_from_court = df_master.loc[0, 'On appeal from (court)'],\n",
    "                    on_appeal_from_type = df_master.loc[0, 'On appeal from (type)'], \n",
    "                    medium_neutral_citation = df_master.loc[0, 'Medium neutral citation'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    reported_citation = df_master.loc[0, 'Reported citation'], \n",
    "                    databases = df_master.loc[0, 'Database(s)'], \n",
    "                    sortby = df_master.loc[0, 'Sort by'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']),\n",
    "                )\n",
    "\n",
    "\n",
    "    hk_search.search()\n",
    "    \n",
    "    results_count = hk_search.results_count\n",
    "    case_infos = hk_search.case_infos\n",
    "\n",
    "    results_url = hk_search.results_url\n",
    "\n",
    "    #st.write(results_url)\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'case_infos': case_infos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60146b-936a-44ca-acad-4f5c66dcf714",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def4dad4-432b-4480-8804-c9cb50300e30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound \u001b[38;5;66;03m#role_content, intro_for_GPT\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import basic_model, flagship_model\n",
    "#For batch mode\n",
    "from functions.gpt_functions import gpt_get_custom_id, gpt_batch_input_id_line, gpt_batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d1ef7e-32d2-427a-bc26-b05eff19cfe0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#For checking questions and answers\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_questions_answers\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81667591-fb42-499a-a899-aa7b93b277f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "\n",
    "role_content_hk = \"\"\"You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. \n",
    "Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from a part of the judgment or metadata, include a page or paragraph reference to that part of the judgment or metadata. \n",
    "If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". \n",
    "The JSON given to you is in English or Chinese or both. Please answer questions based on either or both languages.\"\"\"\n",
    "\n",
    "#Respond in JSON form. In your response, produce as many keys as you need. \n",
    "\n",
    "#system_instruction = role_content_hk\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f113a45-55d0-4b16-b8ff-1fb7347812de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 10:40:54.912 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hk_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "        \n",
    "    hk_search = hk_search_function(\n",
    "                    any_of_these_words = df_master.loc[0, 'Any of these words'], \n",
    "                    these_words_in_any_order = df_master.loc[0, 'These words in any order'], \n",
    "                    this_phrase = df_master.loc[0, 'This phrase'], \n",
    "                    stemming = df_master.loc[0, 'Stemming'], \n",
    "                    date_of_judgment = df_master.loc[0, 'Date of judgment'],\n",
    "                    coram = df_master.loc[0, 'Coram'],\n",
    "                    parties = df_master.loc[0, 'Parties'], \n",
    "                    representation = df_master.loc[0, 'Representation'], \n",
    "                    offence = df_master.loc[0, 'Offence'],\n",
    "                    court_levels_filter = df_master.loc[0, 'Court level(s) filter'], \n",
    "                    on_appeal_from_court = df_master.loc[0, 'On appeal from (court)'],\n",
    "                    on_appeal_from_type = df_master.loc[0, 'On appeal from (type)'], \n",
    "                    medium_neutral_citation = df_master.loc[0, 'Medium neutral citation'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    reported_citation = df_master.loc[0, 'Reported citation'], \n",
    "                    databases = df_master.loc[0, 'Database(s)'], \n",
    "                    sortby = df_master.loc[0, 'Sort by'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']),\n",
    "                )\n",
    "\n",
    "    hk_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in hk_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    #Pop judgment and appendices\n",
    "    if pop_judgment() > 0:\n",
    "        for col in df_updated.columns:\n",
    "            if (col == 'judgment') or (re.search(r'^appendix', col)):\n",
    "                df_updated.pop(col)\n",
    "\n",
    "    #Pop empty columns (eg columns of Chinese original, English translation)\n",
    "    df_updated.replace(\"\", np.nan, inplace=True)\n",
    "    df_updated.dropna(how='all', axis=1, inplace=True)\n",
    "    df_updated.replace(np.nan, '', inplace=True)\n",
    "    \n",
    "    return df_updated\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313937c7-659a-4347-864f-0703b999f479",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hk_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "        \n",
    "    hk_search = hk_search_function(\n",
    "                    any_of_these_words = df_master.loc[0, 'Any of these words'], \n",
    "                    these_words_in_any_order = df_master.loc[0, 'These words in any order'], \n",
    "                    this_phrase = df_master.loc[0, 'This phrase'], \n",
    "                    stemming = df_master.loc[0, 'Stemming'], \n",
    "                    date_of_judgment = df_master.loc[0, 'Date of judgment'],\n",
    "                    coram = df_master.loc[0, 'Coram'],\n",
    "                    parties = df_master.loc[0, 'Parties'], \n",
    "                    representation = df_master.loc[0, 'Representation'], \n",
    "                    offence = df_master.loc[0, 'Offence'],\n",
    "                    court_levels_filter = df_master.loc[0, 'Court level(s) filter'], \n",
    "                    on_appeal_from_court = df_master.loc[0, 'On appeal from (court)'],\n",
    "                    on_appeal_from_type = df_master.loc[0, 'On appeal from (type)'], \n",
    "                    medium_neutral_citation = df_master.loc[0, 'Medium neutral citation'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    reported_citation = df_master.loc[0, 'Reported citation'], \n",
    "                    databases = df_master.loc[0, 'Database(s)'], \n",
    "                    sortby = df_master.loc[0, 'Sort by'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']),\n",
    "                )\n",
    "\n",
    "    hk_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in hk_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
