{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64\n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import math\n",
    "import mammoth\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb\n",
    "\n",
    "#Conversion to text\n",
    "#import fitz\n",
    "#from io import StringIO\n",
    "#from io import BytesIO\n",
    "#import mammoth\n",
    "#from doc2docx import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_value_check, list_range_check, save_input, date_parser, pdf_judgment, docx_judgment\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_value_check, list_range_check, save_input, date_parser, pdf_judgment, docx_judgment\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# HK search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5ac824a-8e0b-4d42-87ca-12d66c0fdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrape javascript\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait as Wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument('--no-sandbox')  \n",
    "options.add_argument('--disable-dev-shm-usage')  \n",
    "\n",
    "#@st.cache_resource(show_spinner = False, ttl=600)\n",
    "def get_driver():\n",
    "    return webdriver.Chrome(options=options)\n",
    "\n",
    "try:\n",
    "    browser = get_driver()\n",
    "    \n",
    "    browser.implicitly_wait(15)\n",
    "    browser.set_page_load_timeout(15)\n",
    "\n",
    "    #browser.quit()\n",
    "    \n",
    "except Exception as e:\n",
    "    st.error('Sorry, your internet connection is not stable enough for this app. Please check or change your internet connection and try again.')\n",
    "    print(e)\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ec122ed-339b-4862-8a02-f92040165436",
   "metadata": {},
   "outputs": [],
   "source": [
    "#judgment_url = 'https://legalref.judiciary.hk/lrs/common/search/search_result_detail_frame.jsp?DIS=137279&QS=%24%28murder%29&TP=JU'\n",
    "\n",
    "#browser.get(judgment_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950f19c-6439-4b3a-b56f-eb631b93f5d8",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fabc67-27ea-4315-ab5b-a1433198c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_sortby_dict = {'Relevance': '1', 'Date': '0', 'Title': '2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3fd03a-055e-4efb-bc41-7225e429b906",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_sortby_keys = [*hk_sortby_dict.keys()]\n",
    "hk_sortby_values = [*hk_sortby_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a74e934-127f-4baf-a829-88efd55e4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 means True, 0 means False\n",
    "#hk_stemming_dict = {1: '1', 0: ''}\n",
    "#hk_stemming_keys = [*hk_stemming_dict.keys()]\n",
    "#hk_stemming_values = [*hk_stemming_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea0798bb-0cb5-40f8-9597-ec871ab93cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_courts_dict = {'Court of Final Appeal': 'FA',\n",
    " 'Court of Appeal': 'CA',\n",
    " 'Court of First Instance': 'HC',\n",
    " 'Competition Tribunal': 'CT',\n",
    " 'District Court': 'DC',\n",
    " 'Family Court': 'FC',\n",
    " 'Lands Tribunal': 'LD',\n",
    " 'Other Court Levels': 'OT'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56dfa7e2-e57e-46f8-9616-328ef5023b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_courts_keys = [*hk_courts_dict.keys()]\n",
    "hk_courts_values = [*hk_courts_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6afff2b-b71e-4bb6-a33b-e060f8d68f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_ca = {'Application for Review': 'AR',\n",
    "\"Attorney General's Reference\": 'AG',\n",
    "'Civil Appeal': 'CV',\n",
    "'Criminal Appeal': 'CC',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Reservation of Question of Law': 'QL',\n",
    "\"Secretary for Justice's Reference\": 'SJ'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07f9b14a-6877-4a13-b146-8552e91af0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_hc = {'Admiralty Action': 'AJ',\n",
    "'Adoption Application': 'AD',\n",
    "'Application for Grant': 'AG',\n",
    "'Application to set aside a Statutory Demand (under Bankruptcy Ordinance)': 'SD',\n",
    "'Applications under the Mental Health Ordinance': 'MH',\n",
    "'Bankruptcy Proceedings': 'B',\n",
    "'Bill of Sale Registration': 'BS',\n",
    "'Bookdebt Registration': 'BD',\n",
    "'Caveat': 'CA',\n",
    "'Citation Application': 'CI',\n",
    "'Civil Action': 'A',\n",
    "'Commercial Action': 'CL',\n",
    "'Companies Winding-up Proceedings': 'CW',\n",
    "'Confidential Miscellaneous Proceedings': 'CM',\n",
    "'Constitutional and Administrative Law Proceedings': 'AL',\n",
    "'Construction and Arbitration Proceedings': 'CT',\n",
    "'Criminal Case': 'CC',\n",
    "'Estate Duty Appeal': 'ED',\n",
    "'Ex-parte Application': 'EA',\n",
    "'High Court Bankruptcy Interim Order': 'BI',\n",
    "'Inland Revenue Appeal': 'IA',\n",
    "'Intellectual Property Case': 'IP',\n",
    "'Intended Action': 'ZZ',\n",
    "'Labour Tribunal Appeal': 'LA',\n",
    "'Legal Aid Appeal': 'AA',\n",
    "'Magistracy Appeal': 'MA',\n",
    "'Matrimonial Causes': 'MC',\n",
    "'Minor Employment Claims Appeal': 'ME',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Miscellaneous Proceedings (Criminal)': 'CP',\n",
    "'Obscene Articles Tribunal Appeal': 'OA',\n",
    "'Personal Injuries Action': 'PI',\n",
    "'Probate Action': 'AP',\n",
    "'Reciprocal Enforcement Case': 'RE',\n",
    "'Referral Case': 'RC',\n",
    "'Small Claims Tribunal Appeal': 'SA',\n",
    "'Stop Notice': 'SN',\n",
    "'Trade Unions Appeal': 'UA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d63a8f61-169b-4811-8f28-f7b002b5e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_dc = {'Civil Action': 'CJ',\n",
    "'Criminal Case': 'CC',\n",
    "'Distraint Case': 'DT',\n",
    "'District Court Tax Claim': 'TC',\n",
    "\"Employee's Compensation Case\": 'EC',\n",
    "'Equal Opportunities Action': 'EO',\n",
    "'Intended Action': 'ZZ',\n",
    "'Miscellaneous Appeals': 'MA',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Occupational Deafness (Compensation) Appeal': 'OA',\n",
    "'Personal Injuries Action': 'PI',\n",
    "'Pneumoconiosis (Compensation) Appeal': 'PA',\n",
    "'Stamp Duty Appeal': 'SA',\n",
    "'Stop Notice': 'SN'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08cc12a5-d904-4134-8a3f-76435e0b42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_appeals_from_fc = {'Joint application': 'JA',\n",
    "'Matrimonial Causes': 'MC',\n",
    "'Miscellaneous Proceedings': 'MP',\n",
    "'Reciprocal Enforcement Proceedings': 'RE'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a18794f-d707-4121-bed5-b478e6400502",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_databases_dict = {'Judgments': 'JU',\n",
    "'Reasons for Verdict': 'RV',\n",
    "'Reasons for Sentence': 'RS',\n",
    "'Practice Directions': 'PD'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c51f547-cd2d-4558-97aa-3016f67dca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_databases_keys = [*hk_databases_dict.keys()]\n",
    "hk_databases_values = [*hk_databases_dict.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0ea5ce8-d089-413e-a047-17cb1a60bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_appeal_dict = {'Court of Appeal': hk_appeals_from_ca,\n",
    "'Court of First Instance': hk_appeals_from_hc,\n",
    "'District Court': hk_appeals_from_dc,\n",
    "'Family Court': hk_appeals_from_fc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cefb71ee-f9e4-45b0-a261-bdf9d332f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for changing selection menu for type on Streamlit\n",
    "\n",
    "def dict_value_or_none(some_dict, some_key):\n",
    "\n",
    "    if (some_key in [None, '']) or (not isinstance(some_dict, dict)):\n",
    "\n",
    "        return None\n",
    "    \n",
    "    elif some_key not in some_dict.keys():\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "\n",
    "        return_value = some_dict[some_key]\n",
    "\n",
    "        if isinstance(return_value, dict):\n",
    "            \n",
    "            return_value = [*return_value.keys()]\n",
    "        \n",
    "        return return_value\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ec5e858-c3e1-4ada-81da-272d6463fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for turning month or year choice to number or empty string\n",
    "\n",
    "def month_year_to_str(x):\n",
    "\n",
    "    if not re.search(r'\\d+', str(x)):\n",
    "\n",
    "        return ''\n",
    "\n",
    "    else:\n",
    "        \n",
    "        return re.findall(r'\\d+', str(x))[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb20cc-89d1-43e6-a1ee-6f29ddab2149",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e527ab6-2d04-4d85-a4cf-8a4ebef5bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87137e31-baca-41a5-a69e-ec49f0376ae1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hk_courts_keys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mhk_search_tool\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43many_of_these_words\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mthese_words_in_any_order\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#Initialise parameters\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many_of_these_words\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43many_of_these_words\u001b[49m\u001b[43m \u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 13\u001b[0m, in \u001b[0;36mhk_search_tool\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mhk_search_tool\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m      4\u001b[0m                 any_of_these_words \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                 these_words_in_any_order \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      6\u001b[0m                 this_phrase \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      7\u001b[0m                 stemming \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, \n\u001b[1;32m      8\u001b[0m                 date_of_judgment \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      9\u001b[0m                 coram \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m                 parties \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     11\u001b[0m                 representation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     12\u001b[0m                 offence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m---> 13\u001b[0m                 court_levels_filter \u001b[38;5;241m=\u001b[39m \u001b[43mhk_courts_keys\u001b[49m, \n\u001b[1;32m     14\u001b[0m                 on_appeal_from_court \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                 on_appeal_from_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     16\u001b[0m                 medium_neutral_citation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     17\u001b[0m                 case_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     18\u001b[0m                 reported_citation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     19\u001b[0m                 databases \u001b[38;5;241m=\u001b[39m hk_databases_keys, \n\u001b[1;32m     20\u001b[0m                 sortby \u001b[38;5;241m=\u001b[39m hk_sortby_keys[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     21\u001b[0m                 judgment_counter_bound \u001b[38;5;241m=\u001b[39m default_judgment_counter_bound\n\u001b[1;32m     22\u001b[0m                 ):\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m         \u001b[38;5;66;03m#Initialise parameters\u001b[39;00m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39many_of_these_words \u001b[38;5;241m=\u001b[39m any_of_these_words \n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthese_words_in_any_order \u001b[38;5;241m=\u001b[39m these_words_in_any_order\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hk_courts_keys' is not defined"
     ]
    }
   ],
   "source": [
    "class hk_search_tool:\n",
    "\n",
    "    def __init__(self, \n",
    "                any_of_these_words = '', \n",
    "                these_words_in_any_order = '', \n",
    "                this_phrase = '', \n",
    "                stemming = True, \n",
    "                date_of_judgment = None,\n",
    "                coram = '',\n",
    "                parties = '', \n",
    "                representation = '', \n",
    "                offence = '',\n",
    "                court_levels_filter = hk_courts_keys, \n",
    "                on_appeal_from_court = '',\n",
    "                on_appeal_from_type = '', \n",
    "                medium_neutral_citation = '', \n",
    "                case_number = '', \n",
    "                reported_citation = '', \n",
    "                databases = hk_databases_keys, \n",
    "                sortby = hk_sortby_keys[0],\n",
    "                judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "\n",
    "        #Initialise parameters\n",
    "        self.any_of_these_words = any_of_these_words \n",
    "        self.these_words_in_any_order = these_words_in_any_order\n",
    "        self.this_phrase = this_phrase \n",
    "        self.stemming = stemming \n",
    "        self.date_of_judgment = date_of_judgment \n",
    "        self.coram = coram\n",
    "        self.parties = parties \n",
    "        self.representation = representation \n",
    "        self.offence = offence\n",
    "        self.court_levels_filter = court_levels_filter\n",
    "        self.on_appeal_from_court = on_appeal_from_court\n",
    "        self.on_appeal_from_type = on_appeal_from_type \n",
    "        self.medium_neutral_citation = medium_neutral_citation \n",
    "        self.case_number = case_number \n",
    "        self.reported_citation = reported_citation \n",
    "        self.databases = databases\n",
    "        self.sortby = sortby\n",
    "        \n",
    "        self.judgment_counter_bound = judgment_counter_bound\n",
    "\n",
    "        self.params = []\n",
    "        \n",
    "        self.page = 1\n",
    "        \n",
    "        self.results_count = 0\n",
    "\n",
    "        self.total_pages = 1\n",
    "        \n",
    "        self.results_url = ''\n",
    "        \n",
    "        self.soup = None\n",
    "        \n",
    "        self.case_infos = []\n",
    "    \n",
    "    #Function for getting search results\n",
    "    def search(self):\n",
    "\n",
    "        #Reset infos of cases found\n",
    "        self.case_infos = []\n",
    "        \n",
    "        params_raw = []\n",
    "\n",
    "        params_raw.append(('txtselectopt', '1'))\n",
    "\n",
    "        params_raw.append(('txtSearch', self.any_of_these_words))\n",
    "\n",
    "        params_raw.append(('txtselectopt1', '2'))\n",
    "\n",
    "        params_raw.append(('txtSearch1', self.these_words_in_any_order))\n",
    "\n",
    "        params_raw.append(('txtselectopt2', '3'))\n",
    "        \n",
    "        params_raw.append(('txtSearch2', self.this_phrase))\n",
    "\n",
    "        stemming_param = int(float(self.stemming))\n",
    "\n",
    "        if stemming_param == 1:\n",
    "\n",
    "            params_raw.append(('stem', stemming_param))\n",
    "\n",
    "        params_raw.append(('txtselectopt3', '5'))\n",
    "\n",
    "        #st.write(f\"self.date_of_judgment == {self.date_of_judgment}\")\n",
    "\n",
    "        date_entered = None\n",
    "\n",
    "        if isinstance(self.date_of_judgment, datetime):\n",
    "\n",
    "            date_entered = self.date_of_judgment\n",
    "        \n",
    "        elif self.date_of_judgment != [None, '']:\n",
    "            \n",
    "            date_entered = date_parser(self.date_of_judgment)\n",
    "\n",
    "        #st.write(f\"date_entered == {date_entered}\")\n",
    "\n",
    "        if isinstance(date_entered, datetime):\n",
    "\n",
    "            day = date_entered.day\n",
    "            month = date_entered.month\n",
    "            year = date_entered.year\n",
    "                            \n",
    "            params_raw.append(('txtSearch3', f'{day}/{month}/{year}'))\n",
    "\n",
    "        else:\n",
    "\n",
    "            day = '0'\n",
    "            month = '0'\n",
    "            year = '0' \n",
    "\n",
    "            #Enter incomplete date if given\n",
    "            date_list = self.date_of_judgment.split('/')\n",
    "\n",
    "            if len(date_list) == 3:\n",
    "            \n",
    "                if len(date_list[0]) > 0:\n",
    "                    day = date_list[0]\n",
    "            \n",
    "                if len(date_list[1]) > 0:\n",
    "                    month = date_list[1]\n",
    "            \n",
    "                if len(date_list[2]) > 0:\n",
    "                    year = date_list[2]\n",
    "\n",
    "            txtSearch3_param = ''\n",
    "\n",
    "            for info in [day, month, year]:\n",
    "\n",
    "                if info != '0':\n",
    "\n",
    "                    txtSearch3_param += f'{info}/'\n",
    "\n",
    "                else:\n",
    "                    \n",
    "                    txtSearch3_param += f'/'\n",
    "\n",
    "            \n",
    "            if txtSearch3_param == '///':\n",
    "\n",
    "                txtSearch3_param = ''\n",
    "            \n",
    "            params_raw.append(('txtSearch3', f'{txtSearch3_param}'))\n",
    "\n",
    "        #st.write(f\"day == {day}, month = {month}, year = {year}\")\n",
    "        \n",
    "        params_raw.append(('day1', day))\n",
    "\n",
    "        params_raw.append(('month', month))\n",
    "\n",
    "        params_raw.append(('year', year))\n",
    "\n",
    "        params_raw.append(('txtselectopt4', '6'))\n",
    "\n",
    "        params_raw.append(('txtSearch4', self.coram))\n",
    "\n",
    "        params_raw.append(('txtselectopt5', '7'))\n",
    "\n",
    "        params_raw.append(('txtSearch5', self.parties))\n",
    "\n",
    "        params_raw.append(('txtselectopt6', '8'))\n",
    "        \n",
    "        params_raw.append(('txtSearch6', self.representation))\n",
    "\n",
    "        params_raw.append(('txtselectopt7', '9'))\n",
    "        \n",
    "        params_raw.append(('txtSearch7', self.offence))\n",
    "\n",
    "        if self.court_levels_filter != [None, '']:\n",
    "            \n",
    "            if isinstance(self.court_levels_filter, str):\n",
    "                \n",
    "                self.court_levels_filter = ast.literal_eval(self.court_levels_filter)\n",
    "    \n",
    "            if len(self.court_levels_filter) == 0:\n",
    "    \n",
    "                params_raw.append(('selSchct', hk_courts_values[0]))\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                if len(self.court_levels_filter) == len(hk_courts_keys):\n",
    "    \n",
    "                    params_raw.append(('selallct', '1'))\n",
    "                \n",
    "                for court in self.court_levels_filter:\n",
    "                    \n",
    "                    params_raw.append(('selSchct', hk_courts_dict[court]))\n",
    "        \n",
    "        else:\n",
    "            params_raw.append(('selSchct', hk_courts_values[0]))\n",
    "\n",
    "        try:# self.on_appeal_from_court != [None, '']:\n",
    "        \n",
    "            params_raw.append(('selcourtname', hk_courts_dict[self.on_appeal_from_court]))\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"on_appeal_from_court not entered.\")\n",
    "            \n",
    "            params_raw.append(('selcourtname', ''))\n",
    "\n",
    "        #st.write(f\"self.on_appeal_from_court == {self.on_appeal_from_court}\")\n",
    "\n",
    "        #st.write(f\"self.on_appeal_from_type == {self.on_appeal_from_type}\")\n",
    "        \n",
    "        #if (self.on_appeal_from_type != [None, '']) and (self.on_appeal_from_court != [None, '']):\n",
    "        try:\n",
    "            \n",
    "            params_raw.append(('selcourtype', hc_appeal_dict[self.on_appeal_from_court][self.on_appeal_from_type]))\n",
    "        \n",
    "        except Exception as e:\n",
    "\n",
    "            print(\"on_appeal_from_type not entered.\")\n",
    "            \n",
    "            params_raw.append(('selcourtype', ''))\n",
    "    \n",
    "        params_raw.append(('txtselectopt8', '10'))\n",
    "\n",
    "        params_raw.append(('txtSearch8', self.medium_neutral_citation))\n",
    "\n",
    "        params_raw.append(('txtselectopt9', '4'))\n",
    "\n",
    "        params_raw.append(('txtSearch9', self.case_number))\n",
    "\n",
    "        params_raw.append(('txtselectopt10', '12'))\n",
    "        \n",
    "        params_raw.append(('txtSearch10', self.reported_citation))\n",
    "\n",
    "        if self.databases != [None, '']:\n",
    "\n",
    "            if isinstance(self.databases, str):\n",
    "                \n",
    "                self.databases = ast.literal_eval(self.databases)\n",
    "    \n",
    "            if len(self.databases) == 0:\n",
    "    \n",
    "                params_raw.append(('selDatabase2', hk_databases_values[0]))\n",
    "    \n",
    "            else:\n",
    "    \n",
    "                if len(self.databases) == len(hk_databases_keys):\n",
    "    \n",
    "                    params_raw.append(('selall2', '1'))\n",
    "                \n",
    "                for database in self.databases:\n",
    "                    \n",
    "                    params_raw.append(('selDatabase2', hk_databases_dict[database]))\n",
    "        \n",
    "        else:\n",
    "            params_raw.append(('selDatabase2', hk_databases_values[0]))\n",
    "\n",
    "        params_raw.append(('order', hk_sortby_dict[self.sortby]))        \n",
    "\n",
    "        params_raw.append(('SHC', ''))        \n",
    "\n",
    "        params_raw.append(('page', self.page))        \n",
    "        \n",
    "        #Save params\n",
    "        params = urllib.parse.urlencode(params_raw, quote_via=urllib.parse.quote)\n",
    "        \n",
    "        self.params = params\n",
    "\n",
    "        #API url\n",
    "        search_form = 'https://legalref.judiciary.hk/lrs/common/search/search_result_form.jsp?isadvsearch=1'\n",
    "\n",
    "        #Get results page\n",
    "        response = requests.get(search_form, params=self.params, headers= {'User-Agent': 'whatever'}, allow_redirects=True)\n",
    "\n",
    "        #soup = BeautifulSoup(response.content, \"lxml\")\n",
    "\n",
    "        #Update return values\n",
    "        self.results_url = response.url\n",
    "\n",
    "        #Try to get search results a few times\n",
    "\n",
    "        try_counter = 0\n",
    "        try_success = False\n",
    "\n",
    "        while (try_counter < 3) and (not try_success):\n",
    "\n",
    "            try_counter += 1\n",
    "            \n",
    "            try:\n",
    "                \n",
    "                browser.get(self.results_url)\n",
    "                #browser.delete_all_cookies()\n",
    "                browser.refresh()\n",
    "        \n",
    "                #self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "                \n",
    "                results_count_list = Wait(browser, 15).until(EC.presence_of_all_elements_located((By.ID, \"searchresult-total\")))\n",
    "                \n",
    "                self.results_count = int(results_count_list[0].text)\n",
    "        \n",
    "                page_count_list = Wait(browser, 15).until(EC.presence_of_all_elements_located((By.ID, \"searchresult-totalpages\")))\n",
    "        \n",
    "                self.total_pages = int(page_count_list[0].text)\n",
    "                                \n",
    "                self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "        \n",
    "                #Get case infos from search results page\n",
    "                \n",
    "                case_numbers_list_raw = self.soup.find_all('a', {'class': 'searchfont result-caseno'})\n",
    "                \n",
    "                link_mnc_list_raw = self.soup.find_all('div', {'class': 'col-md-6 pl-1'}) #Every second item in this list is redundant\n",
    "\n",
    "                #st.write(f\"link_mnc_list_raw == {link_mnc_list_raw}\")\n",
    "                \n",
    "                date_list_raw = self.soup.find_all('div', {'class': 'col-md-4 pl-1'})\n",
    "                \n",
    "                case_names_list_raw = self.soup.find_all('div', {'class': 'col-md-12 pl-1'})\n",
    "                \n",
    "                case_numbers_list = []\n",
    "\n",
    "                reported_list = []\n",
    "                \n",
    "                mnc_list = []\n",
    "                \n",
    "                judgment_urls_list = []\n",
    "                \n",
    "                date_list = []\n",
    "                \n",
    "                case_names_list = []\n",
    "                \n",
    "                for case_number_raw in case_numbers_list_raw:\n",
    "                    case_number = case_number_raw.get_text(strip = True)\n",
    "                    case_numbers_list.append(case_number)\n",
    "                \n",
    "                mnc_counter = 0\n",
    "                \n",
    "                for link_mnc_raw in link_mnc_list_raw:\n",
    "\n",
    "                    if mnc_counter % 2 == 0:\n",
    "                        \n",
    "                        #link_mnc_raw = link_mnc_raw.get_text(strip = True) #This doesn't work on Streamlit Cloud\n",
    "                        \n",
    "                        link_mnc_raw = str(link_mnc_raw)\n",
    "                        \n",
    "                        #st.write(f\"link_mnc_raw == {link_mnc_raw}\")\n",
    "\n",
    "                        if re.search(r'\\[\\d{4}\\].+\\d+', link_mnc_raw):\n",
    "                            \n",
    "                            mnc = re.findall(r'\\[\\d{4}\\].+\\d+', link_mnc_raw)[0]\n",
    "                        \n",
    "                        else:\n",
    "                            \n",
    "                            mnc = ''\n",
    "                \n",
    "                        if re.search(r\"\\'DIS.+\\'\", link_mnc_raw):\n",
    "                        \n",
    "                            judgment_url = re.findall(r\"\\'DIS.+\\'\", link_mnc_raw)[0]\n",
    "                        \n",
    "                        else:\n",
    "                            \n",
    "                            judgment_url = ''\n",
    "                        \n",
    "                        judgment_url =  \"https://legalref.judiciary.hk/lrs/common/search/search_result_detail_frame.jsp?\" + judgment_url.replace(\"'\", \"\")\n",
    "                            \n",
    "                        mnc_list.append(mnc)\n",
    "                \n",
    "                        judgment_urls_list.append(judgment_url)\n",
    "                    \n",
    "                    mnc_counter += 1\n",
    "                \n",
    "                for date_raw in date_list_raw:\n",
    "                    \n",
    "                    date = date_raw.get_text(strip = True)\n",
    "                \n",
    "                    if ':' in date:\n",
    "                        date = date.split(':')[-1]\n",
    "                \n",
    "                    date = date.replace(' ', '')\n",
    "                        \n",
    "                    date_list.append(date)\n",
    "                \n",
    "                for case_name_raw in case_names_list_raw:\n",
    "                    \n",
    "                    case_name = case_name_raw.get_text(strip = True)\n",
    "\n",
    "                    reported = ''\n",
    "\n",
    "                    if 'Reported in' in case_name:\n",
    "                        \n",
    "                        case_name_reported = case_name.split('Reported in')\n",
    "\n",
    "                        case_name = case_name_reported[0]\n",
    "                        \n",
    "                        while case_name[-1] in [';', ' ']:\n",
    "                            case_name = case_name[:-1]\n",
    "\n",
    "                        reported = case_name_reported[1]\n",
    "\n",
    "                        while reported[0] in [':', ' ']:\n",
    "                            reported = reported[1:]\n",
    "                    \n",
    "                    case_names_list.append(case_name)\n",
    "\n",
    "                    reported_list.append(reported)\n",
    "                    \n",
    "                for case_name in case_names_list:\n",
    "        \n",
    "                    if len(self.case_infos) < self.judgment_counter_bound:\n",
    "        \n",
    "                        counter = len(self.case_infos)\n",
    "        \n",
    "                        judgment_url = judgment_urls_list[counter]\n",
    "        \n",
    "                        mnc = mnc_list[counter]\n",
    "\n",
    "                        reported = reported_list[counter]\n",
    "                        \n",
    "                        case_number = case_numbers_list[counter]\n",
    "        \n",
    "                        date = date_list[counter]\n",
    "                        \n",
    "                        case_info = {'Case name': case_name,\n",
    "                                    'Hyperlink to the Hong Kong Legal Reference System': judgment_url, \n",
    "                                     'Medium neutral citation': mnc,\n",
    "                                     'Reported': reported,\n",
    "                                    'Case number': case_number,\n",
    "                                    'Date': date\n",
    "                                    }\n",
    "        \n",
    "                        self.case_infos.append(case_info)\n",
    "        \n",
    "                #browser.delete_all_cookies()\n",
    "                #browser.close()\n",
    "\n",
    "                try_success = True\n",
    "\n",
    "                #print(f\"Got {self.results_count} search results based on page {self.page}.\")\n",
    "                \n",
    "            except Exception as e:\n",
    "\n",
    "                print(f\"Failed to get search results due to error: {e}\")\n",
    "    \n",
    "    #Function for attaching judgment text to case_info dict\n",
    "    def attach_judgment_text_and_urls(self, case_info):\n",
    "\n",
    "        #Initialise urls for docx, pdf, and Chinese translation and English original, and for judgment text\n",
    "        docx_url = ''\n",
    "        pdf_url = ''\n",
    "        chinese_url = ''\n",
    "        english_url = ''        \n",
    "        judgment_text = ''\n",
    "\n",
    "        case_number = case_info['Case number']\n",
    "        \n",
    "        #Try to get judgment from html first\n",
    "        try:\n",
    "\n",
    "            judgment_url = case_info['Hyperlink to the Hong Kong Legal Reference System']\n",
    "\n",
    "            browser.get(judgment_url)\n",
    "            \n",
    "            #Click away any altert\n",
    "            try:\n",
    "                Wait(browser, 5).until(EC.alert_is_present())\n",
    "                browser.switch_to.alert.accept()\n",
    "                print(f'{case_number}: clicked away alert.')\n",
    "            \n",
    "            except:\n",
    "                print(f'{case_number}: no alert or failed to click away any altert.')\n",
    "            \n",
    "            #Get urls for docx, pdf, and Chinese translation/English original if available\n",
    "            browser.switch_to.frame(\"topFrame\")\n",
    "            \n",
    "            hrefs = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "            \n",
    "            top_buttons_dict = {}\n",
    "            \n",
    "            for elem in hrefs:\n",
    "                button_name = {elem.text}\n",
    "                button_link = elem.get_attribute('href')\n",
    "                \n",
    "                top_buttons_dict.update({str(button_name).lower(): button_link})\n",
    "            \n",
    "            for key in top_buttons_dict.keys():\n",
    "            \n",
    "                if 'word' in key:\n",
    "                    docx_url = top_buttons_dict[key]\n",
    "            \n",
    "                if 'pdf' in key:\n",
    "                    pdf_url = top_buttons_dict[key]\n",
    "            \n",
    "                if 'chinese' in key:\n",
    "                    chinese_url = top_buttons_dict[key]\n",
    "                    \n",
    "                if 'english' in key:\n",
    "                    english_url = top_buttons_dict[key]\n",
    "\n",
    "            #Redirect to English original if available\n",
    "            if len(english_url) > 0:\n",
    "            \n",
    "                judgment_url = english_url\n",
    "                \n",
    "                print(f\"{case_number}: redirecting to Englsh original\")\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(5)\n",
    "                \n",
    "                browser.get(judgment_url)\n",
    "\n",
    "                #Get urls for docx, pdf, and Chinese translation for the English original\n",
    "                browser.switch_to.frame(\"topFrame\")\n",
    "                \n",
    "                hrefs = browser.find_elements(By.XPATH, \"//a[@href]\")\n",
    "                \n",
    "                english_top_buttons_dict = {}\n",
    "                \n",
    "                for elem in hrefs:\n",
    "                    button_name = {elem.text}\n",
    "                    button_link = elem.get_attribute('href')\n",
    "                    \n",
    "                    english_top_buttons_dict.update({str(button_name).lower(): button_link})\n",
    "                \n",
    "                for key in top_buttons_dict.keys():\n",
    "                \n",
    "                    if 'word' in key:\n",
    "                        docx_url = english_top_buttons_dict[key]\n",
    "                \n",
    "                    if 'pdf' in key:\n",
    "                        pdf_url = english_top_buttons_dict[key]\n",
    "                \n",
    "                    if 'chinese' in key:\n",
    "                        chinese_url = english_top_buttons_dict[key]\n",
    "\n",
    "                browser.switch_to.default_content()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                browser.switch_to.default_content()\n",
    "            \n",
    "            browser.switch_to.frame(\"mainFrame\")\n",
    "\n",
    "            judgment_text = BeautifulSoup(browser.page_source, \"lxml\").get_text()\n",
    "\n",
    "            print(f\"{case_number}: Got judgment from html.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            \n",
    "            print(f\"{case_number}: Failed to get judgment from html.\")\n",
    "        \n",
    "        #Get judgment text from pdf if necessary\n",
    "        if len(judgment_text) == 0:\n",
    "        \n",
    "            try:\n",
    "                \n",
    "                judgment_text = pdf_judgment(pdf_url)\n",
    "                \n",
    "                print(f\"{case_number}: Got judgment from pdf.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                print(f\"{case_number}: Can't get judgment from pdf.\")\n",
    "\n",
    "        #Get judgment text from docx if necessary\n",
    "        if len(judgment_text) == 0:\n",
    "        \n",
    "            try:\n",
    "                \n",
    "                judgment_text = docx_judgment(docx_url)\n",
    "                \n",
    "                print(f\"{case_number}: Got judgment from docx.\")\n",
    "            \n",
    "            except Exception as e:\n",
    "\n",
    "                print(f\"{case_number}: Can't get judgment from docx.\")\n",
    "        \n",
    "        #Older method for getting judgment text from pdf or docx by inference from case number\n",
    "\n",
    "        #if len(judgment_text) == 0:\n",
    "\n",
    "            #case_number_ds = re.findall(r'\\d+', case_number)\n",
    "            #case_number_numbers = case_number_ds[0]\n",
    "            #case_number_alphabets = case_number.split(case_number_numbers)[0]\n",
    "            #case_number_year = case_number_ds[1]\n",
    "            #case_number_numbers_6_digis = case_number_numbers\n",
    "            #while len(case_number_numbers_6_digis) < 6:\n",
    "                #case_number_numbers_6_digis = '0' + case_number_numbers_6_digis\n",
    "                \n",
    "            #for language in ['en', 'ch']:\n",
    "\n",
    "                #for doc_type in ['docx', 'doc']:\n",
    "\n",
    "                    #pdf_url = f'https://legalref.judiciary.hk/lrs/common/ju/loadPdf.jsp?url=https://legalref.judiciary.hk/doc/judg/word/vetted/other/{language}/{case_number_year}/{case_number_alphabets}{case_number_numbers_6_digis}_{case_number_year}.{doc_type}&mobile=N'\n",
    "\n",
    "                    #if len(judgment_text) == 0:\n",
    "\n",
    "                        #pdf_url = f'https://legalref.judiciary.hk/lrs/common/ju/loadPdf.jsp?url=https://legalref.judiciary.hk/doc/judg/word/vetted/other/{language}/{case_number_year}/{case_number_alphabets}{case_number_numbers_6_digis}_{case_number_year}.{doc_type}&mobile=N'\n",
    "                    \n",
    "                        #try:\n",
    "                            \n",
    "                            #judgment_text = pdf_judgment(pdf_url)\n",
    "                            \n",
    "                            #print(f\"{case_number}: Got judgment in language == {language} from pdf based on doc_type == {doc_type}.\")\n",
    "                        \n",
    "                        #except Exception as e:\n",
    "\n",
    "                            #print(f\"{case_number}: Can't get judgment in language == {language} from pdf based on doc_type == {doc_type}.\")\n",
    "\n",
    "            #if len(judgment_text) == 0:\n",
    "            \n",
    "                #try:\n",
    "\n",
    "                    #docx_url = f'https://legalref.judiciary.hk/doc/judg/word/vetted/other/{language}/{case_number_year}/{case_number_alphabets}{case_number_numbers_6_digis}_{case_number_year}.docx'\n",
    "                    \n",
    "                    #judgment_text = docx_judgment(docx_url)\n",
    "                    \n",
    "                    #print(f\"{case_number}: Got judgment in language == {language} from docx.\")\n",
    "\n",
    "                #except Exception as e:\n",
    "                    \n",
    "                    #print(f\"{case_number}: Can't get judgment from pdf or docx.\")\n",
    "        \n",
    "        #Create updated case_info dict with judgment text and links to Chinese translation, English original\n",
    "        case_info_w_judgment = {'Case name': case_info['Case name'],\n",
    "                                'Hyperlink to the Hong Kong Legal Reference System': case_info['Hyperlink to the Hong Kong Legal Reference System'],\n",
    "                                'Hyperlink to Chinese translation (if any)': chinese_url,\n",
    "                                'Hyperlink to English original (if any)': english_url, \n",
    "                                 'Medium neutral citation': case_info['Medium neutral citation'],\n",
    "                                 'Reported': case_info['Reported'],\n",
    "                                'Case number': case_info['Case number'],\n",
    "                                'Date': case_info['Date'], \n",
    "                                'judgment': judgment_text\n",
    "                                }\n",
    "\n",
    "        #Make links clickable\n",
    "        for key in case_info_w_judgment:\n",
    "            if 'Hyperlink' in key:\n",
    "                case_info_w_judgment[key] = link(case_info_w_judgment[key])\n",
    "\n",
    "        #case_info_w_judgment['Hyperlink to the Hong Kong Legal Reference System'] = link(case_info['Hyperlink to the Hong Kong Legal Reference System'])\n",
    "        \n",
    "        return case_info_w_judgment\n",
    "        \n",
    "    #Function for getting all requested judgments\n",
    "    def get_judgments(self):\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "\n",
    "        #Search if not done yet\n",
    "        if len(self.case_infos) == 0:\n",
    "\n",
    "            self.search()\n",
    "        \n",
    "        #Get judgments from cases shown on the initial page (page 1)\n",
    "        for case_info in self.case_infos:\n",
    "            \n",
    "            if len(self.case_infos_w_judgments) < self.judgment_counter_bound:\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(5, 10))\n",
    "\n",
    "                #Attach judgment text and urls to case_info dict\n",
    "                case_info_w_judgment = self.attach_judgment_text_and_urls(case_info)\n",
    "        \n",
    "                self.case_infos_w_judgments.append(case_info_w_judgment)\n",
    "                \n",
    "                print(f\"Processed {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)}\")\n",
    "\n",
    "        #Scrape the next page if necessary and available\n",
    "        while (len(self.case_infos_w_judgments) < min(self.results_count, self.judgment_counter_bound)) and (self.page < self.total_pages):\n",
    "            \n",
    "            self.page += 1\n",
    "\n",
    "            #Pause to avoid getting kicked out\n",
    "            pause.seconds(np.random.randint(5, 10))\n",
    "        \n",
    "            #Get cases on subsequent page\n",
    "            self.search()\n",
    "\n",
    "            #Get judgments from cases shown on the initial page (page 1)\n",
    "            for case_info in self.case_infos:\n",
    "                \n",
    "                if len(self.case_infos_w_judgments) < self.judgment_counter_bound:\n",
    "    \n",
    "                    #Pause to avoid getting kicked out\n",
    "                    pause.seconds(np.random.randint(5, 10))\n",
    "\n",
    "                    #Attach judgment text and urls to case_info dict\n",
    "                    case_info_w_judgment = self.attach_judgment_text_and_urls(case_info)\n",
    "\n",
    "                    self.case_infos_w_judgments.append(case_info_w_judgment)\n",
    "                    \n",
    "                    print(f\"Processed {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)}\")\n",
    "    \n",
    "        #browser.delete_all_cookies()\n",
    "        #browser.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "367cefda-29f4-43da-9456-f6f87f3c7ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hk_search_function(\n",
    "                    any_of_these_words, \n",
    "                    these_words_in_any_order, \n",
    "                    this_phrase, \n",
    "                    stemming, \n",
    "                    date_of_judgment,\n",
    "                    coram,\n",
    "                    parties, \n",
    "                    representation, \n",
    "                    offence,\n",
    "                    court_levels_filter, \n",
    "                    on_appeal_from_court,\n",
    "                    on_appeal_from_type, \n",
    "                    medium_neutral_citation, \n",
    "                    case_number, \n",
    "                    reported_citation, \n",
    "                    databases, \n",
    "                    sortby,\n",
    "                    judgment_counter_bound,\n",
    "                ):\n",
    "\n",
    "    #Conduct search\n",
    "\n",
    "    hk_search = hk_search_tool(\n",
    "                    any_of_these_words = any_of_these_words, \n",
    "                    these_words_in_any_order = these_words_in_any_order, \n",
    "                    this_phrase = this_phrase, \n",
    "                    stemming = stemming, \n",
    "                    date_of_judgment = date_of_judgment,\n",
    "                    coram = coram,\n",
    "                    parties = parties, \n",
    "                    representation = representation, \n",
    "                    offence = offence,\n",
    "                    court_levels_filter = court_levels_filter, \n",
    "                    on_appeal_from_court = on_appeal_from_court,\n",
    "                    on_appeal_from_type = on_appeal_from_type, \n",
    "                    medium_neutral_citation = medium_neutral_citation, \n",
    "                    case_number = case_number, \n",
    "                    reported_citation = reported_citation, \n",
    "                    databases = databases, \n",
    "                    sortby = sortby,\n",
    "                    judgment_counter_bound = judgment_counter_bound,\n",
    "                )\n",
    "        \n",
    "    hk_search.search()\n",
    "    \n",
    "    return hk_search\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a97e723-4286-4231-bfd3-d18f5ab44ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hk_search_preview(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "            \n",
    "    #Conduct search\n",
    "\n",
    "    hk_search = hk_search_tool(\n",
    "                    any_of_these_words = df_master.loc[0, 'Any of these words'], \n",
    "                    these_words_in_any_order = df_master.loc[0, 'These words in any order'], \n",
    "                    this_phrase = df_master.loc[0, 'This phrase'], \n",
    "                    stemming = df_master.loc[0, 'Stemming'], \n",
    "                    date_of_judgment = df_master.loc[0, 'Date of judgment'],\n",
    "                    coram = df_master.loc[0, 'Coram'],\n",
    "                    parties = df_master.loc[0, 'Parties'], \n",
    "                    representation = df_master.loc[0, 'Representation'], \n",
    "                    offence = df_master.loc[0, 'Offence'],\n",
    "                    court_levels_filter = df_master.loc[0, 'Court level(s) filter'], \n",
    "                    on_appeal_from_court = df_master.loc[0, 'On appeal from (court)'],\n",
    "                    on_appeal_from_type = df_master.loc[0, 'On appeal from (type)'], \n",
    "                    medium_neutral_citation = df_master.loc[0, 'Medium neutral citation'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    reported_citation = df_master.loc[0, 'Reported citation'], \n",
    "                    databases = df_master.loc[0, 'Database(s)'], \n",
    "                    sortby = df_master.loc[0, 'Sort by'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']),\n",
    "                )\n",
    "\n",
    "\n",
    "    hk_search.search()\n",
    "    \n",
    "    results_count = hk_search.results_count\n",
    "    case_infos = hk_search.case_infos\n",
    "\n",
    "    results_url = hk_search.results_url\n",
    "\n",
    "    #st.write(results_url)\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'case_infos': case_infos}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c60146b-936a-44ca-acad-4f5c66dcf714",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "def4dad4-432b-4480-8804-c9cb50300e30",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 13:14:50.286 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-26 13:14:50.287 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-26 13:14:50.287 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-26 13:14:50.288 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-26 13:14:50.290 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound #role_content, intro_for_GPT\n",
    "#For batch mode\n",
    "from functions.gpt_functions import gpt_get_custom_id, gpt_batch_input_id_line, gpt_batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "72d1ef7e-32d2-427a-bc26-b05eff19cfe0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81667591-fb42-499a-a899-aa7b93b277f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "\n",
    "role_content_hk = \"\"\"You are a legal research assistant helping an academic researcher to answer questions about a public judgment. You will be provided with the judgment and metadata in JSON form. \n",
    "Please answer questions based only on information contained in the judgment and metadata. Where your answer comes from a part of the judgment or metadata, include a page or paragraph reference to that part of the judgment or metadata. \n",
    "If you cannot answer the questions based on the judgment or metadata, do not make up information, but instead write \"answer not found\". \n",
    "The \"judgment\" field of the JSON given to you is in English or Chinese or both. Please answer questions based on either or both languages. \n",
    "\"\"\"\n",
    "\n",
    "#Respond in JSON form. In your response, produce as many keys as you need. \n",
    "\n",
    "system_instruction = role_content_hk\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f113a45-55d0-4b16-b8ff-1fb7347812de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 13:14:50.304 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hk_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "        \n",
    "    hk_search = hk_search_function(\n",
    "                    any_of_these_words = df_master.loc[0, 'Any of these words'], \n",
    "                    these_words_in_any_order = df_master.loc[0, 'These words in any order'], \n",
    "                    this_phrase = df_master.loc[0, 'This phrase'], \n",
    "                    stemming = df_master.loc[0, 'Stemming'], \n",
    "                    date_of_judgment = df_master.loc[0, 'Date of judgment'],\n",
    "                    coram = df_master.loc[0, 'Coram'],\n",
    "                    parties = df_master.loc[0, 'Parties'], \n",
    "                    representation = df_master.loc[0, 'Representation'], \n",
    "                    offence = df_master.loc[0, 'Offence'],\n",
    "                    court_levels_filter = df_master.loc[0, 'Court level(s) filter'], \n",
    "                    on_appeal_from_court = df_master.loc[0, 'On appeal from (court)'],\n",
    "                    on_appeal_from_type = df_master.loc[0, 'On appeal from (type)'], \n",
    "                    medium_neutral_citation = df_master.loc[0, 'Medium neutral citation'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    reported_citation = df_master.loc[0, 'Reported citation'], \n",
    "                    databases = df_master.loc[0, 'Database(s)'], \n",
    "                    sortby = df_master.loc[0, 'Sort by'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']),\n",
    "                )\n",
    "\n",
    "    hk_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in hk_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    #Pop judgment\n",
    "    if (pop_judgment() > 0) and ('judgment' in df_updated.columns):\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    #Pop empty columns (eg columns of Chinese original, English translation)\n",
    "    df_updated.replace(\"\", np.nan, inplace=True)\n",
    "    df_updated.dropna(how='all', axis=1, inplace=True)\n",
    "    df_updated.replace(np.nan, '', inplace=True)\n",
    "    \n",
    "    return df_updated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0da47caf-4ebd-444e-ada6-f56b38907a31",
   "metadata": {
    "editable": true,
    "lines_to_next_cell": 3,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-26 13:14:50.309 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def hk_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "        \n",
    "    hk_search = hk_search_function(\n",
    "                    any_of_these_words = df_master.loc[0, 'Any of these words'], \n",
    "                    these_words_in_any_order = df_master.loc[0, 'These words in any order'], \n",
    "                    this_phrase = df_master.loc[0, 'This phrase'], \n",
    "                    stemming = df_master.loc[0, 'Stemming'], \n",
    "                    date_of_judgment = df_master.loc[0, 'Date of judgment'],\n",
    "                    coram = df_master.loc[0, 'Coram'],\n",
    "                    parties = df_master.loc[0, 'Parties'], \n",
    "                    representation = df_master.loc[0, 'Representation'], \n",
    "                    offence = df_master.loc[0, 'Offence'],\n",
    "                    court_levels_filter = df_master.loc[0, 'Court level(s) filter'], \n",
    "                    on_appeal_from_court = df_master.loc[0, 'On appeal from (court)'],\n",
    "                    on_appeal_from_type = df_master.loc[0, 'On appeal from (type)'], \n",
    "                    medium_neutral_citation = df_master.loc[0, 'Medium neutral citation'], \n",
    "                    case_number = df_master.loc[0, 'Case number'], \n",
    "                    reported_citation = df_master.loc[0, 'Reported citation'], \n",
    "                    databases = df_master.loc[0, 'Database(s)'], \n",
    "                    sortby = df_master.loc[0, 'Sort by'],\n",
    "                    judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']),\n",
    "                )\n",
    "\n",
    "    hk_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in hk_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "\n",
    "    #Need to convert date column to string\n",
    "    if 'Date' in df_individual.columns:\n",
    "\n",
    "        df_individual['Date'] = df_individual['Date'].astype(str)\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
