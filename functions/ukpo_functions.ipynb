{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import math\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb\n",
    "\n",
    "#Conversion to text\n",
    "#import fitz\n",
    "#from io import StringIO\n",
    "#from io import BytesIO\n",
    "#import mammoth\n",
    "#from doc2docx import convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_value_check, list_range_check, save_input, pdf_judgment\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_value_check, list_range_check, save_input, pdf_image_judgment\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# UK Pensions Ombudsman search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2950f19c-6439-4b3a-b56f-eb631b93f5d8",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45dc7c9b-a8b8-45c2-b4be-60a5f8c02dd7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ukpo_outcomes_dict = {'Not upheld': '14', \n",
    "                           'Partly upheld': '13', \n",
    "                            'Upheld': '12',\n",
    "                           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d95f8846-bfe6-496e-bd89-6ceb01515c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpo_topics_dict = {'Abatement': '282',\n",
    " 'Administration': '228',\n",
    " 'Automatic enrolment': '279',\n",
    " 'Benefits: incorrect calculation': '221',\n",
    " 'Benefits: missing': '231',\n",
    " 'Benefits: overpayment (recovery of)': '232',\n",
    " 'Benefits: refusal/failure to pay or late payment': '229',\n",
    " 'Breach of trust': '278',\n",
    " 'Charges/fees': '235',\n",
    " 'Compensation': '285',\n",
    " 'Contributions: failure to pay into scheme': '230',\n",
    " 'Contributions: incorrect calculation': '233',\n",
    " 'Contributions: refunds': '238',\n",
    " 'CPI: switch to': '239',\n",
    " 'Death benefits': '225',\n",
    " 'Divorce': '236',\n",
    " 'Equal treatment': '280',\n",
    " 'Equalisation of retirement age': '283',\n",
    " 'Failure to provide information/act on instructions': '224',\n",
    " 'Fund switches': '271',\n",
    " 'Guaranteed annuity rate': '234',\n",
    " 'Ill Health': '223',\n",
    " 'Injury benefit': '240',\n",
    " 'Interpretation of scheme rules/policy terms': '227',\n",
    " 'Membership': '226',\n",
    " 'Misquote/misinformation': '222',\n",
    " 'Other': '277',\n",
    " 'Pension liberation': '237',\n",
    " 'Post retirement increases (escalation): general': '270',\n",
    " 'Post retirement increases (escalation): RPI/CPI': '269',\n",
    " 'Pre retirement increases (revaluation)': '274',\n",
    " 'Transfers: club transfers': '272',\n",
    " 'Transfers: general': '220',\n",
    " 'Unsecured pension/drawdown': '289',\n",
    " 'Winding up': '273',\n",
    " 'With-profits issues': '288'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfa06ecc-f22d-4f6a-b0a2-5821a20c86be",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpo_types_dict = {'Financial Assistance Scheme appeal': '15',\n",
    " 'Pension complaint or dispute': '16',\n",
    " 'Pensions Protection Fund complaint': '17',\n",
    " 'Pensions Protection Fund referral': '18'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23aea741-a877-45ed-a95c-8340f4cce880",
   "metadata": {},
   "outputs": [],
   "source": [
    "ukpo_sortby_dict = {'Sort A – Z': 'title_ASC', \n",
    "                  'Sort Z – A': 'title_DESC', \n",
    "                  'Decision Date Asc': 'field_decision_date_value_ASC', \n",
    "                  'Decision Date Desc': 'field_decision_date_value_DESC'    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acb20cc-89d1-43e6-a1ee-6f29ddab2149",
   "metadata": {},
   "source": [
    "## Search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e527ab6-2d04-4d85-a4cf-8a4ebef5bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.common_functions import link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0750bead-4e06-454f-adab-04b6bdabd84d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ukpo_sortby_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mukpo_search_tool\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                 \u001b[49m\u001b[43moutcomes_list\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#Initialise parameters\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeyword\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 8\u001b[0m, in \u001b[0;36mukpo_search_tool\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mukpo_search_tool\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m      4\u001b[0m                  keyword \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      5\u001b[0m                  outcomes_list \u001b[38;5;241m=\u001b[39m [], \n\u001b[1;32m      6\u001b[0m                  topics_list \u001b[38;5;241m=\u001b[39m [], \n\u001b[1;32m      7\u001b[0m                  types_list \u001b[38;5;241m=\u001b[39m [], \n\u001b[0;32m----> 8\u001b[0m                  sortby \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mukpo_sortby_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \n\u001b[1;32m      9\u001b[0m                  judgment_counter_bound \u001b[38;5;241m=\u001b[39m default_judgment_counter_bound\n\u001b[1;32m     10\u001b[0m                 ):\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m#Initialise parameters\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeyword \u001b[38;5;241m=\u001b[39m keyword\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutcomes_list \u001b[38;5;241m=\u001b[39m outcomes_list\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ukpo_sortby_dict' is not defined"
     ]
    }
   ],
   "source": [
    "class ukpo_search_tool:\n",
    "\n",
    "    def __init__(self, \n",
    "                 keyword = '', \n",
    "                 outcomes_list = [], \n",
    "                 topics_list = [], \n",
    "                 types_list = [], \n",
    "                 sortby = list(ukpo_sortby_dict.keys())[-1], \n",
    "                 judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "\n",
    "        #Initialise parameters\n",
    "        self.keyword = keyword\n",
    "        self.outcomes_list = outcomes_list\n",
    "        self.topics_list = topics_list\n",
    "        self.types_list = types_list\n",
    "        self.sortby = sortby\n",
    "        self.page = 0\n",
    "        \n",
    "        self.judgment_counter_bound = judgment_counter_bound\n",
    "\n",
    "        self.results_count = 0\n",
    "        self.results_url = ''\n",
    "        self.soup = None\n",
    "        self.case_infos = []\n",
    "\n",
    "    #Function for getting search results\n",
    "    #def search(self, keyword = '', outcomes_list = [], topics_list = [], types_list = [], sortby = list(ukpo_sortby_dict.keys())[-1], page = 0):\n",
    "    def search(self):\n",
    "\n",
    "        #st.write('Running search()')\n",
    "\n",
    "        ukpo_url = 'https://www.pensions-ombudsman.org.uk/decisions'\n",
    "    \n",
    "        #Add search params\n",
    "        params = {}\n",
    "    \n",
    "        #Add keyword\n",
    "        if len(self.keyword) > 0:\n",
    "            params.update({'keys': self.keyword})\n",
    "        \n",
    "        #Add outcomes\n",
    "        for outcome in self.outcomes_list:\n",
    "            outcome_value = ukpo_outcomes_dict[outcome]\n",
    "            outcome_param = {f'outcome[{outcome_value}]': outcome_value}\n",
    "            params.update(outcome_param)\n",
    "    \n",
    "        #Add topics\n",
    "        for topic in self.topics_list:\n",
    "            topic_value = ukpo_topics_dict[topic]\n",
    "            topic_param = {f'topic[{topic_value}]': topic_value}\n",
    "            params.update(topic_param)\n",
    "    \n",
    "        #Add types\n",
    "        for type_chosen in self.types_list:\n",
    "            type_value = ukpo_types_dict[type_chosen]\n",
    "            type_param = {f'type[{type_value}]': type_value}\n",
    "            params.update(type_param)\n",
    "    \n",
    "        #Add sortby\n",
    "        sortby_value = ukpo_sortby_dict[self.sortby]\n",
    "        params.update({'sort_bef_combine': sortby_value})\n",
    "    \n",
    "        #Add page number to search parameter if page > 0:\n",
    "        if self.page > 0:\n",
    "            params.update({'page': self.page})\n",
    "        \n",
    "        #Conduct search\n",
    "        response = requests.get(ukpo_url, params = params, headers= {'User-Agent': 'whatever'})\n",
    "        soup = BeautifulSoup(response.content, \"lxml\")\n",
    "        \n",
    "        #Get number of results    \n",
    "        results_text = soup.find('div', {'role': 'status'}).text\n",
    "        results_text = results_text.replace(',', '').replace('.', '')\n",
    "        results_count_list = re.findall(r'\\d+', results_text)\n",
    "    \n",
    "        if len(results_count_list) > 0:\n",
    "            results_count = int(results_count_list[0])\n",
    "    \n",
    "        else:\n",
    "            results_count = 0\n",
    "    \n",
    "        print(results_text)\n",
    "\n",
    "        #Update return values\n",
    "        self.results_url = response.url\n",
    "        self.results_count = results_count\n",
    "        self.soup = soup\n",
    "        \n",
    "        #return {'results_url': response.url, 'results_count': results_count, 'soup': soup}\n",
    "\n",
    "    #Function for getting case infos from search results page\n",
    "    def get_case_infos(self):\n",
    "\n",
    "        #Get case infos\n",
    "\n",
    "        #st.write(f'judgment_counter_bound == {self.judgment_counter_bound}')\n",
    "        \n",
    "        #Initialise results obtained\n",
    "        #result_counter = 0\n",
    "\n",
    "        #There are 12 cases per page, where the page number parameter starts at 0/none\n",
    "        page_max = math.ceil(self.results_count/12-1)\n",
    "    \n",
    "        for page_to_check in range(0, page_max + 1):\n",
    "\n",
    "            #st.write(f'result_counter == {result_counter}')\n",
    "\n",
    "            #st.write(f'Checking page {page_to_check}')\n",
    "            \n",
    "            #st.write(f'len(self.case_infos) == {len(self.case_infos)}')\n",
    "            \n",
    "            #if result_counter < self.judgment_counter_bound:\n",
    "            if len(self.case_infos) < self.judgment_counter_bound:\n",
    "\n",
    "                #For all pages except the initial page, need to pause and update search results page\n",
    "                if page_to_check > 0:\n",
    "                    \n",
    "                    #Pause to avoid getting kicked out\n",
    "                    pause.seconds(np.random.randint(15, 20))\n",
    "                    \n",
    "                    self.page = page_to_check\n",
    "\n",
    "                    self.search()\n",
    "\n",
    "                #Get case infos\n",
    "                search_results = self.soup.find_all('div', {'class': 'card-item teal'})\n",
    "            \n",
    "                for search_result in search_results:\n",
    "                    \n",
    "                    #if result_counter < self.judgment_counter_bound:\n",
    "                    if len(self.case_infos) < self.judgment_counter_bound:\n",
    "\n",
    "                        #Get case name\n",
    "                        case_name = search_result.find('a', {'class': 'h3'}).text\n",
    "                        #case_name\n",
    "                        \n",
    "                        #Link to case\n",
    "                        link = search_result.find('a', {'class': 'h3'})['href']\n",
    "                        #link\n",
    "                        \n",
    "                        #Get metadata\n",
    "                        meta_text =  search_result.find('div', {'class': 'teal_font'}).get_text()\n",
    "                        meta_list = meta_text.splitlines()\n",
    "                        #meta_list\n",
    "                        \n",
    "                        #Initialise meta labels\n",
    "                        complainant = ''\n",
    "                        respondent = ''\n",
    "                        outcome = ''\n",
    "                        topic = ''\n",
    "                        ref = ''\n",
    "                        date = ''\n",
    "                        \n",
    "                        case_info = {'Case name': case_name,\n",
    "                                    'Hyperlink to the Pensions Ombudsman': link, \n",
    "                                    'Complainant': complainant,\n",
    "                                    'Respondent': respondent,\n",
    "                                    'Outcome': outcome,\n",
    "                                    'Complaint Topic': topic,\n",
    "                                    'Ref': ref,\n",
    "                                    'Date': date\n",
    "                        }\n",
    "                        \n",
    "                        #Last added status to capture any lines with no commencing label\n",
    "                        last_added = None\n",
    "                        \n",
    "                        for meta in meta_list:\n",
    "                            \n",
    "                            if 'complainant' in meta.lower():\n",
    "                                case_info['Complainant'] += meta.split(': ')[1]\n",
    "                                last_added = 'Complainant'\n",
    "                                \n",
    "                            elif 'respondent' in meta.lower():\n",
    "                                case_info['Respondent'] += meta.split(': ')[1]\n",
    "                                last_added = 'Respondent'\n",
    "                                \n",
    "                            elif 'outcome'  in meta.lower():\n",
    "                                case_info['Outcome'] += meta.split(': ')[1]\n",
    "                                last_added = 'Outcome'\n",
    "\n",
    "                            elif 'topic' in meta.lower():\n",
    "                                case_info['Complaint Topic'] += meta.split(': ')[1]\n",
    "                                last_added = 'Complaint Topic'\n",
    "\n",
    "                            elif 'ref' in meta.lower():\n",
    "                                case_info['Ref'] += meta.split(': ')[1]\n",
    "                                last_added = 'Ref'\n",
    "\n",
    "                            elif 'date' in meta.lower():\n",
    "                                case_info['Date'] += meta.split(': ')[1]\n",
    "                                last_added = 'Date'\n",
    "\n",
    "                            else:\n",
    "                                if last_added in case_info.keys():\n",
    "                                    case_info[last_added] += meta\n",
    "                                \n",
    "                        #Append case to return list and increase counter\n",
    "                        self.case_infos.append(case_info)\n",
    "            \n",
    "                        #result_counter += 1\n",
    "                    \n",
    "                    else:\n",
    "                        #stop if reached the maximum number of results wanted\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                #stop if reached the maximum number of results wanted\n",
    "                break     \n",
    "\n",
    "        #st.write(self.case_infos)\n",
    "            \n",
    "    #Function for getting judgment text\n",
    "    def get_judgments(self):\n",
    "\n",
    "        #st.write('Running get_judgments()')\n",
    "\n",
    "        #Create folder for saving files\n",
    "        doc_folder = 'UKPO_FILES'\n",
    "\n",
    "        #Save file\n",
    "        try:\n",
    "            os.mkdir(doc_folder)\n",
    "            print(f\"Directory '{doc_folder}' created successfully.\")\n",
    "        except:\n",
    "            print(f\"Directory '{doc_folder}' already exists.\")\n",
    "\n",
    "        #Initialise list of case_infos with judgment text\n",
    "        \n",
    "        self.case_infos_w_judgments = []\n",
    "\n",
    "        judgment_counter = 0\n",
    "            \n",
    "        for case_info in self.case_infos:\n",
    "\n",
    "            case_info_w_judgment = case_info.copy()\n",
    "\n",
    "            if judgment_counter < self.judgment_counter_bound:\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(15, 20))\n",
    "\n",
    "                result_url = case_info['Hyperlink to the Pensions Ombudsman']\n",
    "                result_response = requests.get(result_url, headers = {'User-Agent': 'whatever'})\n",
    "                result_soup = BeautifulSoup(result_response.content, \"lxml\")\n",
    "\n",
    "                #Get appeal status\n",
    "\n",
    "                appeal = ''\n",
    "\n",
    "                try:\n",
    "                    result_meta_text = result_soup.find('div', {'class': 'bg__teal decision-details'}).get_text()\n",
    "                    result_meta_list = result_meta_text.splitlines()\n",
    "                    \n",
    "                    for line in result_meta_list:\n",
    "                        if 'appeal' in line.lower():\n",
    "                            appeal = line.split(': ')[-1]\n",
    "                            break\n",
    "\n",
    "                except:\n",
    "                    \n",
    "                    print(f\"{case_info['Case name']}: can't get appeal status.\")\n",
    "\n",
    "                case_info_w_judgment.update({'Appeal': appeal}) \n",
    "                \n",
    "                #Get summary\n",
    "\n",
    "                summary = ''\n",
    "\n",
    "                try:\n",
    "                    summary = result_soup.find('div', {'class': 'article--body'}).get_text()\n",
    "\n",
    "                    if 'View determination' in summary:\n",
    "                        summary = summary.split('View determination')[0]\n",
    "                    \n",
    "                except:\n",
    "                    print(f\"{case_info['Case name']}: can't get summary.\")\n",
    "\n",
    "                case_info_w_judgment.update({'Summary': summary}) \n",
    "\n",
    "                #get judgment text or save .doc file locally\n",
    "                judgment_link_raw = result_soup.find('a', {'class': 'btn btn_teal download_btn'})['href']\n",
    "                judgment_link = 'https://www.pensions-ombudsman.org.uk' + judgment_link_raw\n",
    "                judgment_text = ''\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(15, 20))\n",
    "\n",
    "                try:\n",
    "\n",
    "                    #Save file first\n",
    "                    r = requests.get(judgment_link)\n",
    "                \n",
    "                    doc_file_name = f\"{doc_folder}/{judgment_link.split('/')[-1]}\"\n",
    "                    \n",
    "                    with open(doc_file_name, 'wb') as f:\n",
    "                        f.write(r.content)\n",
    "\n",
    "                    print(f\"{case_info['Case name']}: saved file.\")\n",
    "                    \n",
    "                    #If the judgment is in .doc, can only save the judgment to a local folder                    \n",
    "                    if '.pdf' in judgment_link:\n",
    "    \n",
    "                        judgment_text = pdf_image_judgment(url_or_path = judgment_link, url_given = True)\n",
    "                    \n",
    "                        print(f\"{case_info['Case name']}: got judgment.\")\n",
    "                    \n",
    "                    #if '.doc' in judgment_link:\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    print(f\"{case_info['Case name']}: can't get judgment or save file due to error: {e}.\")\n",
    "                    \n",
    "                #Add judgment to dict of case_info_w_judgment\n",
    "                case_info_w_judgment.update({'judgment': judgment_text}) \n",
    "\n",
    "                #Make link clickable\n",
    "                clickable_link = link(case_info['Hyperlink to the Pensions Ombudsman'])\n",
    "                case_info_w_judgment.update({'Hyperlink to the Pensions Ombudsman': clickable_link}) \n",
    "    \n",
    "                #Keep case_info_w_judgment\n",
    "                self.case_infos_w_judgments.append(case_info_w_judgment)\n",
    "\n",
    "                judgment_counter += 1\n",
    "\n",
    "                print(f\"Scrapped {judgment_counter}/{self.judgment_counter_bound} judgments.\")\n",
    "            \n",
    "            else:\n",
    "                #stop if reached the maximum number of results wanted\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5908320f-a29b-4129-9386-c35ae9a032e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 15:02:54.400 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def ukpo_search_function(keyword, \n",
    "                         outcomes_list, \n",
    "                         topics_list, \n",
    "                         types_list, \n",
    "                         sortby, \n",
    "                         judgment_counter_bound\n",
    "                        ):\n",
    "\n",
    "    #Conduct search\n",
    "    ukpo_search = ukpo_search_tool(keyword = keyword, \n",
    "                         outcomes_list = outcomes_list, \n",
    "                         topics_list = topics_list, \n",
    "                         types_list = types_list, \n",
    "                         sortby = sortby, \n",
    "                         judgment_counter_bound = judgment_counter_bound\n",
    "                )\n",
    "    \n",
    "    ukpo_search.search()\n",
    "\n",
    "    ukpo_search.get_case_infos()\n",
    "    \n",
    "    return ukpo_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5872a83-ccda-4408-a44f-29f3d418c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ukpo_search_preview(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "            \n",
    "    #Conduct search\n",
    "    \n",
    "    ukpo_search = ukpo_search_function(\n",
    "                keyword = df_master.loc[0, 'Keyword search'],\n",
    "                outcomes_list = df_master.loc[0, 'Select outcome'],\n",
    "                topics_list = df_master.loc[0, 'Select complaint topic'], \n",
    "                types_list = df_master.loc[0, 'Select type'], \n",
    "                sortby = df_master.loc[0, 'Sort by'],\n",
    "                judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']), \n",
    "                )\n",
    "    \n",
    "    results_count = ukpo_search.results_count\n",
    "    results_url = ukpo_search.results_url\n",
    "    results_to_show = ukpo_search.case_infos\n",
    "\n",
    "    #st.write(results_to_show)\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'results_to_show': results_to_show}\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 15:02:59.276 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-12-19 15:02:59.284 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-12-19 15:02:59.286 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-12-19 15:02:59.289 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2024-12-19 15:02:59.291 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import basic_model, flagship_model#, role_content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60382f2e-c063-4018-acab-9acfd25292fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9475a24b-3784-4cab-b901-112865bf45e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction and functions\n",
    "\n",
    "#system_instruction = role_content\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def ukpo_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "    \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "                \n",
    "    ukpo_search = ukpo_search_function(\n",
    "                keyword = df_master.loc[0, 'Keyword search'],\n",
    "                outcomes_list = df_master.loc[0, 'Select outcome'],\n",
    "                topics_list = df_master.loc[0, 'Select complaint topic'], \n",
    "                types_list = df_master.loc[0, 'Select type'], \n",
    "                sortby = df_master.loc[0, 'Sort by'],\n",
    "                judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments']), \n",
    "                )\n",
    "\n",
    "    #Get judgments\n",
    "    ukpo_search.get_judgments()\n",
    "\n",
    "    for judgment_json in ukpo_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "        \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = flagship_model\n",
    "    else:        \n",
    "        gpt_model = basic_model\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, system_instruction = system_instruction)\n",
    "\n",
    "    #Remove 'judgment' column\n",
    "    if (pop_judgment() > 0) and ('judgment' in df_updated.columns):\n",
    "        df_updated.pop('judgment')\n",
    "    \n",
    "    return df_updated"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
