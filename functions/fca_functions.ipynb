{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "import httplib2\n",
    "import urllib\n",
    "from urllib.request import urlretrieve\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "import copy\n",
    "import math\n",
    "\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface == True\n",
      "current_dir == /Users/Ben/Library/CloudStorage/Dropbox/Python/GitHub/lawtodata\n",
      "Running locally or on Streamlit\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_range_check, date_parser, save_input, pdf_judgment\n",
    "#Import variables\n",
    "from functions.common_functions import huggingface, today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
    "\n",
    "#Load oalc\n",
    "from functions.oalc_functions import get_judgment_from_oalc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# Federal Courts search engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b2f7a-41a4-44a3-bd25-99cbe8a85957",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb5735b-cbd1-454a-937d-bdefcdcbcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define format functions for courts choice, and GPT questions\n",
    "\n",
    "#auxiliary lists and variables\n",
    "\n",
    "fca_courts = {'All': 'FCA+FCAFC+IRCA+ACOMPT+ACOPYT+ADFDAT+FPDT+ATPT+NFSC',\n",
    "              'Federal Court': 'FCA+FCAFC', \n",
    "              'Industrial Relations Court of Australia': 'IRCA', \n",
    "              'Australian Competition Tribunal': 'ACOMPT', \n",
    "              'Copyright Tribunal': 'ACOPYT', \n",
    "              'Defence Force Discipline Appeal Tribunal': 'ADFDAT', \n",
    "              'Federal Police Discipline Tribunal': 'FPDT', \n",
    "              'Trade Practices Tribunal': 'ATPT', \n",
    "              'Supreme Court of Norfolk Island': 'NFSC',\n",
    "             }\n",
    "\n",
    "fca_courts_list = list(fca_courts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f676e99-b155-4dee-8d25-3cf805348810",
   "metadata": {},
   "outputs": [],
   "source": [
    "npa_dict = {'All': '', \n",
    "    'Admin., Constitutional, Human Rights': 'administrative', \n",
    "  'Admiralty and Maritime': 'admiralty', \n",
    "  'Commercial and Corporations': 'commercial', \n",
    "  'Employment and Industrial Relations': 'employment', \n",
    "  'Federal Crime and Related Proceedings': 'crime', \n",
    "  'Intellectual Property': 'intellectual', \n",
    "  'Native Title': 'native', \n",
    "  'Taxation': 'taxation',\n",
    "      'Other Federal Jurisdiction': 'other',\n",
    "    }\n",
    "\n",
    "npa_list = list(npa_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43ab32f9-f1c1-4f79-8eec-10fd4d6547ee",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "sort_dict = {\"Relevance\": \"\",\n",
    "    \"Most Recent\": \"date\",\n",
    "    \"Least Recent\": \"adate\",\n",
    "    \"Title Ascending\": \"metaMNC\",\n",
    "    \"Title Descending\": \"dmetaMNC\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "cab75516-2893-46ba-a996-e2a367e23e5e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "fca_metalabels = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'Date.published', 'Appeal_to']\n",
    "#'MNC', 'FileName', 'Asset_ID', \n",
    "fca_metalabels_droppable = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'Date.published', 'Appeal_to', 'Order']\n",
    "#'FileName', 'Asset_ID', "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539d3ee-d2a7-45ec-b5bf-6413804aeb00",
   "metadata": {},
   "source": [
    "### Search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691465c5-24d4-4139-a259-faa25c043031",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from functions.common_functions import running_locally_dir, get_uc_driver\n",
    "\n",
    "#For downloading judgments\n",
    "download_dir = f\"{os.getcwd()}/FCA_PDFs\"\n",
    "\n",
    "#Headless mode?\n",
    "if running_locally_dir in os.getcwd(): \n",
    "\n",
    "    headless = False\n",
    "\n",
    "else:\n",
    "\n",
    "    headless = False\n",
    "    \n",
    "    from pyvirtualdisplay import Display\n",
    "    \n",
    "    display = Display(visible=0, size=(1200, 1600))  \n",
    "    display.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77dda4d0-c28f-4c8a-8f5e-0d7e92bfeaa4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Get uc modules\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from webdriver_manager.core.os_manager import ChromeType\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait as Wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import ElementClickInterceptedException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c26b3-7f47-476d-a00f-4ce71eb62694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.common_functions import link, split_title_mnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4df9a781-66e5-4262-9ec7-436818e21b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class fca_search_tool:\n",
    "\n",
    "    def __init__(self,\n",
    "                court = list(fca_courts.keys())[0], \n",
    "                case_name_mnc= None, \n",
    "                judge =None, \n",
    "                reported_citation =None, \n",
    "                file_number =None, \n",
    "                npa = list(npa_dict.keys())[0], \n",
    "                with_all_the_words = None, \n",
    "                with_at_least_one_of_the_words = None, \n",
    "                without_the_words = None, \n",
    "                phrase = None, \n",
    "                proximity = None, \n",
    "                on_this_date = None, \n",
    "                after_date = None, \n",
    "                before_date = None, \n",
    "                legislation = None, \n",
    "                cases_cited = None, \n",
    "                catchwords = None,\n",
    "                 sort = list(sort_dict.keys())[0], \n",
    "                judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "\n",
    "        #Initialise parameters\n",
    "        self.court = court\n",
    "        self.case_name_mnc= case_name_mnc\n",
    "        self.judge =judge\n",
    "        self.reported_citation =reported_citation\n",
    "        self.file_number =file_number\n",
    "        self.npa = npa\n",
    "        self.with_all_the_words = with_all_the_words\n",
    "        self.with_at_least_one_of_the_words = with_at_least_one_of_the_words\n",
    "        self.without_the_words = without_the_words\n",
    "        self.phrase = phrase\n",
    "        self.proximity = proximity\n",
    "        self.on_this_date = on_this_date\n",
    "        self.after_date = after_date\n",
    "        self.before_date = before_date\n",
    "        self.legislation = legislation\n",
    "        self.cases_cited = cases_cited\n",
    "        self.catchwords = catchwords\n",
    "        self.sort = sort\n",
    "\n",
    "        self.judgment_counter_bound = judgment_counter_bound\n",
    "        \n",
    "        self.page = 1\n",
    "                \n",
    "        self.results_count = 0\n",
    "\n",
    "        self.total_pages = 1\n",
    "        \n",
    "        self.results_url = ''\n",
    "\n",
    "        self.results_url_to_show = ''\n",
    "        \n",
    "        self.soup = None\n",
    "        \n",
    "        self.case_infos = []\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "        \n",
    "        #For getting judgment directly from FCA database if can't get from OALC\n",
    "        self.case_infos_direct = []\n",
    "\n",
    "    #Function for getting case infos from search results page\n",
    "    def get_case_infos(self):\n",
    "        \n",
    "        results_list = self.soup.find_all('div', attrs={'class' : 'result'})\n",
    "            \n",
    "        for result in results_list:\n",
    "            \n",
    "            if len(self.case_infos) < min(self.judgment_counter_bound, self.results_count):\n",
    "    \n",
    "                #Initialise default values\n",
    "                title = ''\n",
    "                case_name = ''\n",
    "                mnc = ''\n",
    "                link_to_case = ''\n",
    "                date = ''\n",
    "                judge = ''\n",
    "                catchwords = ''\n",
    "                subject = ''\n",
    "                \n",
    "                #Get full title\n",
    "                \n",
    "                title = result.h3.get_text(strip = True)\n",
    "    \n",
    "                #Get PDF status\n",
    "                pdf_status = False\n",
    "                \n",
    "                if '(pdf' in title.lower():\n",
    "                    \n",
    "                    pdf_status = True\n",
    "                \n",
    "                #Get case name and mnc\n",
    "                case_name_mnc = split_title_mnc(title)\n",
    "                \n",
    "                case_name = case_name_mnc[0]\n",
    "                \n",
    "                mnc = case_name_mnc[1]\n",
    "                \n",
    "                if '(PDF' in mnc:\n",
    "                    mnc = mnc.replace('(PDF', '')\n",
    "                \n",
    "                #Get link to case\n",
    "                link_to_case = result.h3.find('a').get('href')\n",
    "    \n",
    "                #Get decision date, subject area, judge\n",
    "                date_area_court_str = str(result.find('p', attrs={'class' : 'meta'}))\n",
    "                date_area_court_raw = str(date_area_court_str).split('<span class=\"divide\"></span>')\n",
    "    \n",
    "                date = date_area_court_raw[0].replace('<p class=\"meta\">', '')\n",
    "                \n",
    "                if len(date) > 0:\n",
    "                    if date[-1] == ' ':\n",
    "                        date = date[: -1]\n",
    "                \n",
    "                judge = date_area_court_raw[-1].replace('</p>', '')\n",
    "                \n",
    "                subject = result.find('p', attrs={'class' : 'meta'}).text.replace(date, '').replace(judge, '')\n",
    "                \n",
    "                if len(subject) > 0:\n",
    "                    if subject[0] == ' ':\n",
    "                        subject = subject[1:]\n",
    "    \n",
    "                #Get catchwords\n",
    "                catchwords = ''\n",
    "                try:\n",
    "                    catchwords = result.find('p', attrs={'class' : 'summary'}).get_text(strip = True)\n",
    "                except:\n",
    "                    print(f\"{case_name}: can't get catchwords\")\n",
    "                \n",
    "                case_info = {'Case name': case_name,\n",
    "                     'Medium neutral citation': mnc,\n",
    "                    'Hyperlink to Federal Court Digital Law Library' : link_to_case,\n",
    "                    'Judge': judge,\n",
    "                     'Judgment_Dated' : date,  \n",
    "                     'Catchwords' : catchwords,  \n",
    "                     'Subject' : subject,\n",
    "                    'Judgment in PDF': pdf_status\n",
    "                            }\n",
    "                self.case_infos.append(case_info)\n",
    "    \n",
    "    #Function for getting search results\n",
    "    def search(self):\n",
    "\n",
    "        #Reset infos of cases found\n",
    "        self.case_infos = []\n",
    "        \n",
    "        params_raw = []\n",
    "        \n",
    "        base_url = 'https://www.fedcourt.gov.au/digital-law-library/judgments/search'\n",
    "\n",
    "        #Url for selenium to start\n",
    "\n",
    "        self.results_url = base_url\n",
    "        \n",
    "        #Before entering year, justice or CLR, must enter keywords or case number first, then load\n",
    "\n",
    "        browser = get_uc_driver(download_dir = download_dir, headless = headless)\n",
    "        \n",
    "        browser.get(self.results_url)\n",
    "\n",
    "        #Clear form first\n",
    "        clear_form = Wait(browser, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"a.clear-form\")))\n",
    "        clear_form.click()\n",
    "        \n",
    "        # Wait for the Court dropdown\n",
    "        court_select_el = Wait(browser, 15).until(EC.presence_of_element_located((By.ID, \"scope\")))\n",
    "        court_select = Select(court_select_el)\n",
    "        \n",
    "        if self.court != list(fca_courts.keys())[0]:\n",
    "            \n",
    "            court_select.select_by_value(fca_courts[self.court])\n",
    "        \n",
    "        # Wait for the NPA dropdown\n",
    "        npa_select_el = Wait(browser, 15).until(EC.presence_of_element_located((By.ID, \"NPA\")))\n",
    "        npa_select = Select(npa_select_el)\n",
    "        \n",
    "        if self.npa != list(npa_dict.keys())[0]:\n",
    "            npa_select.select_by_visible_text(npa_dict[self.npa])\n",
    "        \n",
    "        # Case Name / MNC\n",
    "        case_name = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"caseName\")))\n",
    "        \n",
    "        if (not pd.isna(self.case_name_mnc)) and (not self.case_name_mnc == None) and (not str(self.case_name_mnc) == 'None'):\n",
    "            \n",
    "            case_name.send_keys(self.case_name_mnc)\n",
    "        \n",
    "        # Judge\n",
    "        judge = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"searchJudge\")))\n",
    "        \n",
    "        if (not pd.isna(self.judge)) and (not self.judge == None) and (not str(self.judge) == 'None'):\n",
    "        \n",
    "            judge.send_keys(self.judge)\n",
    "        \n",
    "        # Reported Citation\n",
    "        reported = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"searchReportedCitation\")))\n",
    "        \n",
    "        if (not pd.isna(self.reported_citation)) and (not self.reported_citation == None) and (not str(self.reported_citation) == 'None'):\n",
    "            \n",
    "            reported.send_keys(self.reported_citation)\n",
    "        \n",
    "        # File number\n",
    "        file_no = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"searchFileNumber\")))\n",
    "        \n",
    "        if (not pd.isna(self.file_number)) and (not self.file_number == None) and (not str(self.file_number) == 'None'):\n",
    "            \n",
    "            file_no.send_keys(self.file_number)\n",
    "            \n",
    "        #Click the \"Full Text & Proximity\" accordion full_text_tab\n",
    "        full_text_tab = Wait(browser, 15).until(EC.element_to_be_clickable(\n",
    "            (By.CSS_SELECTOR, 'h2.accordion a[href=\"#fulltext\"]')\n",
    "        ))\n",
    "        full_text_tab.click()\n",
    "        \n",
    "        # Wait for a field inside the section to be visible (means it's \"opened\")\n",
    "        Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"allWords\")))\n",
    "        \n",
    "        #With ALL the words, With at least one of the words, Without the words, Phrase, and Proximity\n",
    "        all_words = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"allWords\")))\n",
    "        \n",
    "        if (not pd.isna(self.with_all_the_words)) and (not self.with_all_the_words == None) and (not str(self.with_all_the_words) == 'None'):\n",
    "        \n",
    "            all_words.send_keys(self.with_all_the_words)\n",
    "        \n",
    "        one_word = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"oneWord\")))\n",
    "        \n",
    "        if (not pd.isna(self.with_at_least_one_of_the_words)) and (not self.with_at_least_one_of_the_words == None) and (not str(self.with_at_least_one_of_the_words) == 'None'):\n",
    "            \n",
    "            one_word.send_keys(self.with_at_least_one_of_the_words)\n",
    "        \n",
    "        without_words = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"withoutWords\")))\n",
    "        \n",
    "        if (not pd.isna(self.without_the_words)) and (not self.without_the_words == None) and (not str(self.without_the_words) == 'None'):\n",
    "            \n",
    "            without_words.clear()\n",
    "            without_words.send_keys(self.without_the_words)\n",
    "        \n",
    "        phrase = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"phrase\")))\n",
    "        \n",
    "        if (not pd.isna(self.phrase)) and (not self.phrase == None) and (not str(self.phrase) == 'None'):\n",
    "            \n",
    "            phrase.send_keys(self.phrase)\n",
    "        \n",
    "        proximity = Wait(browser, 15).until(EC.element_to_be_clickable((By.ID, \"proximity\")))\n",
    "        \n",
    "        if (not pd.isna(self.proximity)) and (not self.proximity == None) and (not str(self.proximity) == 'None'):\n",
    "            \n",
    "            proximity.send_keys(self.proximity)\n",
    "        \n",
    "        \n",
    "        #Click the Date tab\n",
    "        date_tab = Wait(browser, 15).until(EC.element_to_be_clickable(\n",
    "            (By.CSS_SELECTOR, 'h2.accordion a[href=\"#date\"]')\n",
    "        ))\n",
    "        date_tab.click()\n",
    "        \n",
    "        # Wait until a field inside the Date section is visible\n",
    "        Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"date-specific\")))\n",
    "        \n",
    "        #On this date, After and Before\n",
    "        on_this_date = Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"date-specific\")))\n",
    "        \n",
    "        if (not pd.isna(self.on_this_date)) and (not self.on_this_date == None) and (not str(self.on_this_date) == 'None'):\n",
    "            \n",
    "            on_this_date.send_keys(self.on_this_date)\n",
    "        \n",
    "        date_from = Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"date-from\")))\n",
    "        \n",
    "        if (not pd.isna(self.after_date)) and (not self.after_date == None) and (not str(self.after_date) == 'None'):\n",
    "            \n",
    "            date_from.send_keys(self.after_date)\n",
    "        \n",
    "        date_to = Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"date-to\")))\n",
    "        \n",
    "        if (not pd.isna(self.before_date)) and (not self.before_date == None) and (not str(self.before_date) == 'None'):\n",
    "\n",
    "            date_to.send_keys(self.before_date)\n",
    "        \n",
    "        # Click the Legislation accordion tab\n",
    "        leg_tab = Wait(browser, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'h2.accordion a[href=\"#legislation\"]')))\n",
    "        leg_tab.click()\n",
    "        \n",
    "        #Legislation, Cases Cited, and Catchwords?\n",
    "        \n",
    "        legislation = Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"searchLegislation\")))\n",
    "        \n",
    "        if (not pd.isna(self.legislation)) and (not self.legislation == None) and (not str(self.legislation) == 'None'):\n",
    "            \n",
    "            legislation.send_keys(self.legislation)\n",
    "        \n",
    "        cases_cited = Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"searchCasesCited\")))\n",
    "        \n",
    "        if (not pd.isna(self.cases_cited)) and (not self.cases_cited == None) and (not str(self.cases_cited) == 'None'):\n",
    "            \n",
    "            cases_cited.send_keys(self.cases_cited)\n",
    "        \n",
    "        catchwords = Wait(browser, 15).until(EC.visibility_of_element_located((By.ID, \"searchCatchwords\")))\n",
    "        \n",
    "        if (not pd.isna(self.catchwords)) and (not self.catchwords == None) and (not str(self.catchwords) == 'None'):\n",
    "                        \n",
    "            catchwords.send_keys(self.catchwords)\n",
    "\n",
    "        #Submit\n",
    "        search_button = Wait(browser, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'fieldset.actions input[type=\"submit\"][value=\"Search\"]')))\n",
    "        search_button.click()\n",
    "\n",
    "        #Wait until number of search results present\n",
    "        RESULT_CARD    = (By.CSS_SELECTOR, \"#fb-results .result\")\n",
    "        NO_RESULTS_BOX = (By.ID, \"fb-no-results\")\n",
    "        \n",
    "        Wait(browser, 15).until(EC.any_of(\n",
    "            EC.presence_of_element_located(RESULT_CARD),\n",
    "            EC.presence_of_element_located(NO_RESULTS_BOX),\n",
    "        ))\n",
    "    \n",
    "        #If positive results found\n",
    "        if browser.find_elements(*RESULT_CARD):\n",
    "    \n",
    "            summary = Wait(browser, 15).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \".tools p.txarial\")))\n",
    "            m = re.search(r\"\\bof\\s+([\\d,]+)\\b\", summary.text)\n",
    "            results_count = int(m.group(1).replace(\",\", \"\")) if m else 0\n",
    "    \n",
    "            #Update self.results_count\n",
    "            self.results_count = results_count\n",
    "\n",
    "        #Update self.results_url\n",
    "        self.results_url = browser.current_url\n",
    "\n",
    "        print(f\"There are {self.results_count} search results from self.results_url == {self.results_url}\")\n",
    "        \n",
    "        #If at least 1 result\n",
    "        if self.results_count > 0:\n",
    "\n",
    "            #Get page count\n",
    "            #20 results per page. Each page url ends with 20*(page number - 1) + 1\n",
    "            self.total_pages = math.ceil(self.results_count/20)\n",
    "\n",
    "            #Sort results\n",
    "            # Wait until the select exists\n",
    "            sort_select_el = Wait(browser, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"form.updateSort select[name='sort']\")))\n",
    "            sort_select = Select(sort_select_el)\n",
    "            \n",
    "            if self.sort != list(sort_dict.keys())[0]:\n",
    "    \n",
    "                sort_select.select_by_value(sort_dict[self.sort])\n",
    "                \n",
    "                # Click Sort button\n",
    "                sort_button = Wait(browser, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"form.updateSort input[type='submit']\")))\n",
    "                sort_button.click()\n",
    "                \n",
    "                # Wait for navigation to complete (URL contains sort=adate)\n",
    "                Wait(browser, 15).until(lambda d: f\"sort={sort_dict[self.sort]}\" in d.current_url)\n",
    "\n",
    "            #Wait search results present\n",
    "            loaded = Wait(browser, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#fb-results .result h3 a\")))\n",
    "            \n",
    "            #Update self.soup\n",
    "            self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "            for page in range(0, self.total_pages):\n",
    "\n",
    "                if len(self.case_infos) < min(self.results_count, self.judgment_counter_bound):\n",
    "                    \n",
    "                    #Update self.soup from new page if necessary\n",
    "                    if page > 0:\n",
    "    \n",
    "                        #Pause to avoid getting kicked out\n",
    "                        pause.seconds(np.random.randint(10, 15))\n",
    "\n",
    "                        next20 = Wait(browser, 15).until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'a[rel=\"next\"].fb-next-result-page')))\n",
    "                        next20.click()\n",
    "                        \n",
    "                        #Wait until search results present, if any\n",
    "                        loaded = Wait(browser, 15).until(EC.presence_of_element_located((By.CSS_SELECTOR, \"#fb-results .result h3 a\")))\n",
    "\n",
    "                        #Update self.soup\n",
    "                        self.soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "\n",
    "                    print(f\"Getting results from page {page} (0 denotes first page)\")\n",
    "    \n",
    "                #Get search results from current page\n",
    "                self.get_case_infos()\n",
    "\n",
    "        browser.quit()\n",
    "\n",
    "    #Function for attaching judgment text to case_info dict\n",
    "    def attach_judgment(self, case_info):\n",
    "\n",
    "        judgment_dict = copy.deepcopy(case_info)\n",
    "        \n",
    "        judgment_url = case_info['Hyperlink to Federal Court Digital Law Library']\n",
    "    \n",
    "        #Get judgment text\n",
    "        judgment_text = ''\n",
    "    \n",
    "        #Check if getting taken to a PDF\n",
    "        if 'Judgment in PDF' not in judgment_dict.keys():\n",
    "    \n",
    "            judgment_dict.update({'Judgment in PDF': False})\n",
    "        \n",
    "        #Check if not taken to a PDF\n",
    "        if not bool(judgment_dict['Judgment in PDF']):\n",
    "        \n",
    "            try:\n",
    "    \n",
    "                browser = get_uc_driver(download_dir = download_dir, headless = headless)\n",
    "                browser.get(judgment_url)\n",
    "        \n",
    "                #Wait until judgment present\n",
    "                loaded = Wait(browser, 15).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"div.judgment_content\")))\n",
    "\n",
    "                #Wait until end of judgment\n",
    "                top_link = Wait(browser, 15).until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"div.top-link-wrapper a.top-link\")))\n",
    "\n",
    "                #pause.seconds(10)\n",
    "                \n",
    "                soup = BeautifulSoup(browser.page_source, \"lxml\")\n",
    "                \n",
    "                browser.quit()\n",
    "                \n",
    "                #Attach judgment\n",
    "                try:\n",
    "                    \n",
    "                    judgment_text = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "                                    \n",
    "                except:\n",
    "                    \n",
    "                    judgment_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "                #Attach meta tags\n",
    "                meta_tags = soup.find_all(\"meta\")\n",
    "            \n",
    "                #Attach meta tags\n",
    "                if len(meta_tags)>0:\n",
    "                    for tag_index in range(len(meta_tags)):\n",
    "                        meta_name = meta_tags[tag_index].get(\"name\")\n",
    "                        if meta_name in fca_metalabels:\n",
    "                            meta_content = meta_tags[tag_index].get(\"content\")\n",
    "                            judgment_dict.update({meta_name: meta_content})\n",
    "                            \n",
    "            except Exception as e:\n",
    "                \n",
    "                print(f\"{judgment_dict['Case name']}: can't get html judgment or meta due to error {e}.\")\n",
    "                \n",
    "        #Check if gets taken to a PDF\n",
    "        else:\n",
    "            \n",
    "            print(f\"{judgment_dict['Case name']}: trying to get pdf judgment\")\n",
    "            \n",
    "            #Get judgment pdf text\n",
    "            try:\n",
    "                \n",
    "                #judgment_text = pdf_judgment(url_or_path = judgment_url, url_given = True)\n",
    "\n",
    "                browser = get_uc_driver(download_dir = download_dir, headless = headless)\n",
    "                browser.get(judgment_url)\n",
    "                \n",
    "                pdf_file = judgment_url.split('/')[-1]    \n",
    "    \n",
    "                pdf_file = urllib.parse.unquote(pdf_file)\n",
    "                \n",
    "                pdf_path = f\"{download_dir}/{pdf_file.upper()}.pdf\"\n",
    "    \n",
    "                #Limiting waiting time for downloading PDF to 1 min\n",
    "                \n",
    "                waiting_counter = 0\n",
    "                \n",
    "                while ((not os.path.exists(pdf_path)) and (waiting_counter < 10)):\n",
    "                    pause.seconds(10)\n",
    "                    waiting_counter += 1\n",
    "                                \n",
    "                print(f\"{case_info['Case name']}: Trying to OCR pdf from pdf_path == {pdf_path}\")\n",
    "    \n",
    "                judgment_text = pdf_judgment(url_or_path = pdf_path, url_given = False)\n",
    "                                                                    \n",
    "                #MUST remove pdf from download folder automatically or manually\n",
    "                os.remove(pdf_path)\n",
    "    \n",
    "                browser.quit()\n",
    "                \n",
    "            except Exception as e:\n",
    "                \n",
    "                print(f\"{judgment_dict['Case name']}: can't get pdf judgment due to error {e}.\")\n",
    "    \n",
    "        judgment_dict['judgment'] = judgment_text\n",
    "        \n",
    "        return judgment_dict\n",
    "\n",
    "    #Function for getting all requested judgments\n",
    "    def get_judgments(self):\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "\n",
    "        #Search if not done yet\n",
    "        if len(self.case_infos) == 0:\n",
    "\n",
    "            self.search()\n",
    "\n",
    "        #If huggingface enabled\n",
    "        if huggingface == True:\n",
    "\n",
    "            #Create a list of mncs for HuggingFace:\n",
    "            mnc_list = []\n",
    "    \n",
    "            for case_info in self.case_infos:\n",
    "\n",
    "                if len(self.case_infos_w_judgments) < self.judgment_counter_bound:\n",
    "                    \n",
    "                    #Add mnc to list for HuggingFace\n",
    "                    mnc_list.append(case_info['Medium neutral citation'])\n",
    "    \n",
    "            #Get judgments from oalc first\n",
    "            mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "        \n",
    "            #Append OALC judgment \n",
    "            for case_info in self.case_infos:\n",
    "                \n",
    "                #Append judgments from oalc first\n",
    "                if case_info['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                    \n",
    "                    case_info.update({'judgment': mnc_judgment_dict[case_info['Medium neutral citation']]})\n",
    "\n",
    "                    #Make link clickable\n",
    "                    judgment_url = case_info['Hyperlink to Federal Court Digital Law Library']\n",
    "                    case_info.update({'Hyperlink to Federal Court Digital Law Library': link(judgment_url)})\n",
    "\n",
    "                    #Add case_info to self.case_infos_w_judgments\n",
    "                    self.case_infos_w_judgments.append(case_info)\n",
    "    \n",
    "                    print(f\"{case_info['Case name']} {case_info['Medium neutral citation']}: got judgment from OALC\")\n",
    "    \n",
    "                else:\n",
    "                    \n",
    "                    #To get from FCA database directly if can't get from OALC\n",
    "                    self.case_infos_direct.append(case_info)\n",
    "\n",
    "            print(f\"Scraped {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)} judgments from OALC\")\n",
    "\n",
    "        else:\n",
    "            \n",
    "            #If huggingface not enabled\n",
    "            self.case_infos_direct = copy.deepcopy(self.case_infos)\n",
    "        \n",
    "        #Get judgments from FCA database directly\n",
    "        for case_info in self.case_infos_direct:\n",
    "\n",
    "            if len(self.case_infos_w_judgments) < self.judgment_counter_bound:\n",
    "\n",
    "                #Pause to avoid getting kicked out\n",
    "                pause.seconds(np.random.randint(10, 15))\n",
    "    \n",
    "                case_info = self.attach_judgment(case_info)\n",
    "    \n",
    "                #Make link clickable\n",
    "                judgment_url = case_info['Hyperlink to Federal Court Digital Law Library']\n",
    "                case_info.update({'Hyperlink to Federal Court Digital Law Library': link(judgment_url)})\n",
    "    \n",
    "                #Add case_info to self.case_infos_w_judgments\n",
    "    \n",
    "                self.case_infos_w_judgments.append(case_info)\n",
    "                \n",
    "                print(f\"{case_info['Case name']} {case_info['Medium neutral citation']}: got judgment from FCA directly\")\n",
    "                \n",
    "                print(f\"Scraped {len(self.case_infos_w_judgments)}/{min(self.results_count, self.judgment_counter_bound)} judgments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f63d1-8a5b-41ed-9c95-8fcf5637cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fca_search_preview(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "        \n",
    "    fca_search = fca_search_tool(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'],\n",
    "                    sort = df_master.loc[0, 'Sort'],\n",
    "                    )\n",
    "\n",
    "    fca_search.search()\n",
    "    \n",
    "    results_count = fca_search.results_count\n",
    "    \n",
    "    case_infos = fca_search.case_infos\n",
    "\n",
    "    results_url = fca_search.results_url\n",
    "\n",
    "    #st.write(results_url)\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'case_infos': case_infos}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 07:53:03.016 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-02-21 07:53:03.017 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-02-21 07:53:03.018 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-02-21 07:53:03.019 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-02-21 07:53:03.020 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_batch_input\n",
    "#Import variables\n",
    "from functions.gpt_functions import basic_model#, flagship_model#, role_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20ba06e-2c4c-4ae6-ac7e-06a8d84d4252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "#system_instruction = role_content\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1201c6-e12d-40c8-b13a-9632ab67102f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-04 10:55:38.136 No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#For getting judgments from the Federal Court if unavailable in OALC\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def fca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "\n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search    \n",
    "    fca_search = fca_search_tool(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'],\n",
    "                     sort = df_master.loc[0, 'Sort'],\n",
    "                     judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                    )\n",
    "    \n",
    "    fca_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in fca_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    #if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        #gpt_model = flagship_model\n",
    "    #else:        \n",
    "        #gpt_model = basic_model\n",
    "\n",
    "    gpt_model = df_master.loc[0, 'gpt_model']\n",
    "\n",
    "    temperature = df_master.loc[0, 'temperature']\n",
    "\n",
    "    reasoning_effort = df_master.loc[0, 'reasoning_effort']\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, temperature = temperature, reasoning_effort = reasoning_effort, system_instruction = system_instruction)\n",
    "\n",
    "    #Pop jugdment\n",
    "    if (pop_judgment() > 0) and ('judgment' in df_updated.columns):\n",
    "        df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in fca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90e35be4-5b48-4711-bddf-bdbbd566e93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 07:53:03.037 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def fca_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Conduct search    \n",
    "    fca_search = fca_search_tool(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'],\n",
    "                     sort = df_master.loc[0, 'Sort'],\n",
    "                     judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                    )\n",
    "    \n",
    "    fca_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in fca_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "                        \n",
    "    #Drop metadata if not wanted\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in fca_metalabels_droppable:\n",
    "            if meta_label in df_individual.columns:\n",
    "                df_individual.pop(meta_label)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    #if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        #gpt_model = flagship_model\n",
    "    #else:        \n",
    "        #gpt_model = basic_model\n",
    "\n",
    "    gpt_model = df_master.loc[0, 'gpt_model']\n",
    "\n",
    "    temperature = df_master.loc[0, 'temperature']\n",
    "\n",
    "    reasoning_effort = df_master.loc[0, 'reasoning_effort']\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, temperature = temperature, reasoning_effort = reasoning_effort, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d3ee80-003b-4657-a24e-96134bfe0a45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
