{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3b8b879",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2312235",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "111133cd-06ce-45a6-8556-91199246e001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By default, users are allowed to use their own account\n",
      "The pause between judgment scraping is 5 second.\n",
      "\n",
      "The lower bound on lenth of judgment text to process is 5000 tokens.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_range_check, au_date, save_input, pdf_judgment\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e819e27",
   "metadata": {},
   "source": [
    "# Federal Courts search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3329d8-1716-4570-8dd0-4b5aa22aaed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.common_functions import link, split_title_mnc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cb5735b-cbd1-454a-937d-bdefcdcbcb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define format functions for courts choice, and GPT questions\n",
    "\n",
    "#auxiliary lists and variables\n",
    "\n",
    "fca_courts = {'Federal Court': 'fca', \n",
    "              'Industrial Relations Court of Australia': 'irc', \n",
    "              'Australian Competition Tribunal': 'tribunals%2Facompt', \n",
    "              'Copyright Tribunal': 'tribunals%2Facopyt', \n",
    "              'Defence Force Discipline Appeal Tribunal': 'tribunals%2Fadfdat', \n",
    "              'Federal Police Discipline Tribunal': 'tribunals%2Ffpdt', \n",
    "              'Trade Practices Tribunal': 'tribunals%2Fatpt', \n",
    "              'Supreme Court of Norfolk Island': 'nfsc',\n",
    "             'All': ''}\n",
    "\n",
    "fca_courts_list = list(fca_courts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a0e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function turning search terms to search results url\n",
    "def fca_search(court = '', \n",
    "               case_name_mnc= '', \n",
    "               judge ='', \n",
    "               reported_citation ='', \n",
    "               file_number ='', \n",
    "               npa = '', \n",
    "               with_all_the_words = '', \n",
    "               with_at_least_one_of_the_words = '', \n",
    "               without_the_words = '', \n",
    "               phrase = '', \n",
    "               proximity = '', \n",
    "               on_this_date = '', \n",
    "               after_date = '', \n",
    "               before_date = '', \n",
    "               legislation = '', \n",
    "               cases_cited = '', \n",
    "               catchwords = ''):\n",
    "\n",
    "    #If only searching FCA\n",
    "    #base_url = \"https://search2.fedcourt.gov.au/s/search.html?collection=judgments&sort=date&meta_v_phrase_orsand=judgments%2FJudgments%2Ffca\"\n",
    "\n",
    "    #If allowing users to search which court\n",
    "    base_url = \"https://search2.fedcourt.gov.au/s/search.html?collection=judgments&sort=date&meta_v_phrase_orsand=judgments%2FJudgments%2F\" + fca_courts[court]\n",
    "    \n",
    "    params = {'meta_2' : case_name_mnc, \n",
    "              'meta_A' : judge, \n",
    "              'meta_z' : reported_citation, \n",
    "              'meta_3' : file_number, \n",
    "              'meta_n_phrase_orsand' : npa, \n",
    "              'query_sand' : with_all_the_words, \n",
    "              'query_or' : with_at_least_one_of_the_words, \n",
    "              'query_not' : without_the_words, \n",
    "              'query_phrase' : phrase, \n",
    "              'query_prox' : proximity, \n",
    "              'meta_d' : on_this_date, \n",
    "              'meta_d1' : after_date, \n",
    "              'meta_d2' : before_date, \n",
    "              'meta_7' : legislation, \n",
    "              'meta_4' : cases_cited, \n",
    "              'meta_B' : catchwords}\n",
    "\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    # Process the response (e.g., extract relevant information)\n",
    "    # Your code here...\n",
    "    return response.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6321d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 17:15:07.845 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function turning search results url to links to judgments\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def fca_search_results_to_judgment_links(url_search_results, judgment_counter_bound):\n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "\n",
    "    #Start counter\n",
    "\n",
    "    counter = 1\n",
    "    \n",
    "    # Get links of first 20 results\n",
    "    #links_raw = soup.find_all(\"a\", href=re.compile(\"fca\")) #If want to search FCA only\n",
    "    \n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "    links = []\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            remove_title = str(i).split('\" title=')[0]\n",
    "            remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "            if 'a class=' not in remove_leading_words:\n",
    "                case_name_mnc = split_title_mnc(i.get_text(strip = True))\n",
    "                case_name = case_name_mnc[0]\n",
    "                mnc = case_name_mnc[1]\n",
    "                if '(PDF' in mnc:\n",
    "                    mnc = mnc.replace('(PDF', '')\n",
    "                    \n",
    "                case_info = {'Case name': case_name,\n",
    "                     'Medium neutral citation': mnc,\n",
    "                    'Hyperlink to Federal Court Digital Law Library' : remove_leading_words\n",
    "                            }\n",
    "                links.append(case_info)\n",
    "                counter = counter + 1\n",
    "\n",
    "    #Go beyond first 20 results\n",
    "\n",
    "    #Auxiliary list for getting more pages of search results\n",
    "    further_page_ending_list = []\n",
    "    for i in range(100):\n",
    "        further_page_ending = 20 + i\n",
    "        if ((str(further_page_ending)[-1] =='1') & (str(further_page_ending)[0] not in ['3', '5', '7', '9', '11'])):\n",
    "            further_page_ending_list.append(str(further_page_ending))\n",
    "    \n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            #links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\"))  #If want to search FCA only\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "\n",
    "            #Check if stll more results\n",
    "            if len(links_next_page_raw) > 0:\n",
    "                for i in links_next_page_raw:\n",
    "                    if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "                        remove_title = str(i).split('\" title=')[0]\n",
    "                        remove_leading_words = remove_title.replace('<a href=\"', '')\n",
    "                        if 'a class=' not in remove_leading_words:\n",
    "                            case_name_mnc = split_title_mnc(i.get_text(strip = True))\n",
    "                            case_name = case_name_mnc[0]\n",
    "                            mnc = case_name_mnc[1]\n",
    "                            if '(PDF' in mnc:\n",
    "                                mnc = mnc.replace('(PDF', '')\n",
    "                                \n",
    "                            case_info = {'Case name': case_name,\n",
    "                                 'Medium neutral citation': mnc,\n",
    "                                'Hyperlink to Federal Court Digital Law Library' : remove_leading_words\n",
    "                                        }\n",
    "                            links.append(case_info)\n",
    "                            counter = counter + 1\n",
    "\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962fad87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:01:50.649 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Meta labels and judgment combined\n",
    "#IN USE\n",
    "fca_metalabels = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published', 'Appeal_to']\n",
    "#'MNC', \n",
    "fca_metalabels_droppable = ['Year', 'Appeal', 'File_Number', 'Judge', 'Judgment_Dated', 'Catchwords', 'Subject', 'Words_Phrases', 'Legislation', 'Cases_Cited', 'Division', 'NPA', 'Sub_NPA', 'Pages', 'All_Parties', 'Jurisdiction', 'Reported', 'Summary', 'Corrigenda', 'Parties', 'FileName', 'Asset_ID', 'Date.published', 'Appeal_to', 'Order']\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def fca_meta_judgment_dict(case_info):\n",
    "#def fca_meta_judgment_dict(judgment_url):\n",
    "    judgment_dict = {'Case name': '',\n",
    "                 'Medium neutral citation': '',\n",
    "                'Hyperlink to Federal Court Digital Law Library' : '', \n",
    "                #'MNC' : '',  \n",
    "                 'Year' : '',  \n",
    "                 'Appeal' : '',  \n",
    "                 'File_Number' : '',  \n",
    "                 'Judge' : '',  \n",
    "                 'Judgment_Dated' : '',  \n",
    "                 'Catchwords' : '',  \n",
    "                 'Subject' : '',  \n",
    "                 'Words_Phrases' : '',  \n",
    "                 'Legislation' : '',  \n",
    "                 'Cases_Cited' : '',  \n",
    "                 'Division' : '',  \n",
    "                 'NPA' : '',  \n",
    "                'Sub_NPA' : '', \n",
    "                 'Pages' : '',  \n",
    "                 'All_Parties' : '',  \n",
    "                 'Jurisdiction' : '',  \n",
    "                 'Reported' : '',  \n",
    "                 'Summary' : '',  \n",
    "                 'Corrigenda' : '',  \n",
    "                 'Parties' : '',  'FileName' : '',  \n",
    "                 'Asset_ID' : '',  \n",
    "                 'Date.published' : '', \n",
    "                'Appeal_to' : '', \n",
    "                'Order': '',\n",
    "                'judgment' : ''\n",
    "                }\n",
    "\n",
    "\n",
    "    if 'Case name' in case_info.keys():\n",
    "        judgment_dict['Case name'] = case_info['Case name']\n",
    "\n",
    "    if 'Medium neutral citation' in case_info.keys():\n",
    "        judgment_dict['Medium neutral citation'] = case_info['Medium neutral citation']\n",
    "\n",
    "    #Attach hyperlink\n",
    "\n",
    "    judgment_url = case_info['Hyperlink to Federal Court Digital Law Library']\n",
    "    \n",
    "    judgment_dict['Hyperlink to Federal Court Digital Law Library'] = link(judgment_url)\n",
    "    \n",
    "    page = requests.get(judgment_url)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    meta_tags = soup.find_all(\"meta\")\n",
    "\n",
    "    #Attach meta tags\n",
    "    if len(meta_tags)>0:\n",
    "        for tag_index in range(len(meta_tags)):\n",
    "            meta_name = meta_tags[tag_index].get(\"name\")\n",
    "            if meta_name in fca_metalabels:\n",
    "                meta_content = meta_tags[tag_index].get(\"content\")\n",
    "                judgment_dict[meta_name] = meta_content\n",
    "\n",
    "    #Check if not gets taken to a PDF\n",
    "\n",
    "    if '.pdf' not in judgment_url.lower():\n",
    "    \n",
    "        #try:\n",
    "            #case_name_mnc = split_title_mnc(judgment_dict['MNC'])\n",
    "            #case_name = case_name_mnc[0]\n",
    "            #mnc = case_name_mnc[1]\n",
    "            \n",
    "            #judgment_dict['Case name'] = case_name\n",
    "            #judgment_dict['Medium neutral citation'] = mnc\n",
    "            \n",
    "            #del judgment_dict['MNC']\n",
    "    \n",
    "        #except:\n",
    "            #pass\n",
    "\n",
    "        #Attach order_text and judgment\n",
    "    \n",
    "        judgment_text = ''\n",
    "        order_text = ''\n",
    "    \n",
    "        try:\n",
    "            judgment_raw = ''\n",
    "            judgment_raw = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "    \n",
    "            above_reasons_for_judgment = str(re.split(\"REASONS FOR JUDGMENT\", judgment_raw, flags=re.IGNORECASE)[0])\n",
    "    \n",
    "            below_reasons_for_judgment = str(re.split(\"REASONS FOR JUDGMENT\", judgment_raw, flags=re.IGNORECASE)[1:])\n",
    "    \n",
    "            order_text = \"BETWEEEN:\" + str(re.split(\"BETWEEN:\", above_reasons_for_judgment, flags=re.IGNORECASE)[1:])[2:][:-2]\n",
    "    \n",
    "            judgment_text = below_reasons_for_judgment\n",
    "    \n",
    "        except:\n",
    "            try:\n",
    "                judgment_text = soup.find(\"div\", {\"class\": \"judgment_content\"}).get_text(separator=\"\\n\", strip=True)\n",
    "            except:\n",
    "                judgment_text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "        \n",
    "        judgment_dict['judgment'] = judgment_text\n",
    "        judgment_dict['Order'] = order_text\n",
    "\n",
    "    #Check if gets taken to a PDF\n",
    "\n",
    "    else:\n",
    "        #Attach case name\n",
    "        #judgment_dict['Case name'] = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.'\n",
    "\n",
    "        #Attach judgment pdf text\n",
    "        try:\n",
    "            judgment_pdf_raw = pdf_judgment(judgment_url)\n",
    "            judgment_dict['judgment'] = judgment_pdf_raw\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "        #Attach medium neutral citation\n",
    "        #try:\n",
    "            #mnc_raw = judgment_url.split('/')[-1].replace('.pdf', '')\n",
    "\n",
    "            #for court_i in ['fca', 'fcafc', 'irc', 'acompt', 'acopyt', 'adfdat', 'fpdt', 'atpt', 'nfsc']:\n",
    "                #if court_i in mnc_raw.lower():\n",
    "                    #mnc_list = mnc_raw.lower().split(court_i)\n",
    "                    #judgment_dict['Medium neutral citation'] = '[' + mnc_list[0] + '] ' + court_i.upper()  + ' ' +  mnc_list[1]\n",
    "\n",
    "                    #while ' 0' in judgment_dict['Medium neutral citation']:\n",
    "                        #judgment_dict['Medium neutral citation'] = judgment_dict['Medium neutral citation'].replace(' 0', ' ')\n",
    "            \n",
    "            #del judgment_dict['MNC']\n",
    "    \n",
    "        #except:\n",
    "            #pass        \n",
    "            \n",
    "    return judgment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a30f606a-d641-4752-8fde-07f5b04d5596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 10:01:51.233 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Preliminary function for changing names for any PDF judgments\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def fca_pdf_name_mnc_list(url_search_results, judgment_counter_bound):\n",
    "                      \n",
    "    #Scrape webpage of search results\n",
    "    page = requests.get(url_search_results)\n",
    "    soup = BeautifulSoup(page.content, \"lxml\")\n",
    "    \n",
    "    #Placeholder\n",
    "    name_mnc_list = []\n",
    "\n",
    "    #Start counter\n",
    "    counter = 1\n",
    "    # Get links of first 20 results\n",
    "    #links_raw = soup.find_all(\"a\", href=re.compile(\"fca\")) #If want to search FCA only\n",
    "    links_raw = soup.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "    \n",
    "    for i in links_raw:\n",
    "        if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "            name_mnc_list.append(i['title'])\n",
    "            counter = counter + 1\n",
    "    \n",
    "    #Go beyond first 20 results\n",
    "\n",
    "    #Auxiliary list for getting more pages of search results\n",
    "    further_page_ending_list = []\n",
    "    for i in range(100):\n",
    "        further_page_ending = 20 + i\n",
    "        if ((str(further_page_ending)[-1] =='1') & (str(further_page_ending)[0] not in ['3', '5', '7', '9', '11'])):\n",
    "            further_page_ending_list.append(str(further_page_ending))\n",
    "\n",
    "    for ending in further_page_ending_list:\n",
    "        if counter <=judgment_counter_bound:\n",
    "            url_next_page = url_search_results + '&start_rank=' + f\"{ending}\"\n",
    "            page_judgment_next_page = requests.get(url_next_page)\n",
    "            soup_judgment_next_page = BeautifulSoup(page_judgment_next_page.content, \"lxml\")\n",
    "            #links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"fca\")) #If want to search FCA only\n",
    "            links_next_page_raw = soup_judgment_next_page.find_all(\"a\", href=re.compile(\"judgments\"))\n",
    "    \n",
    "            #Check if stll more results\n",
    "            if len(links_next_page_raw) > 0:\n",
    "                for i in links_next_page_raw:\n",
    "                    if (('title=' in str(i)) and (counter <=judgment_counter_bound)):\n",
    "                        name_mnc_list.append(i['title'])\n",
    "                        counter = counter + 1\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "    return name_mnc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8810eb17-ef74-4083-9801-f8c36395344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for changing names for any PDF judgments\n",
    "#NOT IN USE\n",
    "\n",
    "def fca_pdf_name(name_mnc_list, mnc):\n",
    "    #Placeholder\n",
    "    name = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.' \n",
    "    \n",
    "    for i in name_mnc_list:\n",
    "        if mnc in i:\n",
    "            name_raw = i.split(' ' + mnc)[0]\n",
    "            name = name_raw.replace('Cached: ', '')\n",
    "            \n",
    "    return name\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd2241e-0ecd-40f7-9d5b-e9269d58f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fca_search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url = fca_search(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "    return url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2d594",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3be60b-5f6b-44fe-9e59-1c51310b8824",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json, gpt_batch_input\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, role_content#, intro_for_GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfae300-2b55-45a0-842c-83f12e8a555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20ba06e-2c4c-4ae6-ac7e-06a8d84d4252",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d529e704-08e0-4af6-98f0-b10e29d009ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "system_instruction = role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83981e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def fca_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "    \n",
    "    #Conduct search\n",
    "    \n",
    "    url_search_results = fca_search(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "        \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    #Get relevant cases\n",
    "    case_infos = fca_search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    for case_info in case_infos:\n",
    "        judgment_dict = fca_meta_judgment_dict(case_info)\n",
    "        judgments_file.append(judgment_dict)\n",
    "        pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Create list of direct judgment links\n",
    "    #judgments_links  = []\n",
    "\n",
    "    #for case in case_infos:\n",
    "        #judgments_links.append(case['Hyperlink to Federal Court Digital Law Library'])\n",
    "    \n",
    "    #for link in judgments_links:\n",
    "\n",
    "        #judgment_dict = fca_meta_judgment_dict(link)\n",
    "        #judgments_file.append(judgment_dict)\n",
    "        #pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Correct case names for any PDFs\n",
    "\n",
    "    #name_mnc_list = fca_pdf_name_mnc_list(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    #for judgment_index in df_individual.index:\n",
    "        \n",
    "        #if (('pdf' in df_individual.loc[judgment_index, 'Case name'].lower()) or ('.pdf' in str(df_individual.loc[judgment_index, 'Hyperlink to Federal Court Digital Law Library']).lower())):\n",
    "            #try:\n",
    "                #df_individual.loc[judgment_index, 'Case name'] = fca_pdf_name(name_mnc_list, df_individual.loc[judgment_index, 'Medium neutral citation'])\n",
    "            #except Exception as e:\n",
    "                #print(f\"{df_individual.loc[judgment_index, 'Medium neutral citation']}: cannot change case name for PDF.\")\n",
    "                #print(e)\n",
    "                    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "\n",
    "    df_updated.pop('judgment')\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in fca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90e35be4-5b48-4711-bddf-bdbbd566e93b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Obtain parameters\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;129m@st\u001b[39m\u001b[38;5;241m.\u001b[39mcache_data(show_spinner \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfca_batch\u001b[39m(df_master):\n\u001b[1;32m      5\u001b[0m     df_master \u001b[38;5;241m=\u001b[39m df_master\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#Apply split and format functions for headnotes choice, court choice and GPT questions\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'st' is not defined"
     ]
    }
   ],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data(show_spinner = False)\n",
    "def fca_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Conduct search    \n",
    "    url_search_results = fca_search(court = df_master.loc[0, 'Courts'], \n",
    "                     case_name_mnc = df_master.loc[0, 'Case name or medium neutral citation'],\n",
    "                     judge = df_master.loc[0, 'Judge'], \n",
    "                     reported_citation = df_master.loc[0, 'Reported citation'],\n",
    "                     file_number  = df_master.loc[0, 'File number'],\n",
    "                     npa = df_master.loc[0, 'National practice area'], \n",
    "                     with_all_the_words  = df_master.loc[0, 'With all the words'], \n",
    "                     with_at_least_one_of_the_words = df_master.loc[0, 'With at least one of the words'],\n",
    "                     without_the_words = df_master.loc[0, 'Without the words'],\n",
    "                     phrase  = df_master.loc[0, 'Phrase'], \n",
    "                     proximity = df_master.loc[0, 'Proximity'], \n",
    "                     on_this_date = df_master.loc[0, 'On this date'], \n",
    "                     after_date = df_master.loc[0, 'Decision date is after'], \n",
    "                     before_date = df_master.loc[0, 'Decision date is before'], \n",
    "                     legislation = df_master.loc[0, 'Legislation'], \n",
    "                     cases_cited = df_master.loc[0, 'Cases cited'], \n",
    "                     catchwords = df_master.loc[0, 'Catchwords'] \n",
    "                    )\n",
    "    \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "\n",
    "    #Get relevant cases\n",
    "    case_infos = fca_search_results_to_judgment_links(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "        \n",
    "    #Check if running on HuggingFace\n",
    "    from functions.oalc_functions import huggingface\n",
    "    \n",
    "    if huggingface == False: #If not running on HuggingFace\n",
    "        \n",
    "        for case_info in case_infos:\n",
    "            judgment_dict = fca_meta_judgment_dict(case_info)\n",
    "            judgments_file.append(judgment_dict)\n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    else: #If running on HuggingFace\n",
    "\n",
    "        #Load oalc\n",
    "        from functions.oalc_functions import load_corpus, get_judgment_from_oalc\n",
    "\n",
    "        #Create a list of mncs for HuggingFace:\n",
    "        mnc_list = []\n",
    "\n",
    "        for case in case_infos:\n",
    "\n",
    "            #add search results to json\n",
    "            judgments_file.append(case)\n",
    "\n",
    "            #Add mnc to list for HuggingFace\n",
    "            mnc_list.append(case['Medium neutral citation'])\n",
    "\n",
    "        #Get judgments from oalc first\n",
    "        mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "        \n",
    "        #print(f\"{Obtained from OALC: mnc_judgment_dict.keys()}\")\n",
    "    \n",
    "        #Append judgment to judgments_file \n",
    "        for decision in judgments_file:\n",
    "            \n",
    "            #Append judgments from oalc first\n",
    "            if decision['Medium neutral citation'] in mnc_judgment_dict.keys():\n",
    "                \n",
    "                decision.update({'judgment': mnc_judgment_dict[decision['Medium neutral citation']]})\n",
    "\n",
    "                #Make judgment_link clickable\n",
    "                decision['Hyperlink to Federal Court Digital Law Library'] = link(decision['Hyperlink to Federal Court Digital Law Library'])\n",
    "            \n",
    "            else: #Get judgment from FCA if can't get from oalc\n",
    "                judgment_dict_direct = fca_meta_judgment_dict(decision)\n",
    "                \n",
    "                for key in judgment_dict_direct.keys():\n",
    "                        if key not in decision.keys():\n",
    "                            decision.update({key: judgment_dict_direct[key]})\n",
    "\n",
    "                pause.seconds(np.random.randint(5, 15))\n",
    "                \n",
    "    #Create list of direct judgment links\n",
    "    #judgments_links  = []\n",
    "\n",
    "    #for case in case_infos:\n",
    "        #judgments_links.append(case['Hyperlink to Federal Court Digital Law Library'])\n",
    "        \n",
    "\n",
    "    #for link in judgments_links:\n",
    "\n",
    "        #judgment_dict = fca_meta_judgment_dict(link)\n",
    "        #judgments_file.append(judgment_dict)\n",
    "        #pause.seconds(np.random.randint(5, 15))\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "\n",
    "#    df_individual = pd.DataFrame(judgments_file)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Correct case names for any PDFs\n",
    "\n",
    "    #name_mnc_list = fca_pdf_name_mnc_list(url_search_results, judgments_counter_bound)\n",
    "\n",
    "    #for judgment_index in df_individual.index:\n",
    "        \n",
    "        #if (('pdf' in df_individual.loc[judgment_index, 'Case name'].lower()) or ('.pdf' in str(df_individual.loc[judgment_index, 'Hyperlink to Federal Court Digital Law Library']).lower())):\n",
    "            #try:\n",
    "                #df_individual.loc[judgment_index, 'Case name'] = fca_pdf_name(name_mnc_list, df_individual.loc[judgment_index, 'Medium neutral citation'])\n",
    "            #except Exception as e:\n",
    "                #print(f\"{df_individual.loc[judgment_index, 'Medium neutral citation']}: cannot change case name for PDF.\")\n",
    "                #print(e)\n",
    "                    \n",
    "    #Drop metadata if not wanted\n",
    "\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in fca_metalabels_droppable:\n",
    "            try:\n",
    "                df_updated.pop(meta_label)\n",
    "            except Exception as e:\n",
    "                print(f'{meta_label} not popped.')\n",
    "                print(e)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "        \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "\n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "    \n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
