{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51218f00-183e-4f7a-9fe5-2393c3de15b0",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07019cf3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "from dateutil import parser\n",
    "from dateutil.relativedelta import *\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "from streamlit.components.v1 import html\n",
    "import streamlit_ext as ste\n",
    "from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#NSWCaseLaw\n",
    "from nswcaselaw.search import Search\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5120eafa-8759-48bb-9e56-cee8e8cd2ac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'parentdirectory'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[1;32m      2\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../parentdirectory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparentdirectory\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, mnc_cleaner \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mparentdirectory\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'parentdirectory'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_range_check, au_date, save_input\n",
    "#Import variables\n",
    "from functions.common_functions import today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
    "\n",
    "if own_account_allowed() > 0:\n",
    "    print(f'By default, users are allowed to use their own account')\n",
    "else:\n",
    "    print(f'By default, users are NOT allowed to use their own account')\n",
    "\n",
    "print(f\"The pause between judgment scraping is {scraper_pause_mean} second.\\n\")\n",
    "\n",
    "print(f\"The lower bound on lenth of judgment text to process is {judgment_text_lower_bound} tokens.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e432b7",
   "metadata": {},
   "source": [
    "# CaseLaw NSW functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b999856b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Auxiliary lists\n",
    "#search_criteria = ['Free text', 'Case name', 'Before', 'Catchwords', 'Party names', 'Medium neutral citation', 'Decision date from', 'Decision date to', 'File number', 'Legislation cited', 'Cases cited']\n",
    "nsw_meta_labels_droppable = [\"Catchwords\", \"Before\", \"Decision date(s)\", \"Hearing date(s)\", \"Date(s) of order\",  \"Jurisdiction\", \"Decision\", \"Legislation cited\", \"Cases cited\", \"Texts cited\", \"Category\", \"Parties\", \"File number\", \"Representation\", \"Decision under appeal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28525de2-5be8-495a-af01-b3b172106e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of nsw courts\n",
    "\n",
    "#For showing as menu\n",
    "nsw_courts =[\"Court of Appeal\", \n",
    "             \"Court of Criminal Appeal\", \n",
    "             \"Supreme Court\", \n",
    "             'Land and Environment Court (Judges)', \n",
    "             'Land and Environment Court (Commissioners)', \n",
    "             'District Court', \n",
    "             'Local Court',\n",
    "             \"Children's Court\", \n",
    "             'Compensation Court', \n",
    "             'Drug Court', \n",
    "             'Industrial Court',\n",
    "             'Industrial Relations Commission (Judges)', \n",
    "             'Industrial Relations Commission (Commissioners)'\n",
    "            ] #, \"All of the above Courts\"]\n",
    "\n",
    "#For positioning\n",
    "nsw_courts_positioning = [\"Placeholder\", \"Children's Court\",\n",
    " 'Compensation Court',\n",
    " 'Court of Appeal',\n",
    " 'Court of Criminal Appeal',\n",
    " 'District Court',\n",
    " 'Drug Court',\n",
    " 'Industrial Court',\n",
    " 'Industrial Relations Commission (Commissioners)',\n",
    " 'Industrial Relations Commission (Judges)',\n",
    " 'Land and Environment Court (Commissioners)',\n",
    " 'Land and Environment Court (Judges)',\n",
    " 'Local Court',\n",
    " 'Supreme Court']\n",
    "\n",
    "#Default courts\n",
    "nsw_default_courts = [\"Court of Appeal\", \"Court of Criminal Appeal\", \"Supreme Court\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7183b01d-ed57-4d21-836c-0ac3a49bb09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of NSW tribunals\n",
    "\n",
    "nsw_tribunals = ['Administrative Decisions Tribunal (Appeal Panel)',\n",
    " 'Administrative Decisions Tribunal (Divisions)',\n",
    " 'Civil and Administrative Tribunal (Administrative and Equal Opportunity Division)',\n",
    " 'Civil and Administrative Tribunal (Appeal Panel)',\n",
    " 'Civil and Administrative Tribunal (Consumer and Commercial Division)',\n",
    " 'Civil and Administrative Tribunal (Enforcement)',\n",
    " 'Civil and Administrative Tribunal (Guardianship Division)',\n",
    " 'Civil and Administrative Tribunal (Occupational Division)',\n",
    " 'Dust Diseases Tribunal',\n",
    " 'Equal Opportunity Tribunal',\n",
    " 'Fair Trading Tribunal',\n",
    " 'Legal Services Tribunal',\n",
    " 'Medical Tribunal',\n",
    " 'Transport Appeal Boards']\n",
    "\n",
    "nsw_tribunals_positioning = ['Placeholder',\n",
    " 'Administrative Decisions Tribunal (Appeal Panel)',\n",
    " 'Administrative Decisions Tribunal (Divisions)',\n",
    " 'Civil and Administrative Tribunal (Administrative and Equal Opportunity Division)',\n",
    " 'Civil and Administrative Tribunal (Appeal Panel)',\n",
    " 'Civil and Administrative Tribunal (Consumer and Commercial Division)',\n",
    " 'Civil and Administrative Tribunal (Enforcement)',\n",
    " 'Civil and Administrative Tribunal (Guardianship Division)',\n",
    " 'Civil and Administrative Tribunal (Occupational Division)',\n",
    " 'Dust Diseases Tribunal',\n",
    " 'Equal Opportunity Tribunal',\n",
    " 'Fair Trading Tribunal',\n",
    " 'Legal Services Tribunal',\n",
    " 'Medical Tribunal',\n",
    " 'Transport Appeal Boards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ef07dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to convert the string of chosen courts to a list; 13 = NSWSC, 3 = NSWCA, 4 = NSWCCA\n",
    "#For more, see https://github.com/Sydney-Informatics-Hub/nswcaselaw/blob/main/src/nswcaselaw/constants.py\n",
    "\n",
    "def nsw_court_choice(x):\n",
    "    individual_choice = []\n",
    "\n",
    "    if len(x) < 5:\n",
    "        pass #If want to select no court absent any choice\n",
    "        #individual_choice = [3, 4, 13] #If want to select NSWSC, CA and CCA absent any choice\n",
    "        #for j in range(1, len(nsw_courts_positioning)):\n",
    "            #individual_choice.append(j) #If want to select all courts absent any choice\n",
    "    else:\n",
    "        y = x.split(', ')\n",
    "        for i in y:\n",
    "            individual_choice.append(nsw_courts_positioning.index(i))            \n",
    "    \n",
    "    return individual_choice\n",
    "\n",
    "def nsw_tribunal_choice(x):\n",
    "    individual_choice = []\n",
    "\n",
    "    if len(x) < 5:\n",
    "        pass #If want to select no tribunal absent any choice\n",
    "        #for j in range(1, len(nsw_tribunals_positioning)):\n",
    "            #individual_choice.append(j) #If want to select all tribunals absent any choice\n",
    "    else:\n",
    "        y = x.split(', ')\n",
    "        for i in y:\n",
    "            individual_choice.append(nsw_tribunals_positioning.index(i))            \n",
    "    \n",
    "    return individual_choice\n",
    "\n",
    "#Functions for tidying up\n",
    "\n",
    "#Tidy up dates\n",
    "def nsw_date(x):\n",
    "    if len(str(x)) >0:\n",
    "        return str(x).split()[0]\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "# Headnotes fields\n",
    "headnotes_fields = [\"Free text\", \"Case name\", \"Before\", \"Decision date(s)\", \"Catchwords\", \"Hearing date(s)\", \"Date(s) of order\",  \"Jurisdiction\", \"Decision\", \"Legislation cited\", \"Cases cited\", \"Texts cited\", \"Category\", \"Parties\", \"Medium neutral citation\", \"Decision date from\", \"Decision date to\", \"File number\", \"Representation\", \"Decision under appeal\"]\n",
    "headnotes_keys = [\"body\", \"title\", \"before\", \"decisionDate\", \"catchwords\", \"hearingDates\", \"dateOfOrders\", \"jurisdiction\", \"decision\", \"legislationCited\", \"casesCited\", \"textsCited\", \"category\", \"parties\", \"mnc\", \"startDate\", \"endDate\", \"fileNumber\", \"representation\", \"decisionUnderAppeal\"]\n",
    "\n",
    "#Functions for tidying up headings of columns\n",
    "\n",
    "#Tidy up hyperlink\n",
    "def nsw_link(x):\n",
    "    link='https://www.caselaw.nsw.gov.au'+ str(x)\n",
    "    value = '=HYPERLINK(\"' + link + '\")'\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12bc2af9-d2ed-4d64-95a0-7e0a84dda2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-25 09:48:32.279 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function for short judgments, which checks if judgment is in PDF\n",
    "#returns a list of judgment type and judgment text\n",
    "\n",
    "@st.cache_data\n",
    "def nsw_short_judgment(html_link):\n",
    "    page_html = requests.get(html_link)\n",
    "    soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "\n",
    "    judgment_type = ''\n",
    "\n",
    "    #Check if judgment contains PDF link\n",
    "    PDF_raw_link = soup_html.find('a', string='See Attachment (PDF)')\n",
    "    \n",
    "    if str(PDF_raw_link).lower() != 'none':\n",
    "        PDF_link = 'https://www.caselaw.nsw.gov.au' + PDF_raw_link.get('href')    \n",
    "        headers = {'User-Agent': 'whatever'}\n",
    "        r = requests.get(PDF_link, headers=headers)\n",
    "        remote_file_bytes = io.BytesIO(r.content)\n",
    "        pdfdoc_remote = pypdf.PdfReader(remote_file_bytes)\n",
    "        text_list = []\n",
    "        \n",
    "        for page in pdfdoc_remote.pages:\n",
    "            text_list.append(page.extract_text())\n",
    "\n",
    "        judgment_type = 'pdf'\n",
    "        \n",
    "        return [judgment_type, str(text_list)]\n",
    "\n",
    "    #Return html text if no PDF\n",
    "    else:\n",
    "        judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "        judgment_type = 'html'\n",
    "\n",
    "        return [judgment_type, judgment_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69fbb2-62e9-4f28-be14-5c539b630c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nsw_search_url(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['Courts'] = df_master['Courts'].apply(nsw_court_choice)\n",
    "    df_master['Tribunals'] = df_master['Tribunals'].apply(nsw_tribunal_choice)\n",
    "\n",
    "    #df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    #df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Combining catchwords into new column\n",
    "    \n",
    "    search_dict = {'body': df_master.loc[0, 'Free text']}\n",
    "    search_dict.update({'title': df_master.loc[0, 'Case name']})\n",
    "    search_dict.update({'before': df_master.loc[0, 'Before']})\n",
    "    search_dict.update({'catchwords': df_master.loc[0, 'Catchwords']})\n",
    "    search_dict.update({'party': df_master.loc[0, 'Party names']})\n",
    "    search_dict.update({'mnc': df_master.loc[0, 'Medium neutral citation']})\n",
    "    search_dict.update({'startDate': df_master.loc[0, 'Decision date from']})\n",
    "    search_dict.update({'endDate': df_master.loc[0, 'Decision date to']})\n",
    "    search_dict.update({'fileNumber': df_master.loc[0, 'File number']})\n",
    "    search_dict.update({'legislationCited': df_master.loc[0, 'Legislation cited']})\n",
    "    search_dict.update({'casesCited': df_master.loc[0, 'Cases cited']})\n",
    "    df_master.loc[0, 'SearchCriteria']=[search_dict]\n",
    "\n",
    "    #Conduct search\n",
    "    \n",
    "    query = Search(courts=df_master.loc[0, 'Courts'], \n",
    "                   tribunals=df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, \"SearchCriteria\"]['body'], \n",
    "                   title = df_master.loc[0, \"SearchCriteria\"]['title'], \n",
    "                   before = df_master.loc[0, \"SearchCriteria\"]['before'], \n",
    "                   catchwords = df_master.loc[0, \"SearchCriteria\"]['catchwords'], \n",
    "                   party = df_master.loc[0, \"SearchCriteria\"]['party'], \n",
    "                   mnc = df_master.loc[0, \"SearchCriteria\"]['mnc'], \n",
    "                   startDate = nsw_date(df_master.loc[0, \"SearchCriteria\"]['startDate']), \n",
    "                   endDate = nsw_date(df_master.loc[0, \"SearchCriteria\"]['endDate']),\n",
    "                   fileNumber = df_master.loc[0, \"SearchCriteria\"]['fileNumber'], \n",
    "                   legislationCited  = df_master.loc[0, \"SearchCriteria\"]['legislationCited'], \n",
    "                   casesCited = df_master.loc[0, \"SearchCriteria\"]['legislationCited'],\n",
    "                   pause = 0\n",
    "                  )\n",
    "    \n",
    "    return query.url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984b836",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264f776f-9383-4727-bc0f-fdee31463433",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string, judgment_prompt_json, GPT_json_tokens, engage_GPT_json_tokens  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound, role_content\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import question_characters_bound, role_content#, intro_for_GPT\n",
    "#For batch mode\n",
    "from functions.gpt_functions import gpt_get_custom_id, gpt_batch_input_id_line, gpt_batch_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b3481-b897-4ee6-af9c-ca38d2412631",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Questions for GPT are capped at {question_characters_bound} characters.\\n\")\n",
    "print(f\"The default number of judgments to scrape per request is capped at {default_judgment_counter_bound}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6dde1-e2da-480b-80d9-f839f8e1778f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction\n",
    "\n",
    "if check_questions_answers() > 0:\n",
    "    print(f'By default, questions and answers are checked for potential privacy violation.')\n",
    "else:\n",
    "    print(f'By default, questions and answers are NOT checked for potential privacy violation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8b81-719b-4672-a141-7d9331cde96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "system_instruction = role_content\n",
    "\n",
    "intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b046b-d0f2-47ac-b02b-bc2032811b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tidy up output\n",
    "\n",
    "def nsw_tidying_up(df_master, df_individual):\n",
    "\n",
    "    #Reorganise columns\n",
    "\n",
    "    old_columns = list(df_individual.columns)\n",
    "    \n",
    "    for i in ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw']:\n",
    "        if i in old_columns:\n",
    "            old_columns.remove(i)\n",
    "    \n",
    "    new_columns = ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw'] + old_columns\n",
    "    \n",
    "    df_individual = df_individual.reindex(columns=new_columns)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "    \n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in nsw_meta_labels_droppable:\n",
    "            try:\n",
    "                df_individual.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    #Remove judgment and uri columns\n",
    "    try:\n",
    "        df_individual.pop(\"judgment\")\n",
    "        df_individual.pop(\"uri\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    #Check case name, medium neutral citation \n",
    "\n",
    "    for k in df_individual.index:\n",
    "        if ' [' in df_individual.loc[k, \"Case name\"]:\n",
    "            case_name_proper = df_individual.loc[k, \"Case name\"].split(' [')[0]\n",
    "            mnc_proper = '[' + df_individual.loc[k, \"Case name\"].split(' [')[-1]\n",
    "            df_individual.loc[k, \"Case name\"] = case_name_proper\n",
    "            df_individual.loc[k, \"Medium neutral citation\"] = mnc_proper\n",
    "        elif ' [' in df_individual.loc[k, \"Medium neutral citation\"]:\n",
    "            case_name_proper = df_individual.loc[k, \"Medium neutral citation\"].split(' [')[0]\n",
    "            mnc_proper = '[' + df_individual.loc[k, \"Medium neutral citation\"].split(' [')[-1]\n",
    "            df_individual.loc[k, \"Case name\"] = case_name_proper\n",
    "            df_individual.loc[k, \"Medium neutral citation\"] = mnc_proper\n",
    "\n",
    "    return df_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c798e6-3059-4a0a-93cf-df0c2e32506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tidy up output\n",
    "\n",
    "def nsw_tidying_up_prebatch(df_master, df_individual):\n",
    "\n",
    "    #Reorganise columns\n",
    "\n",
    "    old_columns = list(df_individual.columns)\n",
    "    \n",
    "    for i in ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw']:\n",
    "        if i in old_columns:\n",
    "            old_columns.remove(i)\n",
    "    \n",
    "    new_columns = ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw'] + old_columns\n",
    "    \n",
    "    df_individual = df_individual.reindex(columns=new_columns)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "    \n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in nsw_meta_labels_droppable:\n",
    "            try:\n",
    "                df_individual.pop(meta_label)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    #Remove judgment and uri columns\n",
    "    try:\n",
    "        #df_individual.pop(\"judgment\")\n",
    "        df_individual.pop(\"uri\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    #Check case name, medium neutral citation \n",
    "\n",
    "    for k in df_individual.index:\n",
    "        if ' [' in df_individual.loc[k, \"Case name\"]:\n",
    "            case_name_proper = df_individual.loc[k, \"Case name\"].split(' [')[0]\n",
    "            mnc_proper = '[' + df_individual.loc[k, \"Case name\"].split(' [')[-1]\n",
    "            df_individual.loc[k, \"Case name\"] = case_name_proper\n",
    "            df_individual.loc[k, \"Medium neutral citation\"] = mnc_proper\n",
    "        elif ' [' in df_individual.loc[k, \"Medium neutral citation\"]:\n",
    "            case_name_proper = df_individual.loc[k, \"Medium neutral citation\"].split(' [')[0]\n",
    "            mnc_proper = '[' + df_individual.loc[k, \"Medium neutral citation\"].split(' [')[-1]\n",
    "            df_individual.loc[k, \"Case name\"] = case_name_proper\n",
    "            df_individual.loc[k, \"Medium neutral citation\"] = mnc_proper\n",
    "\n",
    "    return df_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35635339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data\n",
    "def nsw_run(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "#    df_master['Information to Collect from Judgment Headnotes'] = df_master['Information to Collect from Judgment Headnotes'].apply(headnotes_choice)\n",
    "    df_master['Courts'] = df_master['Courts'].apply(nsw_court_choice)\n",
    "    df_master['Tribunals'] = df_master['Tribunals'].apply(nsw_tribunal_choice)\n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Do search\n",
    "\n",
    "    search_dict = {'body': df_master.loc[0, 'Free text']}\n",
    "    search_dict.update({'title': df_master.loc[0, 'Case name']})\n",
    "    search_dict.update({'before': df_master.loc[0, 'Before']})\n",
    "    search_dict.update({'catchwords': df_master.loc[0, 'Catchwords']})\n",
    "    search_dict.update({'party': df_master.loc[0, 'Party names']})\n",
    "    search_dict.update({'mnc': df_master.loc[0, 'Medium neutral citation']})\n",
    "    search_dict.update({'startDate': df_master.loc[0, 'Decision date from']})\n",
    "    search_dict.update({'endDate': df_master.loc[0, 'Decision date to']})\n",
    "    search_dict.update({'fileNumber': df_master.loc[0, 'File number']})\n",
    "    search_dict.update({'legislationCited': df_master.loc[0, 'Legislation cited']})\n",
    "    search_dict.update({'casesCited': df_master.loc[0, 'Cases cited']})\n",
    "    df_master.loc[0, 'SearchCriteria']=[search_dict]\n",
    "\n",
    "    #Conduct search\n",
    "    \n",
    "    query = Search(courts=df_master.loc[0, 'Courts'], \n",
    "                   tribunals=df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, \"SearchCriteria\"]['body'], \n",
    "                   title = df_master.loc[0, \"SearchCriteria\"]['title'], \n",
    "                   before = df_master.loc[0, \"SearchCriteria\"]['before'], \n",
    "                   catchwords = df_master.loc[0, \"SearchCriteria\"]['catchwords'], \n",
    "                   party = df_master.loc[0, \"SearchCriteria\"]['party'], \n",
    "                   mnc = df_master.loc[0, \"SearchCriteria\"]['mnc'], \n",
    "                   startDate = nsw_date(df_master.loc[0, \"SearchCriteria\"]['startDate']), \n",
    "                   endDate = nsw_date(df_master.loc[0, \"SearchCriteria\"]['endDate']),\n",
    "                   fileNumber = df_master.loc[0, \"SearchCriteria\"]['fileNumber'], \n",
    "                   legislationCited  = df_master.loc[0, \"SearchCriteria\"]['legislationCited'], \n",
    "                   casesCited = df_master.loc[0, \"SearchCriteria\"]['legislationCited'],\n",
    "                   pause = 0\n",
    "                  )\n",
    "\n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Counter to limit search results to append\n",
    "    counter = 0\n",
    "\n",
    "    #Go through search results\n",
    "    \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "    \n",
    "    for decision in query.results():\n",
    "        if counter < judgments_counter_bound:\n",
    "    \n",
    "            decision.fetch()\n",
    "            decision_v=decision.values\n",
    "                                    \n",
    "            #add search results to json\n",
    "            judgments_file.append(decision_v)\n",
    "            counter +=1\n",
    "    \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Check length of judgment text, replace with raw html if smaller than lower boound\n",
    "\n",
    "    for judgment_index in df_individual.index:\n",
    "\n",
    "        #Checking if judgment text has been scrapped\n",
    "        try:\n",
    "            judgment_raw_text = str(df_individual.loc[judgment_index, \"judgment\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"judgment\"] = ['Error. Judgment text not scrapped.']\n",
    "            judgment_raw_text = str(df_individual.loc[judgment_index, \"judgment\"])\n",
    "            print(f'{df_individual.loc[judgment_index, \"title\"]}: judgment text scraping error.')\n",
    "            print(e)\n",
    "            \n",
    "        if num_tokens_from_string(judgment_raw_text, \"cl100k_base\") < judgment_text_lower_bound:\n",
    "            html_link = 'https://www.caselaw.nsw.gov.au'+ df_individual.loc[judgment_index, \"uri\"]\n",
    "\n",
    "#            page_html = requests.get(html_link)\n",
    "#            soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "#            judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            judgment_type_text = nsw_short_judgment(html_link)\n",
    "\n",
    "            #attach judgment text\n",
    "            df_individual.loc[judgment_index, \"judgment\"] = judgment_type_text[1]\n",
    "\n",
    "            #identify pdf judgment\n",
    "\n",
    "            if judgment_type_text[0] == 'pdf':\n",
    "                try:\n",
    "                    mnc_raw = df_individual.loc[judgment_index, \"mnc\"]\n",
    "                    df_individual.loc[judgment_index, \"title\"] =  mnc_raw.split(' [')[0]\n",
    "                    df_individual.loc[judgment_index, \"mnc\"] = '[' + mnc_raw.split(' [')[1]\n",
    "                    df_individual.loc[judgment_index, \"catchwords\"] = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.'\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Rename column titles\n",
    "    \n",
    "    try:\n",
    "        df_individual['Hyperlink to NSW Caselaw'] = df_individual['uri'].apply(nsw_link)\n",
    "        df_individual.pop('uri')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for col_name in headnotes_keys:\n",
    "        if col_name in df_individual.columns:\n",
    "            col_index = headnotes_keys.index(col_name)\n",
    "            new_col_name = headnotes_fields[col_index]\n",
    "            df_individual[new_col_name] = df_individual[col_name]\n",
    "            df_individual.pop(col_name)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Engage GPT\n",
    "    df_updated = engage_GPT_json(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "\n",
    "    #tidy up\n",
    "    df_updated = nsw_tidying_up(df_master, df_updated)\n",
    "    \n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbacc1-8134-4a9d-a3f2-eee6f755a013",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Obtain parameters\n",
    "\n",
    "@st.cache_data\n",
    "def nsw_batch(df_master):\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "#    df_master['Information to Collect from Judgment Headnotes'] = df_master['Information to Collect from Judgment Headnotes'].apply(headnotes_choice)\n",
    "    df_master['Courts'] = df_master['Courts'].apply(nsw_court_choice)\n",
    "    df_master['Tribunals'] = df_master['Tribunals'].apply(nsw_tribunal_choice)\n",
    "    df_master['Enter your questions for GPT'] = df_master['Enter your questions for GPT'][0: question_characters_bound].apply(split_by_line)\n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Do search\n",
    "\n",
    "    search_dict = {'body': df_master.loc[0, 'Free text']}\n",
    "    search_dict.update({'title': df_master.loc[0, 'Case name']})\n",
    "    search_dict.update({'before': df_master.loc[0, 'Before']})\n",
    "    search_dict.update({'catchwords': df_master.loc[0, 'Catchwords']})\n",
    "    search_dict.update({'party': df_master.loc[0, 'Party names']})\n",
    "    search_dict.update({'mnc': df_master.loc[0, 'Medium neutral citation']})\n",
    "    search_dict.update({'startDate': df_master.loc[0, 'Decision date from']})\n",
    "    search_dict.update({'endDate': df_master.loc[0, 'Decision date to']})\n",
    "    search_dict.update({'fileNumber': df_master.loc[0, 'File number']})\n",
    "    search_dict.update({'legislationCited': df_master.loc[0, 'Legislation cited']})\n",
    "    search_dict.update({'casesCited': df_master.loc[0, 'Cases cited']})\n",
    "    df_master.loc[0, 'SearchCriteria']=[search_dict]\n",
    "\n",
    "    #Conduct search\n",
    "    \n",
    "    query = Search(courts=df_master.loc[0, 'Courts'], \n",
    "                   tribunals=df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, \"SearchCriteria\"]['body'], \n",
    "                   title = df_master.loc[0, \"SearchCriteria\"]['title'], \n",
    "                   before = df_master.loc[0, \"SearchCriteria\"]['before'], \n",
    "                   catchwords = df_master.loc[0, \"SearchCriteria\"]['catchwords'], \n",
    "                   party = df_master.loc[0, \"SearchCriteria\"]['party'], \n",
    "                   mnc = df_master.loc[0, \"SearchCriteria\"]['mnc'], \n",
    "                   startDate = nsw_date(df_master.loc[0, \"SearchCriteria\"]['startDate']), \n",
    "                   endDate = nsw_date(df_master.loc[0, \"SearchCriteria\"]['endDate']),\n",
    "                   fileNumber = df_master.loc[0, \"SearchCriteria\"]['fileNumber'], \n",
    "                   legislationCited  = df_master.loc[0, \"SearchCriteria\"]['legislationCited'], \n",
    "                   casesCited = df_master.loc[0, \"SearchCriteria\"]['legislationCited'],\n",
    "                   pause = 0\n",
    "                  )\n",
    "\n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Counter to limit search results to append\n",
    "    counter = 0\n",
    "\n",
    "    #Go through search results\n",
    "    \n",
    "    judgments_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "    \n",
    "    for decision in query.results():\n",
    "        if counter < judgments_counter_bound:\n",
    "    \n",
    "            decision.fetch()\n",
    "            decision_v=decision.values\n",
    "                                    \n",
    "            #add search results to json\n",
    "            judgments_file.append(decision_v)\n",
    "            counter +=1\n",
    "    \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "            \n",
    "        else:\n",
    "            break\n",
    "\n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Check length of judgment text, replace with raw html if smaller than lower boound\n",
    "\n",
    "    for judgment_index in df_individual.index:\n",
    "\n",
    "        #Checking if judgment text has been scrapped\n",
    "        try:\n",
    "            judgment_raw_text = str(df_individual.loc[judgment_index, \"judgment\"])\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            df_individual.loc[judgment_index, \"judgment\"] = ['Error. Judgment text not scrapped.']\n",
    "            judgment_raw_text = str(df_individual.loc[judgment_index, \"judgment\"])\n",
    "            print(f'{df_individual.loc[judgment_index, \"title\"]}: judgment text scraping error.')\n",
    "            print(e)\n",
    "            \n",
    "        if num_tokens_from_string(judgment_raw_text, \"cl100k_base\") < judgment_text_lower_bound:\n",
    "            html_link = 'https://www.caselaw.nsw.gov.au'+ df_individual.loc[judgment_index, \"uri\"]\n",
    "\n",
    "#            page_html = requests.get(html_link)\n",
    "#            soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "#            judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "            judgment_type_text = nsw_short_judgment(html_link)\n",
    "\n",
    "            #attach judgment text\n",
    "            df_individual.loc[judgment_index, \"judgment\"] = judgment_type_text[1]\n",
    "\n",
    "            #identify pdf judgment\n",
    "\n",
    "            if judgment_type_text[0] == 'pdf':\n",
    "                try:\n",
    "                    mnc_raw = df_individual.loc[judgment_index, \"mnc\"]\n",
    "                    df_individual.loc[judgment_index, \"title\"] =  mnc_raw.split(' [')[0]\n",
    "                    df_individual.loc[judgment_index, \"mnc\"] = '[' + mnc_raw.split(' [')[1]\n",
    "                    df_individual.loc[judgment_index, \"catchwords\"] = 'Not working properly because judgment in PDF. References to paragraphs likely to pages or wrong.'\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            pause.seconds(np.random.randint(5, 15))\n",
    "\n",
    "    #Rename column titles\n",
    "    \n",
    "    try:\n",
    "        df_individual['Hyperlink to NSW Caselaw'] = df_individual['uri'].apply(nsw_link)\n",
    "        df_individual.pop('uri')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for col_name in headnotes_keys:\n",
    "        if col_name in df_individual.columns:\n",
    "            col_index = headnotes_keys.index(col_name)\n",
    "            new_col_name = headnotes_fields[col_index]\n",
    "            df_individual[new_col_name] = df_individual[col_name]\n",
    "            df_individual.pop(col_name)\n",
    "\n",
    "    #tidy up\n",
    "    df_individual = nsw_tidying_up_prebatch(df_master, df_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        gpt_model = \"gpt-4o-2024-08-06\"\n",
    "    else:        \n",
    "        gpt_model = \"gpt-4o-mini\"\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "            \n",
    "    #Send batch input to gpt\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json, df_individual, GPT_activation, gpt_model, system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
