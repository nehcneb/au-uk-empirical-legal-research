{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51218f00-183e-4f7a-9fe5-2393c3de15b0",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07019cf3",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Preliminary modules\n",
    "import base64 \n",
    "import json\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import numpy as np\n",
    "#import re\n",
    "#import datetime\n",
    "#from datetime import date\n",
    "#from dateutil import parser\n",
    "#from dateutil.relativedelta import *\n",
    "#from datetime import datetime, timedelta\n",
    "import sys\n",
    "import pause\n",
    "import requests\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "#import httplib2\n",
    "#from urllib.request import urlretrieve\n",
    "import os\n",
    "#import pypdf\n",
    "import io\n",
    "from io import BytesIO\n",
    "import ast\n",
    "import copy\n",
    "\n",
    "#Streamlit\n",
    "import streamlit as st\n",
    "#from streamlit_gsheets import GSheetsConnection\n",
    "#from streamlit.components.v1 import html\n",
    "#import streamlit_ext as ste\n",
    "#from streamlit_extras.stylable_container import stylable_container\n",
    "\n",
    "#NSWCaseLaw\n",
    "from nswcaselaw.search import Search\n",
    "\n",
    "#OpenAI\n",
    "import openai\n",
    "import tiktoken\n",
    "\n",
    "#Google\n",
    "#from google.oauth2 import service_account\n",
    "\n",
    "#Excel\n",
    "from pyxlsb import open_workbook as open_xlsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5120eafa-8759-48bb-9e56-cee8e8cd2ac1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m own_account_allowed, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, list_range_check, au_date, save_input\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfunctions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound, no_results_msg\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.common_functions import own_account_allowed, pop_judgment, convert_df_to_json, convert_df_to_csv, convert_df_to_excel, clear_cache, date_parser, save_input, split_title_mnc, pdf_image_judgment\n",
    "#Import variables\n",
    "from functions.common_functions import huggingface, today_in_nums, errors_list, scraper_pause_mean, judgment_text_lower_bound, default_judgment_counter_bound\n",
    "\n",
    "#Load oalc\n",
    "from functions.oalc_functions import get_judgment_from_oalc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e432b7",
   "metadata": {},
   "source": [
    "# CaseLaw NSW functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0680ac-6525-449c-b0fd-05ec8a62755c",
   "metadata": {},
   "source": [
    "### Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999856b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#Auxiliary lists\n",
    "#search_criteria = ['Free text', 'Case name', 'Before', 'Catchwords', 'Party names', 'Medium neutral citation', 'Decision date from', 'Decision date to', 'File number', 'Legislation cited', 'Cases cited']\n",
    "nsw_meta_labels_droppable = [\"Catchwords\", \"Before\", \"Decision date(s)\", \"Hearing date(s)\", \"Date(s) of order\",  \"Jurisdiction\", \"Decision\", \"Legislation cited\", \"Cases cited\", \"Texts cited\", \"Category\", \"Parties\", \"File number\", \"Representation\", \"Decision under appeal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28525de2-5be8-495a-af01-b3b172106e9f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#List of nsw courts\n",
    "\n",
    "#For showing as menu\n",
    "nsw_courts =[\"Court of Appeal\", \n",
    "             \"Court of Criminal Appeal\", \n",
    "             \"Supreme Court\", \n",
    "             'Land and Environment Court (Judges)', \n",
    "             'Land and Environment Court (Commissioners)', \n",
    "             'District Court', \n",
    "             'Local Court',\n",
    "             \"Children's Court\", \n",
    "             'Compensation Court', \n",
    "             'Drug Court', \n",
    "             'Industrial Court',\n",
    "             'Industrial Relations Commission (Judges)', \n",
    "             'Industrial Relations Commission (Commissioners)'\n",
    "            ] #, \"All of the above Courts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9bc62e-a54e-458c-8c4a-6b26a166ecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default courts\n",
    "nsw_default_courts = [\"Court of Appeal\", \"Court of Criminal Appeal\", \"Supreme Court\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7183b01d-ed57-4d21-836c-0ac3a49bb09e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#List of NSW tribunals\n",
    "\n",
    "nsw_tribunals = ['Administrative Decisions Tribunal (Appeal Panel)',\n",
    " 'Administrative Decisions Tribunal (Divisions)',\n",
    " 'Civil and Administrative Tribunal (Administrative and Equal Opportunity Division)',\n",
    " 'Civil and Administrative Tribunal (Appeal Panel)',\n",
    " 'Civil and Administrative Tribunal (Consumer and Commercial Division)',\n",
    " 'Civil and Administrative Tribunal (Enforcement)',\n",
    " 'Civil and Administrative Tribunal (Guardianship Division)',\n",
    " 'Civil and Administrative Tribunal (Occupational Division)',\n",
    " 'Dust Diseases Tribunal',\n",
    " 'Equal Opportunity Tribunal',\n",
    " 'Fair Trading Tribunal',\n",
    " 'Legal Services Tribunal',\n",
    " 'Medical Tribunal',\n",
    " 'Transport Appeal Boards']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ef07dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to convert the list of chosen courts to a list; 13 = NSWSC, 3 = NSWCA, 4 = NSWCCA\n",
    "#For more, see https://github.com/Sydney-Informatics-Hub/nswcaselaw/blob/main/src/nswcaselaw/constants.py\n",
    "\n",
    "nsw_courts_positioning = [\"Placeholder\", \"Children's Court\",\n",
    " 'Compensation Court',\n",
    " 'Court of Appeal',\n",
    " 'Court of Criminal Appeal',\n",
    " 'District Court',\n",
    " 'Drug Court',\n",
    " 'Industrial Court',\n",
    " 'Industrial Relations Commission (Commissioners)',\n",
    " 'Industrial Relations Commission (Judges)',\n",
    " 'Land and Environment Court (Commissioners)',\n",
    " 'Land and Environment Court (Judges)',\n",
    " 'Local Court',\n",
    " 'Supreme Court']\n",
    "\n",
    "def nsw_court_choice(chosen_list):\n",
    "    \n",
    "    chosen_indice = []\n",
    "\n",
    "    if isinstance(chosen_list, str):\n",
    "        chosen_list = ast.literal_eval(chosen_list)\n",
    "\n",
    "    for i in chosen_list:\n",
    "        chosen_indice.append(nsw_courts_positioning.index(i))       \n",
    "        \n",
    "    return chosen_indice\n",
    "\n",
    "nsw_tribunals_positioning = ['Placeholder',\n",
    " 'Administrative Decisions Tribunal (Appeal Panel)',\n",
    " 'Administrative Decisions Tribunal (Divisions)',\n",
    " 'Civil and Administrative Tribunal (Administrative and Equal Opportunity Division)',\n",
    " 'Civil and Administrative Tribunal (Appeal Panel)',\n",
    " 'Civil and Administrative Tribunal (Consumer and Commercial Division)',\n",
    " 'Civil and Administrative Tribunal (Enforcement)',\n",
    " 'Civil and Administrative Tribunal (Guardianship Division)',\n",
    " 'Civil and Administrative Tribunal (Occupational Division)',\n",
    " 'Dust Diseases Tribunal',\n",
    " 'Equal Opportunity Tribunal',\n",
    " 'Fair Trading Tribunal',\n",
    " 'Legal Services Tribunal',\n",
    " 'Medical Tribunal',\n",
    " 'Transport Appeal Boards']\n",
    "\n",
    "def nsw_tribunal_choice(chosen_list):\n",
    "    \n",
    "    chosen_indice = []\n",
    "\n",
    "    if isinstance(chosen_list, str):\n",
    "        chosen_list = ast.literal_eval(chosen_list)\n",
    "\n",
    "    for i in chosen_list:\n",
    "        chosen_indice.append(nsw_tribunals_positioning.index(i))            \n",
    "\n",
    "    return chosen_indice\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998ebb8-a339-4d7d-9dc5-eec41e568bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for tidying up\n",
    "\n",
    "#Tidy up dates\n",
    "def nsw_date(x):\n",
    "    if len(str(x)) > 0:\n",
    "        return str(x).split()[0]\n",
    "    else:\n",
    "        return str(x)\n",
    "\n",
    "# Headnotes fields\n",
    "headnotes_fields = [\"Free text\", \"Case name\", \"Before\", \"Decision date(s)\", \"Catchwords\", \"Hearing date(s)\", \"Date(s) of order\",  \"Jurisdiction\", \"Decision\", \"Legislation cited\", \"Cases cited\", \"Texts cited\", \"Category\", \"Parties\", \"Medium neutral citation\", \"Decision date from\", \"Decision date to\", \"File number\", \"Representation\", \"Decision under appeal\"]\n",
    "headnotes_keys = [\"body\", \"title\", \"before\", \"decisionDate\", \"catchwords\", \"hearingDates\", \"dateOfOrders\", \"jurisdiction\", \"decision\", \"legislationCited\", \"casesCited\", \"textsCited\", \"category\", \"parties\", \"mnc\", \"startDate\", \"endDate\", \"fileNumber\", \"representation\", \"decisionUnderAppeal\"]\n",
    "\n",
    "#Functions for tidying up headings of columns\n",
    "\n",
    "#Tidy up hyperlink\n",
    "def nsw_link(x):\n",
    "    link='https://www.caselaw.nsw.gov.au'+ str(x)\n",
    "    value = '=HYPERLINK(\"' + link + '\")'\n",
    "    return value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016f0732-2f73-4eb6-8986-f30c7b6cfd60",
   "metadata": {},
   "source": [
    "### Search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12bc2af9-d2ed-4d64-95a0-7e0a84dda2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 07:58:46.969 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n"
     ]
    }
   ],
   "source": [
    "#Define function for short judgments, which checks if judgment is in PDF\n",
    "#returns a list of judgment type and judgment text\n",
    "\n",
    "#@st.cache_data(show_spinner = False, ttl=600)\n",
    "def nsw_short_judgment(uri):\n",
    "    \n",
    "    html_link = 'https://www.caselaw.nsw.gov.au'+ uri\n",
    "    \n",
    "    page_html = requests.get(html_link, headers = {'User-Agent': 'whatever'})\n",
    "    \n",
    "    soup_html = BeautifulSoup(page_html.content, \"lxml\")\n",
    "\n",
    "    judgment_type = ''\n",
    "\n",
    "    #Check if judgment contains PDF link\n",
    "    PDF_raw_link = soup_html.find('a', string='See Attachment (PDF)')\n",
    "    \n",
    "    if str(PDF_raw_link).lower() != 'none':\n",
    "        PDF_link = 'https://www.caselaw.nsw.gov.au' + PDF_raw_link.get('href')    \n",
    "        judgment_text = pdf_image_judgment(url_or_path = PDF_link, url_given = True)\n",
    "        judgment_type = 'pdf'\n",
    "        \n",
    "    #Return html text if no PDF\n",
    "    else:\n",
    "        judgment_text = soup_html.get_text(separator=\"\\n\", strip=True)\n",
    "        judgment_type = 'html'\n",
    "\n",
    "    return [judgment_type, judgment_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558af22-ab8e-4b8c-a49c-6a06294f7ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nsw_search_tool:\n",
    "\n",
    "    def __init__(self,\n",
    "                courts = [],\n",
    "                tribunals = [],\n",
    "                body = '',\n",
    "                title = '',\n",
    "                before = '',\n",
    "                catchwords = '',\n",
    "                party = '',\n",
    "                mnc = '',\n",
    "                startDate = '',\n",
    "                endDate = '',\n",
    "                fileNumber = '',\n",
    "                legislationCited = '',\n",
    "                casesCited = '',\n",
    "                pause = int(0),\n",
    "                 judgment_counter_bound = default_judgment_counter_bound\n",
    "                ):\n",
    "\n",
    "        #Initialise parameters\n",
    "        self.courts = courts\n",
    "        self.tribunals = tribunals\n",
    "        self.body = body\n",
    "        self.title = title\n",
    "        self.before = before\n",
    "        self.catchwords = catchwords\n",
    "        self.party = party\n",
    "        self.mnc = mnc\n",
    "        self.startDate = startDate\n",
    "        self.endDate = endDate\n",
    "        self.fileNumber = fileNumber\n",
    "        self.legislationCited = legislationCited\n",
    "        self.casesCited = casesCited\n",
    "        self.pause = pause\n",
    "\n",
    "        #Initialise scraper object\n",
    "        self.query = None\n",
    "\n",
    "        #Initialise other objects to update\n",
    "        self.judgment_counter_bound = judgment_counter_bound\n",
    "        \n",
    "        #self.page = 1\n",
    "                \n",
    "        self.results_count = 0\n",
    "\n",
    "        #self.total_pages = 1\n",
    "        \n",
    "        self.results_url = ''\n",
    "\n",
    "        #self.results_url_to_show = ''\n",
    "        \n",
    "        self.soup = None\n",
    "        \n",
    "        self.case_infos = []\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "        \n",
    "        #For getting judgment directly from NSW Caselaw database if can't get from OALC\n",
    "        self.case_infos_direct = []\n",
    "\n",
    "    def search(self):\n",
    "\n",
    "        #Reset infos of cases found\n",
    "        self.case_infos = []\n",
    "\n",
    "        #Conduct search\n",
    "        self.query = Search(courts = nsw_court_choice(self.courts),\n",
    "                tribunals = nsw_tribunal_choice(self.tribunals), \n",
    "                body = self.body, \n",
    "                title = self.title, \n",
    "                before = self.before, \n",
    "                catchwords = self.catchwords, \n",
    "                party = self.party, \n",
    "                mnc = self.mnc, \n",
    "                startDate = nsw_date(self.startDate), \n",
    "                endDate = nsw_date(self.endDate),\n",
    "                fileNumber = self.fileNumber, \n",
    "                legislationCited  = self.legislationCited, \n",
    "                casesCited = self.casesCited,\n",
    "                pause = self.pause\n",
    "                )\n",
    "\n",
    "        #Get url to NSW Caselaw search page\n",
    "        self.results_url = self.query.url\n",
    "\n",
    "        #Check for positive result\n",
    "        positive_result = False\n",
    "        \n",
    "        for decision in self.query.results():\n",
    "\n",
    "            positive_result = True\n",
    "            \n",
    "            break\n",
    "        \n",
    "        #If positive result\n",
    "        if positive_result:\n",
    "            \n",
    "            pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))\n",
    "\n",
    "            #Get number of results\n",
    "            page_html = requests.get(self.query.url)\n",
    "            self.soup = BeautifulSoup(page_html.content, \"lxml\")\n",
    "            results_count_raw = self.soup.find('div', {'id': 'paginationcontainer'})\n",
    "            results_count_text = results_count_raw.get_text(strip = True)\n",
    "            results_count_text = results_count_text.replace(',', '').replace('.', '')\n",
    "            self.results_count = int(float(results_count_text.split(' ')[-2]))\n",
    "\n",
    "            pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))            \n",
    "            \n",
    "            #Get case infos\n",
    "            for decision in self.query.results():\n",
    "                \n",
    "                if len(self.case_infos) < min(self.judgment_counter_bound, self.results_count):\n",
    "        \n",
    "                    decision_w_meta = copy.deepcopy(decision.values)\n",
    "        \n",
    "                    self.case_infos.append(decision_w_meta)\n",
    "                            \n",
    "                else:\n",
    "                    \n",
    "                    break\n",
    "\n",
    "    #Function for getting all requested judgments\n",
    "    def get_judgments(self):\n",
    "\n",
    "        self.case_infos_w_judgments = []\n",
    "\n",
    "        #Search if not done yet\n",
    "        if len(self.case_infos) == 0:\n",
    "\n",
    "            self.search()\n",
    "    \n",
    "        #Create a list of mncs\n",
    "        mnc_list = []\n",
    "    \n",
    "        for case_info in self.case_infos:\n",
    "\n",
    "            if len(self.case_infos_w_judgments) < self.judgment_counter_bound:\n",
    "                \n",
    "                mnc = split_title_mnc(case_info['title'])[1]\n",
    "                \n",
    "                #Add mnc to list for HuggingFace\n",
    "                mnc_list.append(mnc)\n",
    "    \n",
    "        if huggingface == False: #If not running on HuggingFace\n",
    "    \n",
    "            mnc_judgment_dict = {}\n",
    "        \n",
    "        else: #If running on HuggingFace    \n",
    "        \n",
    "            #Get judgments from oalc first\n",
    "            mnc_judgment_dict = get_judgment_from_oalc(mnc_list)\n",
    "    \n",
    "        #Append judgment to self.case_infos_w_judgments \n",
    "        \n",
    "        for case_info in self.case_infos:\n",
    "            \n",
    "            mnc = split_title_mnc(case_info['title'])[1]\n",
    "            \n",
    "            if mnc in mnc_judgment_dict.keys():\n",
    "                \n",
    "                case_info.update({'judgment': mnc_judgment_dict[mnc]})\n",
    "                \n",
    "                print(f\"{case_info['title']} got judgment from OALC.\")\n",
    "\n",
    "                #Add case_info to self.case_infos_w_judgments\n",
    "                self.case_infos_w_judgments.append(case_info)\n",
    "\n",
    "            else: #Get case from Caselaw NSW if can't get from oalc\n",
    "                \n",
    "                for case in self.query.results():\n",
    "    \n",
    "                    case_meta = copy.deepcopy(case.values)\n",
    "                    \n",
    "                    if mnc == split_title_mnc(case_meta['title'])[1]:\n",
    "                        \n",
    "                        try:\n",
    "\n",
    "                            case_info.update({'judgment': ''})\n",
    "                            \n",
    "                            case.fetch()\n",
    "                                                        \n",
    "                            for key in case.values.keys():\n",
    "    \n",
    "                                if key not in case_info.keys():\n",
    "    \n",
    "                                    case_info.update({key: case.values[key]})\n",
    "                                \n",
    "                            case_info.update({'judgment': str(case.values)})\n",
    "    \n",
    "                            print(f\"{case_info['title']} got judgment from NSW Caselaw directly.\")\n",
    "                            \n",
    "                        except:\n",
    "                            \n",
    "                            case_info.update({'judgment': ''})\n",
    "                            \n",
    "                            print(f'{case_info[\"title\"]}: judgment text scraping error.')\n",
    "\n",
    "                        #Add case_info to self.case_infos_w_judgments\n",
    "                        self.case_infos_w_judgments.append(case_info)\n",
    "                        \n",
    "                        #Pause only if need to get judgment from Caselaw NSW\n",
    "                        pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))\n",
    "                \n",
    "            print(f\"Scraped {len(self.case_infos_w_judgments)}/{min(self.judgment_counter_bound, self.results_count)} judgments.\")\n",
    "    \n",
    "        #Check length of judgment text, replace with text scraped from raw html if smaller than lower boound\n",
    "        judgment_dicts_to_remove = []\n",
    "        judgment_dicts_to_append = []\n",
    "        for judgment_dict in self.case_infos_w_judgments:\n",
    "    \n",
    "            #Checking if judgment text is too short                \n",
    "            judgment_raw_text = str(judgment_dict[\"judgment\"])\n",
    "                    \n",
    "            if num_tokens_from_string(judgment_raw_text, \"cl100k_base\") < judgment_text_lower_bound:\n",
    "\n",
    "                judgment_dicts_to_remove.append(judgment_dict)\n",
    "\n",
    "                judgment_dict_updated = copy.deepcopy(judgment_dict)\n",
    "                \n",
    "                try:\n",
    "\n",
    "                    pause.seconds(np.random.randint(scraper_pause_mean - 5, scraper_pause_mean + 5))\n",
    "                    \n",
    "                    judgment_type_text = nsw_short_judgment(judgment_dict[\"uri\"])\n",
    "        \n",
    "                    #attach judgment text, judgment_type_text[0] has judgment type, eg 'pdf', while judgment_type_text[1] the text\n",
    "                    judgment_dict_updated[\"judgment\"] = judgment_type_text[1]\n",
    "    \n",
    "                    print(f'{judgment_dict[\"title\"]}: given judgment tokens < {judgment_text_lower_bound}, scraped whole judgment from raw html.')                        \n",
    "                    \n",
    "                except Exception as e:\n",
    "                    \n",
    "                    judgment_dict_updated[\"judgment\"] = ''\n",
    "                    print(f'{judgment_dict[\"title\"]}: while judgment tokens < {judgment_text_lower_bound}, cannot scrape whole judgment from raw html due to error: {e}')\n",
    "\n",
    "                judgment_dicts_to_append.append(judgment_dict_updated)\n",
    "\n",
    "            for judgment_dict in judgment_dicts_to_remove:\n",
    "\n",
    "                if judgment_dict in self.case_infos_w_judgments:\n",
    "\n",
    "                    #print(f'Removing judgment_dict[\"title\"] == {judgment_dict[\"title\"]} of length {len(str(judgment_dict))}')\n",
    "\n",
    "                    self.case_infos_w_judgments.remove(judgment_dict)\n",
    "\n",
    "            for judgment_dict_updated in judgment_dicts_to_append:\n",
    "\n",
    "                if judgment_dict_updated not in self.case_infos_w_judgments:\n",
    "\n",
    "                    #print(f'Appending judgment_dict_updated[\"title\"] == {judgment_dict_updated[\"title\"]} of length {len(str(judgment_dict_updated))}')\n",
    "                    \n",
    "                    self.case_infos_w_judgments.append(judgment_dict_updated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3a424b-b3fd-4a26-94c0-4020fbf24a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@st.cache_data(show_spinner = False)\n",
    "def nsw_search_preview(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "\n",
    "    #Conduct search\n",
    "    nsw_search = nsw_search_tool(courts = df_master.loc[0, 'Courts'], \n",
    "                   tribunals = df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, 'Free text'], \n",
    "                   title = df_master.loc[0, 'Case name'], \n",
    "                   before = df_master.loc[0, 'Before'], \n",
    "                   catchwords = df_master.loc[0, 'Catchwords'], \n",
    "                   party = df_master.loc[0, 'Party names'],\n",
    "                   mnc = df_master.loc[0, 'Medium neutral citation'], \n",
    "                   startDate = df_master.loc[0, 'Decision date from'], \n",
    "                   endDate = df_master.loc[0, 'Decision date to'],\n",
    "                   fileNumber = df_master.loc[0, 'File number'], \n",
    "                   legislationCited = df_master.loc[0, 'Legislation cited'], \n",
    "                   casesCited = df_master.loc[0, 'Cases cited'],\n",
    "                #pause = 0,\n",
    "                 judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                  )\n",
    "\n",
    "    nsw_search.search()\n",
    "    \n",
    "    results_count = nsw_search.results_count\n",
    "    \n",
    "    case_infos = nsw_search.case_infos\n",
    "\n",
    "    results_url = nsw_search.results_url\n",
    "\n",
    "    #st.write(results_url)\n",
    "    \n",
    "    return {'results_url': results_url, 'results_count': results_count, 'case_infos': case_infos}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e984b836",
   "metadata": {},
   "source": [
    "# GPT functions and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "264f776f-9383-4727-bc0f-fdee31463433",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gpt_functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Import functions\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m split_by_line, GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, num_tokens_from_string, judgment_prompt_json, GPT_json_tokens, engage_GPT_json_tokens  \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#Import variables\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgpt_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m question_characters_bound, default_judgment_counter_bound, role_content\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gpt_functions'"
     ]
    }
   ],
   "source": [
    "#Import functions\n",
    "from functions.gpt_functions import GPT_label_dict, is_api_key_valid, gpt_input_cost, gpt_output_cost, tokens_cap, max_output, num_tokens_from_string, judgment_prompt_json, GPT_json, engage_GPT_json\n",
    "#Import variables\n",
    "from functions.gpt_functions import basic_model#, flagship_model#, role_content\n",
    "#For batch mode\n",
    "from functions.gpt_functions import gpt_get_custom_id, gpt_batch_input_id_line, gpt_batch_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb6dde1-e2da-480b-80d9-f839f8e1778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For checking questions and answers\n",
    "from functions.common_functions import check_questions_answers\n",
    "\n",
    "from functions.gpt_functions import questions_check_system_instruction, GPT_questions_check, checked_questions_json, answers_check_system_instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fa8b81-719b-4672-a141-7d9331cde96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Jurisdiction specific instruction\n",
    "#system_instruction = role_content\n",
    "\n",
    "#intro_for_GPT = [{\"role\": \"system\", \"content\": system_instruction}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b046b-d0f2-47ac-b02b-bc2032811b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tidy up after GPT output is produced\n",
    "\n",
    "def nsw_tidying_up(df_master, df_individual):\n",
    "\n",
    "    #Rename column titles\n",
    "    try:\n",
    "        df_individual['Hyperlink to NSW Caselaw'] = df_individual['uri'].apply(nsw_link)\n",
    "        df_individual.pop('uri')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #Replace abbreviated column names with full names\n",
    "    for col_name in headnotes_keys:\n",
    "        if col_name in df_individual.columns:\n",
    "            col_index = headnotes_keys.index(col_name)\n",
    "            new_col_name = headnotes_fields[col_index]\n",
    "            df_individual.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "            #df_individual[new_col_name] = df_individual[col_name]\n",
    "            #df_individual.pop(col_name)\n",
    "\n",
    "    #Reorganise columns\n",
    "    df_individual = df_individual.loc[:,~df_individual.columns.duplicated()].copy()\n",
    "\n",
    "    old_columns = df_individual.columns.to_list()\n",
    "    \n",
    "    for i in ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw']:\n",
    "        if i in old_columns:\n",
    "            old_columns.remove(i)\n",
    "    \n",
    "    new_columns = ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw'] + old_columns\n",
    "    \n",
    "    df_individual = df_individual.reindex(columns=new_columns)\n",
    "\n",
    "    #Drop metadata if not wanted \n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in nsw_meta_labels_droppable:\n",
    "            if meta_label in df_individual.columns:\n",
    "                df_individual.pop(meta_label)\n",
    "\n",
    "    #Remove judgment column\n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    if (pop_judgment() > 0) and ('judgment' in df_individual.columns):\n",
    "        df_individual.pop(\"judgment\")\n",
    "        \n",
    "    #Check case name, medium neutral citation \n",
    "\n",
    "    for k in df_individual.index:\n",
    "        \n",
    "        most_informative_key = ''\n",
    "\n",
    "        if len(str(df_individual.loc[k, \"Case name\"])) > len(str(df_individual.loc[k, \"Medium neutral citation\"])):\n",
    "            most_informative_key = \"Case name\"\n",
    "        else:\n",
    "            most_informative_key = \"Medium neutral citation\"\n",
    "        \n",
    "        case_name_mnc = split_title_mnc(df_individual.loc[k, most_informative_key])\n",
    "        case_name = case_name_mnc[0]\n",
    "        mnc = case_name_mnc[1]\n",
    "        \n",
    "        df_individual.loc[k, \"Case name\"] = case_name\n",
    "        df_individual.loc[k, \"Medium neutral citation\"] = mnc\n",
    "\n",
    "    return df_individual\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c798e6-3059-4a0a-93cf-df0c2e32506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to tidy up before GPT output is produced\n",
    "\n",
    "def nsw_tidying_up_pre_gpt(df_master, df_individual):\n",
    "\n",
    "    #Rename column titles\n",
    "    try:\n",
    "        df_individual['Hyperlink to NSW Caselaw'] = df_individual['uri'].apply(nsw_link)\n",
    "        df_individual.pop('uri')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #Replace abbreviated column names with full names\n",
    "    for col_name in headnotes_keys:\n",
    "        if col_name in df_individual.columns:\n",
    "            col_index = headnotes_keys.index(col_name)\n",
    "            new_col_name = headnotes_fields[col_index]\n",
    "            df_individual.rename(columns={col_name: new_col_name}, inplace=True)\n",
    "\n",
    "    #Reorganise columns\n",
    "    old_columns = list(df_individual.columns)\n",
    "    \n",
    "    for i in ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw']:\n",
    "        if i in old_columns:\n",
    "            old_columns.remove(i)\n",
    "    \n",
    "    new_columns = ['Case name', 'Medium neutral citation', 'Hyperlink to NSW Caselaw'] + old_columns\n",
    "    \n",
    "    df_individual = df_individual.reindex(columns=new_columns)\n",
    "\n",
    "    #Drop metadata if not wanted\n",
    "    if int(float(df_master.loc[0, 'Metadata inclusion'])) == 0:\n",
    "        for meta_label in nsw_meta_labels_droppable:\n",
    "            if meta_label in df_individual.columns:\n",
    "                df_individual.pop(meta_label)\n",
    "        \n",
    "    #Check case name, medium neutral citation \n",
    "    for k in df_individual.index:\n",
    "\n",
    "        most_informative_key = ''\n",
    "\n",
    "        if len(str(df_individual.loc[k, \"Case name\"])) > len(str(df_individual.loc[k, \"Medium neutral citation\"])):\n",
    "            most_informative_key = \"Case name\"\n",
    "        else:\n",
    "            most_informative_key = \"Medium neutral citation\"\n",
    "        \n",
    "        case_name_mnc = split_title_mnc(df_individual.loc[k, most_informative_key])\n",
    "        case_name = case_name_mnc[0]\n",
    "        mnc = case_name_mnc[1]\n",
    "        \n",
    "        df_individual.loc[k, \"Case name\"] = case_name\n",
    "        df_individual.loc[k, \"Medium neutral citation\"] = mnc\n",
    "\n",
    "    return df_individual\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709d9235-8db3-4b78-b08f-91e3bc18ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download from Caselaw NSW if can't find judgment in OALC\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def nsw_run(df_master):\n",
    "    \n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Conduct search\n",
    "    nsw_search = nsw_search_tool(courts = df_master.loc[0, 'Courts'], \n",
    "                   tribunals = df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, 'Free text'], \n",
    "                   title = df_master.loc[0, 'Case name'], \n",
    "                   before = df_master.loc[0, 'Before'], \n",
    "                   catchwords = df_master.loc[0, 'Catchwords'], \n",
    "                   party = df_master.loc[0, 'Party names'],\n",
    "                   mnc = df_master.loc[0, 'Medium neutral citation'], \n",
    "                   startDate = df_master.loc[0, 'Decision date from'], \n",
    "                   endDate = df_master.loc[0, 'Decision date to'],\n",
    "                   fileNumber = df_master.loc[0, 'File number'], \n",
    "                   legislationCited = df_master.loc[0, 'Legislation cited'], \n",
    "                   casesCited = df_master.loc[0, 'Cases cited'],\n",
    "                #pause = 0,\n",
    "                 judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                  )\n",
    "\n",
    "    nsw_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in nsw_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "\n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    #if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        #gpt_model = flagship_model\n",
    "    #else:        \n",
    "        #gpt_model = basic_model\n",
    "\n",
    "    gpt_model = df_master.loc[0, 'gpt_model']\n",
    "\n",
    "    temperature = df_master.loc[0, 'temperature']\n",
    "\n",
    "    reasoning_effort = df_master.loc[0, 'reasoning_effort']\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Engage GPT    \n",
    "    df_updated = engage_GPT_json(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, temperature = temperature, reasoning_effort = reasoning_effort, system_instruction = system_instruction)\n",
    "\n",
    "    #tidy up\n",
    "    df_updated = nsw_tidying_up(df_master, df_updated)\n",
    "\n",
    "    return df_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afbacc1-8134-4a9d-a3f2-eee6f755a013",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#For batch mode\n",
    "\n",
    "@st.cache_data(show_spinner = False, ttl=600)\n",
    "def nsw_batch(df_master):\n",
    "\n",
    "    df_master = df_master.fillna('')\n",
    "    \n",
    "    #Apply split and format functions for headnotes choice, court choice and GPT questions\n",
    "     \n",
    "    df_master['questions_json'] = df_master['Enter your questions for GPT'].apply(GPT_label_dict)\n",
    "    \n",
    "    #Create judgments file\n",
    "    judgments_file = []\n",
    "\n",
    "    #Conduct search\n",
    "    \n",
    "    nsw_search = nsw_search_tool(courts = df_master.loc[0, 'Courts'], \n",
    "                   tribunals = df_master.loc[0, 'Tribunals'], \n",
    "                   body = df_master.loc[0, 'Free text'], \n",
    "                   title = df_master.loc[0, 'Case name'], \n",
    "                   before = df_master.loc[0, 'Before'], \n",
    "                   catchwords = df_master.loc[0, 'Catchwords'], \n",
    "                   party = df_master.loc[0, 'Party names'],\n",
    "                   mnc = df_master.loc[0, 'Medium neutral citation'], \n",
    "                   startDate = df_master.loc[0, 'Decision date from'], \n",
    "                   endDate = df_master.loc[0, 'Decision date to'],\n",
    "                   fileNumber = df_master.loc[0, 'File number'], \n",
    "                   legislationCited = df_master.loc[0, 'Legislation cited'], \n",
    "                   casesCited = df_master.loc[0, 'Cases cited'],\n",
    "                #pause = 0,\n",
    "                 judgment_counter_bound = int(df_master.loc[0, 'Maximum number of judgments'])\n",
    "                  )\n",
    "\n",
    "    nsw_search.get_judgments()\n",
    "    \n",
    "    for judgment_json in nsw_search.case_infos_w_judgments:\n",
    "\n",
    "        judgments_file.append(judgment_json)\n",
    "    \n",
    "    #Create and export json file with search results\n",
    "    json_individual = json.dumps(judgments_file, indent=2)\n",
    "    \n",
    "    df_individual = pd.read_json(json_individual)\n",
    "    \n",
    "    #Instruct GPT\n",
    "    \n",
    "    #GPT model\n",
    "\n",
    "    #if df_master.loc[0, 'Use flagship version of GPT'] == True:\n",
    "        #gpt_model = flagship_model\n",
    "    #else:        \n",
    "        #gpt_model = basic_model\n",
    "\n",
    "    gpt_model = df_master.loc[0, 'gpt_model']\n",
    "\n",
    "    temperature = df_master.loc[0, 'temperature']\n",
    "\n",
    "    reasoning_effort = df_master.loc[0, 'reasoning_effort']\n",
    "    \n",
    "    #apply GPT_individual to each respondent's judgment spreadsheet\n",
    "    \n",
    "    GPT_activation = int(df_master.loc[0, 'Use GPT'])\n",
    "    \n",
    "    questions_json = df_master.loc[0, 'questions_json']\n",
    "\n",
    "    system_instruction = df_master.loc[0, 'System instruction']\n",
    "    \n",
    "    #Tidu up then send batch input to gpt\n",
    "    df_individual = nsw_tidying_up_pre_gpt(df_master, df_individual)\n",
    "\n",
    "    #Engage GPT\n",
    "    batch_record_df_individual = gpt_batch_input(questions_json = questions_json, df_example = df_master.loc[0, 'Example'], df_individual = df_individual, GPT_activation = GPT_activation, gpt_model = gpt_model, temperature = temperature, reasoning_effort = reasoning_effort, system_instruction = system_instruction)\n",
    "    \n",
    "    return batch_record_df_individual"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
